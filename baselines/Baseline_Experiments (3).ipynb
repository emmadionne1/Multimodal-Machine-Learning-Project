{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "I4DezKyBFgmC",
        "JjLltCM8OmYa",
        "z4j-njyhOld8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0d73325ab804e14bcbf3127a522f9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eb0886e04564b68a534d951100663f6",
              "IPY_MODEL_ed93d9a6ace845c6bb8f5ca420777d38",
              "IPY_MODEL_f799693a715e461a8c6f7054eaeb3490"
            ],
            "layout": "IPY_MODEL_be46c2cbebe84a8f86f0c1a639483bf4"
          }
        },
        "0eb0886e04564b68a534d951100663f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912bf3de54f8402a95c7c808deadec74",
            "placeholder": "​",
            "style": "IPY_MODEL_04fe89967a614e10a6e87404a4b76aab",
            "value": "Loading weights: 100%"
          }
        },
        "ed93d9a6ace845c6bb8f5ca420777d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22ec2e3b3084d40b74f22a71a4a7d71",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d68d224b2b343faae1667a392c62fbf",
            "value": 398
          }
        },
        "f799693a715e461a8c6f7054eaeb3490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7fed93a15240c390679a5f3de3ee62",
            "placeholder": "​",
            "style": "IPY_MODEL_edee28f67a8442cabcb75be4091b21b2",
            "value": " 398/398 [00:00&lt;00:00, 6433.80it/s, Materializing param=visual_projection.weight]"
          }
        },
        "be46c2cbebe84a8f86f0c1a639483bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912bf3de54f8402a95c7c808deadec74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04fe89967a614e10a6e87404a4b76aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e22ec2e3b3084d40b74f22a71a4a7d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d68d224b2b343faae1667a392c62fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e7fed93a15240c390679a5f3de3ee62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edee28f67a8442cabcb75be4091b21b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cb919c00caa470a8b1038a5128eba4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82193e8d7fa141558b5476d74ebc4445",
              "IPY_MODEL_280e230519cd4604be0ea4c37d703c7e",
              "IPY_MODEL_646bf18c09e94602a1ba5f978b31002e"
            ],
            "layout": "IPY_MODEL_80b005b21d864324ad3cc4a17b8ec4a2"
          }
        },
        "82193e8d7fa141558b5476d74ebc4445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0a42d4cbf14bb5a348120ee33a1a09",
            "placeholder": "​",
            "style": "IPY_MODEL_fa8a5f8d70ff4482a0a0c2b53c8f84d0",
            "value": "Loading weights: 100%"
          }
        },
        "280e230519cd4604be0ea4c37d703c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33f9a713a4f64f28ac88bc0f0b963f65",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c4bfe279a54302abfad72e8bb6884b",
            "value": 398
          }
        },
        "646bf18c09e94602a1ba5f978b31002e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e8effdcf4234fafb95e2f073cc497d3",
            "placeholder": "​",
            "style": "IPY_MODEL_c914f625900f4ab0b8a98de537cdedda",
            "value": " 398/398 [00:00&lt;00:00, 4754.89it/s, Materializing param=model.norm.weight]"
          }
        },
        "80b005b21d864324ad3cc4a17b8ec4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0a42d4cbf14bb5a348120ee33a1a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8a5f8d70ff4482a0a0c2b53c8f84d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33f9a713a4f64f28ac88bc0f0b963f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c4bfe279a54302abfad72e8bb6884b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e8effdcf4234fafb95e2f073cc497d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c914f625900f4ab0b8a98de537cdedda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32859958a3004c5894bb2c80bb6f7d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36c65c75b244466ea32928161e3fe14a",
              "IPY_MODEL_0a7615c912ec482f97a1629bc3cb2c80",
              "IPY_MODEL_699ca7ff6df944b19d4b9ed585004b35"
            ],
            "layout": "IPY_MODEL_cdc2227637214876b21bddd471db714c"
          }
        },
        "36c65c75b244466ea32928161e3fe14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_832a6e5fd9a74067bde13b090bf835f9",
            "placeholder": "​",
            "style": "IPY_MODEL_8b17839e469d4bcc8631280b2d6e2aea",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "0a7615c912ec482f97a1629bc3cb2c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28acc3f8bbdd4bad81022f859e20573b",
            "max": 362,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_991afa497754417ea503f202f420f0a8",
            "value": 362
          }
        },
        "699ca7ff6df944b19d4b9ed585004b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_634ad556d1df407ead5a2890b61cfa01",
            "placeholder": "​",
            "style": "IPY_MODEL_68b38b11276e462484204f7b2c896801",
            "value": " 362/362 [00:00&lt;00:00, 46.8kB/s]"
          }
        },
        "cdc2227637214876b21bddd471db714c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832a6e5fd9a74067bde13b090bf835f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b17839e469d4bcc8631280b2d6e2aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28acc3f8bbdd4bad81022f859e20573b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991afa497754417ea503f202f420f0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "634ad556d1df407ead5a2890b61cfa01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b38b11276e462484204f7b2c896801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a31513e734c64deba6d9f77835233d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_827f8af0e0ae41dc91378e710abe314b",
              "IPY_MODEL_e6b1640b59d841e49af6cd0feb1c0a32",
              "IPY_MODEL_65e1437f673a478fb46584acdb9544a7"
            ],
            "layout": "IPY_MODEL_3a19b0e044b9496aaa8905ea4128c684"
          }
        },
        "827f8af0e0ae41dc91378e710abe314b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21fff9663cc44a20bbdbdde7769ec1c7",
            "placeholder": "​",
            "style": "IPY_MODEL_683c21f0dd50436d83e1a09e95f7c2b3",
            "value": "config.json: "
          }
        },
        "e6b1640b59d841e49af6cd0feb1c0a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2757ae298f35407881634de9e0515a80",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a2e835be56249288c9ba8f062602086",
            "value": 1
          }
        },
        "65e1437f673a478fb46584acdb9544a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_328346a37d134f92acc09025ddd92215",
            "placeholder": "​",
            "style": "IPY_MODEL_8e58d851477243039f2c3f409b16c130",
            "value": " 4.74k/? [00:00&lt;00:00, 381kB/s]"
          }
        },
        "3a19b0e044b9496aaa8905ea4128c684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21fff9663cc44a20bbdbdde7769ec1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "683c21f0dd50436d83e1a09e95f7c2b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2757ae298f35407881634de9e0515a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6a2e835be56249288c9ba8f062602086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "328346a37d134f92acc09025ddd92215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e58d851477243039f2c3f409b16c130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "444eebfb3b4744ebaecd4200b3732721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dee666055e014a8da4d2c3d236dedf95",
              "IPY_MODEL_b47ed6d95fa1476f914c5304aa09f17e",
              "IPY_MODEL_0a37b3cc38fe454ca1cf0f36d1a76c60"
            ],
            "layout": "IPY_MODEL_74f617f6656b4b40b5fa8cc57ce3394b"
          }
        },
        "dee666055e014a8da4d2c3d236dedf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e37b5f044df646ff86c23ba8c2b0b196",
            "placeholder": "​",
            "style": "IPY_MODEL_105b083c62ac4f5e8d36ac610b06b784",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b47ed6d95fa1476f914c5304aa09f17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_572bbc09c8e547d093136a78c0326190",
            "max": 536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de37d9305d1d45258498c7e9fcee935c",
            "value": 536
          }
        },
        "0a37b3cc38fe454ca1cf0f36d1a76c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc37b6135a4249c791869f3369632487",
            "placeholder": "​",
            "style": "IPY_MODEL_307f177451924e23a23641d5ca2eba64",
            "value": " 536/536 [00:00&lt;00:00, 73.4kB/s]"
          }
        },
        "74f617f6656b4b40b5fa8cc57ce3394b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37b5f044df646ff86c23ba8c2b0b196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "105b083c62ac4f5e8d36ac610b06b784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "572bbc09c8e547d093136a78c0326190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de37d9305d1d45258498c7e9fcee935c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc37b6135a4249c791869f3369632487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "307f177451924e23a23641d5ca2eba64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6b1eea6fa3d44dda1358e5d4646297b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54c544f1ef054a799ece0b4b3bb8391a",
              "IPY_MODEL_9b94883d52f34f18ae2b62f0f474b057",
              "IPY_MODEL_a5c50fccec4149f48d00c7050c86d2a1"
            ],
            "layout": "IPY_MODEL_d3f53567af8548bb8f7fa196f4d8e324"
          }
        },
        "54c544f1ef054a799ece0b4b3bb8391a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f447bd9ca50f4e0183fd0738a7bcfb2f",
            "placeholder": "​",
            "style": "IPY_MODEL_db0af7fb05a04af79d39b5fa64baf3e0",
            "value": "tokenizer.json: "
          }
        },
        "9b94883d52f34f18ae2b62f0f474b057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3fa32d730d4534adcc7c96e3a4e28b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6ef009c77ab415a8ccbaa013fcc3ef1",
            "value": 1
          }
        },
        "a5c50fccec4149f48d00c7050c86d2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20a638443fb24445953779bfdf8f3a83",
            "placeholder": "​",
            "style": "IPY_MODEL_505e36d87e6b4775b5145e290ba13ff1",
            "value": " 4.02M/? [00:00&lt;00:00, 23.5MB/s]"
          }
        },
        "d3f53567af8548bb8f7fa196f4d8e324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f447bd9ca50f4e0183fd0738a7bcfb2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db0af7fb05a04af79d39b5fa64baf3e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff3fa32d730d4534adcc7c96e3a4e28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b6ef009c77ab415a8ccbaa013fcc3ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20a638443fb24445953779bfdf8f3a83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505e36d87e6b4775b5145e290ba13ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f058302059404bdd9ec75e063591deaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea57adc5e87a40b5a597f0f961aa7851",
              "IPY_MODEL_7777674e7e8f4b58af1176d20d635fe5",
              "IPY_MODEL_fb423246b9b24e24bd5433994789a8f3"
            ],
            "layout": "IPY_MODEL_dfb89dbbd95b4874b2477ca33070af3b"
          }
        },
        "ea57adc5e87a40b5a597f0f961aa7851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aa3d16eba5e4a3cb64664b7bc13ef98",
            "placeholder": "​",
            "style": "IPY_MODEL_b9525ef8c3a64dd2a54e649a9ad9f87e",
            "value": "added_tokens.json: "
          }
        },
        "7777674e7e8f4b58af1176d20d635fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1fffc71c0494f22ba66e6e2f244b247",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_748a790b8c2846b8a424e490602f4f53",
            "value": 1
          }
        },
        "fb423246b9b24e24bd5433994789a8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56dcf4c93c1d4af190d71f7cebe5894c",
            "placeholder": "​",
            "style": "IPY_MODEL_07c3f4e4d352455b9a92622d46401c70",
            "value": " 1.52k/? [00:00&lt;00:00, 190kB/s]"
          }
        },
        "dfb89dbbd95b4874b2477ca33070af3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa3d16eba5e4a3cb64664b7bc13ef98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9525ef8c3a64dd2a54e649a9ad9f87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1fffc71c0494f22ba66e6e2f244b247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "748a790b8c2846b8a424e490602f4f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56dcf4c93c1d4af190d71f7cebe5894c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c3f4e4d352455b9a92622d46401c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b64898514ba7455e816454f83abd489f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2158a7d5ad1344149e1e996d1c7e3dcf",
              "IPY_MODEL_70ee52e6bfa04318bcee2bf48d1e5082",
              "IPY_MODEL_703084337bc54dfc81f261f8b9cda4b7"
            ],
            "layout": "IPY_MODEL_2cd5c2e725e84a74bae2f006ff471b6f"
          }
        },
        "2158a7d5ad1344149e1e996d1c7e3dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e99dcb21754493a9f1d7043da2a2fa",
            "placeholder": "​",
            "style": "IPY_MODEL_bc1857d901f54b4c8870428f1fcf8a72",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "70ee52e6bfa04318bcee2bf48d1e5082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_123f321390dd41428a1b5bd74ac12ed5",
            "max": 335,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8c8cfbf03134a8aa03faf83d7e76591",
            "value": 335
          }
        },
        "703084337bc54dfc81f261f8b9cda4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf9a531ba5d4c64a44337ad2fe8479e",
            "placeholder": "​",
            "style": "IPY_MODEL_673dda9ca3ff4e389b4ff5151375109b",
            "value": " 335/335 [00:00&lt;00:00, 45.3kB/s]"
          }
        },
        "2cd5c2e725e84a74bae2f006ff471b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30e99dcb21754493a9f1d7043da2a2fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc1857d901f54b4c8870428f1fcf8a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "123f321390dd41428a1b5bd74ac12ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c8cfbf03134a8aa03faf83d7e76591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbf9a531ba5d4c64a44337ad2fe8479e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673dda9ca3ff4e389b4ff5151375109b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48dba45e546040049617cb44ad63f17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d95c3292c610420e91d60d14489d1a09",
              "IPY_MODEL_83c37b78fb224959bcb7e51a1e9b15b3",
              "IPY_MODEL_7330581910bd43109d7f5764f0d0348e"
            ],
            "layout": "IPY_MODEL_f61769ee1fff4e4d9dbd0f83b46471e2"
          }
        },
        "d95c3292c610420e91d60d14489d1a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e21a2dcde54c8b836fb64ea9ffce4a",
            "placeholder": "​",
            "style": "IPY_MODEL_03d0344c6d83442088b4d00801453b4f",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "83c37b78fb224959bcb7e51a1e9b15b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c7f911f8ea40fe8c966dd7354037af",
            "max": 806248251,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0f434f582594fba9b3f21e2e8bcbebb",
            "value": 806248251
          }
        },
        "7330581910bd43109d7f5764f0d0348e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c99ca49939634a67a7808c4c4504ea69",
            "placeholder": "​",
            "style": "IPY_MODEL_2da8793f34e84fc7b9e97f4eca79a442",
            "value": " 806M/806M [00:01&lt;00:00, 805MB/s]"
          }
        },
        "f61769ee1fff4e4d9dbd0f83b46471e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e21a2dcde54c8b836fb64ea9ffce4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d0344c6d83442088b4d00801453b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47c7f911f8ea40fe8c966dd7354037af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f434f582594fba9b3f21e2e8bcbebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c99ca49939634a67a7808c4c4504ea69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da8793f34e84fc7b9e97f4eca79a442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f9a119a16984569ada7550c2ddbc472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_994317696a664740b90b0cb29f407bf0",
              "IPY_MODEL_2a26dfab377543a7a779de34762b1ccc",
              "IPY_MODEL_d69605e34e704a97a990aaa92ddd927d"
            ],
            "layout": "IPY_MODEL_c6a6827eeacd4a0eb4956c3fe2aa35ac"
          }
        },
        "994317696a664740b90b0cb29f407bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab7bf8061af4dfbab122b9f316df53e",
            "placeholder": "​",
            "style": "IPY_MODEL_b863b8b6186246ddb74dca6ede11353e",
            "value": "Loading weights: 100%"
          }
        },
        "2a26dfab377543a7a779de34762b1ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a173181d97ad40dc95f49d3b96319f27",
            "max": 484,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ff563ee363940cb94aef0f9ce81df32",
            "value": 484
          }
        },
        "d69605e34e704a97a990aaa92ddd927d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8394862f284f42fcb79ef1fc7241d027",
            "placeholder": "​",
            "style": "IPY_MODEL_ef2e4f7e285846b2b1e421b1ff3eec21",
            "value": " 484/484 [00:00&lt;00:00, 1544.60it/s, Materializing param=encoder.encoder.layers.3.blocks.1.output.dense.weight]"
          }
        },
        "c6a6827eeacd4a0eb4956c3fe2aa35ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bab7bf8061af4dfbab122b9f316df53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b863b8b6186246ddb74dca6ede11353e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a173181d97ad40dc95f49d3b96319f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff563ee363940cb94aef0f9ce81df32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8394862f284f42fcb79ef1fc7241d027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef2e4f7e285846b2b1e421b1ff3eec21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b311cac5f644edca1b4c4c7466206f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8341926c8c3f4e3c8f24fa244762e67f",
              "IPY_MODEL_9352ea1bfaad4bc5a964eee6393400f7",
              "IPY_MODEL_b9e2b2e774bf42dfaed1fe566246b4e5"
            ],
            "layout": "IPY_MODEL_363aaf0bef2247b4a83f5e5b3a7992c3"
          }
        },
        "8341926c8c3f4e3c8f24fa244762e67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_439d63f02fc241388c389e552f60e4e3",
            "placeholder": "​",
            "style": "IPY_MODEL_dd0d771e5b3a471686d5a04e008001f2",
            "value": "model.safetensors: 100%"
          }
        },
        "9352ea1bfaad4bc5a964eee6393400f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cf8a9f630fc47b0825f03ddbda1dba9",
            "max": 806150296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_276c05d9d1ad4c7699d1f67dcb6988c4",
            "value": 806150296
          }
        },
        "b9e2b2e774bf42dfaed1fe566246b4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810856c18928405f99c256b0b7655b5b",
            "placeholder": "​",
            "style": "IPY_MODEL_917f30882b474535b3b7314b25ae2ac1",
            "value": " 806M/806M [00:02&lt;00:00, 665MB/s]"
          }
        },
        "363aaf0bef2247b4a83f5e5b3a7992c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "439d63f02fc241388c389e552f60e4e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd0d771e5b3a471686d5a04e008001f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cf8a9f630fc47b0825f03ddbda1dba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276c05d9d1ad4c7699d1f67dcb6988c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "810856c18928405f99c256b0b7655b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917f30882b474535b3b7314b25ae2ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8f104d537e1460ab937ab8e31827063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f85291e205e24a0ab853ac18b8de9468",
              "IPY_MODEL_6dbbc008e2a841f19b05cd102a534e3f",
              "IPY_MODEL_c9f393aa263d4a8aacd8c1fda415fec0"
            ],
            "layout": "IPY_MODEL_6fc3ad1557f14f54ad81e9185b6e9c8b"
          }
        },
        "f85291e205e24a0ab853ac18b8de9468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b268483c72941cd91d138eb2d621b95",
            "placeholder": "​",
            "style": "IPY_MODEL_3633b5635f6543689ae7d08e0e2e4c06",
            "value": "config.json: 100%"
          }
        },
        "6dbbc008e2a841f19b05cd102a534e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7acecfb10f374076891d0e9eaa72c7ca",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f1661380e584959be571d66b7cf2269",
            "value": 727
          }
        },
        "c9f393aa263d4a8aacd8c1fda415fec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d43cd14e1aa4afe9beacf705153dd63",
            "placeholder": "​",
            "style": "IPY_MODEL_c97a57e644b8431b93d3496135737fc0",
            "value": " 727/727 [00:00&lt;00:00, 85.4kB/s]"
          }
        },
        "6fc3ad1557f14f54ad81e9185b6e9c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b268483c72941cd91d138eb2d621b95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3633b5635f6543689ae7d08e0e2e4c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7acecfb10f374076891d0e9eaa72c7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f1661380e584959be571d66b7cf2269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d43cd14e1aa4afe9beacf705153dd63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97a57e644b8431b93d3496135737fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f7387b7c3f342e7a80bf9ab5407bf67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99a40716b3084e55a75c68fba56da268",
              "IPY_MODEL_5aac73c6b3254322bd3869504cd41255",
              "IPY_MODEL_2d3dfcf12a194191ae19defec950e40f"
            ],
            "layout": "IPY_MODEL_95d00393195542beac05b227ceab3db0"
          }
        },
        "99a40716b3084e55a75c68fba56da268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a21c8821576469aa44471a162b8e939",
            "placeholder": "​",
            "style": "IPY_MODEL_b71e25e74927486cb7fd6b02d34da57b",
            "value": "tokenizer_config.json: "
          }
        },
        "5aac73c6b3254322bd3869504cd41255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a609f5345b1f4822b9ee7e05fd8463fb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6560ade813d148d2800b617327c1a2dc",
            "value": 1
          }
        },
        "2d3dfcf12a194191ae19defec950e40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54202429005340d4bfd513403b23d8c3",
            "placeholder": "​",
            "style": "IPY_MODEL_c3c228dca8f0483083d6b6f7f57034a9",
            "value": " 9.38k/? [00:00&lt;00:00, 958kB/s]"
          }
        },
        "95d00393195542beac05b227ceab3db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a21c8821576469aa44471a162b8e939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71e25e74927486cb7fd6b02d34da57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a609f5345b1f4822b9ee7e05fd8463fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6560ade813d148d2800b617327c1a2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54202429005340d4bfd513403b23d8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c228dca8f0483083d6b6f7f57034a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2429c50e6f7245089721111362f23d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_022c7071cc274696b57e2a104e314867",
              "IPY_MODEL_b210aa7ccc584fad8840e2e49afdeed2",
              "IPY_MODEL_983185ecf2664d08bedb848d67c2e056"
            ],
            "layout": "IPY_MODEL_e4ca98ba56a342f8a51b6281824c0746"
          }
        },
        "022c7071cc274696b57e2a104e314867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7c90538a38f451c9e08f26ad264cd7f",
            "placeholder": "​",
            "style": "IPY_MODEL_207ef3315a4a45b58326f341f2f23cc9",
            "value": "vocab.json: "
          }
        },
        "b210aa7ccc584fad8840e2e49afdeed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fa0319beaf46e3a7424cbc4bcab427",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32cb363c65ff46e9a8e04963de683bf8",
            "value": 1
          }
        },
        "983185ecf2664d08bedb848d67c2e056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75047788f7774e77b8fc8e532fd1c2fc",
            "placeholder": "​",
            "style": "IPY_MODEL_7ef07535d83d450888c7817ef3ec864f",
            "value": " 2.78M/? [00:00&lt;00:00, 56.5MB/s]"
          }
        },
        "e4ca98ba56a342f8a51b6281824c0746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c90538a38f451c9e08f26ad264cd7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "207ef3315a4a45b58326f341f2f23cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63fa0319beaf46e3a7424cbc4bcab427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "32cb363c65ff46e9a8e04963de683bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75047788f7774e77b8fc8e532fd1c2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef07535d83d450888c7817ef3ec864f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea19486e6aab43cb8ee3f203771ddd7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72e3837370d84f84bf2e53645510d9c3",
              "IPY_MODEL_6cb18bc3f87d49c68c5a0bc41be15755",
              "IPY_MODEL_60e121e013084b66930040f9e7de92b3"
            ],
            "layout": "IPY_MODEL_572815e2b211443da668d417251ba64d"
          }
        },
        "72e3837370d84f84bf2e53645510d9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c51080c0c6dc4e459664063ba047e36e",
            "placeholder": "​",
            "style": "IPY_MODEL_34ca77685746483ea30b238a50da1257",
            "value": "merges.txt: "
          }
        },
        "6cb18bc3f87d49c68c5a0bc41be15755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f4730ffcd564344b18c0c02607e86ee",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_756afc79fd50458d9c0cb06f4592f66f",
            "value": 1
          }
        },
        "60e121e013084b66930040f9e7de92b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ea6ae6a1993436989fd79a718d31d1f",
            "placeholder": "​",
            "style": "IPY_MODEL_6e23c0cb94424a1bafc913e0fc58fff0",
            "value": " 1.67M/? [00:00&lt;00:00, 30.3MB/s]"
          }
        },
        "572815e2b211443da668d417251ba64d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c51080c0c6dc4e459664063ba047e36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ca77685746483ea30b238a50da1257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f4730ffcd564344b18c0c02607e86ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "756afc79fd50458d9c0cb06f4592f66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ea6ae6a1993436989fd79a718d31d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e23c0cb94424a1bafc913e0fc58fff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2964e75c6fc4bf6b7b4333f03c68480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c620766f5def4caf995bb0aefc1a790f",
              "IPY_MODEL_edf35bd9b8234e1b92d9afdf212525f2",
              "IPY_MODEL_d65329f2bf5b4320a898789ce85d7165"
            ],
            "layout": "IPY_MODEL_1ee5c535d2a14831b90a2258affbc4c7"
          }
        },
        "c620766f5def4caf995bb0aefc1a790f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ef8bbbecc64ce0814cdf1cc043a561",
            "placeholder": "​",
            "style": "IPY_MODEL_216553e8ef0e4233b3ee26b4eda90f50",
            "value": "tokenizer.json: 100%"
          }
        },
        "edf35bd9b8234e1b92d9afdf212525f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66710b0b8cda402c9da526620535310b",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b32afced8b98490d9eb9d23b89e1faa3",
            "value": 11422654
          }
        },
        "d65329f2bf5b4320a898789ce85d7165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00ca46506f94432dac28293260d8350c",
            "placeholder": "​",
            "style": "IPY_MODEL_1f4f7878415d4d31abde6dd11ab9037e",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 22.4MB/s]"
          }
        },
        "1ee5c535d2a14831b90a2258affbc4c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ef8bbbecc64ce0814cdf1cc043a561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216553e8ef0e4233b3ee26b4eda90f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66710b0b8cda402c9da526620535310b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32afced8b98490d9eb9d23b89e1faa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00ca46506f94432dac28293260d8350c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4f7878415d4d31abde6dd11ab9037e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f934b0622c1e4312be93fea3a832aeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83a1dbbe9b54417a8fdaa67165292a20",
              "IPY_MODEL_d5fb655c49ba47e9871d6de01d8e8c91",
              "IPY_MODEL_4debb011941f43b9b4c01fa0a058f8d5"
            ],
            "layout": "IPY_MODEL_94a9e3ef80ff4c88962a247899869ac4"
          }
        },
        "83a1dbbe9b54417a8fdaa67165292a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb6f00d5fd44dd5869a77105c15d56c",
            "placeholder": "​",
            "style": "IPY_MODEL_956e0f7db3b84607bf88adf5ef578a9c",
            "value": "model.safetensors.index.json: "
          }
        },
        "d5fb655c49ba47e9871d6de01d8e8c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a2b0c4705c42cdb75a31fca815a0c9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c572b77b736484f9c48ec1f587c6534",
            "value": 1
          }
        },
        "4debb011941f43b9b4c01fa0a058f8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b163db671ef044f9a88783239a59638e",
            "placeholder": "​",
            "style": "IPY_MODEL_aa1c39f9ddb649f89227d11bd7975e88",
            "value": " 32.8k/? [00:00&lt;00:00, 3.91MB/s]"
          }
        },
        "94a9e3ef80ff4c88962a247899869ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb6f00d5fd44dd5869a77105c15d56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956e0f7db3b84607bf88adf5ef578a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3a2b0c4705c42cdb75a31fca815a0c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2c572b77b736484f9c48ec1f587c6534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b163db671ef044f9a88783239a59638e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa1c39f9ddb649f89227d11bd7975e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34eff405c52e41aa8738d97f1fc23e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59507645c63147b9ab2bb2cf29bcfd73",
              "IPY_MODEL_e4ccea16aa9d480285d8a4b84a4e5bb7",
              "IPY_MODEL_fa409ad48e214d05827048ab174ec96a"
            ],
            "layout": "IPY_MODEL_81a5f7f3d4d24b8b97fcef858558bb1c"
          }
        },
        "59507645c63147b9ab2bb2cf29bcfd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f18d0d2b7c0e477ba24fb58d399f9c58",
            "placeholder": "​",
            "style": "IPY_MODEL_7aa19026489542bebaf87af1cbd6b50a",
            "value": "Download complete: 100%"
          }
        },
        "e4ccea16aa9d480285d8a4b84a4e5bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce7b357bc9eb421aa3959e2363b6ffa7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60ea14287ee148809829400a91009121",
            "value": 1
          }
        },
        "fa409ad48e214d05827048ab174ec96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f96ea6f34514df4ab794c12fcaf8b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_0d3d2583941546d8847f967c452649bf",
            "value": " 8.04G/8.04G [00:25&lt;00:00, 323MB/s]"
          }
        },
        "81a5f7f3d4d24b8b97fcef858558bb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f18d0d2b7c0e477ba24fb58d399f9c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aa19026489542bebaf87af1cbd6b50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce7b357bc9eb421aa3959e2363b6ffa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "60ea14287ee148809829400a91009121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f96ea6f34514df4ab794c12fcaf8b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3d2583941546d8847f967c452649bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f4c3542a7874863b2c1c4d1cf3ef4a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d11b700217ca45cdbe3b827ebe3c5c43",
              "IPY_MODEL_bba6eb488b224099a4750f8ddf7e3062",
              "IPY_MODEL_dbf86cdd686743a789ff8a9970beb4ec"
            ],
            "layout": "IPY_MODEL_21bbf19fa41a4ce28e3fd5c8000ab92f"
          }
        },
        "d11b700217ca45cdbe3b827ebe3c5c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a16e75e2a04bc898a4dc9f63b323f9",
            "placeholder": "​",
            "style": "IPY_MODEL_b84fc34e170348439a75a55ffd08f623",
            "value": "Fetching 3 files: 100%"
          }
        },
        "bba6eb488b224099a4750f8ddf7e3062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9851e89bb8b543769ebca54f0eaa8199",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6906da7df314e1bb3acc68f9da3db06",
            "value": 3
          }
        },
        "dbf86cdd686743a789ff8a9970beb4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeab35c343ee4d9981a043544deafa9a",
            "placeholder": "​",
            "style": "IPY_MODEL_26d12b33b8384128808f0b40b629fc9e",
            "value": " 3/3 [00:25&lt;00:00, 11.08s/it]"
          }
        },
        "21bbf19fa41a4ce28e3fd5c8000ab92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a16e75e2a04bc898a4dc9f63b323f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b84fc34e170348439a75a55ffd08f623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9851e89bb8b543769ebca54f0eaa8199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6906da7df314e1bb3acc68f9da3db06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aeab35c343ee4d9981a043544deafa9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d12b33b8384128808f0b40b629fc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "974e44fb701949e08fe7403d7c452494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d91f7fde426404eb09b792bf1d1f33d",
              "IPY_MODEL_ac58bcbe751642d08dc78822570da01f",
              "IPY_MODEL_cba0727859dc4426a5add6abcc78e11d"
            ],
            "layout": "IPY_MODEL_886c25a7c4cc4e71be77ea2e8c19d440"
          }
        },
        "5d91f7fde426404eb09b792bf1d1f33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0e611159f824bc2951cd09d10b357e1",
            "placeholder": "​",
            "style": "IPY_MODEL_c9991559690742c3987529b25e143208",
            "value": "Loading weights: 100%"
          }
        },
        "ac58bcbe751642d08dc78822570da01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8054f423da9495081b9079cf370fe6e",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e295cac1e92481e804fa2fb6fa9b7e5",
            "value": 398
          }
        },
        "cba0727859dc4426a5add6abcc78e11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab662eeb353b4e888455c339e0095270",
            "placeholder": "​",
            "style": "IPY_MODEL_80a341800f07436d926fccc88c1f64d3",
            "value": " 398/398 [00:02&lt;00:00, 164.80it/s, Materializing param=model.norm.weight]"
          }
        },
        "886c25a7c4cc4e71be77ea2e8c19d440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e611159f824bc2951cd09d10b357e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9991559690742c3987529b25e143208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8054f423da9495081b9079cf370fe6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e295cac1e92481e804fa2fb6fa9b7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab662eeb353b4e888455c339e0095270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a341800f07436d926fccc88c1f64d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03f05bc7e1f14c99a07fdb792d290e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_635382d40768456e81737cf0841da7c1",
              "IPY_MODEL_7b903b7224e945cbad1231d334d606f9",
              "IPY_MODEL_68243adf030044999c384bdb35ca96fe"
            ],
            "layout": "IPY_MODEL_989ee272c3ce4b43a37b65a3964a9f02"
          }
        },
        "635382d40768456e81737cf0841da7c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6b31e52a3a949c7b09b1bac75536628",
            "placeholder": "​",
            "style": "IPY_MODEL_330f72c69b994b52aee50cb3e03a38ed",
            "value": "generation_config.json: 100%"
          }
        },
        "7b903b7224e945cbad1231d334d606f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f32049891c845229e55b7c983f3fbeb",
            "max": 238,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_262d00ab925e48d38883efcc08ee18f3",
            "value": 238
          }
        },
        "68243adf030044999c384bdb35ca96fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef1acf66a4504544b91599ed932fcedf",
            "placeholder": "​",
            "style": "IPY_MODEL_4243d6b871364152be56c6acd49bb2d8",
            "value": " 238/238 [00:00&lt;00:00, 31.1kB/s]"
          }
        },
        "989ee272c3ce4b43a37b65a3964a9f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b31e52a3a949c7b09b1bac75536628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330f72c69b994b52aee50cb3e03a38ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f32049891c845229e55b7c983f3fbeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "262d00ab925e48d38883efcc08ee18f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef1acf66a4504544b91599ed932fcedf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4243d6b871364152be56c6acd49bb2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47cefe835b51453aa82878817e1a2e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1eaaad436be848758a2acbd013c8d3f7",
              "IPY_MODEL_ceeb2ca7883a49618e8c311fef55928d",
              "IPY_MODEL_7b556dec590a4e81b96b9f9fbd27ac2f"
            ],
            "layout": "IPY_MODEL_54c9c44ddf054550bdfacd9b2974a591"
          }
        },
        "1eaaad436be848758a2acbd013c8d3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c91efab70c8417393c2c3688afbf0b4",
            "placeholder": "​",
            "style": "IPY_MODEL_29477b94e84a49fea68f8fca0ab6f2af",
            "value": "config.json: "
          }
        },
        "ceeb2ca7883a49618e8c311fef55928d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34cae60601bb4d23b8832776e5e80062",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9affc34b1e1f428bbf8200fa956b9f21",
            "value": 1
          }
        },
        "7b556dec590a4e81b96b9f9fbd27ac2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f5b16315bd47c0838201cc27eed6e1",
            "placeholder": "​",
            "style": "IPY_MODEL_d2158320534849af99ca56b9ad1a0685",
            "value": " 4.19k/? [00:00&lt;00:00, 438kB/s]"
          }
        },
        "54c9c44ddf054550bdfacd9b2974a591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c91efab70c8417393c2c3688afbf0b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29477b94e84a49fea68f8fca0ab6f2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34cae60601bb4d23b8832776e5e80062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9affc34b1e1f428bbf8200fa956b9f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51f5b16315bd47c0838201cc27eed6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2158320534849af99ca56b9ad1a0685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8378a0ee82441c2ba5bb282a717eac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d3110050d994f2fb251372a22d5fb16",
              "IPY_MODEL_4fffef4cc7044fefbf15505d15b167ad",
              "IPY_MODEL_00b6367a685045cc81ac39f550e025d5"
            ],
            "layout": "IPY_MODEL_6469f7de07c345528b6385a72065a0a7"
          }
        },
        "3d3110050d994f2fb251372a22d5fb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e3d5a84b85f4d55a5d210d684a76f67",
            "placeholder": "​",
            "style": "IPY_MODEL_cd67eb9fab5c407f8c1c1bd4bf08cca4",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4fffef4cc7044fefbf15505d15b167ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25d67078a6e041a9bab9573a1061bf77",
            "max": 605247071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7616f5e8611f4b61a650043886bc6f57",
            "value": 605247071
          }
        },
        "00b6367a685045cc81ac39f550e025d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7fd36b24c78407ab2bc0fc4314a5a6f",
            "placeholder": "​",
            "style": "IPY_MODEL_a8f669de74a94c51b641c28378efd79e",
            "value": " 605M/605M [00:02&lt;00:00, 536MB/s]"
          }
        },
        "6469f7de07c345528b6385a72065a0a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e3d5a84b85f4d55a5d210d684a76f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd67eb9fab5c407f8c1c1bd4bf08cca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25d67078a6e041a9bab9573a1061bf77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7616f5e8611f4b61a650043886bc6f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7fd36b24c78407ab2bc0fc4314a5a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f669de74a94c51b641c28378efd79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f7d2e8f2dcd4b0d868ad5a91a4311db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e3021fc128e4cd3949e9146899a89e6",
              "IPY_MODEL_6ec79224dcbd4b1ab9a4d1a8601f5f88",
              "IPY_MODEL_64c873c30cb240318ee8352da5d7a097"
            ],
            "layout": "IPY_MODEL_45758b22aa0b4f739693062bf31f5cff"
          }
        },
        "7e3021fc128e4cd3949e9146899a89e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef250968e3e489ba0642be9a35dcc88",
            "placeholder": "​",
            "style": "IPY_MODEL_0233a41b85de4eeea54763c7f51cc9b8",
            "value": "Loading weights: 100%"
          }
        },
        "6ec79224dcbd4b1ab9a4d1a8601f5f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f2769370b54fc6b53af91b566c279b",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5cd86537ddd4374a462ece8648b3f59",
            "value": 398
          }
        },
        "64c873c30cb240318ee8352da5d7a097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9831ae2a9d054c42acbd7aa956f4f6a3",
            "placeholder": "​",
            "style": "IPY_MODEL_a9477676d5a04a3eb24132a5c47f7bb4",
            "value": " 398/398 [00:00&lt;00:00, 1395.87it/s, Materializing param=visual_projection.weight]"
          }
        },
        "45758b22aa0b4f739693062bf31f5cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef250968e3e489ba0642be9a35dcc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0233a41b85de4eeea54763c7f51cc9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79f2769370b54fc6b53af91b566c279b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5cd86537ddd4374a462ece8648b3f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9831ae2a9d054c42acbd7aa956f4f6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9477676d5a04a3eb24132a5c47f7bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "516c3a706fff4adbb748f70594cdfd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b07bc360d51044ad86b28bcd902532c3",
              "IPY_MODEL_dad7d7fc16cb4f3d8524353372ad5652",
              "IPY_MODEL_64d7d685e42345c099482579b225ab29"
            ],
            "layout": "IPY_MODEL_631bf725caa24a82b2b400a16b0cbead"
          }
        },
        "b07bc360d51044ad86b28bcd902532c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3461752cfca46ed8102ea8f6aedb5f0",
            "placeholder": "​",
            "style": "IPY_MODEL_261df6c768044d7ab07e82a85782562a",
            "value": "model.safetensors: 100%"
          }
        },
        "dad7d7fc16cb4f3d8524353372ad5652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f7f3b31357b430f97920fda64ceaae8",
            "max": 605157884,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82019471e964461bbf15a646b2806329",
            "value": 605157884
          }
        },
        "64d7d685e42345c099482579b225ab29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb73ee49018440b38f4c308ac734b0e7",
            "placeholder": "​",
            "style": "IPY_MODEL_c37625107d2b4b9f91b6800760dfa0d6",
            "value": " 605M/605M [00:02&lt;00:00, 628MB/s]"
          }
        },
        "631bf725caa24a82b2b400a16b0cbead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3461752cfca46ed8102ea8f6aedb5f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261df6c768044d7ab07e82a85782562a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f7f3b31357b430f97920fda64ceaae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82019471e964461bbf15a646b2806329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb73ee49018440b38f4c308ac734b0e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c37625107d2b4b9f91b6800760dfa0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a1c9c2d6bc64021a852fbfcd99f3aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b573354988a0416daee4a01d01162b85",
              "IPY_MODEL_0ef59b2447894ccda38838005271baf9",
              "IPY_MODEL_4c1bf70ba9964160860b998b10db536d"
            ],
            "layout": "IPY_MODEL_bba6f11047c3435bbbd9f3dafc71b8eb"
          }
        },
        "b573354988a0416daee4a01d01162b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8919d4fd0d743578bcc54aa9e70117f",
            "placeholder": "​",
            "style": "IPY_MODEL_7b3bd40c4e6c41fa9df35124c963b614",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "0ef59b2447894ccda38838005271baf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_155be15a14044a1aaca52ad70f63c0fe",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c648c277e9d34c83b1ecf7716e486d1d",
            "value": 316
          }
        },
        "4c1bf70ba9964160860b998b10db536d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75478a5bee0e46f5a5e33b87df91df9b",
            "placeholder": "​",
            "style": "IPY_MODEL_d605822ba8c94a34be9164252ba33fcb",
            "value": " 316/316 [00:00&lt;00:00, 40.8kB/s]"
          }
        },
        "bba6f11047c3435bbbd9f3dafc71b8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8919d4fd0d743578bcc54aa9e70117f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b3bd40c4e6c41fa9df35124c963b614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "155be15a14044a1aaca52ad70f63c0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c648c277e9d34c83b1ecf7716e486d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75478a5bee0e46f5a5e33b87df91df9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d605822ba8c94a34be9164252ba33fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f2b955aa0344c5e8f3cc9cea4466139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f60565f17164a7e8dcecf87c49cee9d",
              "IPY_MODEL_11d5316e8e2c4b85b034256ca9f80744",
              "IPY_MODEL_907c0ec9321b4650930d87a4f6d0b969"
            ],
            "layout": "IPY_MODEL_2f13a575784840c199e41a708b799d19"
          }
        },
        "3f60565f17164a7e8dcecf87c49cee9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_770486e0430f4ed09113259648aaa37b",
            "placeholder": "​",
            "style": "IPY_MODEL_6d2cf1d5ed6d493d9caf6d88ac53bf84",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "11d5316e8e2c4b85b034256ca9f80744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84d2cb6a54754c2fa92ce2bb7d925d7c",
            "max": 592,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6e399e179ab4005b43a69b35effb943",
            "value": 592
          }
        },
        "907c0ec9321b4650930d87a4f6d0b969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696cdb6374b9484783866a7a9975d383",
            "placeholder": "​",
            "style": "IPY_MODEL_58fbea18476a49c3940867b1ac3b6bbf",
            "value": " 592/592 [00:00&lt;00:00, 75.0kB/s]"
          }
        },
        "2f13a575784840c199e41a708b799d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770486e0430f4ed09113259648aaa37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d2cf1d5ed6d493d9caf6d88ac53bf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84d2cb6a54754c2fa92ce2bb7d925d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e399e179ab4005b43a69b35effb943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "696cdb6374b9484783866a7a9975d383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58fbea18476a49c3940867b1ac3b6bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0240ecc2162f4980a0c055c8aafd867e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_962c12ffa14a4fc8b5346ceba9102a10",
              "IPY_MODEL_344e73fe41c04f819d2efae81006ec91",
              "IPY_MODEL_ba214048317c4b2e84393b01cc61583c"
            ],
            "layout": "IPY_MODEL_25538e69bd1e474698ca59e9bc438b49"
          }
        },
        "962c12ffa14a4fc8b5346ceba9102a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5003637468480eb615685849f942d3",
            "placeholder": "​",
            "style": "IPY_MODEL_2ed8c75322114478bde1ba4d04ac0b34",
            "value": "vocab.json: "
          }
        },
        "344e73fe41c04f819d2efae81006ec91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8268e25b0b74de883a00d71c9521248",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ac7bc9027954bebbe4648bb09814178",
            "value": 1
          }
        },
        "ba214048317c4b2e84393b01cc61583c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5a17b31dd046509bf502290f846ff1",
            "placeholder": "​",
            "style": "IPY_MODEL_b492841b4c6f4b02a41cb1bf9a2474c9",
            "value": " 862k/? [00:00&lt;00:00, 49.3MB/s]"
          }
        },
        "25538e69bd1e474698ca59e9bc438b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a5003637468480eb615685849f942d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ed8c75322114478bde1ba4d04ac0b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8268e25b0b74de883a00d71c9521248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1ac7bc9027954bebbe4648bb09814178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b5a17b31dd046509bf502290f846ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b492841b4c6f4b02a41cb1bf9a2474c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5036dc9f02c74bd09d9480064d830615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_140cbc23c4364ffea5f089c0b4af6272",
              "IPY_MODEL_fea6d7eb309a42ce9f0375807ad8e6f0",
              "IPY_MODEL_b03b097803c14b7182e95a371e124c5e"
            ],
            "layout": "IPY_MODEL_426f664a18e94a1790af0bdf762c0276"
          }
        },
        "140cbc23c4364ffea5f089c0b4af6272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6ba34fddc34d0ca53210d724a4ef7d",
            "placeholder": "​",
            "style": "IPY_MODEL_dca68de6f666442491f168b16b8ae08a",
            "value": "merges.txt: "
          }
        },
        "fea6d7eb309a42ce9f0375807ad8e6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e520946e825747699bf6a31cdef5f545",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f56884ca72143c1b00253e63be91383",
            "value": 1
          }
        },
        "b03b097803c14b7182e95a371e124c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4418fbc72049c7a4a49ec2695033d8",
            "placeholder": "​",
            "style": "IPY_MODEL_969889f994a747cba69d099e516ab439",
            "value": " 525k/? [00:00&lt;00:00, 36.9MB/s]"
          }
        },
        "426f664a18e94a1790af0bdf762c0276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6ba34fddc34d0ca53210d724a4ef7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca68de6f666442491f168b16b8ae08a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e520946e825747699bf6a31cdef5f545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8f56884ca72143c1b00253e63be91383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f4418fbc72049c7a4a49ec2695033d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969889f994a747cba69d099e516ab439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d2ef200c2b343feb2aa3180cd4f12e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b6ab56c1af74e83a266cd8e0159ac9f",
              "IPY_MODEL_1f45918e65fc46b7ad60e09b822fc768",
              "IPY_MODEL_b18e1e9ed38845dd87b7e62cdb98a09d"
            ],
            "layout": "IPY_MODEL_b78fedbe8ba74c1db7a0f4372b656fb3"
          }
        },
        "9b6ab56c1af74e83a266cd8e0159ac9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8556e508cc754b109701464509aff597",
            "placeholder": "​",
            "style": "IPY_MODEL_4aca0a95b4d9427baddeacaecd3dfcc1",
            "value": "tokenizer.json: "
          }
        },
        "1f45918e65fc46b7ad60e09b822fc768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2acc94172d4f67b6f886fd84de00ff",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4234648e2e342ba8fc41e20a03afb35",
            "value": 1
          }
        },
        "b18e1e9ed38845dd87b7e62cdb98a09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_270a3c8e2cee4a37aa3d3c65f9b484ee",
            "placeholder": "​",
            "style": "IPY_MODEL_4374ae5e07154a2bb19864e3268d0f21",
            "value": " 2.22M/? [00:00&lt;00:00, 93.8MB/s]"
          }
        },
        "b78fedbe8ba74c1db7a0f4372b656fb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8556e508cc754b109701464509aff597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aca0a95b4d9427baddeacaecd3dfcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e2acc94172d4f67b6f886fd84de00ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c4234648e2e342ba8fc41e20a03afb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "270a3c8e2cee4a37aa3d3c65f9b484ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4374ae5e07154a2bb19864e3268d0f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e1edec1aa354681bd27c3545886b33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a8909c170854780b70e622a22e21ab4",
              "IPY_MODEL_8946d4575c3d46e9927be0a239180390",
              "IPY_MODEL_e2ffb0f025984d62934fc4e5b637989a"
            ],
            "layout": "IPY_MODEL_dc3d4faae0014b789a44768120fe735f"
          }
        },
        "9a8909c170854780b70e622a22e21ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f629845f4a694b66bb75ae8f7d5b977e",
            "placeholder": "​",
            "style": "IPY_MODEL_d8a45d46d19c4a42a06578d4a52632a7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8946d4575c3d46e9927be0a239180390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_015be046593346d780785714254db505",
            "max": 389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f557561c2d5f41fa8ab3a06129139606",
            "value": 389
          }
        },
        "e2ffb0f025984d62934fc4e5b637989a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a0b8d8e77448998011f7a38d3b83d7",
            "placeholder": "​",
            "style": "IPY_MODEL_f4ab29ce7425493dac98575490f023f2",
            "value": " 389/389 [00:00&lt;00:00, 46.4kB/s]"
          }
        },
        "dc3d4faae0014b789a44768120fe735f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f629845f4a694b66bb75ae8f7d5b977e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a45d46d19c4a42a06578d4a52632a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "015be046593346d780785714254db505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f557561c2d5f41fa8ab3a06129139606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8a0b8d8e77448998011f7a38d3b83d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ab29ce7425493dac98575490f023f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63a4a07987bf4c19b7ec266e47419066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa544ac4405546bbaeffdc1b9244a668",
              "IPY_MODEL_04d64188c18e408594135c6f60f1dee8",
              "IPY_MODEL_a8b167128d1f449892595b807a5c4499"
            ],
            "layout": "IPY_MODEL_71896c82b1b64684b0e58506e2366a75"
          }
        },
        "fa544ac4405546bbaeffdc1b9244a668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a20d120d4264f7a8c9070877fe5e492",
            "placeholder": "​",
            "style": "IPY_MODEL_5553535ba4254de99cb505f642c8495e",
            "value": "config.json: 100%"
          }
        },
        "04d64188c18e408594135c6f60f1dee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94549d944ee94c1ea705b424654970ea",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b3cdbd536634b7fbca59b9afa787ce4",
            "value": 727
          }
        },
        "a8b167128d1f449892595b807a5c4499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cbc6b05e657412f9e167e0b6e778831",
            "placeholder": "​",
            "style": "IPY_MODEL_c32980cfcf774ea7902cdd09a1c0bb4f",
            "value": " 727/727 [00:00&lt;00:00, 97.2kB/s]"
          }
        },
        "71896c82b1b64684b0e58506e2366a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a20d120d4264f7a8c9070877fe5e492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5553535ba4254de99cb505f642c8495e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94549d944ee94c1ea705b424654970ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3cdbd536634b7fbca59b9afa787ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cbc6b05e657412f9e167e0b6e778831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32980cfcf774ea7902cdd09a1c0bb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cda345c012e47a0873371fe348b6055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b2ece92b7eb4218b599e4e8cd9bf1cd",
              "IPY_MODEL_e33975eddc654b38aaa866ec5f6cbe89",
              "IPY_MODEL_07e7a703754f44bd9e63719f9d50e773"
            ],
            "layout": "IPY_MODEL_c0532e53876a47ad8a147b801f37a258"
          }
        },
        "3b2ece92b7eb4218b599e4e8cd9bf1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83db858ccb3d40d6a2fcd864bb08f056",
            "placeholder": "​",
            "style": "IPY_MODEL_9b22294387274db9b6c29630e7418a27",
            "value": "tokenizer_config.json: "
          }
        },
        "e33975eddc654b38aaa866ec5f6cbe89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ca73f11bf149469c9707de3594d632",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1636b0f66d7345558a74a0aae802e77e",
            "value": 1
          }
        },
        "07e7a703754f44bd9e63719f9d50e773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b12f6fda31c46ffa3e0bb6d6d4ea2f1",
            "placeholder": "​",
            "style": "IPY_MODEL_14a17c23fe0a44c397fb39b30f03edb9",
            "value": " 9.38k/? [00:00&lt;00:00, 1.15MB/s]"
          }
        },
        "c0532e53876a47ad8a147b801f37a258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83db858ccb3d40d6a2fcd864bb08f056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b22294387274db9b6c29630e7418a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9ca73f11bf149469c9707de3594d632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1636b0f66d7345558a74a0aae802e77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b12f6fda31c46ffa3e0bb6d6d4ea2f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a17c23fe0a44c397fb39b30f03edb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c1b29de9d5c4466a83768bb8140624c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_871645fcd3e94a34bda09441fa7588d8",
              "IPY_MODEL_5e474a10dd0143469a79c8e931242cc6",
              "IPY_MODEL_8d2230caec94469ea6b45ad63a7c5236"
            ],
            "layout": "IPY_MODEL_f5200584dac24072ad828e66fd68fa55"
          }
        },
        "871645fcd3e94a34bda09441fa7588d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b98b393921d94b6ca6953a257f2a0fff",
            "placeholder": "​",
            "style": "IPY_MODEL_f3bfdecb1873485b800a1663272fb2bd",
            "value": "vocab.json: "
          }
        },
        "5e474a10dd0143469a79c8e931242cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1594fd0a2e2343d6b356d9d05f639158",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7948996ade35468590180d4983bf2ffe",
            "value": 1
          }
        },
        "8d2230caec94469ea6b45ad63a7c5236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6da0287a2651460bb93c1a32988a632d",
            "placeholder": "​",
            "style": "IPY_MODEL_977bd136b5c2457694ec471624daf211",
            "value": " 2.78M/? [00:00&lt;00:00, 85.5MB/s]"
          }
        },
        "f5200584dac24072ad828e66fd68fa55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b98b393921d94b6ca6953a257f2a0fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3bfdecb1873485b800a1663272fb2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1594fd0a2e2343d6b356d9d05f639158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7948996ade35468590180d4983bf2ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6da0287a2651460bb93c1a32988a632d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "977bd136b5c2457694ec471624daf211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f871aec396dc4cfb9773c500cdd3ed18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fc080a673eb41a48a4eb86797beda00",
              "IPY_MODEL_c2f23b46cd764b0a9f1f7fcd3a59fe7b",
              "IPY_MODEL_9fe7a276d4514cbc9b2cfead8ace9b1b"
            ],
            "layout": "IPY_MODEL_bbd8da75e20f424da7c5bc34696ab5b0"
          }
        },
        "8fc080a673eb41a48a4eb86797beda00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14809a2d922c485f9474528a3719eaf0",
            "placeholder": "​",
            "style": "IPY_MODEL_b25287172d5a4e6b9807632d204770c8",
            "value": "merges.txt: "
          }
        },
        "c2f23b46cd764b0a9f1f7fcd3a59fe7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425222ce878747299b14dfd9cfab3c33",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b93be3bdcbc742da8d651bf5d921cbe5",
            "value": 1
          }
        },
        "9fe7a276d4514cbc9b2cfead8ace9b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5272a25544043ab80e5a49a6aecbfc8",
            "placeholder": "​",
            "style": "IPY_MODEL_91f111af841944ec95884b9fec4f29f5",
            "value": " 1.67M/? [00:00&lt;00:00, 69.1MB/s]"
          }
        },
        "bbd8da75e20f424da7c5bc34696ab5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14809a2d922c485f9474528a3719eaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b25287172d5a4e6b9807632d204770c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "425222ce878747299b14dfd9cfab3c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b93be3bdcbc742da8d651bf5d921cbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5272a25544043ab80e5a49a6aecbfc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f111af841944ec95884b9fec4f29f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17927b5bfc0c424aac7b7ef26b08db63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc1c33834b184a24bea03b574837d2fb",
              "IPY_MODEL_b2c5d432eda447e5a646a25815574762",
              "IPY_MODEL_7ce07e0d4f274905a3328303a13a09f6"
            ],
            "layout": "IPY_MODEL_641288fa97b6419c8df11c5b3b8e553b"
          }
        },
        "dc1c33834b184a24bea03b574837d2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18afdae5a65245ae886ce0413013004a",
            "placeholder": "​",
            "style": "IPY_MODEL_9e5ed36d3a80492787ab9be3c6382b8d",
            "value": "tokenizer.json: 100%"
          }
        },
        "b2c5d432eda447e5a646a25815574762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d436cceb712749dca3aa2a388b135013",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93bd1034494b462aa2e6ea9b2863c626",
            "value": 11422654
          }
        },
        "7ce07e0d4f274905a3328303a13a09f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71c80c8c67c6458b9924f3f5082d9088",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e4323b67044e22b875b5e5b65b1e0b",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 20.7MB/s]"
          }
        },
        "641288fa97b6419c8df11c5b3b8e553b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18afdae5a65245ae886ce0413013004a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5ed36d3a80492787ab9be3c6382b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d436cceb712749dca3aa2a388b135013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bd1034494b462aa2e6ea9b2863c626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71c80c8c67c6458b9924f3f5082d9088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e4323b67044e22b875b5e5b65b1e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e83d74989a85461d97228746b9307e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d154e4e785ba4359b6fddd4b604a39fd",
              "IPY_MODEL_07fd5d4d7df84777a41c652e6ea0af4c",
              "IPY_MODEL_094143792b2e435986635f120032ae69"
            ],
            "layout": "IPY_MODEL_a8ee0650bb9c4993aa2176922f36afda"
          }
        },
        "d154e4e785ba4359b6fddd4b604a39fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e4d6b9fc9d34d9bac17950d59368107",
            "placeholder": "​",
            "style": "IPY_MODEL_698dacf08578425daac9463a4be57f82",
            "value": "model.safetensors.index.json: "
          }
        },
        "07fd5d4d7df84777a41c652e6ea0af4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5390213f3b9942dab5edaaf23eefc60f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46c56ee255e4427aa0509665b6adee75",
            "value": 1
          }
        },
        "094143792b2e435986635f120032ae69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3b22da1ef64e4da4fc57feb6c07468",
            "placeholder": "​",
            "style": "IPY_MODEL_4e47a2548b994ec3826525f5f268b984",
            "value": " 32.8k/? [00:00&lt;00:00, 3.96MB/s]"
          }
        },
        "a8ee0650bb9c4993aa2176922f36afda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e4d6b9fc9d34d9bac17950d59368107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698dacf08578425daac9463a4be57f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5390213f3b9942dab5edaaf23eefc60f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "46c56ee255e4427aa0509665b6adee75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b3b22da1ef64e4da4fc57feb6c07468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e47a2548b994ec3826525f5f268b984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1966cfec66194355a6991cd229af9020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8e188fa504546c785b0354f8a9bdef9",
              "IPY_MODEL_d7e389c7eaca493fa21a2f9c8d4157e8",
              "IPY_MODEL_7b7acec4e8c545b5a30432b18bf82293"
            ],
            "layout": "IPY_MODEL_b34999df81b544bf9d527437b7918998"
          }
        },
        "b8e188fa504546c785b0354f8a9bdef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b21c7b91f23488caadac22317da4069",
            "placeholder": "​",
            "style": "IPY_MODEL_1f95843f3bbb4257a0aa5b6f2db7e1a9",
            "value": "Download complete: 100%"
          }
        },
        "d7e389c7eaca493fa21a2f9c8d4157e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_742268e024334d7791c952af71c063db",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cd85a6e3106445689d076c9e610f28e",
            "value": 1
          }
        },
        "7b7acec4e8c545b5a30432b18bf82293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e50ec3842451441ba539203d142b3400",
            "placeholder": "​",
            "style": "IPY_MODEL_98adfb90bbad4587a0fe6d3593ceaa67",
            "value": " 8.04G/8.04G [01:15&lt;00:00, 305MB/s]"
          }
        },
        "b34999df81b544bf9d527437b7918998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b21c7b91f23488caadac22317da4069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f95843f3bbb4257a0aa5b6f2db7e1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "742268e024334d7791c952af71c063db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4cd85a6e3106445689d076c9e610f28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e50ec3842451441ba539203d142b3400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98adfb90bbad4587a0fe6d3593ceaa67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "473e456f64f1417cb0342245d5deeaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7578c37dd0824631a63e333b26b1a3a6",
              "IPY_MODEL_dbe4b07bb5fb4c58b09c38db54678cbc",
              "IPY_MODEL_eb376badb6164738bd837aaa2e585639"
            ],
            "layout": "IPY_MODEL_d9dc7d824f7246ea8ffb7dde04583b1b"
          }
        },
        "7578c37dd0824631a63e333b26b1a3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c854bef519b640fba1546f0f449984ca",
            "placeholder": "​",
            "style": "IPY_MODEL_4396a49fcadc47d1a610e53aa3cc6791",
            "value": "Fetching 3 files: 100%"
          }
        },
        "dbe4b07bb5fb4c58b09c38db54678cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de076c2b5a04fffb0d9ba9c5e4384c0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a85cb1449c3a4f6dbd96de35489ce619",
            "value": 3
          }
        },
        "eb376badb6164738bd837aaa2e585639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee87a70d176d4ade9f5708d9eb2d5633",
            "placeholder": "​",
            "style": "IPY_MODEL_d92da2f51ca1477588bd9e8175ebe40d",
            "value": " 3/3 [00:26&lt;00:00, 11.34s/it]"
          }
        },
        "d9dc7d824f7246ea8ffb7dde04583b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c854bef519b640fba1546f0f449984ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4396a49fcadc47d1a610e53aa3cc6791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6de076c2b5a04fffb0d9ba9c5e4384c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85cb1449c3a4f6dbd96de35489ce619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee87a70d176d4ade9f5708d9eb2d5633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92da2f51ca1477588bd9e8175ebe40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dcad1322f584fe4be3c5dbd0dc28f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4361cdfa1fb54e14af52881d3ceff81a",
              "IPY_MODEL_6b841700d4204ebfa79212b6de9d8df6",
              "IPY_MODEL_8ba41e21adb640b4bc167943c768901e"
            ],
            "layout": "IPY_MODEL_728f56649c6b47509500cc485f3059e9"
          }
        },
        "4361cdfa1fb54e14af52881d3ceff81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1389d4495eaf44ca93aff51f1acc5904",
            "placeholder": "​",
            "style": "IPY_MODEL_0942697bf8e74b8699c2059c319bdac6",
            "value": "Loading weights: 100%"
          }
        },
        "6b841700d4204ebfa79212b6de9d8df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_673e92b8b5014aa0bf2ea536d5036d40",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35522276fda94a19817bf681a4e41e07",
            "value": 398
          }
        },
        "8ba41e21adb640b4bc167943c768901e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b51864294e46988ccaf7d208d54dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_865c5be7e4794d5682106f032e128b23",
            "value": " 398/398 [00:02&lt;00:00, 203.14it/s, Materializing param=model.norm.weight]"
          }
        },
        "728f56649c6b47509500cc485f3059e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1389d4495eaf44ca93aff51f1acc5904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0942697bf8e74b8699c2059c319bdac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "673e92b8b5014aa0bf2ea536d5036d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35522276fda94a19817bf681a4e41e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0b51864294e46988ccaf7d208d54dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "865c5be7e4794d5682106f032e128b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af5e191d8c94b90b421207dfd8bb0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55ebb7a9535e4669a5fbee4d9b732bd7",
              "IPY_MODEL_486947efabaa4f60b777216f481aaede",
              "IPY_MODEL_ea58db00e31d4d5eb155ba97061bad24"
            ],
            "layout": "IPY_MODEL_55f3e8e70edc4877802090baf6ad1bf9"
          }
        },
        "55ebb7a9535e4669a5fbee4d9b732bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b795c31068ab4cb2b452e46a996436fc",
            "placeholder": "​",
            "style": "IPY_MODEL_76f8671ce1ea4f368761839d097d51b8",
            "value": "generation_config.json: 100%"
          }
        },
        "486947efabaa4f60b777216f481aaede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feb578a7d8c342139b350b0e2bf91581",
            "max": 238,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92539627e5ca4e2bb8262f0752c54ef8",
            "value": 238
          }
        },
        "ea58db00e31d4d5eb155ba97061bad24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883220be21cd41e8a3ca187b99d83d32",
            "placeholder": "​",
            "style": "IPY_MODEL_66a1c21dd64942b9ba4861e3e201b8b4",
            "value": " 238/238 [00:00&lt;00:00, 28.5kB/s]"
          }
        },
        "55f3e8e70edc4877802090baf6ad1bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b795c31068ab4cb2b452e46a996436fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f8671ce1ea4f368761839d097d51b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb578a7d8c342139b350b0e2bf91581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92539627e5ca4e2bb8262f0752c54ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "883220be21cd41e8a3ca187b99d83d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a1c21dd64942b9ba4861e3e201b8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a055e9b6e3a9403facfa5f15960474eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8c66b8c9fc54454822d8aff582ee504",
              "IPY_MODEL_51bbd850b50b43679584e6c940df3374",
              "IPY_MODEL_1e88890974eb4a258a09cc1912ffc721"
            ],
            "layout": "IPY_MODEL_9a9227ff02784e6d86d375e4aac6ccbb"
          }
        },
        "b8c66b8c9fc54454822d8aff582ee504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f797bab8a5e14a93a4b3e3c2f1c87fa9",
            "placeholder": "​",
            "style": "IPY_MODEL_258ba2e2bcc9491cb633f9e1bbde9fa6",
            "value": "README.md: 100%"
          }
        },
        "51bbd850b50b43679584e6c940df3374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e228627dea7941cd8cff0a6ceff47d5f",
            "max": 852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70aa36e6dcd04793849a76db7ca44bb5",
            "value": 852
          }
        },
        "1e88890974eb4a258a09cc1912ffc721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1f5e912c5cf408b8e59ba99a6e75d29",
            "placeholder": "​",
            "style": "IPY_MODEL_c3f3f3bad55d4e3083bb049080ee1544",
            "value": " 852/852 [00:00&lt;00:00, 112kB/s]"
          }
        },
        "9a9227ff02784e6d86d375e4aac6ccbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f797bab8a5e14a93a4b3e3c2f1c87fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258ba2e2bcc9491cb633f9e1bbde9fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e228627dea7941cd8cff0a6ceff47d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70aa36e6dcd04793849a76db7ca44bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1f5e912c5cf408b8e59ba99a6e75d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3f3f3bad55d4e3083bb049080ee1544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "add47dd08300451b8fd7a114aa25ded4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fe965be919f403aa784c0c653583a93",
              "IPY_MODEL_523f163ab3164d0f96b8368197f2f3b0",
              "IPY_MODEL_491bd943bcfa43d796541c54e1ab31cb"
            ],
            "layout": "IPY_MODEL_4a96f70b64db463eac9fd4187d7f03ea"
          }
        },
        "3fe965be919f403aa784c0c653583a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4fda8e000f4162b7092cbef623cd6d",
            "placeholder": "​",
            "style": "IPY_MODEL_38489a114b6a4ed49d2afc3131416a53",
            "value": "data/train-00000-of-00003-49492f364babfa(…): 100%"
          }
        },
        "523f163ab3164d0f96b8368197f2f3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34879aaffb34827a771ac0e523597ba",
            "max": 219024215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9060c58be93d497b82482f7ac7728a16",
            "value": 219024215
          }
        },
        "491bd943bcfa43d796541c54e1ab31cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e17aac387ee240cc9057a4dc3552ae58",
            "placeholder": "​",
            "style": "IPY_MODEL_92df41774cd648bbb19999682d1cb20e",
            "value": " 219M/219M [00:01&lt;00:00, 241MB/s]"
          }
        },
        "4a96f70b64db463eac9fd4187d7f03ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4fda8e000f4162b7092cbef623cd6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38489a114b6a4ed49d2afc3131416a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d34879aaffb34827a771ac0e523597ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9060c58be93d497b82482f7ac7728a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e17aac387ee240cc9057a4dc3552ae58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92df41774cd648bbb19999682d1cb20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bede184af3d4045acfb907601311afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca99fe0d35d7432ea3c426d81cf806c3",
              "IPY_MODEL_660fa5c8411d48a49c850e5f8e79a0fd",
              "IPY_MODEL_c6c46d01835b43ef89b2bb592908fd7b"
            ],
            "layout": "IPY_MODEL_79286da9a5454e69a325ebc48e2894d0"
          }
        },
        "ca99fe0d35d7432ea3c426d81cf806c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adef94f03d734b80840ba007a294ebb3",
            "placeholder": "​",
            "style": "IPY_MODEL_ab54aa8faa374459ba20f57c0ef924f1",
            "value": "data/train-00001-of-00003-7302bae5e425bb(…): 100%"
          }
        },
        "660fa5c8411d48a49c850e5f8e79a0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c08a342b9d4f9b82d410ad135d4985",
            "max": 310674206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f699bd486adf4321b16751c29d600471",
            "value": 310674206
          }
        },
        "c6c46d01835b43ef89b2bb592908fd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a989b3d84794f0696a7159199979f52",
            "placeholder": "​",
            "style": "IPY_MODEL_93333e3f94e4434d8cf91a015e250d5c",
            "value": " 311M/311M [00:00&lt;00:00, 267MB/s]"
          }
        },
        "79286da9a5454e69a325ebc48e2894d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adef94f03d734b80840ba007a294ebb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab54aa8faa374459ba20f57c0ef924f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83c08a342b9d4f9b82d410ad135d4985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f699bd486adf4321b16751c29d600471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a989b3d84794f0696a7159199979f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93333e3f94e4434d8cf91a015e250d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d5b06efa5cd4262be14e0e53c0d89b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05e1a52513249bfa9d067d8374f56a2",
              "IPY_MODEL_8383039e69794cc1b52f3d2c3f312212",
              "IPY_MODEL_e8d7cfb16222472fb2f7c1969f14b43c"
            ],
            "layout": "IPY_MODEL_73b5aae0af4443869fd95a0c346276d5"
          }
        },
        "e05e1a52513249bfa9d067d8374f56a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4fbe6b42db4080872d549ae3918f83",
            "placeholder": "​",
            "style": "IPY_MODEL_40211c7c69c04aee95a429a320f8043d",
            "value": "data/train-00002-of-00003-194c9400785577(…): 100%"
          }
        },
        "8383039e69794cc1b52f3d2c3f312212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2db94d408ff4ac29504cf23a4ec9fff",
            "max": 315273201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87ef5fc2d87647f08a5b39f325371596",
            "value": 315273201
          }
        },
        "e8d7cfb16222472fb2f7c1969f14b43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f8b46607524a568ceff79fcb290dc7",
            "placeholder": "​",
            "style": "IPY_MODEL_bded3e7a0d384a87ab444dfa93678380",
            "value": " 315M/315M [00:00&lt;00:00, 349MB/s]"
          }
        },
        "73b5aae0af4443869fd95a0c346276d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf4fbe6b42db4080872d549ae3918f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40211c7c69c04aee95a429a320f8043d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2db94d408ff4ac29504cf23a4ec9fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ef5fc2d87647f08a5b39f325371596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27f8b46607524a568ceff79fcb290dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bded3e7a0d384a87ab444dfa93678380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f294b07243054a48a0d42ee4630e49d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e74cef6e79349e3a593a9db0f02cdf3",
              "IPY_MODEL_3dec9c62a1a845da80113e6388c39c7c",
              "IPY_MODEL_281d1f6024de4ac99b34a447b0c1dfc2"
            ],
            "layout": "IPY_MODEL_e150e29276514ff8bd532aa4326f187c"
          }
        },
        "8e74cef6e79349e3a593a9db0f02cdf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_121ab8a342db4cd6b57fb0760941cbe2",
            "placeholder": "​",
            "style": "IPY_MODEL_52108163e3034c7f87a5f09c893e3273",
            "value": "data/val-00000-of-00001-0f11003c77497969(…): 100%"
          }
        },
        "3dec9c62a1a845da80113e6388c39c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48a30cfed4dd467aac899b3c8cdca3d7",
            "max": 50225558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf4f697f16f34941bac8a4cc05c2ca2c",
            "value": 50225558
          }
        },
        "281d1f6024de4ac99b34a447b0c1dfc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e1aee1628a1490895f29d485baab37d",
            "placeholder": "​",
            "style": "IPY_MODEL_88cc8b668fce486086af76b8c5ca6dad",
            "value": " 50.2M/50.2M [00:01&lt;00:00, 56.9MB/s]"
          }
        },
        "e150e29276514ff8bd532aa4326f187c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "121ab8a342db4cd6b57fb0760941cbe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52108163e3034c7f87a5f09c893e3273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a30cfed4dd467aac899b3c8cdca3d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4f697f16f34941bac8a4cc05c2ca2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e1aee1628a1490895f29d485baab37d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88cc8b668fce486086af76b8c5ca6dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f132b60b69f34e5bb777a346e9197d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b86d818afbd643588a095406aa09f29e",
              "IPY_MODEL_039209e37f4f45ec90beee4169d7cbd3",
              "IPY_MODEL_6a0c9e6c2e274734b4d722b75537d575"
            ],
            "layout": "IPY_MODEL_223bca825c1a40cbaf20fbd38d9dbda7"
          }
        },
        "b86d818afbd643588a095406aa09f29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38533e82c0f44ee790567ca4dcd437a3",
            "placeholder": "​",
            "style": "IPY_MODEL_ce926e0472904dd7aecb76f8c0c1b9b2",
            "value": "data/test-00000-of-00001-e2cd0b7a0f9eb20(…): 100%"
          }
        },
        "039209e37f4f45ec90beee4169d7cbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1076fdaf2730453e80d4a00607d2ff5d",
            "max": 68898419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e926f07b05e340ebab4c2fcac6270792",
            "value": 68898419
          }
        },
        "6a0c9e6c2e274734b4d722b75537d575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18aa7d34da404d3ab87b07c779dbbe3f",
            "placeholder": "​",
            "style": "IPY_MODEL_07ab87f09c3c40a5bf241ba484c86d73",
            "value": " 68.9M/68.9M [00:00&lt;00:00, 2.68MB/s]"
          }
        },
        "223bca825c1a40cbaf20fbd38d9dbda7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38533e82c0f44ee790567ca4dcd437a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce926e0472904dd7aecb76f8c0c1b9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1076fdaf2730453e80d4a00607d2ff5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e926f07b05e340ebab4c2fcac6270792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18aa7d34da404d3ab87b07c779dbbe3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ab87f09c3c40a5bf241ba484c86d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2b2d84218f644d59104d04c6a1d1eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46ad75ee97cd4163abeb454fbc7c699a",
              "IPY_MODEL_26e6693ecbb048fab5e500a1be6fb87e",
              "IPY_MODEL_4b6268c092d9467ca638313aefa9c40f"
            ],
            "layout": "IPY_MODEL_46208855a18e4faf94fcfbda35cb0e88"
          }
        },
        "46ad75ee97cd4163abeb454fbc7c699a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5086c3136224051982916f7dfb302ed",
            "placeholder": "​",
            "style": "IPY_MODEL_bf067a7e58d0449795bb8ab1a4018477",
            "value": "Generating train split: 100%"
          }
        },
        "26e6693ecbb048fab5e500a1be6fb87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0902abad8646456ebd7d232a49ecf9cc",
            "max": 28299,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be28e42a6a694fe18cb4817149d02f1c",
            "value": 28299
          }
        },
        "4b6268c092d9467ca638313aefa9c40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a474d7caff814e209bd4b942893a1706",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c003fc96b64823a75eb16991325c78",
            "value": " 28299/28299 [00:04&lt;00:00, 8289.64 examples/s]"
          }
        },
        "46208855a18e4faf94fcfbda35cb0e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5086c3136224051982916f7dfb302ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf067a7e58d0449795bb8ab1a4018477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0902abad8646456ebd7d232a49ecf9cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be28e42a6a694fe18cb4817149d02f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a474d7caff814e209bd4b942893a1706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c003fc96b64823a75eb16991325c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ed5c3e762614393be5b9def9230d4ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_923e5d1aded94dfeba1a684de3022019",
              "IPY_MODEL_b67b20daf51a45c281816f69e347f83d",
              "IPY_MODEL_56665084a0ed4d1a9e4926997c6f490b"
            ],
            "layout": "IPY_MODEL_4d3de7733c214d5b998785d48c3ea558"
          }
        },
        "923e5d1aded94dfeba1a684de3022019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c403d936b97c4d6e8d6776fad8096a6d",
            "placeholder": "​",
            "style": "IPY_MODEL_03410086a4b8456cbc1fe715c9c5fb69",
            "value": "Generating val split: 100%"
          }
        },
        "b67b20daf51a45c281816f69e347f83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9711471a95f24851be316d2dbb284679",
            "max": 1920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c57ef0aa05e9427f8eacd78b8899bf29",
            "value": 1920
          }
        },
        "56665084a0ed4d1a9e4926997c6f490b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0649d3db45644ac2ae02b24679f470b6",
            "placeholder": "​",
            "style": "IPY_MODEL_1f2c719aef524583a638d303152e4075",
            "value": " 1920/1920 [00:00&lt;00:00, 22076.68 examples/s]"
          }
        },
        "4d3de7733c214d5b998785d48c3ea558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c403d936b97c4d6e8d6776fad8096a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03410086a4b8456cbc1fe715c9c5fb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9711471a95f24851be316d2dbb284679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57ef0aa05e9427f8eacd78b8899bf29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0649d3db45644ac2ae02b24679f470b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f2c719aef524583a638d303152e4075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48b81a50e9e04c4e8d457796a80051a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9adf81376584383b8e3e6b6cf9a6b9e",
              "IPY_MODEL_4e158289052b485293911c7946a5ac5f",
              "IPY_MODEL_2571fd553db746d99f6c585bb2d4e53b"
            ],
            "layout": "IPY_MODEL_4be15da9b0fb4bf19af94970e2e9aeab"
          }
        },
        "f9adf81376584383b8e3e6b6cf9a6b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_415bf2a3e6304d66bb2d9dd6935d6577",
            "placeholder": "​",
            "style": "IPY_MODEL_ec4d1b6d6c48498696035134cc56c887",
            "value": "Generating test split: 100%"
          }
        },
        "4e158289052b485293911c7946a5ac5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef0d392398c4d8a9575e459a7cfa6d8",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e80dbf0186754d87bf321099f549cd58",
            "value": 2500
          }
        },
        "2571fd553db746d99f6c585bb2d4e53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c4a145de0714ae48e7d933bb89c5523",
            "placeholder": "​",
            "style": "IPY_MODEL_56ad08ef36d04de08753ddc574494d86",
            "value": " 2500/2500 [00:00&lt;00:00, 21315.91 examples/s]"
          }
        },
        "4be15da9b0fb4bf19af94970e2e9aeab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415bf2a3e6304d66bb2d9dd6935d6577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4d1b6d6c48498696035134cc56c887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef0d392398c4d8a9575e459a7cfa6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e80dbf0186754d87bf321099f549cd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c4a145de0714ae48e7d933bb89c5523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ad08ef36d04de08753ddc574494d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aac6318716f341f290645dd51ab470e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64a55bc145e14e9787926403a460276b",
              "IPY_MODEL_e348251e2df8487194048beb6cd11edd",
              "IPY_MODEL_50b83a84a2d047a383ca42db3281e908"
            ],
            "layout": "IPY_MODEL_764b4aed287e4661bdaad43784706e9d"
          }
        },
        "64a55bc145e14e9787926403a460276b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2753276c0074f1d8b3e15ae23fa1668",
            "placeholder": "​",
            "style": "IPY_MODEL_da9297c97c3140a8b97df2d587bcc605",
            "value": "README.md: 100%"
          }
        },
        "e348251e2df8487194048beb6cd11edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f280f1c123469d8569a1417987bd3a",
            "max": 852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8089f39e4534f92aeb70eeff66154d8",
            "value": 852
          }
        },
        "50b83a84a2d047a383ca42db3281e908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fd9a790efab40a39ad2c4cfd1333244",
            "placeholder": "​",
            "style": "IPY_MODEL_3b14b29af856457e9c66b72b4070ed88",
            "value": " 852/852 [00:00&lt;00:00, 100kB/s]"
          }
        },
        "764b4aed287e4661bdaad43784706e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2753276c0074f1d8b3e15ae23fa1668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9297c97c3140a8b97df2d587bcc605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03f280f1c123469d8569a1417987bd3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8089f39e4534f92aeb70eeff66154d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fd9a790efab40a39ad2c4cfd1333244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b14b29af856457e9c66b72b4070ed88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b67728627a84772922b7ed09fd3b9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb5c361d6d1e41b290098bdf2baa6a3e",
              "IPY_MODEL_f06b6df725624effaaeb863a98c1dc40",
              "IPY_MODEL_6aa1d04194924216bc8e112c9449332a"
            ],
            "layout": "IPY_MODEL_94e7917a582f4645b6d3a93f9cee57e6"
          }
        },
        "cb5c361d6d1e41b290098bdf2baa6a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa0b4fb77a734e1c9aa7061246250296",
            "placeholder": "​",
            "style": "IPY_MODEL_e28a5af69ec1490b9540918400c0ecdf",
            "value": "data/train-00000-of-00003-49492f364babfa(…): 100%"
          }
        },
        "f06b6df725624effaaeb863a98c1dc40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45206139d2e244e3a1c542ae6257adc0",
            "max": 219024215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66de99cc24974df6a1ac06e52e9db3c4",
            "value": 219024215
          }
        },
        "6aa1d04194924216bc8e112c9449332a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_339a212cb4bd4ea5bf94ba82a7e17978",
            "placeholder": "​",
            "style": "IPY_MODEL_4d84505a886649ac94ca069e03990b10",
            "value": " 219M/219M [00:05&lt;00:00, 231MB/s]"
          }
        },
        "94e7917a582f4645b6d3a93f9cee57e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0b4fb77a734e1c9aa7061246250296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28a5af69ec1490b9540918400c0ecdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45206139d2e244e3a1c542ae6257adc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66de99cc24974df6a1ac06e52e9db3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "339a212cb4bd4ea5bf94ba82a7e17978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d84505a886649ac94ca069e03990b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f308221f02242d5a308c7b67ed8a578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c73434e9865441d921048c4ef8541d6",
              "IPY_MODEL_e12eef7a526841b0b26189ba3a04ba74",
              "IPY_MODEL_6af2963211d34b3c8bf2e1983c52bc70"
            ],
            "layout": "IPY_MODEL_6c58688071c94b4992a550bd09786d70"
          }
        },
        "9c73434e9865441d921048c4ef8541d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d991a3a676af4e31b4298cd141f6704b",
            "placeholder": "​",
            "style": "IPY_MODEL_ebb07636785b4f48b089143da7704664",
            "value": "data/train-00001-of-00003-7302bae5e425bb(…): 100%"
          }
        },
        "e12eef7a526841b0b26189ba3a04ba74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def09616b632470e9c0ae41cab541963",
            "max": 310674206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca333a4a3f664a92a7684a3019cfdb56",
            "value": 310674206
          }
        },
        "6af2963211d34b3c8bf2e1983c52bc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1068453f892344969c446ef1b1ee1268",
            "placeholder": "​",
            "style": "IPY_MODEL_423d12524abf4fc9ada94c286ad4fc4d",
            "value": " 311M/311M [00:02&lt;00:00, 250MB/s]"
          }
        },
        "6c58688071c94b4992a550bd09786d70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d991a3a676af4e31b4298cd141f6704b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebb07636785b4f48b089143da7704664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "def09616b632470e9c0ae41cab541963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca333a4a3f664a92a7684a3019cfdb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1068453f892344969c446ef1b1ee1268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "423d12524abf4fc9ada94c286ad4fc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53bb8b37e9fe48209f6736918f2e93b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c170d11e15f48a8b593cc873f7d9b7a",
              "IPY_MODEL_b54afdf9464f42f386adf4e60d1eeea1",
              "IPY_MODEL_fa031cda49964e8daa1ffccb086340b1"
            ],
            "layout": "IPY_MODEL_d674c8439c7b42f5968b7a0e8a0194ca"
          }
        },
        "8c170d11e15f48a8b593cc873f7d9b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e798a4b5ad147adb33e93b339273e77",
            "placeholder": "​",
            "style": "IPY_MODEL_0a8eb8854eaf4ed29226df2a326d34e9",
            "value": "data/train-00002-of-00003-194c9400785577(…): 100%"
          }
        },
        "b54afdf9464f42f386adf4e60d1eeea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8be08b6ddf04984b3c63633fb63dd1b",
            "max": 315273201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_447bd8fe19e14eca99b453c3725c6fb9",
            "value": 315273201
          }
        },
        "fa031cda49964e8daa1ffccb086340b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9604300752484fd6b218183f3dc4670d",
            "placeholder": "​",
            "style": "IPY_MODEL_7b30b331a67b41768838f14d1032c2aa",
            "value": " 315M/315M [00:02&lt;00:00, 229MB/s]"
          }
        },
        "d674c8439c7b42f5968b7a0e8a0194ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e798a4b5ad147adb33e93b339273e77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8eb8854eaf4ed29226df2a326d34e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8be08b6ddf04984b3c63633fb63dd1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447bd8fe19e14eca99b453c3725c6fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9604300752484fd6b218183f3dc4670d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b30b331a67b41768838f14d1032c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "327af51baa6a4a0bb58b82784e53b10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88a1d05df26d4bbfb4c4c689b816a7b4",
              "IPY_MODEL_210709dfc5d748fa8f86ddbff7fb616a",
              "IPY_MODEL_0ffc22ec5b84418b8b9a34fcd1bdc13d"
            ],
            "layout": "IPY_MODEL_55cee527bde4442e868a6e9a8121d946"
          }
        },
        "88a1d05df26d4bbfb4c4c689b816a7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97017efe9e6747d09c644427e6180420",
            "placeholder": "​",
            "style": "IPY_MODEL_e95b2fe3c1ee4020a3a112044d958564",
            "value": "data/val-00000-of-00001-0f11003c77497969(…): 100%"
          }
        },
        "210709dfc5d748fa8f86ddbff7fb616a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10c7ab90b25489ca927087c4f18d5d7",
            "max": 50225558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52d1e192d2a543a7ba6e5484196065b4",
            "value": 50225558
          }
        },
        "0ffc22ec5b84418b8b9a34fcd1bdc13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ae9ae62a0849a38e616037f5a0634f",
            "placeholder": "​",
            "style": "IPY_MODEL_bca2156c6e864d8f89a47a9e87bfde87",
            "value": " 50.2M/50.2M [00:00&lt;00:00, 50.6MB/s]"
          }
        },
        "55cee527bde4442e868a6e9a8121d946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97017efe9e6747d09c644427e6180420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e95b2fe3c1ee4020a3a112044d958564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f10c7ab90b25489ca927087c4f18d5d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d1e192d2a543a7ba6e5484196065b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1ae9ae62a0849a38e616037f5a0634f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bca2156c6e864d8f89a47a9e87bfde87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28e880ed00414b5093af0af3a0cbb37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_290b0fe4f1b84010a4713db88bb8cad3",
              "IPY_MODEL_2c55c2e5693748b7ab263970c450be0a",
              "IPY_MODEL_c954d0e8928e42a4bda2df83d8fe01e9"
            ],
            "layout": "IPY_MODEL_e03cd749252e45c084617fcd54a0bb42"
          }
        },
        "290b0fe4f1b84010a4713db88bb8cad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326739f4ecd74cafbaf6b1647caab95d",
            "placeholder": "​",
            "style": "IPY_MODEL_9ec9d850b75f4a77bccd7df2038c7afa",
            "value": "data/test-00000-of-00001-e2cd0b7a0f9eb20(…): 100%"
          }
        },
        "2c55c2e5693748b7ab263970c450be0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5229a4d16df410a9c33ed50e4ae1a85",
            "max": 68898419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d69250eaf3154f408812efea92e7847e",
            "value": 68898419
          }
        },
        "c954d0e8928e42a4bda2df83d8fe01e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207de335851b489fa093d5afeae21213",
            "placeholder": "​",
            "style": "IPY_MODEL_f0881009a1e242bda7eac247ee2ff09e",
            "value": " 68.9M/68.9M [00:00&lt;00:00, 574MB/s]"
          }
        },
        "e03cd749252e45c084617fcd54a0bb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "326739f4ecd74cafbaf6b1647caab95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec9d850b75f4a77bccd7df2038c7afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5229a4d16df410a9c33ed50e4ae1a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69250eaf3154f408812efea92e7847e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "207de335851b489fa093d5afeae21213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0881009a1e242bda7eac247ee2ff09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5655effe5b3f49d0b65d3ccb4bb4b1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d4aee7255b04fde8b4b1e7f565859b3",
              "IPY_MODEL_04c836488b994b62bcc1809ee8e30e48",
              "IPY_MODEL_0e47485d5cf54a7ba7edf1b3d792ccf8"
            ],
            "layout": "IPY_MODEL_130fc950d2094b67a688eeafdbae3d85"
          }
        },
        "1d4aee7255b04fde8b4b1e7f565859b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172f421390f3478698e5a351d9e46f63",
            "placeholder": "​",
            "style": "IPY_MODEL_98a2a84ad9e243cea50239d8c6dd07f4",
            "value": "Generating train split: 100%"
          }
        },
        "04c836488b994b62bcc1809ee8e30e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d4b20482c445f98ff21666cffed149",
            "max": 28299,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea41f8c98beb4bf389487ccd788df63e",
            "value": 28299
          }
        },
        "0e47485d5cf54a7ba7edf1b3d792ccf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10357dd5b8443bd9e3e1fc7ad2ca71f",
            "placeholder": "​",
            "style": "IPY_MODEL_2f69223abf4344bf987695a50f292de9",
            "value": " 28299/28299 [00:01&lt;00:00, 15574.07 examples/s]"
          }
        },
        "130fc950d2094b67a688eeafdbae3d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172f421390f3478698e5a351d9e46f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a2a84ad9e243cea50239d8c6dd07f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7d4b20482c445f98ff21666cffed149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea41f8c98beb4bf389487ccd788df63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d10357dd5b8443bd9e3e1fc7ad2ca71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f69223abf4344bf987695a50f292de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "867234609ea64f1caad69cbc2ba13c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_105e200a5d0a405fb111a96197236038",
              "IPY_MODEL_06bc30cfe2844e6e93ffcfec85ebc6ad",
              "IPY_MODEL_ec57d796e2f747b7adbcc11cb0e22fc5"
            ],
            "layout": "IPY_MODEL_256c1fb236ec4669a15cebbd327f9998"
          }
        },
        "105e200a5d0a405fb111a96197236038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bd0dd8926f544dfb0dda1c95a5a3c7d",
            "placeholder": "​",
            "style": "IPY_MODEL_b0c064db5339469ba47118b60befb812",
            "value": "Generating val split: 100%"
          }
        },
        "06bc30cfe2844e6e93ffcfec85ebc6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baaf572724fc4f108796c8cfaf3a6aab",
            "max": 1920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d1a6a62b8cb4fe483405195f8cf4444",
            "value": 1920
          }
        },
        "ec57d796e2f747b7adbcc11cb0e22fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703201c6ea5b4ddeab00662bd1e349dd",
            "placeholder": "​",
            "style": "IPY_MODEL_ae9c74e4d0ef4d0a915590a8001e5927",
            "value": " 1920/1920 [00:00&lt;00:00, 6811.58 examples/s]"
          }
        },
        "256c1fb236ec4669a15cebbd327f9998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd0dd8926f544dfb0dda1c95a5a3c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c064db5339469ba47118b60befb812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baaf572724fc4f108796c8cfaf3a6aab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1a6a62b8cb4fe483405195f8cf4444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "703201c6ea5b4ddeab00662bd1e349dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae9c74e4d0ef4d0a915590a8001e5927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "caebde612f8945558be77e3ab3004d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e7a16827b14408e86a5102a7250c087",
              "IPY_MODEL_779df7f50ce34296859ed0585d4abfa7",
              "IPY_MODEL_3bb800295f174612a691e8e13be783ab"
            ],
            "layout": "IPY_MODEL_64abfbb956d9461695537b44b21b0c1a"
          }
        },
        "5e7a16827b14408e86a5102a7250c087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a994c4cb06403d8f321d7098ea1007",
            "placeholder": "​",
            "style": "IPY_MODEL_16677c8842ff4af5b53ca1a61c78518a",
            "value": "Generating test split: 100%"
          }
        },
        "779df7f50ce34296859ed0585d4abfa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7509231b443142be885c28b6f6f6d56d",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e531afc60294e77a05660b936c521fb",
            "value": 2500
          }
        },
        "3bb800295f174612a691e8e13be783ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a65f9da5efd8485dbf94a71574c26962",
            "placeholder": "​",
            "style": "IPY_MODEL_88a55d6b128b4c02997ebb13f231d804",
            "value": " 2500/2500 [00:00&lt;00:00, 6799.28 examples/s]"
          }
        },
        "64abfbb956d9461695537b44b21b0c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a994c4cb06403d8f321d7098ea1007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16677c8842ff4af5b53ca1a61c78518a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7509231b443142be885c28b6f6f6d56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e531afc60294e77a05660b936c521fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a65f9da5efd8485dbf94a71574c26962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a55d6b128b4c02997ebb13f231d804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "228c1208ed2240afaf8b485bdab99aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe120ae99c9a426faa69e85be9beb0e9",
              "IPY_MODEL_b1282feb7c674280ad857b4560e28474",
              "IPY_MODEL_8edc56355c17489c9caffa7bb47d2164"
            ],
            "layout": "IPY_MODEL_b78304bafd1e442ea9331f33c77f1a83"
          }
        },
        "fe120ae99c9a426faa69e85be9beb0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac00e0f67ab6408fb8ae2761efcc46a1",
            "placeholder": "​",
            "style": "IPY_MODEL_3a5ff848dda14c4fa2eb4896c236e0bd",
            "value": "config.json: 100%"
          }
        },
        "b1282feb7c674280ad857b4560e28474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e04c228ccf443dcb073718a5d7f3075",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faeb200fbbeb4e5e8c88928231ef4127",
            "value": 727
          }
        },
        "8edc56355c17489c9caffa7bb47d2164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7796960879ed46f0acec47b6b32d8559",
            "placeholder": "​",
            "style": "IPY_MODEL_4c70b3b7092245f4a512cb34cced5462",
            "value": " 727/727 [00:00&lt;00:00, 93.5kB/s]"
          }
        },
        "b78304bafd1e442ea9331f33c77f1a83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac00e0f67ab6408fb8ae2761efcc46a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5ff848dda14c4fa2eb4896c236e0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e04c228ccf443dcb073718a5d7f3075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faeb200fbbeb4e5e8c88928231ef4127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7796960879ed46f0acec47b6b32d8559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c70b3b7092245f4a512cb34cced5462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d4031538c94679871c3c8cfb1d3857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44eab69245664aceb3bca5a3a9a357d1",
              "IPY_MODEL_e39037ec039d428980b85e8492172a28",
              "IPY_MODEL_ed2cbed4e87b44cf90c2e6e1987e57c2"
            ],
            "layout": "IPY_MODEL_ca9667b5292446ccad448dd6683ebfe9"
          }
        },
        "44eab69245664aceb3bca5a3a9a357d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd6c78e534e4f709b6471f5837e7e38",
            "placeholder": "​",
            "style": "IPY_MODEL_e63e86c0f108452c9c296f3d0b2f520f",
            "value": "tokenizer_config.json: "
          }
        },
        "e39037ec039d428980b85e8492172a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ceab83c28024c77af3ec718d66b61ac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc430c1c999145c98330349482bebea7",
            "value": 1
          }
        },
        "ed2cbed4e87b44cf90c2e6e1987e57c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d3b3ae3a1e247f7af5a8dd211132880",
            "placeholder": "​",
            "style": "IPY_MODEL_c7f45c805da74e5cb9b6373a1dd2c544",
            "value": " 9.38k/? [00:00&lt;00:00, 939kB/s]"
          }
        },
        "ca9667b5292446ccad448dd6683ebfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd6c78e534e4f709b6471f5837e7e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e63e86c0f108452c9c296f3d0b2f520f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ceab83c28024c77af3ec718d66b61ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dc430c1c999145c98330349482bebea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d3b3ae3a1e247f7af5a8dd211132880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f45c805da74e5cb9b6373a1dd2c544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3202c585d9604418884ec3c0c2d136a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fa3e2d848f74d25a6445b780f256311",
              "IPY_MODEL_99b89224be044719807364051d0f5a8a",
              "IPY_MODEL_7487db88f4a44efb9eb9d2d050761654"
            ],
            "layout": "IPY_MODEL_9628b7ac9e8f44359051d1926e6beb73"
          }
        },
        "0fa3e2d848f74d25a6445b780f256311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a73e071d112f484f864f0af70a29abd4",
            "placeholder": "​",
            "style": "IPY_MODEL_ebed681f45c74db18e7c987e8bc686a7",
            "value": "vocab.json: "
          }
        },
        "99b89224be044719807364051d0f5a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3cb073c6274ecabc3cf5125c5ea1b1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_260f78e6595943c6bb4ddf5cd8adc2c8",
            "value": 1
          }
        },
        "7487db88f4a44efb9eb9d2d050761654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a4f4f4b46554a19be8072920916593e",
            "placeholder": "​",
            "style": "IPY_MODEL_623ebebe5e954d73ba66f44426190576",
            "value": " 2.78M/? [00:01&lt;00:00, 1.99MB/s]"
          }
        },
        "9628b7ac9e8f44359051d1926e6beb73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73e071d112f484f864f0af70a29abd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebed681f45c74db18e7c987e8bc686a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a3cb073c6274ecabc3cf5125c5ea1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "260f78e6595943c6bb4ddf5cd8adc2c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a4f4f4b46554a19be8072920916593e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623ebebe5e954d73ba66f44426190576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f5284d1b7de416d97ecfd010ec3b72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14aea6c9e0924ea9a4898a36395f2efd",
              "IPY_MODEL_aadc1a78e24b44a0854233b16fed2781",
              "IPY_MODEL_f404f482017946e0a5d9359878d1bc36"
            ],
            "layout": "IPY_MODEL_90cb5867d88e4dcc89736f6ce54f2e2b"
          }
        },
        "14aea6c9e0924ea9a4898a36395f2efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b8724f38e0433ab5d556e8007eb1fa",
            "placeholder": "​",
            "style": "IPY_MODEL_7e105fac559f417abe58d2b6e292b39b",
            "value": "merges.txt: "
          }
        },
        "aadc1a78e24b44a0854233b16fed2781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14dde1b8c8024150894e0a703d01c544",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b1e64213581483fbfb6b437d328755b",
            "value": 1
          }
        },
        "f404f482017946e0a5d9359878d1bc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538e8a4ee0434d2dbd0e6f9f3333ebdf",
            "placeholder": "​",
            "style": "IPY_MODEL_9d162b29e6054c36bd869d2795e15751",
            "value": " 1.67M/? [00:00&lt;00:00, 30.8MB/s]"
          }
        },
        "90cb5867d88e4dcc89736f6ce54f2e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b8724f38e0433ab5d556e8007eb1fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e105fac559f417abe58d2b6e292b39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14dde1b8c8024150894e0a703d01c544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4b1e64213581483fbfb6b437d328755b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "538e8a4ee0434d2dbd0e6f9f3333ebdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d162b29e6054c36bd869d2795e15751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c595671e5fd4b58be1cf38562ed3eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ffc76d5ca2c49caaebeb7c04e1f2eac",
              "IPY_MODEL_972de012b667458d81536d942722e282",
              "IPY_MODEL_90aa79fc34264cbfa3bfbe5671697d3b"
            ],
            "layout": "IPY_MODEL_1a1e0e6c7f004b5e8e521444cc8b4b47"
          }
        },
        "0ffc76d5ca2c49caaebeb7c04e1f2eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaf4f0d0ba124007aaaa1cb2a70d35bc",
            "placeholder": "​",
            "style": "IPY_MODEL_6c8bd88ea451499a950ef80215d3c2e0",
            "value": "tokenizer.json: 100%"
          }
        },
        "972de012b667458d81536d942722e282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0abb530147474be4931c287811fc62db",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fe541394ecf43ae878c092b7b187a23",
            "value": 11422654
          }
        },
        "90aa79fc34264cbfa3bfbe5671697d3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5eee970ac248ada6ef94f9867d2862",
            "placeholder": "​",
            "style": "IPY_MODEL_9bed078045a1461c98ffacbc1b9e658f",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 59.0MB/s]"
          }
        },
        "1a1e0e6c7f004b5e8e521444cc8b4b47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf4f0d0ba124007aaaa1cb2a70d35bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8bd88ea451499a950ef80215d3c2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0abb530147474be4931c287811fc62db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe541394ecf43ae878c092b7b187a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec5eee970ac248ada6ef94f9867d2862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bed078045a1461c98ffacbc1b9e658f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c881e05e0ab4800abda1fdc3d520714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb08f358dfc14fcf96e3b1f68610a983",
              "IPY_MODEL_96fdd641b1fa480f94cd488942770d72",
              "IPY_MODEL_56781504e82d4fa1a6794f6cf152c03d"
            ],
            "layout": "IPY_MODEL_70f9339b31014b63a237051a6631dacd"
          }
        },
        "fb08f358dfc14fcf96e3b1f68610a983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce917e446c534ed4b9c861e6a9d3da12",
            "placeholder": "​",
            "style": "IPY_MODEL_6378b26457c8489dabec3d858aa7aa8e",
            "value": "model.safetensors.index.json: "
          }
        },
        "96fdd641b1fa480f94cd488942770d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd700f49d4084f3ea601fd4eb0ddaf3a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74720eda002d4812b6902dc457f011d7",
            "value": 1
          }
        },
        "56781504e82d4fa1a6794f6cf152c03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e7422ae162248358b103c691cb89716",
            "placeholder": "​",
            "style": "IPY_MODEL_b44060d5e2ac46c5bbd409a5a5e8ab17",
            "value": " 32.8k/? [00:00&lt;00:00, 3.47MB/s]"
          }
        },
        "70f9339b31014b63a237051a6631dacd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce917e446c534ed4b9c861e6a9d3da12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6378b26457c8489dabec3d858aa7aa8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd700f49d4084f3ea601fd4eb0ddaf3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "74720eda002d4812b6902dc457f011d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e7422ae162248358b103c691cb89716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b44060d5e2ac46c5bbd409a5a5e8ab17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e1cb51cd6104daab62dbb64874b751c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87109e15ad0d4bd5b6b78b2037e78452",
              "IPY_MODEL_b227887cd8dd41f58448e456831294de",
              "IPY_MODEL_9cd724f4267e46f9bd16d2064ea015ef"
            ],
            "layout": "IPY_MODEL_0c91a8cb08e1466e96abacc9e2e2b485"
          }
        },
        "87109e15ad0d4bd5b6b78b2037e78452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29657154f7514be1b6b1b8833cd8e645",
            "placeholder": "​",
            "style": "IPY_MODEL_196dfdb5b6fe4124a546822841479d65",
            "value": "Download complete: 100%"
          }
        },
        "b227887cd8dd41f58448e456831294de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_758191a079e543ecadc711e990da55d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fd8598970f9434ea96903c3ea21a06c",
            "value": 1
          }
        },
        "9cd724f4267e46f9bd16d2064ea015ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4078aed14b24d16b835bd17b04842f9",
            "placeholder": "​",
            "style": "IPY_MODEL_dd77867eaf0a466bafe1e72aa4b6413b",
            "value": " 8.04G/8.04G [00:26&lt;00:00, 370MB/s]"
          }
        },
        "0c91a8cb08e1466e96abacc9e2e2b485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29657154f7514be1b6b1b8833cd8e645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196dfdb5b6fe4124a546822841479d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "758191a079e543ecadc711e990da55d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6fd8598970f9434ea96903c3ea21a06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4078aed14b24d16b835bd17b04842f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd77867eaf0a466bafe1e72aa4b6413b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d91bebb08c5a4e0fad5a2df2c0691950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35112beae63a457492873c6e1c5c0bb8",
              "IPY_MODEL_ad2f1f0e64c049f499ddbf7ce4760e9f",
              "IPY_MODEL_ca160d9d80ad40879c452d1025f07fe4"
            ],
            "layout": "IPY_MODEL_2121c139647942668681b221d862fbc7"
          }
        },
        "35112beae63a457492873c6e1c5c0bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d29440efd9f745438a8195a214709dda",
            "placeholder": "​",
            "style": "IPY_MODEL_bf57ab1832164516a2d9d4251abd0fd8",
            "value": "Fetching 3 files: 100%"
          }
        },
        "ad2f1f0e64c049f499ddbf7ce4760e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e2559a7b5941f38d65b31a5caaf58a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dab29e18db5d49b6b1d153e799f10d70",
            "value": 3
          }
        },
        "ca160d9d80ad40879c452d1025f07fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80182e3c2cb4f0d8b1f9c86c4e9f094",
            "placeholder": "​",
            "style": "IPY_MODEL_a6957aecfcc84cb3934ffdc0972dfd2a",
            "value": " 3/3 [00:26&lt;00:00, 26.67s/it]"
          }
        },
        "2121c139647942668681b221d862fbc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d29440efd9f745438a8195a214709dda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf57ab1832164516a2d9d4251abd0fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7e2559a7b5941f38d65b31a5caaf58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab29e18db5d49b6b1d153e799f10d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a80182e3c2cb4f0d8b1f9c86c4e9f094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6957aecfcc84cb3934ffdc0972dfd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da4a2353fd70470f9c744d7104259dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2adb3390f36347d9b1756ffb9f132dbb",
              "IPY_MODEL_0d69978f2b2f4bc792015210f8e37172",
              "IPY_MODEL_ad34c2b1a5ee442fa7db682dc9aab8df"
            ],
            "layout": "IPY_MODEL_e86afa07114f4bcc902caa44d2be1349"
          }
        },
        "2adb3390f36347d9b1756ffb9f132dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68357f66e1cf48a3aa5f33c18d25272d",
            "placeholder": "​",
            "style": "IPY_MODEL_a709c8d0d6e044e5971282f24c1675c1",
            "value": "Loading weights: 100%"
          }
        },
        "0d69978f2b2f4bc792015210f8e37172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0791e1d01ca4542a82649d2bd70dda9",
            "max": 398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8218b2bb1be549448626dc6eaabf4e53",
            "value": 398
          }
        },
        "ad34c2b1a5ee442fa7db682dc9aab8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333735c9af4d41c7998bbeec3a6846fd",
            "placeholder": "​",
            "style": "IPY_MODEL_c604d0e27e994223a1428311f68ce39c",
            "value": " 398/398 [00:02&lt;00:00, 154.26it/s, Materializing param=model.norm.weight]"
          }
        },
        "e86afa07114f4bcc902caa44d2be1349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68357f66e1cf48a3aa5f33c18d25272d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a709c8d0d6e044e5971282f24c1675c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0791e1d01ca4542a82649d2bd70dda9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8218b2bb1be549448626dc6eaabf4e53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "333735c9af4d41c7998bbeec3a6846fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c604d0e27e994223a1428311f68ce39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad68d5fd34ce4eebbca3b1d9d047326f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8080490ac5ff406591ac618ae0c3425d",
              "IPY_MODEL_c8a7127d63bf4e5e8b4adc3c15185dfe",
              "IPY_MODEL_30dc0e0742884aa18b12bdd1c471262c"
            ],
            "layout": "IPY_MODEL_e6d1742f545f486caca76e1ae0a7207f"
          }
        },
        "8080490ac5ff406591ac618ae0c3425d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686a98ce8a46452ba673e2fbba3bb60d",
            "placeholder": "​",
            "style": "IPY_MODEL_86c79f915bd04c23895f011b57fc03ed",
            "value": "generation_config.json: 100%"
          }
        },
        "c8a7127d63bf4e5e8b4adc3c15185dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd57dd58c7a74be296c10a817b2a204c",
            "max": 238,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0158a33c4e4d436f8ec10017535b4f81",
            "value": 238
          }
        },
        "30dc0e0742884aa18b12bdd1c471262c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2797d4a271f540879d9cac327ba06053",
            "placeholder": "​",
            "style": "IPY_MODEL_c45a04d7803244d0b32cd2411a102fe6",
            "value": " 238/238 [00:00&lt;00:00, 30.7kB/s]"
          }
        },
        "e6d1742f545f486caca76e1ae0a7207f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686a98ce8a46452ba673e2fbba3bb60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c79f915bd04c23895f011b57fc03ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd57dd58c7a74be296c10a817b2a204c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0158a33c4e4d436f8ec10017535b4f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2797d4a271f540879d9cac327ba06053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c45a04d7803244d0b32cd2411a102fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f28c5b932e6b4d5c95491ff7d50a7cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fefcc53c610042ba9f1f33a82089fc62",
              "IPY_MODEL_33705fff2b75416da61efb071292ac10",
              "IPY_MODEL_eb7823a8d0c34aaea3cab9c376992528"
            ],
            "layout": "IPY_MODEL_ccec84611810423293f33fe37e5a56aa"
          }
        },
        "fefcc53c610042ba9f1f33a82089fc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea2d1e7720d6496ab57bea52c4738bf6",
            "placeholder": "​",
            "style": "IPY_MODEL_6b1ab53dbe8b4854abe906ff9c5d4484",
            "value": "config.json: "
          }
        },
        "33705fff2b75416da61efb071292ac10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae1f79bad324e14aa97580e4aef50ef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7198209673e4468e88bcbadfd31f8128",
            "value": 1
          }
        },
        "eb7823a8d0c34aaea3cab9c376992528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_809af8227b2749cbb68e861ff9af6d02",
            "placeholder": "​",
            "style": "IPY_MODEL_00f0a90528e14431ad8bbebbad195d57",
            "value": " 5.02k/? [00:00&lt;00:00, 517kB/s]"
          }
        },
        "ccec84611810423293f33fe37e5a56aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2d1e7720d6496ab57bea52c4738bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1ab53dbe8b4854abe906ff9c5d4484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cae1f79bad324e14aa97580e4aef50ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7198209673e4468e88bcbadfd31f8128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "809af8227b2749cbb68e861ff9af6d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00f0a90528e14431ad8bbebbad195d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbf51b16c6f24bcd97cf06b01825a47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95280351fc274b25b6f84533b28c74ef",
              "IPY_MODEL_1be8154f8e3145d994f03903ea849603",
              "IPY_MODEL_86db0db8ea744702a281e734b7c95ac5"
            ],
            "layout": "IPY_MODEL_d82c404b1d32411fbb7b092e58016498"
          }
        },
        "95280351fc274b25b6f84533b28c74ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a95981f27be48059c00f6b5217bf6bd",
            "placeholder": "​",
            "style": "IPY_MODEL_186542f658b349b4beffa5c946930003",
            "value": "pytorch_model.bin:  66%"
          }
        },
        "1be8154f8e3145d994f03903ea849603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc024e6017fc41bba56877b9f3833150",
            "max": 809199995,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07b9d18b551f42e9956b66966167b1b0",
            "value": 536810630
          }
        },
        "86db0db8ea744702a281e734b7c95ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c7f550b7a64b61915ed1fa77881220",
            "placeholder": "​",
            "style": "IPY_MODEL_aad15e09ddea451cade5f4be945b4d08",
            "value": " 537M/809M [00:04&lt;00:03, 84.8MB/s]"
          }
        },
        "d82c404b1d32411fbb7b092e58016498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a95981f27be48059c00f6b5217bf6bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186542f658b349b4beffa5c946930003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc024e6017fc41bba56877b9f3833150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b9d18b551f42e9956b66966167b1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2c7f550b7a64b61915ed1fa77881220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad15e09ddea451cade5f4be945b4d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c95352a043a4ec28eb491a740086f43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_535f3c4ca2e64f2eb662f993035115f5",
              "IPY_MODEL_59203cfc92734831a5d200d2e94e8a59",
              "IPY_MODEL_a35ace0f74c0430a962d1109a6cb4207"
            ],
            "layout": "IPY_MODEL_a9f45db87524458988072858cc290772"
          }
        },
        "535f3c4ca2e64f2eb662f993035115f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba428c9ea7448feaa9c071c834a6a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_b72454e2b4254daf9d77d6d4d73c18a8",
            "value": "Loading weights: 100%"
          }
        },
        "59203cfc92734831a5d200d2e94e8a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7974e46806c437a8e721d3e89f3d056",
            "max": 484,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1c636aa152e4a57b70860fbfec4c33b",
            "value": 484
          }
        },
        "a35ace0f74c0430a962d1109a6cb4207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d42bb8c9be7f4456928f75cd4ce8d52d",
            "placeholder": "​",
            "style": "IPY_MODEL_8d1c8abfd930445cb6fe09bc317f832a",
            "value": " 484/484 [00:00&lt;00:00, 1564.10it/s, Materializing param=encoder.encoder.layers.3.blocks.1.output.dense.weight]"
          }
        },
        "a9f45db87524458988072858cc290772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba428c9ea7448feaa9c071c834a6a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72454e2b4254daf9d77d6d4d73c18a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7974e46806c437a8e721d3e89f3d056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c636aa152e4a57b70860fbfec4c33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d42bb8c9be7f4456928f75cd4ce8d52d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d1c8abfd930445cb6fe09bc317f832a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "841c7fbdc9f44812a48ff4b91a856e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9539096515b04b69a3268404ba652d8b",
              "IPY_MODEL_a5be4968ace740f2b866005c38985123",
              "IPY_MODEL_7e527c11ee8c421daee66bdd1aa6a01e"
            ],
            "layout": "IPY_MODEL_d23fae0e9863461cb229292df019bad9"
          }
        },
        "9539096515b04b69a3268404ba652d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27c64368b5464dbbb17116c8a149d04d",
            "placeholder": "​",
            "style": "IPY_MODEL_ac89abb264de4b87961a76e0fca9a88f",
            "value": "model.safetensors:  66%"
          }
        },
        "a5be4968ace740f2b866005c38985123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3a8fa8819d4ff0a07c0777ae6e6fc9",
            "max": 809095376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b304cd4a5cdf4718a3d1a0fd3c19e2cd",
            "value": 537716256
          }
        },
        "7e527c11ee8c421daee66bdd1aa6a01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cfdf0ec75414583966c6c51614880d2",
            "placeholder": "​",
            "style": "IPY_MODEL_37673033d4ed4409a9792b5e8df05651",
            "value": " 538M/809M [00:03&lt;00:03, 74.4MB/s]"
          }
        },
        "d23fae0e9863461cb229292df019bad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c64368b5464dbbb17116c8a149d04d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac89abb264de4b87961a76e0fca9a88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c3a8fa8819d4ff0a07c0777ae6e6fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b304cd4a5cdf4718a3d1a0fd3c19e2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cfdf0ec75414583966c6c51614880d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37673033d4ed4409a9792b5e8df05651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3766a10f795f48a197bcec1793ff13d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f670f42871e40848de085a7a320cc2c",
              "IPY_MODEL_8c52d076eb5447e6a09ffe4f0e5c0524",
              "IPY_MODEL_203c3212983244e4a0868152f935dc41"
            ],
            "layout": "IPY_MODEL_81a964b4e76147e9816d0c8f9dee388e"
          }
        },
        "7f670f42871e40848de085a7a320cc2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f952c78360a54c4d80c724f1e9012f9e",
            "placeholder": "​",
            "style": "IPY_MODEL_26a5cef2a9f144f5a7f5863d68ccbaa0",
            "value": "generation_config.json: 100%"
          }
        },
        "8c52d076eb5447e6a09ffe4f0e5c0524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9f5f51814b45e39dfb3b0436ec9473",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a26310a2f9c94f4f9c9399d21c0cd4b3",
            "value": 181
          }
        },
        "203c3212983244e4a0868152f935dc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321cb39e3175441290f46a0549ad4fa1",
            "placeholder": "​",
            "style": "IPY_MODEL_c0fcc1a9de5c4a17b56f851f5d71575e",
            "value": " 181/181 [00:00&lt;00:00, 20.2kB/s]"
          }
        },
        "81a964b4e76147e9816d0c8f9dee388e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f952c78360a54c4d80c724f1e9012f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a5cef2a9f144f5a7f5863d68ccbaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c9f5f51814b45e39dfb3b0436ec9473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26310a2f9c94f4f9c9399d21c0cd4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "321cb39e3175441290f46a0549ad4fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0fcc1a9de5c4a17b56f851f5d71575e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c02cc532d7649569abbfda1b860dc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15327f1c055f4248823ab881f2d83169",
              "IPY_MODEL_2aed3f5c2e7b4274acc62dd8f36e2b3f",
              "IPY_MODEL_f3b77717c3b244009ce4243556ecdc00"
            ],
            "layout": "IPY_MODEL_d5bc3124cb8747e09a8b5c25ed54bd8c"
          }
        },
        "15327f1c055f4248823ab881f2d83169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93578d83d31432da491354c49930333",
            "placeholder": "​",
            "style": "IPY_MODEL_699d4d07a2d84c7f8f886f5eca9e2ee2",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "2aed3f5c2e7b4274acc62dd8f36e2b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6106649efa5644c08d395bb5ca65b374",
            "max": 439,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2639e05c304e4668a2fd2f724a3141b8",
            "value": 439
          }
        },
        "f3b77717c3b244009ce4243556ecdc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0941df6ebac046e7a4d011a41661ae24",
            "placeholder": "​",
            "style": "IPY_MODEL_cf2d85503237475d90d77cac09966571",
            "value": " 439/439 [00:00&lt;00:00, 49.0kB/s]"
          }
        },
        "d5bc3124cb8747e09a8b5c25ed54bd8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93578d83d31432da491354c49930333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "699d4d07a2d84c7f8f886f5eca9e2ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6106649efa5644c08d395bb5ca65b374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2639e05c304e4668a2fd2f724a3141b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0941df6ebac046e7a4d011a41661ae24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf2d85503237475d90d77cac09966571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b9f4c3888304f16b961e401abee80ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32c9bf35a0664d9f96d8a78a4065f6b1",
              "IPY_MODEL_883d0e647f9e49f19e7997a7681b9348",
              "IPY_MODEL_f65aa58bc9894ee9b60cff5e2ea3381d"
            ],
            "layout": "IPY_MODEL_93963827ccde48daa46a105bbbfa1dce"
          }
        },
        "32c9bf35a0664d9f96d8a78a4065f6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9251e73a164ce687d81d8f57201afc",
            "placeholder": "​",
            "style": "IPY_MODEL_d450bbf9e4674442b9cfb92be79798a4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "883d0e647f9e49f19e7997a7681b9348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d0ec6277b5b4aae9771eb8ace55ca95",
            "max": 510,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb1a98cfa9b34292a72f781f211406e7",
            "value": 510
          }
        },
        "f65aa58bc9894ee9b60cff5e2ea3381d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75473f1cef634641b038762dadc5765a",
            "placeholder": "​",
            "style": "IPY_MODEL_a9e66a6493b54f7398704e47f8dac307",
            "value": " 510/510 [00:00&lt;00:00, 54.7kB/s]"
          }
        },
        "93963827ccde48daa46a105bbbfa1dce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb9251e73a164ce687d81d8f57201afc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d450bbf9e4674442b9cfb92be79798a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d0ec6277b5b4aae9771eb8ace55ca95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb1a98cfa9b34292a72f781f211406e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75473f1cef634641b038762dadc5765a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e66a6493b54f7398704e47f8dac307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c19dfff72c248daa123879e0edf7954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdb7f806d2cd440e9379103c17956fd4",
              "IPY_MODEL_434f65bc637842f980843b86043a0034",
              "IPY_MODEL_49e10e2a726940c8acdc944bd4cdbffe"
            ],
            "layout": "IPY_MODEL_7d623817708149369d7531c0661e1bd4"
          }
        },
        "cdb7f806d2cd440e9379103c17956fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63580c366a024135b877e7f47ca7017e",
            "placeholder": "​",
            "style": "IPY_MODEL_448721bac95b46e382f76101fedfca87",
            "value": "tokenizer.json: "
          }
        },
        "434f65bc637842f980843b86043a0034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_261cce1555f64b108eb3cc5505f4606a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d827115ce8cc448799253c91e84b4f7f",
            "value": 1
          }
        },
        "49e10e2a726940c8acdc944bd4cdbffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76093d5dc46744d98c196e624a5f9c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_74478677b377408aac0370312c1d2f10",
            "value": " 4.01M/? [00:00&lt;00:00, 99.5MB/s]"
          }
        },
        "7d623817708149369d7531c0661e1bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63580c366a024135b877e7f47ca7017e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "448721bac95b46e382f76101fedfca87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "261cce1555f64b108eb3cc5505f4606a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d827115ce8cc448799253c91e84b4f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76093d5dc46744d98c196e624a5f9c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74478677b377408aac0370312c1d2f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5914843230c64391a5a48e7bff0d56a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8dcfeb99ec5485085fba044552192b8",
              "IPY_MODEL_eacdfb01237d465d9a56cf66246757e8",
              "IPY_MODEL_dbb4840135dd48f8b699486962e80a2f"
            ],
            "layout": "IPY_MODEL_a6ebf59d808a402698878d5cfc5b50c5"
          }
        },
        "f8dcfeb99ec5485085fba044552192b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a97a887e464122893c5f1aab8e53bf",
            "placeholder": "​",
            "style": "IPY_MODEL_6f8765d82293478682d9b9426059800b",
            "value": "added_tokens.json: 100%"
          }
        },
        "eacdfb01237d465d9a56cf66246757e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6bb1f2fb2a7490eb38f0ecbb6034bf7",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd921570c39c4c9296925eb4159aa5e7",
            "value": 235
          }
        },
        "dbb4840135dd48f8b699486962e80a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe518c61af94dfeba3c66efb045b207",
            "placeholder": "​",
            "style": "IPY_MODEL_05eb66221ee54817bb98e15eb3a1d8e4",
            "value": " 235/235 [00:00&lt;00:00, 28.6kB/s]"
          }
        },
        "a6ebf59d808a402698878d5cfc5b50c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a97a887e464122893c5f1aab8e53bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8765d82293478682d9b9426059800b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6bb1f2fb2a7490eb38f0ecbb6034bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd921570c39c4c9296925eb4159aa5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebe518c61af94dfeba3c66efb045b207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05eb66221ee54817bb98e15eb3a1d8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30c32d0df6724cb6b48d72091a9ddb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53540fd5c8744ea2b936adcb2ee1f232",
              "IPY_MODEL_586268d2c3854fe5b8f2d212621202cd",
              "IPY_MODEL_84d6fb05cd9845bfb2aeccc6a87919df"
            ],
            "layout": "IPY_MODEL_e850ebe150804ceebd70b6e5ce8e7bf8"
          }
        },
        "53540fd5c8744ea2b936adcb2ee1f232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61442e4db9ce4a5a9dfc0925f3f35944",
            "placeholder": "​",
            "style": "IPY_MODEL_10edc8ea5edf425ba06d0d0af3dc2c9c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "586268d2c3854fe5b8f2d212621202cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df87f4c5490a41139e98fbe64e743447",
            "max": 355,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a58470a03179453a9a81022f7952a710",
            "value": 355
          }
        },
        "84d6fb05cd9845bfb2aeccc6a87919df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e615be3f7554f18aa38e55559fad1cb",
            "placeholder": "​",
            "style": "IPY_MODEL_4e0ef12785bf431c99dca189f271ec29",
            "value": " 355/355 [00:00&lt;00:00, 49.1kB/s]"
          }
        },
        "e850ebe150804ceebd70b6e5ce8e7bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61442e4db9ce4a5a9dfc0925f3f35944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10edc8ea5edf425ba06d0d0af3dc2c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df87f4c5490a41139e98fbe64e743447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a58470a03179453a9a81022f7952a710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e615be3f7554f18aa38e55559fad1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e0ef12785bf431c99dca189f271ec29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eab62f52ec4642429df4891f9db6b488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e4471f3885f4b87897210661165adbd",
              "IPY_MODEL_214b289fffa3434990b8b8ce5ed1f2b1",
              "IPY_MODEL_305841c1c2f54617b3a2ea7f08a46b66"
            ],
            "layout": "IPY_MODEL_5135a40f847849fc8206c2099fe726a8"
          }
        },
        "5e4471f3885f4b87897210661165adbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90e9b43360a4599bfcc292d5dc17f8d",
            "placeholder": "​",
            "style": "IPY_MODEL_fa93942fe88d483f9f2f856156450f68",
            "value": "README.md: 100%"
          }
        },
        "214b289fffa3434990b8b8ce5ed1f2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbfeb44ea4e46ef893c8e982922be45",
            "max": 852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbe25b4d9d2341988d192d2f9ab97b6e",
            "value": 852
          }
        },
        "305841c1c2f54617b3a2ea7f08a46b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f087bd15c54aa4b5a72407cf4de13e",
            "placeholder": "​",
            "style": "IPY_MODEL_28804b676d6d45578cbc7890471bfaea",
            "value": " 852/852 [00:00&lt;00:00, 117kB/s]"
          }
        },
        "5135a40f847849fc8206c2099fe726a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90e9b43360a4599bfcc292d5dc17f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa93942fe88d483f9f2f856156450f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bbfeb44ea4e46ef893c8e982922be45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe25b4d9d2341988d192d2f9ab97b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1f087bd15c54aa4b5a72407cf4de13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28804b676d6d45578cbc7890471bfaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eca265101a945e99240388d073bd059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_541cce30fa7f4268a241569acad2b1d1",
              "IPY_MODEL_f77c5f6a5b944aa4a37daf47f6a8275a",
              "IPY_MODEL_f0dd97b1cf0b459a95745c2628376db2"
            ],
            "layout": "IPY_MODEL_69f5c2f374c84a2d898f14b020f6a1eb"
          }
        },
        "541cce30fa7f4268a241569acad2b1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a64a37aac0468dbd21e72fa95412bf",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc5099cd9624f668eee45f9691b54c8",
            "value": "data/train-00000-of-00003-49492f364babfa(…): 100%"
          }
        },
        "f77c5f6a5b944aa4a37daf47f6a8275a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07aab01728ef49adbafde1f9003a21d9",
            "max": 219024215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_740f1087550645b1bdfdc2cf13c9b50b",
            "value": 219024215
          }
        },
        "f0dd97b1cf0b459a95745c2628376db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bca87714bf934d248836e9ce927fef91",
            "placeholder": "​",
            "style": "IPY_MODEL_cde1bced72144039a355f837f39292be",
            "value": " 219M/219M [00:02&lt;00:00, 131MB/s]"
          }
        },
        "69f5c2f374c84a2d898f14b020f6a1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a64a37aac0468dbd21e72fa95412bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc5099cd9624f668eee45f9691b54c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07aab01728ef49adbafde1f9003a21d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740f1087550645b1bdfdc2cf13c9b50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bca87714bf934d248836e9ce927fef91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde1bced72144039a355f837f39292be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e3e1bcd06f84d2988bcd8e80c1f4590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcf8f092c6dc433095f712675feaafaa",
              "IPY_MODEL_4698472ed45341c1a4990eef285b5ee3",
              "IPY_MODEL_9c5ee25bd5dd46c4b2691bd124993ef5"
            ],
            "layout": "IPY_MODEL_3a4817f80c3c4087bbebb7ecbb40e396"
          }
        },
        "bcf8f092c6dc433095f712675feaafaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1ea26c351964cffa3e07cac12c3154a",
            "placeholder": "​",
            "style": "IPY_MODEL_d53dac18874c41f684d20fc8d915ae4c",
            "value": "data/train-00001-of-00003-7302bae5e425bb(…):  58%"
          }
        },
        "4698472ed45341c1a4990eef285b5ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cce84aab38ad447a931a1bb5b8edfefd",
            "max": 310674206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c488bd459e314f7e9eb51a100b94b57e",
            "value": 181533529
          }
        },
        "9c5ee25bd5dd46c4b2691bd124993ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02fb68ffca7340268dfeacf64404cab9",
            "placeholder": "​",
            "style": "IPY_MODEL_d70d150b5934406db59ba5349b883577",
            "value": " 182M/311M [00:01&lt;00:00, 556MB/s]"
          }
        },
        "3a4817f80c3c4087bbebb7ecbb40e396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ea26c351964cffa3e07cac12c3154a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d53dac18874c41f684d20fc8d915ae4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cce84aab38ad447a931a1bb5b8edfefd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c488bd459e314f7e9eb51a100b94b57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02fb68ffca7340268dfeacf64404cab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70d150b5934406db59ba5349b883577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1948c20bfc914ed9b5dadb71d2eb3a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41bb505d284b47bfb54e747253e628d8",
              "IPY_MODEL_5686cce5d2da40c68ad9818b910c94d0",
              "IPY_MODEL_e7ab762ea5a44a5cab212b2c01d72e9f"
            ],
            "layout": "IPY_MODEL_1bfe45f8d4d04caa8290a9c30c34b35e"
          }
        },
        "41bb505d284b47bfb54e747253e628d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f106ae970d6f43378ea9fec43eb7eb6a",
            "placeholder": "​",
            "style": "IPY_MODEL_b6c0b5de2e754dffa559f91f098e19df",
            "value": "data/train-00002-of-00003-194c9400785577(…): 100%"
          }
        },
        "5686cce5d2da40c68ad9818b910c94d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ffec8d5ca064f4786a3b28c3ea142e6",
            "max": 315273201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40d82259ed5a435bb382d2a58b48a0b1",
            "value": 315273201
          }
        },
        "e7ab762ea5a44a5cab212b2c01d72e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9be74cefaab54f76b729ec4a458de91b",
            "placeholder": "​",
            "style": "IPY_MODEL_363da27df72f4f29b5f3e9306500675d",
            "value": " 315M/315M [00:02&lt;00:00, 63.9MB/s]"
          }
        },
        "1bfe45f8d4d04caa8290a9c30c34b35e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f106ae970d6f43378ea9fec43eb7eb6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6c0b5de2e754dffa559f91f098e19df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ffec8d5ca064f4786a3b28c3ea142e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d82259ed5a435bb382d2a58b48a0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9be74cefaab54f76b729ec4a458de91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363da27df72f4f29b5f3e9306500675d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa011ee0312b4cb2817d18312c286125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10a0167e3607402e9a77ab37efc2357e",
              "IPY_MODEL_21a9293b910148be8a68201e7a20361a",
              "IPY_MODEL_17995c939c8342ec87bf3e4462020a8a"
            ],
            "layout": "IPY_MODEL_9afbaa9a22da42428203c1af240f16e3"
          }
        },
        "10a0167e3607402e9a77ab37efc2357e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0269244e54c84a7dad090e0d86080eaf",
            "placeholder": "​",
            "style": "IPY_MODEL_3953c828ce6248f680f40cd4c9c721e5",
            "value": "data/val-00000-of-00001-0f11003c77497969(…): 100%"
          }
        },
        "21a9293b910148be8a68201e7a20361a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fd3eb0408aa40f4aecaf2e0318c4a6b",
            "max": 50225558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74ce67e127304450b843a75ff4601592",
            "value": 50225558
          }
        },
        "17995c939c8342ec87bf3e4462020a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fc917887b244918d6588d68a69427d",
            "placeholder": "​",
            "style": "IPY_MODEL_142dd4c6b5c7409ea76a6a4a3b1513ef",
            "value": " 50.2M/50.2M [00:00&lt;00:00, 72.0MB/s]"
          }
        },
        "9afbaa9a22da42428203c1af240f16e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0269244e54c84a7dad090e0d86080eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3953c828ce6248f680f40cd4c9c721e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd3eb0408aa40f4aecaf2e0318c4a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ce67e127304450b843a75ff4601592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9fc917887b244918d6588d68a69427d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142dd4c6b5c7409ea76a6a4a3b1513ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c704896c082c41d1af8cb7a02834618f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90ccd2312f6041b69b5bbf0dc5c919be",
              "IPY_MODEL_7b081b1a74654a608169e219115cf337",
              "IPY_MODEL_5a733bf7314348c1a186bea313b819e1"
            ],
            "layout": "IPY_MODEL_c19d630a8ed947e6a759aba6571f7a82"
          }
        },
        "90ccd2312f6041b69b5bbf0dc5c919be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82df27b6cf4f4a4686886ec969b732db",
            "placeholder": "​",
            "style": "IPY_MODEL_51a1b69a38494ce88a08154b6f230c16",
            "value": "data/test-00000-of-00001-e2cd0b7a0f9eb20(…): 100%"
          }
        },
        "7b081b1a74654a608169e219115cf337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7f976e3fb744b40abbc25e1270f31f2",
            "max": 68898419,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856b1ff40b0145eea2b22ca7bc88aba1",
            "value": 68898419
          }
        },
        "5a733bf7314348c1a186bea313b819e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_452465a4d3ae41e9aed61c0673c26760",
            "placeholder": "​",
            "style": "IPY_MODEL_5006340699d94b40af39ec7f7ceef8cb",
            "value": " 68.9M/68.9M [00:00&lt;00:00, 664MB/s]"
          }
        },
        "c19d630a8ed947e6a759aba6571f7a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82df27b6cf4f4a4686886ec969b732db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a1b69a38494ce88a08154b6f230c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f976e3fb744b40abbc25e1270f31f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856b1ff40b0145eea2b22ca7bc88aba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "452465a4d3ae41e9aed61c0673c26760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5006340699d94b40af39ec7f7ceef8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d6bf5e4e343470daf5540036b1938ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_902ea199de0b47808e9ca797dc9bbbba",
              "IPY_MODEL_686f20edb58f4b35bed24d951261b218",
              "IPY_MODEL_76290aca4a3d40a19b2952b1224f0299"
            ],
            "layout": "IPY_MODEL_6aa097873e2240f9ba8dd2925487aa76"
          }
        },
        "902ea199de0b47808e9ca797dc9bbbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a180336d224a402a96b9a01b618e2e47",
            "placeholder": "​",
            "style": "IPY_MODEL_4a742536c66d453aaf9b31c84a428f30",
            "value": "Generating train split: 100%"
          }
        },
        "686f20edb58f4b35bed24d951261b218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47694425a75a4ca78346c8c0c8ebfe46",
            "max": 28299,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_914925cb74c54b2c9cd1e4bda638f1db",
            "value": 28299
          }
        },
        "76290aca4a3d40a19b2952b1224f0299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46b3bc0e667349ebaa0a6df624b6f7bb",
            "placeholder": "​",
            "style": "IPY_MODEL_c95d7ded5586438bbfb04f8f7d3e0f22",
            "value": " 28299/28299 [00:02&lt;00:00, 7785.88 examples/s]"
          }
        },
        "6aa097873e2240f9ba8dd2925487aa76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a180336d224a402a96b9a01b618e2e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a742536c66d453aaf9b31c84a428f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47694425a75a4ca78346c8c0c8ebfe46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "914925cb74c54b2c9cd1e4bda638f1db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46b3bc0e667349ebaa0a6df624b6f7bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c95d7ded5586438bbfb04f8f7d3e0f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7949c8d2c2334c5fbd73e0cdc4262c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_417e51a679d247ebb1b4a9e71027a789",
              "IPY_MODEL_6d994b9a288d4c41ba5e14f7c3e70d37",
              "IPY_MODEL_49f30b4c13bc4a158eae3986a5929fb0"
            ],
            "layout": "IPY_MODEL_1c0c1f8111f6421e9937aa4af96e4118"
          }
        },
        "417e51a679d247ebb1b4a9e71027a789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4777b6e8dfb498c8cbc49068752e97f",
            "placeholder": "​",
            "style": "IPY_MODEL_51f321c4d035482aa2a40409d5c1811c",
            "value": "Generating val split: 100%"
          }
        },
        "6d994b9a288d4c41ba5e14f7c3e70d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d68f8b0bf2ee4af2a7989d0d8e23094c",
            "max": 1920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad9c06033cf7428e8330d8c3d5c47b8c",
            "value": 1920
          }
        },
        "49f30b4c13bc4a158eae3986a5929fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07297ee4f8c429a8b69cbcbdc360561",
            "placeholder": "​",
            "style": "IPY_MODEL_7dedc0b7b011472086d8690a5d2ebeff",
            "value": " 1920/1920 [00:00&lt;00:00, 7630.00 examples/s]"
          }
        },
        "1c0c1f8111f6421e9937aa4af96e4118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4777b6e8dfb498c8cbc49068752e97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f321c4d035482aa2a40409d5c1811c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d68f8b0bf2ee4af2a7989d0d8e23094c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9c06033cf7428e8330d8c3d5c47b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b07297ee4f8c429a8b69cbcbdc360561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dedc0b7b011472086d8690a5d2ebeff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a0ade68fef740f8b342fb2067f9e0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e03e6cd94aec470cb153e710972d8158",
              "IPY_MODEL_433bcf76ec3f477f8bf492d195d612b7",
              "IPY_MODEL_ba7c0b547a7e4adba837a4de1879c497"
            ],
            "layout": "IPY_MODEL_a455453e00e6477e9ecdc08c04dff079"
          }
        },
        "e03e6cd94aec470cb153e710972d8158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea379833d0b2408d9e0984ec296d49ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac8c3b9608a4621bad47a200aed2dd4",
            "value": "Generating test split: 100%"
          }
        },
        "433bcf76ec3f477f8bf492d195d612b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a06a511885a48839a8d5891c5cbc0f7",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27fb3e3fd188485cbca2d702ed1638eb",
            "value": 2500
          }
        },
        "ba7c0b547a7e4adba837a4de1879c497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac88225699d4b298566f5bbe8ce105a",
            "placeholder": "​",
            "style": "IPY_MODEL_aa083fb3d3874a84a2e208add1503be1",
            "value": " 2500/2500 [00:00&lt;00:00, 12649.54 examples/s]"
          }
        },
        "a455453e00e6477e9ecdc08c04dff079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea379833d0b2408d9e0984ec296d49ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac8c3b9608a4621bad47a200aed2dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a06a511885a48839a8d5891c5cbc0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fb3e3fd188485cbca2d702ed1638eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dac88225699d4b298566f5bbe8ce105a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa083fb3d3874a84a2e208add1503be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b95a1065e0e4466ab6754cd6a81c070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b005fa930b644fdcacc60220196dc520",
              "IPY_MODEL_3a8d845994cb4252b73a22044330938c",
              "IPY_MODEL_91d79a1aa9394aebb70e55d5e390445d"
            ],
            "layout": "IPY_MODEL_f44120376530423e869feb2d5c0eadc1"
          }
        },
        "b005fa930b644fdcacc60220196dc520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4135c8bebc7848578d3485288e45b260",
            "placeholder": "​",
            "style": "IPY_MODEL_d7eb7c27e9b4418ebb47a87f0edf20ac",
            "value": "Download complete: "
          }
        },
        "3a8d845994cb4252b73a22044330938c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed4fe2dd57a4605b7348eb8106ba30b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_511a5096962f4781bcfbe2f2c04d7c1d",
            "value": 0
          }
        },
        "91d79a1aa9394aebb70e55d5e390445d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bdd0cb677f34368a89859a23f09a0a4",
            "placeholder": "​",
            "style": "IPY_MODEL_aab1204b9c9149dba41eb7d08d120117",
            "value": " 0.00/0.00 [00:00&lt;?, ?B/s]"
          }
        },
        "f44120376530423e869feb2d5c0eadc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4135c8bebc7848578d3485288e45b260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7eb7c27e9b4418ebb47a87f0edf20ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed4fe2dd57a4605b7348eb8106ba30b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "511a5096962f4781bcfbe2f2c04d7c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bdd0cb677f34368a89859a23f09a0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab1204b9c9149dba41eb7d08d120117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3f53af31b9f4dc2b1b2e44ea8660f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cea8bb80f58f4a5cb9298a264f4754c3",
              "IPY_MODEL_60e61fbad2214b6c934977ad3660cea3",
              "IPY_MODEL_f9b14ebc79b044dfbf10bf1ce7c80c68"
            ],
            "layout": "IPY_MODEL_caf98d8eb071434c98d9f1a5f431908d"
          }
        },
        "cea8bb80f58f4a5cb9298a264f4754c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25809f63534e446aab4b4606be533c56",
            "placeholder": "​",
            "style": "IPY_MODEL_205e5e7fd89c4dbd8805e6a6ab2205eb",
            "value": "Fetching 3 files: 100%"
          }
        },
        "60e61fbad2214b6c934977ad3660cea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fbd74ac0a1a496ba6fa5180bc098691",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee33db35e197447c889f5577171f4418",
            "value": 3
          }
        },
        "f9b14ebc79b044dfbf10bf1ce7c80c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027af948f19048cdb3427811940a9362",
            "placeholder": "​",
            "style": "IPY_MODEL_af4f86050a344a90bcb01b83a25013a6",
            "value": " 3/3 [00:00&lt;00:00, 327.84it/s]"
          }
        },
        "caf98d8eb071434c98d9f1a5f431908d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25809f63534e446aab4b4606be533c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205e5e7fd89c4dbd8805e6a6ab2205eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fbd74ac0a1a496ba6fa5180bc098691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee33db35e197447c889f5577171f4418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "027af948f19048cdb3427811940a9362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4f86050a344a90bcb01b83a25013a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da58cdf5d65f4942be496df49348de29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c8302d61fbc451988479397ad40c0d4",
              "IPY_MODEL_3ddbc95c9bdd4a928aef6167b621dca5",
              "IPY_MODEL_4dc6f81a2bd14b65a89cbe9b632d9f68"
            ],
            "layout": "IPY_MODEL_699b7d35663b461ea72049f927f401b9"
          }
        },
        "8c8302d61fbc451988479397ad40c0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2294c6f395af4d35b8187ba806952ced",
            "placeholder": "​",
            "style": "IPY_MODEL_693ca4223ed142efb3ea8a6b9aa15c69",
            "value": "Loading weights: 100%"
          }
        },
        "3ddbc95c9bdd4a928aef6167b621dca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865acd25f9584d8e8c09a838cb628fa0",
            "max": 603,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_234ab55548644fda8cb3ce067f37bd3d",
            "value": 603
          }
        },
        "4dc6f81a2bd14b65a89cbe9b632d9f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f9b0e66611144b084c4be9bc52ec20a",
            "placeholder": "​",
            "style": "IPY_MODEL_9a8f1ed36dfb49bbb93dda82d124081d",
            "value": " 603/603 [00:01&lt;00:00, 770.84it/s, Materializing param=model.vision_tower.vision_model.post_layernorm.weight]"
          }
        },
        "699b7d35663b461ea72049f927f401b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2294c6f395af4d35b8187ba806952ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693ca4223ed142efb3ea8a6b9aa15c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "865acd25f9584d8e8c09a838cb628fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234ab55548644fda8cb3ce067f37bd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f9b0e66611144b084c4be9bc52ec20a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8f1ed36dfb49bbb93dda82d124081d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Baselines:\n",
        "\n",
        "Unimodal:\n",
        "- Text: Questions --> Qwen LLM --> Answer\n",
        "- Chart to Table: Image --> Table --> Qwen LLM --> Answer\n",
        "\n",
        "Simple:\n",
        "- Image --> CLIP --> projection --> + question --> GPT-2/Qwen3B LLM --> Answer\n",
        "\n",
        "SOTA:\n",
        "- UniChart\n",
        "- AskChart"
      ],
      "metadata": {
        "id": "NVeA9BWbDS29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "E9TTfUyTGvdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "import polars as pl\n",
        "import pandas as pd\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"toekn\")\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"HuggingFaceM4/ChartQA\")"
      ],
      "metadata": {
        "id": "vo7F9JQlEZBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "aac6318716f341f290645dd51ab470e5",
            "64a55bc145e14e9787926403a460276b",
            "e348251e2df8487194048beb6cd11edd",
            "50b83a84a2d047a383ca42db3281e908",
            "764b4aed287e4661bdaad43784706e9d",
            "a2753276c0074f1d8b3e15ae23fa1668",
            "da9297c97c3140a8b97df2d587bcc605",
            "03f280f1c123469d8569a1417987bd3a",
            "a8089f39e4534f92aeb70eeff66154d8",
            "2fd9a790efab40a39ad2c4cfd1333244",
            "3b14b29af856457e9c66b72b4070ed88",
            "5b67728627a84772922b7ed09fd3b9d0",
            "cb5c361d6d1e41b290098bdf2baa6a3e",
            "f06b6df725624effaaeb863a98c1dc40",
            "6aa1d04194924216bc8e112c9449332a",
            "94e7917a582f4645b6d3a93f9cee57e6",
            "fa0b4fb77a734e1c9aa7061246250296",
            "e28a5af69ec1490b9540918400c0ecdf",
            "45206139d2e244e3a1c542ae6257adc0",
            "66de99cc24974df6a1ac06e52e9db3c4",
            "339a212cb4bd4ea5bf94ba82a7e17978",
            "4d84505a886649ac94ca069e03990b10",
            "3f308221f02242d5a308c7b67ed8a578",
            "9c73434e9865441d921048c4ef8541d6",
            "e12eef7a526841b0b26189ba3a04ba74",
            "6af2963211d34b3c8bf2e1983c52bc70",
            "6c58688071c94b4992a550bd09786d70",
            "d991a3a676af4e31b4298cd141f6704b",
            "ebb07636785b4f48b089143da7704664",
            "def09616b632470e9c0ae41cab541963",
            "ca333a4a3f664a92a7684a3019cfdb56",
            "1068453f892344969c446ef1b1ee1268",
            "423d12524abf4fc9ada94c286ad4fc4d",
            "53bb8b37e9fe48209f6736918f2e93b6",
            "8c170d11e15f48a8b593cc873f7d9b7a",
            "b54afdf9464f42f386adf4e60d1eeea1",
            "fa031cda49964e8daa1ffccb086340b1",
            "d674c8439c7b42f5968b7a0e8a0194ca",
            "9e798a4b5ad147adb33e93b339273e77",
            "0a8eb8854eaf4ed29226df2a326d34e9",
            "c8be08b6ddf04984b3c63633fb63dd1b",
            "447bd8fe19e14eca99b453c3725c6fb9",
            "9604300752484fd6b218183f3dc4670d",
            "7b30b331a67b41768838f14d1032c2aa",
            "327af51baa6a4a0bb58b82784e53b10f",
            "88a1d05df26d4bbfb4c4c689b816a7b4",
            "210709dfc5d748fa8f86ddbff7fb616a",
            "0ffc22ec5b84418b8b9a34fcd1bdc13d",
            "55cee527bde4442e868a6e9a8121d946",
            "97017efe9e6747d09c644427e6180420",
            "e95b2fe3c1ee4020a3a112044d958564",
            "f10c7ab90b25489ca927087c4f18d5d7",
            "52d1e192d2a543a7ba6e5484196065b4",
            "f1ae9ae62a0849a38e616037f5a0634f",
            "bca2156c6e864d8f89a47a9e87bfde87",
            "28e880ed00414b5093af0af3a0cbb37c",
            "290b0fe4f1b84010a4713db88bb8cad3",
            "2c55c2e5693748b7ab263970c450be0a",
            "c954d0e8928e42a4bda2df83d8fe01e9",
            "e03cd749252e45c084617fcd54a0bb42",
            "326739f4ecd74cafbaf6b1647caab95d",
            "9ec9d850b75f4a77bccd7df2038c7afa",
            "d5229a4d16df410a9c33ed50e4ae1a85",
            "d69250eaf3154f408812efea92e7847e",
            "207de335851b489fa093d5afeae21213",
            "f0881009a1e242bda7eac247ee2ff09e",
            "5655effe5b3f49d0b65d3ccb4bb4b1fb",
            "1d4aee7255b04fde8b4b1e7f565859b3",
            "04c836488b994b62bcc1809ee8e30e48",
            "0e47485d5cf54a7ba7edf1b3d792ccf8",
            "130fc950d2094b67a688eeafdbae3d85",
            "172f421390f3478698e5a351d9e46f63",
            "98a2a84ad9e243cea50239d8c6dd07f4",
            "f7d4b20482c445f98ff21666cffed149",
            "ea41f8c98beb4bf389487ccd788df63e",
            "d10357dd5b8443bd9e3e1fc7ad2ca71f",
            "2f69223abf4344bf987695a50f292de9",
            "867234609ea64f1caad69cbc2ba13c03",
            "105e200a5d0a405fb111a96197236038",
            "06bc30cfe2844e6e93ffcfec85ebc6ad",
            "ec57d796e2f747b7adbcc11cb0e22fc5",
            "256c1fb236ec4669a15cebbd327f9998",
            "0bd0dd8926f544dfb0dda1c95a5a3c7d",
            "b0c064db5339469ba47118b60befb812",
            "baaf572724fc4f108796c8cfaf3a6aab",
            "6d1a6a62b8cb4fe483405195f8cf4444",
            "703201c6ea5b4ddeab00662bd1e349dd",
            "ae9c74e4d0ef4d0a915590a8001e5927",
            "caebde612f8945558be77e3ab3004d19",
            "5e7a16827b14408e86a5102a7250c087",
            "779df7f50ce34296859ed0585d4abfa7",
            "3bb800295f174612a691e8e13be783ab",
            "64abfbb956d9461695537b44b21b0c1a",
            "14a994c4cb06403d8f321d7098ea1007",
            "16677c8842ff4af5b53ca1a61c78518a",
            "7509231b443142be885c28b6f6f6d56d",
            "0e531afc60294e77a05660b936c521fb",
            "a65f9da5efd8485dbf94a71574c26962",
            "88a55d6b128b4c02997ebb13f231d804"
          ]
        },
        "outputId": "d43f71ee-b5f2-49b1-f9d4-cb4f415aaae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/852 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aac6318716f341f290645dd51ab470e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00003-49492f364babfa(…):   0%|          | 0.00/219M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b67728627a84772922b7ed09fd3b9d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00003-7302bae5e425bb(…):   0%|          | 0.00/311M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f308221f02242d5a308c7b67ed8a578"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00003-194c9400785577(…):   0%|          | 0.00/315M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53bb8b37e9fe48209f6736918f2e93b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/val-00000-of-00001-0f11003c77497969(…):   0%|          | 0.00/50.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "327af51baa6a4a0bb58b82784e53b10f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001-e2cd0b7a0f9eb20(…):   0%|          | 0.00/68.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28e880ed00414b5093af0af3a0cbb37c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/28299 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5655effe5b3f49d0b65d3ccb4bb4b1fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating val split:   0%|          | 0/1920 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "867234609ea64f1caad69cbc2ba13c03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "caebde612f8945558be77e3ab3004d19"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unimodal Baseline: Text\n"
      ],
      "metadata": {
        "id": "I4DezKyBFgmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855,
          "referenced_widgets": [
            "228c1208ed2240afaf8b485bdab99aa6",
            "fe120ae99c9a426faa69e85be9beb0e9",
            "b1282feb7c674280ad857b4560e28474",
            "8edc56355c17489c9caffa7bb47d2164",
            "b78304bafd1e442ea9331f33c77f1a83",
            "ac00e0f67ab6408fb8ae2761efcc46a1",
            "3a5ff848dda14c4fa2eb4896c236e0bd",
            "8e04c228ccf443dcb073718a5d7f3075",
            "faeb200fbbeb4e5e8c88928231ef4127",
            "7796960879ed46f0acec47b6b32d8559",
            "4c70b3b7092245f4a512cb34cced5462",
            "62d4031538c94679871c3c8cfb1d3857",
            "44eab69245664aceb3bca5a3a9a357d1",
            "e39037ec039d428980b85e8492172a28",
            "ed2cbed4e87b44cf90c2e6e1987e57c2",
            "ca9667b5292446ccad448dd6683ebfe9",
            "0fd6c78e534e4f709b6471f5837e7e38",
            "e63e86c0f108452c9c296f3d0b2f520f",
            "7ceab83c28024c77af3ec718d66b61ac",
            "dc430c1c999145c98330349482bebea7",
            "6d3b3ae3a1e247f7af5a8dd211132880",
            "c7f45c805da74e5cb9b6373a1dd2c544",
            "3202c585d9604418884ec3c0c2d136a9",
            "0fa3e2d848f74d25a6445b780f256311",
            "99b89224be044719807364051d0f5a8a",
            "7487db88f4a44efb9eb9d2d050761654",
            "9628b7ac9e8f44359051d1926e6beb73",
            "a73e071d112f484f864f0af70a29abd4",
            "ebed681f45c74db18e7c987e8bc686a7",
            "3a3cb073c6274ecabc3cf5125c5ea1b1",
            "260f78e6595943c6bb4ddf5cd8adc2c8",
            "7a4f4f4b46554a19be8072920916593e",
            "623ebebe5e954d73ba66f44426190576",
            "3f5284d1b7de416d97ecfd010ec3b72b",
            "14aea6c9e0924ea9a4898a36395f2efd",
            "aadc1a78e24b44a0854233b16fed2781",
            "f404f482017946e0a5d9359878d1bc36",
            "90cb5867d88e4dcc89736f6ce54f2e2b",
            "f8b8724f38e0433ab5d556e8007eb1fa",
            "7e105fac559f417abe58d2b6e292b39b",
            "14dde1b8c8024150894e0a703d01c544",
            "4b1e64213581483fbfb6b437d328755b",
            "538e8a4ee0434d2dbd0e6f9f3333ebdf",
            "9d162b29e6054c36bd869d2795e15751",
            "3c595671e5fd4b58be1cf38562ed3eec",
            "0ffc76d5ca2c49caaebeb7c04e1f2eac",
            "972de012b667458d81536d942722e282",
            "90aa79fc34264cbfa3bfbe5671697d3b",
            "1a1e0e6c7f004b5e8e521444cc8b4b47",
            "aaf4f0d0ba124007aaaa1cb2a70d35bc",
            "6c8bd88ea451499a950ef80215d3c2e0",
            "0abb530147474be4931c287811fc62db",
            "3fe541394ecf43ae878c092b7b187a23",
            "ec5eee970ac248ada6ef94f9867d2862",
            "9bed078045a1461c98ffacbc1b9e658f",
            "4c881e05e0ab4800abda1fdc3d520714",
            "fb08f358dfc14fcf96e3b1f68610a983",
            "96fdd641b1fa480f94cd488942770d72",
            "56781504e82d4fa1a6794f6cf152c03d",
            "70f9339b31014b63a237051a6631dacd",
            "ce917e446c534ed4b9c861e6a9d3da12",
            "6378b26457c8489dabec3d858aa7aa8e",
            "bd700f49d4084f3ea601fd4eb0ddaf3a",
            "74720eda002d4812b6902dc457f011d7",
            "0e7422ae162248358b103c691cb89716",
            "b44060d5e2ac46c5bbd409a5a5e8ab17",
            "8e1cb51cd6104daab62dbb64874b751c",
            "87109e15ad0d4bd5b6b78b2037e78452",
            "b227887cd8dd41f58448e456831294de",
            "9cd724f4267e46f9bd16d2064ea015ef",
            "0c91a8cb08e1466e96abacc9e2e2b485",
            "29657154f7514be1b6b1b8833cd8e645",
            "196dfdb5b6fe4124a546822841479d65",
            "758191a079e543ecadc711e990da55d9",
            "6fd8598970f9434ea96903c3ea21a06c",
            "d4078aed14b24d16b835bd17b04842f9",
            "dd77867eaf0a466bafe1e72aa4b6413b",
            "d91bebb08c5a4e0fad5a2df2c0691950",
            "35112beae63a457492873c6e1c5c0bb8",
            "ad2f1f0e64c049f499ddbf7ce4760e9f",
            "ca160d9d80ad40879c452d1025f07fe4",
            "2121c139647942668681b221d862fbc7",
            "d29440efd9f745438a8195a214709dda",
            "bf57ab1832164516a2d9d4251abd0fd8",
            "f7e2559a7b5941f38d65b31a5caaf58a",
            "dab29e18db5d49b6b1d153e799f10d70",
            "a80182e3c2cb4f0d8b1f9c86c4e9f094",
            "a6957aecfcc84cb3934ffdc0972dfd2a",
            "da4a2353fd70470f9c744d7104259dbc",
            "2adb3390f36347d9b1756ffb9f132dbb",
            "0d69978f2b2f4bc792015210f8e37172",
            "ad34c2b1a5ee442fa7db682dc9aab8df",
            "e86afa07114f4bcc902caa44d2be1349",
            "68357f66e1cf48a3aa5f33c18d25272d",
            "a709c8d0d6e044e5971282f24c1675c1",
            "c0791e1d01ca4542a82649d2bd70dda9",
            "8218b2bb1be549448626dc6eaabf4e53",
            "333735c9af4d41c7998bbeec3a6846fd",
            "c604d0e27e994223a1428311f68ce39c",
            "ad68d5fd34ce4eebbca3b1d9d047326f",
            "8080490ac5ff406591ac618ae0c3425d",
            "c8a7127d63bf4e5e8b4adc3c15185dfe",
            "30dc0e0742884aa18b12bdd1c471262c",
            "e6d1742f545f486caca76e1ae0a7207f",
            "686a98ce8a46452ba673e2fbba3bb60d",
            "86c79f915bd04c23895f011b57fc03ed",
            "fd57dd58c7a74be296c10a817b2a204c",
            "0158a33c4e4d436f8ec10017535b4f81",
            "2797d4a271f540879d9cac327ba06053",
            "c45a04d7803244d0b32cd2411a102fe6"
          ]
        },
        "id": "IQrDTX4_DOOW",
        "outputId": "2315406d-877b-4286-a178-fbdac07c2034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "228c1208ed2240afaf8b485bdab99aa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62d4031538c94679871c3c8cfb1d3857"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3202c585d9604418884ec3c0c2d136a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f5284d1b7de416d97ecfd010ec3b72b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c595671e5fd4b58be1cf38562ed3eec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c881e05e0ab4800abda1fdc3d520714"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e1cb51cd6104daab62dbb64874b751c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d91bebb08c5a4e0fad5a2df2c0691950"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da4a2353fd70470f9c744d7104259dbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad68d5fd34ce4eebbca3b1d9d047326f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen3ForCausalLM(\n",
              "  (model): Qwen3Model(\n",
              "    (embed_tokens): Embedding(151936, 2560)\n",
              "    (layers): ModuleList(\n",
              "      (0-35): 36 x Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
              "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
              "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
              "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
              "    (rotary_emb): Qwen3RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_prediction(text):\n",
        "    \"\"\"\n",
        "    Extract first short answer from model output.\n",
        "    \"\"\"\n",
        "    text = text.strip()\n",
        "    text = text.split(\"\\n\")[0]\n",
        "    text = text.split(\"Answer:\")[-1]\n",
        "    return text.strip().strip(\".\")\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    return text.lower().strip()\n",
        "\n",
        "\n",
        "def extract_number(text):\n",
        "    \"\"\"\n",
        "    Extract first numeric value from string if present.\n",
        "    \"\"\"\n",
        "    match = re.search(r\"-?\\d+\\.?\\d*\", text.replace(\",\", \"\"))\n",
        "    if match:\n",
        "        return float(match.group())\n",
        "    return None\n",
        "\n",
        "\n",
        "def relaxed_numeric_match(pred, gt, tol=0.05):\n",
        "    \"\"\"\n",
        "    ±5% tolerance numeric accuracy\n",
        "    \"\"\"\n",
        "    pred_num = extract_number(pred)\n",
        "    gt_num = extract_number(gt)\n",
        "\n",
        "    if pred_num is None or gt_num is None:\n",
        "        return False\n",
        "\n",
        "    return abs(pred_num - gt_num) / (abs(gt_num) + 1e-8) <= tol\n"
      ],
      "metadata": {
        "id": "CJB5iN2nG-dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question):\n",
        "    prompt = (\n",
        "        \"Answer the following chart question with a single short answer.\\n\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=40,\n",
        "            do_sample=False,      # deterministic baseline\n",
        "            temperature=0.0\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(\n",
        "        outputs[0][inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    return clean_prediction(response)"
      ],
      "metadata": {
        "id": "rCptbVevFT6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "print(\"Model device:\", next(model.parameters()).device)\n",
        "\n",
        "\n",
        "split = ds[\"val\"]\n",
        "batch_size = 8   # T4 sweet spot (try 8 or 16)\n",
        "\n",
        "exact_correct = 0\n",
        "relaxed_correct = 0\n",
        "total = 0\n",
        "\n",
        "results = []\n",
        "\n",
        "def build_prompt(question):\n",
        "    return (\n",
        "        \"Answer the following chart question with a single short answer.\\n\\n\"\n",
        "        f\"Question: {question}\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "for i in tqdm(range(0, len(split), batch_size)):\n",
        "\n",
        "    batch = split[i:i+batch_size]\n",
        "\n",
        "    questions = batch[\"query\"]\n",
        "    gt_lists = batch[\"label\"]\n",
        "\n",
        "    prompts = [build_prompt(q) for q in questions]\n",
        "\n",
        "    messages_batch = [\n",
        "        [{\"role\": \"user\", \"content\": p}]\n",
        "        for p in prompts\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages_batch,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "        return_dict=True,\n",
        "    ).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=40,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "    generated_tokens = outputs[:, inputs[\"input_ids\"].shape[-1]:]\n",
        "    preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    for question, pred, gt_list in zip(questions, preds, gt_lists):\n",
        "\n",
        "        pred = clean_prediction(pred)\n",
        "        pred_norm = normalize_text(pred)\n",
        "\n",
        "        exact = False\n",
        "        relaxed = False\n",
        "\n",
        "        for gt in gt_list:\n",
        "            gt_norm = normalize_text(str(gt))\n",
        "\n",
        "            if pred_norm == gt_norm:\n",
        "                exact = True\n",
        "                relaxed = True\n",
        "                break\n",
        "\n",
        "            if relaxed_numeric_match(pred, str(gt)):\n",
        "                relaxed = True\n",
        "\n",
        "        if exact:\n",
        "            exact_correct += 1\n",
        "        if relaxed:\n",
        "            relaxed_correct += 1\n",
        "\n",
        "        total += 1\n",
        "\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"ground_truth\": gt_list,\n",
        "            \"prediction\": pred,\n",
        "            \"exact_match\": exact,\n",
        "            \"relaxed_match\": relaxed\n",
        "        })\n",
        "\n",
        "# Final metrics\n",
        "exact_acc = exact_correct / total\n",
        "relaxed_acc = relaxed_correct / total\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"TEXT-ONLY BASELINE RESULTS\")\n",
        "print(\"==============================\")\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact Accuracy: {exact_acc:.4f}\")\n",
        "print(f\"Relaxed Accuracy (±5%): {relaxed_acc:.4f}\")\n",
        "\n",
        "\n",
        "for r in results[:5]:\n",
        "    print(r[\"question\"])\n",
        "    print(\"GT:\", r[\"ground_truth\"])\n",
        "    print(\"Pred:\", r[\"prediction\"])\n",
        "    print()\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"chartqa_text_only_results_full.csv\", index=False)"
      ],
      "metadata": {
        "id": "v4z8Ih_QFixL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "95137cc7-d0ec-448c-80e6-fa1479722376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Device: NVIDIA L4\n",
            "Model device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/240 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "  5%|▌         | 12/240 [00:31<09:50,  2.59s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4848/2950867429.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# pyrefly: ignore [bad-context-manager]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2669\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2670\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2872\u001b[0m                 \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2873\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_model_for_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2874\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2875\u001b[0m             \u001b[0mprefill_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2876\u001b[0m             model_kwargs = self._update_model_kwargs_for_generation(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 505\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1776\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_rotary_pos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mcos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsqueeze_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0msin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsqueeze_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mq_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrotate_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0mk_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrotate_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mq_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mrotate_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;34m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unimodal Baseline: Chart to Table"
      ],
      "metadata": {
        "id": "JjLltCM8OmYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Use a Donut model finetuned on structured documents (CORD / tables)\n",
        "donut_model_name = \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n",
        "\n",
        "processor = DonutProcessor.from_pretrained(donut_model_name)\n",
        "ocr_model = VisionEncoderDecoderModel.from_pretrained(donut_model_name).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "32859958a3004c5894bb2c80bb6f7d8a",
            "36c65c75b244466ea32928161e3fe14a",
            "0a7615c912ec482f97a1629bc3cb2c80",
            "699ca7ff6df944b19d4b9ed585004b35",
            "cdc2227637214876b21bddd471db714c",
            "832a6e5fd9a74067bde13b090bf835f9",
            "8b17839e469d4bcc8631280b2d6e2aea",
            "28acc3f8bbdd4bad81022f859e20573b",
            "991afa497754417ea503f202f420f0a8",
            "634ad556d1df407ead5a2890b61cfa01",
            "68b38b11276e462484204f7b2c896801",
            "a31513e734c64deba6d9f77835233d48",
            "827f8af0e0ae41dc91378e710abe314b",
            "e6b1640b59d841e49af6cd0feb1c0a32",
            "65e1437f673a478fb46584acdb9544a7",
            "3a19b0e044b9496aaa8905ea4128c684",
            "21fff9663cc44a20bbdbdde7769ec1c7",
            "683c21f0dd50436d83e1a09e95f7c2b3",
            "2757ae298f35407881634de9e0515a80",
            "6a2e835be56249288c9ba8f062602086",
            "328346a37d134f92acc09025ddd92215",
            "8e58d851477243039f2c3f409b16c130",
            "444eebfb3b4744ebaecd4200b3732721",
            "dee666055e014a8da4d2c3d236dedf95",
            "b47ed6d95fa1476f914c5304aa09f17e",
            "0a37b3cc38fe454ca1cf0f36d1a76c60",
            "74f617f6656b4b40b5fa8cc57ce3394b",
            "e37b5f044df646ff86c23ba8c2b0b196",
            "105b083c62ac4f5e8d36ac610b06b784",
            "572bbc09c8e547d093136a78c0326190",
            "de37d9305d1d45258498c7e9fcee935c",
            "fc37b6135a4249c791869f3369632487",
            "307f177451924e23a23641d5ca2eba64",
            "f6b1eea6fa3d44dda1358e5d4646297b",
            "54c544f1ef054a799ece0b4b3bb8391a",
            "9b94883d52f34f18ae2b62f0f474b057",
            "a5c50fccec4149f48d00c7050c86d2a1",
            "d3f53567af8548bb8f7fa196f4d8e324",
            "f447bd9ca50f4e0183fd0738a7bcfb2f",
            "db0af7fb05a04af79d39b5fa64baf3e0",
            "ff3fa32d730d4534adcc7c96e3a4e28b",
            "b6ef009c77ab415a8ccbaa013fcc3ef1",
            "20a638443fb24445953779bfdf8f3a83",
            "505e36d87e6b4775b5145e290ba13ff1",
            "f058302059404bdd9ec75e063591deaf",
            "ea57adc5e87a40b5a597f0f961aa7851",
            "7777674e7e8f4b58af1176d20d635fe5",
            "fb423246b9b24e24bd5433994789a8f3",
            "dfb89dbbd95b4874b2477ca33070af3b",
            "0aa3d16eba5e4a3cb64664b7bc13ef98",
            "b9525ef8c3a64dd2a54e649a9ad9f87e",
            "d1fffc71c0494f22ba66e6e2f244b247",
            "748a790b8c2846b8a424e490602f4f53",
            "56dcf4c93c1d4af190d71f7cebe5894c",
            "07c3f4e4d352455b9a92622d46401c70",
            "b64898514ba7455e816454f83abd489f",
            "2158a7d5ad1344149e1e996d1c7e3dcf",
            "70ee52e6bfa04318bcee2bf48d1e5082",
            "703084337bc54dfc81f261f8b9cda4b7",
            "2cd5c2e725e84a74bae2f006ff471b6f",
            "30e99dcb21754493a9f1d7043da2a2fa",
            "bc1857d901f54b4c8870428f1fcf8a72",
            "123f321390dd41428a1b5bd74ac12ed5",
            "f8c8cfbf03134a8aa03faf83d7e76591",
            "bbf9a531ba5d4c64a44337ad2fe8479e",
            "673dda9ca3ff4e389b4ff5151375109b",
            "48dba45e546040049617cb44ad63f17c",
            "d95c3292c610420e91d60d14489d1a09",
            "83c37b78fb224959bcb7e51a1e9b15b3",
            "7330581910bd43109d7f5764f0d0348e",
            "f61769ee1fff4e4d9dbd0f83b46471e2",
            "70e21a2dcde54c8b836fb64ea9ffce4a",
            "03d0344c6d83442088b4d00801453b4f",
            "47c7f911f8ea40fe8c966dd7354037af",
            "e0f434f582594fba9b3f21e2e8bcbebb",
            "c99ca49939634a67a7808c4c4504ea69",
            "2da8793f34e84fc7b9e97f4eca79a442",
            "5f9a119a16984569ada7550c2ddbc472",
            "994317696a664740b90b0cb29f407bf0",
            "2a26dfab377543a7a779de34762b1ccc",
            "d69605e34e704a97a990aaa92ddd927d",
            "c6a6827eeacd4a0eb4956c3fe2aa35ac",
            "bab7bf8061af4dfbab122b9f316df53e",
            "b863b8b6186246ddb74dca6ede11353e",
            "a173181d97ad40dc95f49d3b96319f27",
            "7ff563ee363940cb94aef0f9ce81df32",
            "8394862f284f42fcb79ef1fc7241d027",
            "ef2e4f7e285846b2b1e421b1ff3eec21"
          ]
        },
        "id": "v9EOYlpeCMd_",
        "outputId": "2817fd2c-c0a7-4866-d187-4e0b21d123cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/362 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32859958a3004c5894bb2c80bb6f7d8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The image processor of type `DonutImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a31513e734c64deba6d9f77835233d48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/536 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "444eebfb3b4744ebaecd4200b3732721"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6b1eea6fa3d44dda1358e5d4646297b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f058302059404bdd9ec75e063591deaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b64898514ba7455e816454f83abd489f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/806M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48dba45e546040049617cb44ad63f17c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/484 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f9a119a16984569ada7550c2ddbc472"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie decoder.model.decoder.embed_tokens.weight to decoder.lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "\n",
        "# ocr_model_name = \"microsoft/trocr-base-printed\"\n",
        "# processor = TrOCRProcessor.from_pretrained(ocr_model_name)\n",
        "# ocr_model = VisionEncoderDecoderModel.from_pretrained(ocr_model_name).to(\"cuda\")\n",
        "\n",
        "# from paddleocr import PaddleOCR\n",
        "# ocr_model = PaddleOCR(use_angle_cls=True, lang='en')"
      ],
      "metadata": {
        "id": "WbyCJQ1zHB9k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "a79b70b7-ffa7-4e38-b91c-4f9859f4f16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `PADDLE_PDX_DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1777309056.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ocr_model = VisionEncoderDecoderModel.from_pretrained(ocr_model_name).to(\"cuda\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddleocr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPaddleOCR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mocr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPaddleOCR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_angle_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddleocr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m from ._models import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddlex/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_dataset_checker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_evaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddlex/inference/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_predictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_pipeline_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhpi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHPIConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddlex/inference/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhpi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHPIConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mofficial_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mofficial_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0manomaly_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUadPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasePredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddlex/inference/utils/official_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m \u001b[0mofficial_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ModelManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddlex/inference/utils/official_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hosters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_hosters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hosters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddlex/inference/utils/official_models.py\u001b[0m in \u001b[0;36m_build_hosters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mhosters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhoster_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mhoster_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                     \u001b[0mhosters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhoster_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhosters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/paddlex/inference/utils/official_models.py\u001b[0m in \u001b[0;36mis_available\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             response = requests.head(\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhealthcheck_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_healthcheck_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mhead\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"head\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qwen_model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(qwen_model_name)\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
        "    qwen_model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "1b311cac5f644edca1b4c4c7466206f3",
            "8341926c8c3f4e3c8f24fa244762e67f",
            "9352ea1bfaad4bc5a964eee6393400f7",
            "b9e2b2e774bf42dfaed1fe566246b4e5",
            "363aaf0bef2247b4a83f5e5b3a7992c3",
            "439d63f02fc241388c389e552f60e4e3",
            "dd0d771e5b3a471686d5a04e008001f2",
            "6cf8a9f630fc47b0825f03ddbda1dba9",
            "276c05d9d1ad4c7699d1f67dcb6988c4",
            "810856c18928405f99c256b0b7655b5b",
            "917f30882b474535b3b7314b25ae2ac1",
            "b8f104d537e1460ab937ab8e31827063",
            "f85291e205e24a0ab853ac18b8de9468",
            "6dbbc008e2a841f19b05cd102a534e3f",
            "c9f393aa263d4a8aacd8c1fda415fec0",
            "6fc3ad1557f14f54ad81e9185b6e9c8b",
            "2b268483c72941cd91d138eb2d621b95",
            "3633b5635f6543689ae7d08e0e2e4c06",
            "7acecfb10f374076891d0e9eaa72c7ca",
            "2f1661380e584959be571d66b7cf2269",
            "1d43cd14e1aa4afe9beacf705153dd63",
            "c97a57e644b8431b93d3496135737fc0",
            "3f7387b7c3f342e7a80bf9ab5407bf67",
            "99a40716b3084e55a75c68fba56da268",
            "5aac73c6b3254322bd3869504cd41255",
            "2d3dfcf12a194191ae19defec950e40f",
            "95d00393195542beac05b227ceab3db0",
            "0a21c8821576469aa44471a162b8e939",
            "b71e25e74927486cb7fd6b02d34da57b",
            "a609f5345b1f4822b9ee7e05fd8463fb",
            "6560ade813d148d2800b617327c1a2dc",
            "54202429005340d4bfd513403b23d8c3",
            "c3c228dca8f0483083d6b6f7f57034a9",
            "2429c50e6f7245089721111362f23d8b",
            "022c7071cc274696b57e2a104e314867",
            "b210aa7ccc584fad8840e2e49afdeed2",
            "983185ecf2664d08bedb848d67c2e056",
            "e4ca98ba56a342f8a51b6281824c0746",
            "c7c90538a38f451c9e08f26ad264cd7f",
            "207ef3315a4a45b58326f341f2f23cc9",
            "63fa0319beaf46e3a7424cbc4bcab427",
            "32cb363c65ff46e9a8e04963de683bf8",
            "75047788f7774e77b8fc8e532fd1c2fc",
            "7ef07535d83d450888c7817ef3ec864f",
            "ea19486e6aab43cb8ee3f203771ddd7d",
            "72e3837370d84f84bf2e53645510d9c3",
            "6cb18bc3f87d49c68c5a0bc41be15755",
            "60e121e013084b66930040f9e7de92b3",
            "572815e2b211443da668d417251ba64d",
            "c51080c0c6dc4e459664063ba047e36e",
            "34ca77685746483ea30b238a50da1257",
            "2f4730ffcd564344b18c0c02607e86ee",
            "756afc79fd50458d9c0cb06f4592f66f",
            "6ea6ae6a1993436989fd79a718d31d1f",
            "6e23c0cb94424a1bafc913e0fc58fff0",
            "d2964e75c6fc4bf6b7b4333f03c68480",
            "c620766f5def4caf995bb0aefc1a790f",
            "edf35bd9b8234e1b92d9afdf212525f2",
            "d65329f2bf5b4320a898789ce85d7165",
            "1ee5c535d2a14831b90a2258affbc4c7",
            "f5ef8bbbecc64ce0814cdf1cc043a561",
            "216553e8ef0e4233b3ee26b4eda90f50",
            "66710b0b8cda402c9da526620535310b",
            "b32afced8b98490d9eb9d23b89e1faa3",
            "00ca46506f94432dac28293260d8350c",
            "1f4f7878415d4d31abde6dd11ab9037e",
            "f934b0622c1e4312be93fea3a832aeb4",
            "83a1dbbe9b54417a8fdaa67165292a20",
            "d5fb655c49ba47e9871d6de01d8e8c91",
            "4debb011941f43b9b4c01fa0a058f8d5",
            "94a9e3ef80ff4c88962a247899869ac4",
            "6cb6f00d5fd44dd5869a77105c15d56c",
            "956e0f7db3b84607bf88adf5ef578a9c",
            "e3a2b0c4705c42cdb75a31fca815a0c9",
            "2c572b77b736484f9c48ec1f587c6534",
            "b163db671ef044f9a88783239a59638e",
            "aa1c39f9ddb649f89227d11bd7975e88",
            "34eff405c52e41aa8738d97f1fc23e3e",
            "59507645c63147b9ab2bb2cf29bcfd73",
            "e4ccea16aa9d480285d8a4b84a4e5bb7",
            "fa409ad48e214d05827048ab174ec96a",
            "81a5f7f3d4d24b8b97fcef858558bb1c",
            "f18d0d2b7c0e477ba24fb58d399f9c58",
            "7aa19026489542bebaf87af1cbd6b50a",
            "ce7b357bc9eb421aa3959e2363b6ffa7",
            "60ea14287ee148809829400a91009121",
            "0f96ea6f34514df4ab794c12fcaf8b4a",
            "0d3d2583941546d8847f967c452649bf",
            "5f4c3542a7874863b2c1c4d1cf3ef4a4",
            "d11b700217ca45cdbe3b827ebe3c5c43",
            "bba6eb488b224099a4750f8ddf7e3062",
            "dbf86cdd686743a789ff8a9970beb4ec",
            "21bbf19fa41a4ce28e3fd5c8000ab92f",
            "56a16e75e2a04bc898a4dc9f63b323f9",
            "b84fc34e170348439a75a55ffd08f623",
            "9851e89bb8b543769ebca54f0eaa8199",
            "d6906da7df314e1bb3acc68f9da3db06",
            "aeab35c343ee4d9981a043544deafa9a",
            "26d12b33b8384128808f0b40b629fc9e",
            "974e44fb701949e08fe7403d7c452494",
            "5d91f7fde426404eb09b792bf1d1f33d",
            "ac58bcbe751642d08dc78822570da01f",
            "cba0727859dc4426a5add6abcc78e11d",
            "886c25a7c4cc4e71be77ea2e8c19d440",
            "e0e611159f824bc2951cd09d10b357e1",
            "c9991559690742c3987529b25e143208",
            "c8054f423da9495081b9079cf370fe6e",
            "8e295cac1e92481e804fa2fb6fa9b7e5",
            "ab662eeb353b4e888455c339e0095270",
            "80a341800f07436d926fccc88c1f64d3",
            "03f05bc7e1f14c99a07fdb792d290e01",
            "635382d40768456e81737cf0841da7c1",
            "7b903b7224e945cbad1231d334d606f9",
            "68243adf030044999c384bdb35ca96fe",
            "989ee272c3ce4b43a37b65a3964a9f02",
            "c6b31e52a3a949c7b09b1bac75536628",
            "330f72c69b994b52aee50cb3e03a38ed",
            "3f32049891c845229e55b7c983f3fbeb",
            "262d00ab925e48d38883efcc08ee18f3",
            "ef1acf66a4504544b91599ed932fcedf",
            "4243d6b871364152be56c6acd49bb2d8"
          ]
        },
        "id": "rf_FVZKBOuyP",
        "outputId": "c8424193-0674-488d-b934-ebc1ba4535a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/806M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b311cac5f644edca1b4c4c7466206f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8f104d537e1460ab937ab8e31827063"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f7387b7c3f342e7a80bf9ab5407bf67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2429c50e6f7245089721111362f23d8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea19486e6aab43cb8ee3f203771ddd7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2964e75c6fc4bf6b7b4333f03c68480"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f934b0622c1e4312be93fea3a832aeb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34eff405c52e41aa8738d97f1fc23e3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f4c3542a7874863b2c1c4d1cf3ef4a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "974e44fb701949e08fe7403d7c452494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03f05bc7e1f14c99a07fdb792d290e01"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def ocr_extract_text(image_or_path):\n",
        "    \"\"\"Extract text from PIL Image or path using TrOCR\"\"\"\n",
        "    if isinstance(image_or_path, str):\n",
        "        image = Image.open(image_or_path).convert(\"RGB\")\n",
        "    else:\n",
        "        image = image_or_path.convert(\"RGB\")\n",
        "\n",
        "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        generated_ids = ocr_model.generate(pixel_values)\n",
        "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return text.strip()\n",
        "\n",
        "def ocr_to_table_text(raw_text):\n",
        "    \"\"\"Convert OCR text to Markdown-like table\"\"\"\n",
        "    lines = raw_text.split(\"\\n\")\n",
        "    lines = [l.strip() for l in lines if l.strip()]\n",
        "    # replace multiple spaces with pipe separators\n",
        "    lines = [\" | \".join(l.split()) for l in lines]\n",
        "    table_text = \"\\n\".join(lines)\n",
        "    return table_text\n",
        "\n",
        "\n",
        "\n",
        "def generate_answer_from_table(table_text, question):\n",
        "    \"\"\"Pass table text + question to Qwen\"\"\"\n",
        "    prompt = f\"Given the following table extracted from a chart:\\n\\n{table_text}, Question: {question}, \\n\\nAnswer:\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        padding=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(qwen_model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = qwen_model.generate(**inputs, max_new_tokens=60, do_sample=False)\n",
        "    answer = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "    return answer.strip()"
      ],
      "metadata": {
        "id": "61kNe0x6O71V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Setup\n",
        "# ------------------------------\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "print(\"Model device:\", next(qwen_model.parameters()).device)\n",
        "\n",
        "# Use first 50 validation examples\n",
        "split = ds[\"val\"]#.select(range(25))\n",
        "split_list = [dict(ex) for ex in split]\n",
        "batch_size = 4  # safe for Qwen3-4B on your GPU\n",
        "\n",
        "exact_correct = 0\n",
        "relaxed_correct = 0\n",
        "total = 0\n",
        "results = []\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Helper functions\n",
        "# ------------------------------\n",
        "def build_prompt(table_text, question):\n",
        "    return (\n",
        "        f\"Given the following table extracted from a chart:\\n\\n{table_text}\\n\\n\"\n",
        "        f\"Answer the following question:\\n{question}\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Batched loop\n",
        "# ------------------------------\n",
        "for i in tqdm(range(0, len(split_list), batch_size)):\n",
        "    batch = split_list[i:i+batch_size]\n",
        "\n",
        "    # ------------------------------\n",
        "    # 3a. OCR each chart → table\n",
        "    # ------------------------------\n",
        "    raw_texts = []\n",
        "    table_texts = []\n",
        "    for ex in batch:\n",
        "        img = ex[\"image\"]  # PIL Image\n",
        "        raw_text = ocr_extract_text(img)\n",
        "        table_text = ocr_to_table_text(raw_text)\n",
        "        raw_texts.append(raw_text)\n",
        "        table_texts.append(table_text)\n",
        "\n",
        "    # ------------------------------\n",
        "    # 3b. Build batch prompts\n",
        "    # ------------------------------\n",
        "    messages_batch = []\n",
        "    for ex, table_text in zip(batch, table_texts):\n",
        "        prompt = build_prompt(table_text, ex[\"query\"])\n",
        "        messages_batch.append([{\"role\": \"user\", \"content\": prompt}])\n",
        "\n",
        "    # ------------------------------\n",
        "    # 3c. Tokenize batch\n",
        "    # ------------------------------\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages_batch,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        padding=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(qwen_model.device)\n",
        "\n",
        "    # ------------------------------\n",
        "    # 3d. Generate batch answers\n",
        "    # ------------------------------\n",
        "    with torch.no_grad():\n",
        "        outputs = qwen_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=60,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "    # ------------------------------\n",
        "    # 3e. Decode batch\n",
        "    # ------------------------------\n",
        "    preds = tokenizer.batch_decode(\n",
        "        outputs[:, inputs[\"input_ids\"].shape[-1]:],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # ------------------------------\n",
        "    # 3f. Evaluate batch\n",
        "    # ------------------------------\n",
        "    for ex, raw_text, table_text, pred in zip(batch, raw_texts, table_texts, preds):\n",
        "        question = ex[\"query\"]\n",
        "        gt_list = ex[\"label\"]\n",
        "\n",
        "        pred = clean_prediction(pred)\n",
        "        pred_norm = normalize_text(pred)\n",
        "\n",
        "        exact = False\n",
        "        relaxed = False\n",
        "\n",
        "        for gt in gt_list:\n",
        "            gt_norm = normalize_text(str(gt))\n",
        "            if pred_norm == gt_norm:\n",
        "                exact = True\n",
        "                relaxed = True\n",
        "                break\n",
        "            if relaxed_numeric_match(pred_norm, gt_norm):\n",
        "                relaxed = True\n",
        "\n",
        "        if exact:\n",
        "            exact_correct += 1\n",
        "        if relaxed:\n",
        "            relaxed_correct += 1\n",
        "        total += 1\n",
        "\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"ground_truth\": gt_list,\n",
        "            \"ocr_text\": raw_text,\n",
        "            \"table_text\": table_text,\n",
        "            \"prediction\": pred,\n",
        "            \"exact_match\": exact,\n",
        "            \"relaxed_match\": relaxed\n",
        "        })\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Final metrics\n",
        "# ------------------------------\n",
        "exact_acc = exact_correct / total\n",
        "relaxed_acc = relaxed_correct / total\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"CHART-TO-TABLE BASELINE RESULTS (50 samples)\")\n",
        "print(\"==============================\")\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact Accuracy: {exact_acc:.4f}\")\n",
        "print(f\"Relaxed Accuracy (±5%): {relaxed_acc:.4f}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Preview first 5 results\n",
        "# ------------------------------\n",
        "for r in results[:5]:\n",
        "    print(r[\"question\"])\n",
        "    print(\"GT:\", r[\"ground_truth\"])\n",
        "    print(\"Pred:\", r[\"prediction\"])\n",
        "    print(\"OCR Text (truncated):\", r[\"ocr_text\"][:100])\n",
        "    print(\"Table Text (truncated):\", r[\"table_text\"][:100])\n",
        "    print()\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Save results\n",
        "# ------------------------------\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"chartqa_chart_to_table_results_50.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fs6u_uEO8gw",
        "outputId": "f7a892ff-2249-4e58-e97e-d454f3d4f5b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Device: NVIDIA L4\n",
            "Model device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480/480 [39:47<00:00,  4.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "CHART-TO-TABLE BASELINE RESULTS (50 samples)\n",
            "==============================\n",
            "Total samples: 1920\n",
            "Exact Accuracy: 0.0000\n",
            "Relaxed Accuracy (±5%): 0.0156\n",
            "What's the color of graph with 56 as the highest value?\n",
            "GT: ['Blue']\n",
            "Pred: The question asks: *\"What's the color of the graph with 56 as the highest value?\"*\n",
            "OCR Text (truncated): 34 26 29 28 Germanyityityis U.S. 56<sep/> 5.6 천 천\n",
            "Table Text (truncated): 34 | 26 | 29 | 28 | Germanyityityis | U.S. | 56<sep/> | 5.6 | 천 | 천\n",
            "\n",
            "In which year the difference between blue and green graph 1?\n",
            "GT: ['2018']\n",
            "Pred: The question asks: *\"In which year the difference between blue and green graph 1?\"*\n",
            "OCR Text (truncated): 34 26 29 28 Germanyityityis U.S. 56<sep/> 5.6 천 천\n",
            "Table Text (truncated): 34 | 26 | 29 | 28 | Germanyityityis | U.S. | 56<sep/> | 5.6 | 천 | 천\n",
            "\n",
            "What does the blue line represent?\n",
            "GT: ['Not too much/not at all']\n",
            "Pred: The provided table contains only the repeated label \"총\" (which means \"total\" in Korean) and does not include any data points, colors, or descriptions of lines (such as a blue line). Since there is no visual chart or additional context (like axis labels, legends, or descriptions of\n",
            "OCR Text (truncated): 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총\n",
            "Table Text (truncated): 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총\n",
            "\n",
            "What is the max value of blue line?\n",
            "GT: ['0.72']\n",
            "Pred: The table provided consists only of the repeated value \"총\" (which means \"total\" in Korean), and there are no numerical values or data points to determine a maximum value for a \"blue line.\"\n",
            "OCR Text (truncated): 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총 총\n",
            "Table Text (truncated): 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총 | 총\n",
            "\n",
            "What's the percentage of respondents who say Job is a top priority for the president and Congress in 2016?\n",
            "GT: ['68']\n",
            "Pred: To find the percentage of respondents who say \"Job is a top priority\" for the president and Congress in 2016, we need to analyze the given data\n",
            "OCR Text (truncated): 48 48 49 49 49 49 49 49 36 36 36 36 36 36 36 36 36 36\n",
            "Table Text (truncated): 48 | 48 | 49 | 49 | 49 | 49 | 49 | 49 | 36 | 36 | 36 | 36 | 36 | 36 | 36 | 36 | 36 | 36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOTAs"
      ],
      "metadata": {
        "id": "z4j-njyhOld8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================\n",
        "# 2️⃣ Imports\n",
        "# ============================\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ============================\n",
        "# 3️⃣ Load pretrained UniChart ChartQA\n",
        "# ============================\n",
        "model_name = \"ahmed-masry/unichart-chartqa-960\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_pretrained(model_name).to(device)\n",
        "processor = DonutProcessor.from_pretrained(model_name)\n",
        "\n",
        "# ============================\n",
        "# 4️⃣ Load a small subset of ChartQA (first 25 samples)\n",
        "# ============================\n",
        "dataset = load_dataset(\"HuggingFaceM4/ChartQA\")[\"val\"]#.select(range(25))\n",
        "dataset = [dict(ex) for ex in dataset]\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 5️⃣ Helper function: run inference\n",
        "# ============================\n",
        "def run_chartqa_inference(image_or_path, question):\n",
        "    input_prompt = f\"<chartqa> {question} <s_answer>\"\n",
        "\n",
        "    # Accept either a path or a PIL.Image\n",
        "    if isinstance(image_or_path, str):\n",
        "        image = Image.open(image_or_path).convert(\"RGB\")\n",
        "    else:\n",
        "        image = image_or_path.convert(\"RGB\")\n",
        "\n",
        "    decoder_input_ids = processor.tokenizer(\n",
        "        input_prompt, add_special_tokens=False, return_tensors=\"pt\"\n",
        "    ).input_ids\n",
        "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "    outputs = model.generate(\n",
        "        pixel_values.to(device),\n",
        "        decoder_input_ids=decoder_input_ids.to(device),\n",
        "        max_length=model.decoder.config.max_position_embeddings,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=processor.tokenizer.pad_token_id,\n",
        "        eos_token_id=processor.tokenizer.eos_token_id,\n",
        "        use_cache=True,\n",
        "        num_beams=4,\n",
        "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "        return_dict_in_generate=True,\n",
        "    )\n",
        "    sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "    # clean up the token artifacts\n",
        "    sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(\n",
        "        processor.tokenizer.pad_token, \"\"\n",
        "    )\n",
        "    if \"<s_answer>\" in sequence:\n",
        "        sequence = sequence.split(\"<s_answer>\")[1].strip()\n",
        "    return sequence\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 6️⃣ Run baseline on first 25 samples\n",
        "# ============================\n",
        "exact_correct = 0\n",
        "relaxed_correct = 0\n",
        "\n",
        "for i, example in enumerate(dataset):\n",
        "    image_path = example[\"image\"]  # adjust if using local files\n",
        "    question = example[\"query\"]\n",
        "    gt_answer = example[\"label\"][0]  # assume single-answer GT\n",
        "\n",
        "    try:\n",
        "        pred_answer = run_chartqa_inference(image_path, question)\n",
        "    except Exception as e:\n",
        "        pred_answer = \"\"\n",
        "        print(f\"[WARN] Error on sample {i}: {e}\")\n",
        "\n",
        "    # exact match\n",
        "    if pred_answer.lower() == gt_answer.lower():\n",
        "        exact_correct += 1\n",
        "\n",
        "    # relaxed match (numerical ±5% if float, else substring match)\n",
        "    try:\n",
        "        gt_val = float(gt_answer)\n",
        "        pred_val = float(pred_answer)\n",
        "        if abs(pred_val - gt_val) / max(gt_val, 1e-6) <= 0.05:\n",
        "            relaxed_correct += 1\n",
        "    except:\n",
        "        # fallback: substring match\n",
        "        if gt_answer.lower() in pred_answer.lower():\n",
        "            relaxed_correct += 1\n",
        "\n",
        "    print(f\"Sample {i+1}: Q: {question} | GT: {gt_answer} | Pred: {pred_answer}\")\n",
        "\n",
        "total = len(dataset)\n",
        "print(\"==============================\")\n",
        "print(\"CHART-TO-CHARTQA BASELINE RESULTS (first 25 samples)\")\n",
        "print(\"==============================\")\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact Accuracy: {exact_correct/total:.4f}\")\n",
        "print(f\"Relaxed Accuracy: {relaxed_correct/total:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f28c5b932e6b4d5c95491ff7d50a7cab",
            "fefcc53c610042ba9f1f33a82089fc62",
            "33705fff2b75416da61efb071292ac10",
            "eb7823a8d0c34aaea3cab9c376992528",
            "ccec84611810423293f33fe37e5a56aa",
            "ea2d1e7720d6496ab57bea52c4738bf6",
            "6b1ab53dbe8b4854abe906ff9c5d4484",
            "cae1f79bad324e14aa97580e4aef50ef",
            "7198209673e4468e88bcbadfd31f8128",
            "809af8227b2749cbb68e861ff9af6d02",
            "00f0a90528e14431ad8bbebbad195d57",
            "cbf51b16c6f24bcd97cf06b01825a47f",
            "95280351fc274b25b6f84533b28c74ef",
            "1be8154f8e3145d994f03903ea849603",
            "86db0db8ea744702a281e734b7c95ac5",
            "d82c404b1d32411fbb7b092e58016498",
            "9a95981f27be48059c00f6b5217bf6bd",
            "186542f658b349b4beffa5c946930003",
            "cc024e6017fc41bba56877b9f3833150",
            "07b9d18b551f42e9956b66966167b1b0",
            "d2c7f550b7a64b61915ed1fa77881220",
            "aad15e09ddea451cade5f4be945b4d08",
            "8c95352a043a4ec28eb491a740086f43",
            "535f3c4ca2e64f2eb662f993035115f5",
            "59203cfc92734831a5d200d2e94e8a59",
            "a35ace0f74c0430a962d1109a6cb4207",
            "a9f45db87524458988072858cc290772",
            "8ba428c9ea7448feaa9c071c834a6a5d",
            "b72454e2b4254daf9d77d6d4d73c18a8",
            "d7974e46806c437a8e721d3e89f3d056",
            "e1c636aa152e4a57b70860fbfec4c33b",
            "d42bb8c9be7f4456928f75cd4ce8d52d",
            "8d1c8abfd930445cb6fe09bc317f832a",
            "841c7fbdc9f44812a48ff4b91a856e15",
            "9539096515b04b69a3268404ba652d8b",
            "a5be4968ace740f2b866005c38985123",
            "7e527c11ee8c421daee66bdd1aa6a01e",
            "d23fae0e9863461cb229292df019bad9",
            "27c64368b5464dbbb17116c8a149d04d",
            "ac89abb264de4b87961a76e0fca9a88f",
            "1c3a8fa8819d4ff0a07c0777ae6e6fc9",
            "b304cd4a5cdf4718a3d1a0fd3c19e2cd",
            "0cfdf0ec75414583966c6c51614880d2",
            "37673033d4ed4409a9792b5e8df05651",
            "3766a10f795f48a197bcec1793ff13d9",
            "7f670f42871e40848de085a7a320cc2c",
            "8c52d076eb5447e6a09ffe4f0e5c0524",
            "203c3212983244e4a0868152f935dc41",
            "81a964b4e76147e9816d0c8f9dee388e",
            "f952c78360a54c4d80c724f1e9012f9e",
            "26a5cef2a9f144f5a7f5863d68ccbaa0",
            "8c9f5f51814b45e39dfb3b0436ec9473",
            "a26310a2f9c94f4f9c9399d21c0cd4b3",
            "321cb39e3175441290f46a0549ad4fa1",
            "c0fcc1a9de5c4a17b56f851f5d71575e",
            "9c02cc532d7649569abbfda1b860dc3a",
            "15327f1c055f4248823ab881f2d83169",
            "2aed3f5c2e7b4274acc62dd8f36e2b3f",
            "f3b77717c3b244009ce4243556ecdc00",
            "d5bc3124cb8747e09a8b5c25ed54bd8c",
            "c93578d83d31432da491354c49930333",
            "699d4d07a2d84c7f8f886f5eca9e2ee2",
            "6106649efa5644c08d395bb5ca65b374",
            "2639e05c304e4668a2fd2f724a3141b8",
            "0941df6ebac046e7a4d011a41661ae24",
            "cf2d85503237475d90d77cac09966571",
            "4b9f4c3888304f16b961e401abee80ac",
            "32c9bf35a0664d9f96d8a78a4065f6b1",
            "883d0e647f9e49f19e7997a7681b9348",
            "f65aa58bc9894ee9b60cff5e2ea3381d",
            "93963827ccde48daa46a105bbbfa1dce",
            "bb9251e73a164ce687d81d8f57201afc",
            "d450bbf9e4674442b9cfb92be79798a4",
            "4d0ec6277b5b4aae9771eb8ace55ca95",
            "bb1a98cfa9b34292a72f781f211406e7",
            "75473f1cef634641b038762dadc5765a",
            "a9e66a6493b54f7398704e47f8dac307",
            "3c19dfff72c248daa123879e0edf7954",
            "cdb7f806d2cd440e9379103c17956fd4",
            "434f65bc637842f980843b86043a0034",
            "49e10e2a726940c8acdc944bd4cdbffe",
            "7d623817708149369d7531c0661e1bd4",
            "63580c366a024135b877e7f47ca7017e",
            "448721bac95b46e382f76101fedfca87",
            "261cce1555f64b108eb3cc5505f4606a",
            "d827115ce8cc448799253c91e84b4f7f",
            "76093d5dc46744d98c196e624a5f9c8e",
            "74478677b377408aac0370312c1d2f10",
            "5914843230c64391a5a48e7bff0d56a0",
            "f8dcfeb99ec5485085fba044552192b8",
            "eacdfb01237d465d9a56cf66246757e8",
            "dbb4840135dd48f8b699486962e80a2f",
            "a6ebf59d808a402698878d5cfc5b50c5",
            "23a97a887e464122893c5f1aab8e53bf",
            "6f8765d82293478682d9b9426059800b",
            "f6bb1f2fb2a7490eb38f0ecbb6034bf7",
            "cd921570c39c4c9296925eb4159aa5e7",
            "ebe518c61af94dfeba3c66efb045b207",
            "05eb66221ee54817bb98e15eb3a1d8e4",
            "30c32d0df6724cb6b48d72091a9ddb88",
            "53540fd5c8744ea2b936adcb2ee1f232",
            "586268d2c3854fe5b8f2d212621202cd",
            "84d6fb05cd9845bfb2aeccc6a87919df",
            "e850ebe150804ceebd70b6e5ce8e7bf8",
            "61442e4db9ce4a5a9dfc0925f3f35944",
            "10edc8ea5edf425ba06d0d0af3dc2c9c",
            "df87f4c5490a41139e98fbe64e743447",
            "a58470a03179453a9a81022f7952a710",
            "4e615be3f7554f18aa38e55559fad1cb",
            "4e0ef12785bf431c99dca189f271ec29",
            "eab62f52ec4642429df4891f9db6b488",
            "5e4471f3885f4b87897210661165adbd",
            "214b289fffa3434990b8b8ce5ed1f2b1",
            "305841c1c2f54617b3a2ea7f08a46b66",
            "5135a40f847849fc8206c2099fe726a8",
            "c90e9b43360a4599bfcc292d5dc17f8d",
            "fa93942fe88d483f9f2f856156450f68",
            "1bbfeb44ea4e46ef893c8e982922be45",
            "fbe25b4d9d2341988d192d2f9ab97b6e",
            "c1f087bd15c54aa4b5a72407cf4de13e",
            "28804b676d6d45578cbc7890471bfaea",
            "9eca265101a945e99240388d073bd059",
            "541cce30fa7f4268a241569acad2b1d1",
            "f77c5f6a5b944aa4a37daf47f6a8275a",
            "f0dd97b1cf0b459a95745c2628376db2",
            "69f5c2f374c84a2d898f14b020f6a1eb",
            "c8a64a37aac0468dbd21e72fa95412bf",
            "9dc5099cd9624f668eee45f9691b54c8",
            "07aab01728ef49adbafde1f9003a21d9",
            "740f1087550645b1bdfdc2cf13c9b50b",
            "bca87714bf934d248836e9ce927fef91",
            "cde1bced72144039a355f837f39292be",
            "7e3e1bcd06f84d2988bcd8e80c1f4590",
            "bcf8f092c6dc433095f712675feaafaa",
            "4698472ed45341c1a4990eef285b5ee3",
            "9c5ee25bd5dd46c4b2691bd124993ef5",
            "3a4817f80c3c4087bbebb7ecbb40e396",
            "f1ea26c351964cffa3e07cac12c3154a",
            "d53dac18874c41f684d20fc8d915ae4c",
            "cce84aab38ad447a931a1bb5b8edfefd",
            "c488bd459e314f7e9eb51a100b94b57e",
            "02fb68ffca7340268dfeacf64404cab9",
            "d70d150b5934406db59ba5349b883577",
            "1948c20bfc914ed9b5dadb71d2eb3a84",
            "41bb505d284b47bfb54e747253e628d8",
            "5686cce5d2da40c68ad9818b910c94d0",
            "e7ab762ea5a44a5cab212b2c01d72e9f",
            "1bfe45f8d4d04caa8290a9c30c34b35e",
            "f106ae970d6f43378ea9fec43eb7eb6a",
            "b6c0b5de2e754dffa559f91f098e19df",
            "0ffec8d5ca064f4786a3b28c3ea142e6",
            "40d82259ed5a435bb382d2a58b48a0b1",
            "9be74cefaab54f76b729ec4a458de91b",
            "363da27df72f4f29b5f3e9306500675d",
            "fa011ee0312b4cb2817d18312c286125",
            "10a0167e3607402e9a77ab37efc2357e",
            "21a9293b910148be8a68201e7a20361a",
            "17995c939c8342ec87bf3e4462020a8a",
            "9afbaa9a22da42428203c1af240f16e3",
            "0269244e54c84a7dad090e0d86080eaf",
            "3953c828ce6248f680f40cd4c9c721e5",
            "8fd3eb0408aa40f4aecaf2e0318c4a6b",
            "74ce67e127304450b843a75ff4601592",
            "e9fc917887b244918d6588d68a69427d",
            "142dd4c6b5c7409ea76a6a4a3b1513ef",
            "c704896c082c41d1af8cb7a02834618f",
            "90ccd2312f6041b69b5bbf0dc5c919be",
            "7b081b1a74654a608169e219115cf337",
            "5a733bf7314348c1a186bea313b819e1",
            "c19d630a8ed947e6a759aba6571f7a82",
            "82df27b6cf4f4a4686886ec969b732db",
            "51a1b69a38494ce88a08154b6f230c16",
            "b7f976e3fb744b40abbc25e1270f31f2",
            "856b1ff40b0145eea2b22ca7bc88aba1",
            "452465a4d3ae41e9aed61c0673c26760",
            "5006340699d94b40af39ec7f7ceef8cb",
            "7d6bf5e4e343470daf5540036b1938ce",
            "902ea199de0b47808e9ca797dc9bbbba",
            "686f20edb58f4b35bed24d951261b218",
            "76290aca4a3d40a19b2952b1224f0299",
            "6aa097873e2240f9ba8dd2925487aa76",
            "a180336d224a402a96b9a01b618e2e47",
            "4a742536c66d453aaf9b31c84a428f30",
            "47694425a75a4ca78346c8c0c8ebfe46",
            "914925cb74c54b2c9cd1e4bda638f1db",
            "46b3bc0e667349ebaa0a6df624b6f7bb",
            "c95d7ded5586438bbfb04f8f7d3e0f22",
            "7949c8d2c2334c5fbd73e0cdc4262c71",
            "417e51a679d247ebb1b4a9e71027a789",
            "6d994b9a288d4c41ba5e14f7c3e70d37",
            "49f30b4c13bc4a158eae3986a5929fb0",
            "1c0c1f8111f6421e9937aa4af96e4118",
            "a4777b6e8dfb498c8cbc49068752e97f",
            "51f321c4d035482aa2a40409d5c1811c",
            "d68f8b0bf2ee4af2a7989d0d8e23094c",
            "ad9c06033cf7428e8330d8c3d5c47b8c",
            "b07297ee4f8c429a8b69cbcbdc360561",
            "7dedc0b7b011472086d8690a5d2ebeff",
            "9a0ade68fef740f8b342fb2067f9e0aa",
            "e03e6cd94aec470cb153e710972d8158",
            "433bcf76ec3f477f8bf492d195d612b7",
            "ba7c0b547a7e4adba837a4de1879c497",
            "a455453e00e6477e9ecdc08c04dff079",
            "ea379833d0b2408d9e0984ec296d49ec",
            "0ac8c3b9608a4621bad47a200aed2dd4",
            "2a06a511885a48839a8d5891c5cbc0f7",
            "27fb3e3fd188485cbca2d702ed1638eb",
            "dac88225699d4b298566f5bbe8ce105a",
            "aa083fb3d3874a84a2e208add1503be1"
          ]
        },
        "id": "Mzl0zOSGOlS6",
        "outputId": "b7adb788-4680-41af-c494-af80dbb2acba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f28c5b932e6b4d5c95491ff7d50a7cab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/809M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbf51b16c6f24bcd97cf06b01825a47f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/484 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c95352a043a4ec28eb491a740086f43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie decoder.model.decoder.embed_tokens.weight to decoder.lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/809M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "841c7fbdc9f44812a48ff4b91a856e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3766a10f795f48a197bcec1793ff13d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/439 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c02cc532d7649569abbfda1b860dc3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The image processor of type `DonutImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/510 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b9f4c3888304f16b961e401abee80ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c19dfff72c248daa123879e0edf7954"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/235 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5914843230c64391a5a48e7bff0d56a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/355 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30c32d0df6724cb6b48d72091a9ddb88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/852 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eab62f52ec4642429df4891f9db6b488"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00003-49492f364babfa(…):   0%|          | 0.00/219M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eca265101a945e99240388d073bd059"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00003-7302bae5e425bb(…):   0%|          | 0.00/311M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e3e1bcd06f84d2988bcd8e80c1f4590"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00003-194c9400785577(…):   0%|          | 0.00/315M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1948c20bfc914ed9b5dadb71d2eb3a84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/val-00000-of-00001-0f11003c77497969(…):   0%|          | 0.00/50.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa011ee0312b4cb2817d18312c286125"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001-e2cd0b7a0f9eb20(…):   0%|          | 0.00/68.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c704896c082c41d1af8cb7a02834618f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/28299 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d6bf5e4e343470daf5540036b1938ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating val split:   0%|          | 0/1920 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7949c8d2c2334c5fbd73e0cdc4262c71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a0ade68fef740f8b342fb2067f9e0aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2599/1211089660.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# ============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HuggingFaceM4/ChartQA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#.select(range(25))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2464\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_subtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m                     \u001b[0mpa_subtable_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa_subtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2466\u001b[0;31m                     formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2467\u001b[0m                         \u001b[0mpa_subtable_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m                         \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mdecode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m         return {\n\u001b[0;32m-> 2093\u001b[0;31m             \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2094\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decode_example\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;31m# we pass the token to read and decode files from private repositories in streaming mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/features/image.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# to avoid \"Too many open files\" errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetexif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExifTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrientation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexif_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# ChartGemma SOTA Baseline on ChartQA (All‑in‑One Cell)\n",
        "# ==========================================================\n",
        "\n",
        "# ============================\n",
        "# 1️⃣ Imports\n",
        "# ============================\n",
        "import torch\n",
        "from PIL import Image\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
        "\n",
        "# ============================\n",
        "# 2️⃣ Load ChartGemma\n",
        "# ============================\n",
        "model_name = \"ahmed-masry/chartgemma\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model and processor\n",
        "model = PaliGemmaForConditionalGeneration.from_pretrained(model_name, torch_dtype=torch.float16).to(device)\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "\n",
        "# ============================\n",
        "# 3️⃣ Load ChartQA subset\n",
        "# ============================\n",
        "dataset = load_dataset(\"HuggingFaceM4/ChartQA\")[\"val\"]#.select(range(25))\n",
        "dataset = [dict(ex) for ex in dataset]\n",
        "\n",
        "# ============================\n",
        "# 4️⃣ Inference helper\n",
        "# ============================\n",
        "def run_chartgemma_inference(image_or_path, question):\n",
        "    # Build the prompt\n",
        "    prompt = f\"program of thought: {question}\"\n",
        "\n",
        "    # Load image (path or PIL)\n",
        "    if isinstance(image_or_path, str):\n",
        "        image = Image.open(image_or_path).convert(\"RGB\")\n",
        "    else:\n",
        "        image = image_or_path.convert(\"RGB\")\n",
        "\n",
        "    # Tokenize inputs\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Track prompt length (for decoding later)\n",
        "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
        "\n",
        "    # Generate\n",
        "    outputs = model.generate(**inputs, num_beams=4, max_new_tokens=128)\n",
        "\n",
        "    # Decode only the *generated* output beyond the prompt\n",
        "    decoded = processor.batch_decode(outputs[:, prompt_len :], skip_special_tokens=True)[0]\n",
        "    return decoded.strip()\n",
        "\n",
        "# ============================\n",
        "# 5️⃣ Run baseline on first 25 samples\n",
        "# ============================\n",
        "exact_correct = 0\n",
        "relaxed_correct = 0\n",
        "\n",
        "for i, example in enumerate(dataset):\n",
        "    image_path = example[\"image\"]\n",
        "    question = example[\"query\"]\n",
        "    gt_answer = example[\"label\"][0]  # assume single GT\n",
        "\n",
        "    try:\n",
        "        pred_answer = run_chartgemma_inference(image_path, question)\n",
        "    except Exception as e:\n",
        "        pred_answer = \"\"\n",
        "        print(f\"[WARN] Error on sample {i}: {e}\")\n",
        "\n",
        "    # exact\n",
        "    if pred_answer.lower() == gt_answer.lower():\n",
        "        exact_correct += 1\n",
        "\n",
        "    # relaxed (±5% numeric or substring)\n",
        "    try:\n",
        "        gt_val = float(gt_answer)\n",
        "        pred_val = float(pred_answer)\n",
        "        if abs(pred_val - gt_val) / max(abs(gt_val), 1e-6) <= 0.05:\n",
        "            relaxed_correct += 1\n",
        "    except:\n",
        "        if gt_answer.lower() in pred_answer.lower():\n",
        "            relaxed_correct += 1\n",
        "\n",
        "    print(f\"Sample {i+1}: Q: {question} | GT: {gt_answer} | Pred: {pred_answer}\")\n",
        "\n",
        "total = len(dataset)\n",
        "print(\"\\n==============================\")\n",
        "print(\"ChartGemma SOTA Results (first 25)\")\n",
        "print(\"==============================\")\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact Accuracy: {exact_correct/total:.4f}\")\n",
        "print(f\"Relaxed Accuracy: {relaxed_correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5b95a1065e0e4466ab6754cd6a81c070",
            "b005fa930b644fdcacc60220196dc520",
            "3a8d845994cb4252b73a22044330938c",
            "91d79a1aa9394aebb70e55d5e390445d",
            "f44120376530423e869feb2d5c0eadc1",
            "4135c8bebc7848578d3485288e45b260",
            "d7eb7c27e9b4418ebb47a87f0edf20ac",
            "1ed4fe2dd57a4605b7348eb8106ba30b",
            "511a5096962f4781bcfbe2f2c04d7c1d",
            "2bdd0cb677f34368a89859a23f09a0a4",
            "aab1204b9c9149dba41eb7d08d120117",
            "f3f53af31b9f4dc2b1b2e44ea8660f52",
            "cea8bb80f58f4a5cb9298a264f4754c3",
            "60e61fbad2214b6c934977ad3660cea3",
            "f9b14ebc79b044dfbf10bf1ce7c80c68",
            "caf98d8eb071434c98d9f1a5f431908d",
            "25809f63534e446aab4b4606be533c56",
            "205e5e7fd89c4dbd8805e6a6ab2205eb",
            "3fbd74ac0a1a496ba6fa5180bc098691",
            "ee33db35e197447c889f5577171f4418",
            "027af948f19048cdb3427811940a9362",
            "af4f86050a344a90bcb01b83a25013a6",
            "da58cdf5d65f4942be496df49348de29",
            "8c8302d61fbc451988479397ad40c0d4",
            "3ddbc95c9bdd4a928aef6167b621dca5",
            "4dc6f81a2bd14b65a89cbe9b632d9f68",
            "699b7d35663b461ea72049f927f401b9",
            "2294c6f395af4d35b8187ba806952ced",
            "693ca4223ed142efb3ea8a6b9aa15c69",
            "865acd25f9584d8e8c09a838cb628fa0",
            "234ab55548644fda8cb3ce067f37bd3d",
            "8f9b0e66611144b084c4be9bc52ec20a",
            "9a8f1ed36dfb49bbb93dda82d124081d"
          ]
        },
        "id": "B2GDa1Mfn7OG",
        "outputId": "e11685e1-6321-40f3-e1c5-39e12953a143"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b95a1065e0e4466ab6754cd6a81c070"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3f53af31b9f4dc2b1b2e44ea8660f52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/603 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da58cdf5d65f4942be496df49348de29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n",
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: Q: What's the color of graph with 56 as the highest value? | GT: Blue | Pred: print(\"U.S.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 2: Q: In which year the difference between blue and green graph 1? | GT: 2018 | Pred: print(\"2011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 3: Q: What does the blue line represent? | GT: Not too much/not at all | Pred: print(\"Not too much/not at all\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 4: Q: What is the max value of blue line? | GT: 0.72 | Pred: print(72)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 5: Q: What's the percentage of respondents who say Job is a top priority for the president and Congress in 2016? | GT: 68 | Pred: print(68)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 6: Q: Which line has the lowest value of 71%? | GT: Economy | Pred: print('Economy')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 7: Q: What is the unfavourable value in 2014? | GT: 64 | Pred: print(64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 8: Q: What is the median value of favourable line in the graph? | GT: 40 | Pred: favorable_values = [30, 40, 31]\n",
            "favorable_values.sort()\n",
            "median_value = favorable_values[1]\n",
            "print(median_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 9: Q: Which answer response has the highest value on this graph? | GT: Disapprove | Pred: print(\"53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 10: Q: How many data points on the disapprove line are above 50? | GT: 2 | Pred: disapprove_lines = [52, 51, 47, 51, 49, 46, 46, 44, 53, 49, 49, 43]\n",
            "above_50 = 0\n",
            "for disappro in disappro:\n",
            "  if disappro == 53:\n",
            "    above_50 += 1\n",
            "print(above_50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 11: Q: Which indicator remains all time lowest from Dec. 2008 to Sep. 2011? | GT: Mostly good news | Pred: print(\"Mostly good news\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 12: Q: How much value of 'Mostly bad news' increased from Jan. 2011 to Sept. 2011? | GT: 37 | Pred: value_jan2011 = 33\n",
            "value_sept2011 = 30\n",
            "increase = value_jan2011 - value_sept2011\n",
            "print(increase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 13: Q: When does the red line reach the peak? | GT: 44538 | Pred: print(\"Jan 2011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 14: Q: What's the total sum of peak points of all three lines? | GT: 155 | Pred: peak_1 = 80\n",
            "peak_2 = 68\n",
            "peak_3 = 67\n",
            "total = peak_1 + peak_2 + peak_3\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 15: Q: When does the yellow line reach the peak? | GT: 44207 | Pred: print(\"Jan 2011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 16: Q: What's the total sum of peak points of green and red lines? | GT: 87 | Pred: green_peak = 4\n",
            "red_peak = 68\n",
            "total = green_peak + red_peak\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 17: Q: What's the lowest value of yellow line? | GT: 19 | Pred: print(19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 18: Q: What's the difference of value of highiest value of red and lowest value of green line? | GT: 79 | Pred: highest_red = 80\n",
            "lowest_green = 3\n",
            "difference = highest_red - lowest_green\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 19: Q: What is the colour of oppose in the graph? | GT: Light blue | Pred: print(\"Blue\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 20: Q: How many times there is 44 value in the Favor? | GT: 3 | Pred: answer = 2\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 21: Q: What is the percentage of people who are dissatisfied with Spain's democracy? | GT: 68 | Pred: print(68)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 22: Q: What is the ratio of people who are dissatisfied and satisfied with Spain's democracy? | GT: 2.125 | Pred: dissatisfied = 68\n",
            "satisfied = 32\n",
            "ratio = dissatisfied / satisfied\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 23: Q: Is the Pie chart divided into 3 segment? | GT: Yes | Pred: print(\"Yes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 24: Q: IS the value of No more then sum of Yes and Dk? | GT: Yes | Pred: yes = 17\n",
            "dk = 10\n",
            "no = 73\n",
            "\n",
            "if no > yes + dk:\n",
            "  print(\"Yes\")\n",
            "else:\n",
            "  print(\"No\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 25: Q: What is the percentage of Iraqi dependents citizen? | GT: 0.12 | Pred: print(18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 26: Q: What is the total percentage of Afghan applicants and Iraqi applicants? | GT: 0.34 | Pred: print(22 + 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 27: Q: Is the color of 53% segment light green? | GT: No | Pred: # The color of the 53% segment is light green.\n",
            "print(\"Yes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 28: Q: What's the ratio of Lean Republican segment and Republican segment? | GT: 0.7358 | Pred: lean_republican = 39\n",
            "republican = 53\n",
            "ratio = lean_republican / republican\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 29: Q: What segment represent by dark grey color? | GT: Both | Pred: print(\"Both\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 30: Q: What is the percentage of both and don't know? | GT: [4, 9] | Pred: both = 4\n",
            "don_t_know = 9\n",
            "print(both)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 31: Q: What's the value of leftmost bar in the bottom? | GT: 12 | Pred: print(12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 32: Q: What is the largest value of dark green bar? | GT: 0.92 | Pred: print(92)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 33: Q: Which country data analysed here? | GT: cuba | Pred: print(\"Cuba\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 34: Q: What is the maximum value of dark brown bar? | GT: 7 | Pred: print(max([42, 48, 46, 35, 34, 33, 36, 50, 47, 56]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 35: Q: What's the percentage of very important bar for healthy eating habits? | GT: 0.72 | Pred: print(72)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 36: Q: What's the average of green bar median and light blue bar median? | GT: 17 | Pred: green_bar_median = 34\n",
            "light_blue_bar_median = 45\n",
            "average = (green_bar_median + light_blue_bar_median) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 37: Q: What does dark blue bar represents? | GT: Very Important | Pred: print(\"Somewhat important\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 38: Q: What's the average value of all dark blue bars? | GT: 62.75 | Pred: dark_blue_bars = [72, 71, 61, 47]\n",
            "average = sum(dark_blue_bars) / len(dark_blue_bars)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 39: Q: What does the color green indicate? | GT: Support | Pred: print(\"Support\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 40: Q: What is the difference between the longest and the shortest green bar? | GT: 7 | Pred: longest_green_bar = 73\n",
            "shortest_green_bar = 66\n",
            "difference = longest_green_bar - shortest_green_bar\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 41: Q: Which country has the highest percentage value of \"a lot\"? | GT: Kenya | Pred: print(\"Hungary\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 42: Q: What is the maximum value of \"a lot\" among countries? | GT: 0.69 | Pred: a_lot_values = [69, 68, 62, 56, 55, 55, 50, 48, 32]\n",
            "max_a_lot_index = a_lot_values.index(max(a_lot_values))\n",
            "countries = ['Kenya', 'Nigeria', 'South Africa', 'U.S.', 'India', 'Greece', 'Italy', 'Poland', 'Hungary']\n",
            "print(countries[max_a_lot_index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 43: Q: How many bars are there in the graph? | GT: 2 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 44: Q: What is the total sum of both the bars? | GT: 7.81 | Pred: print(6.47 + 1.34)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 45: Q: What's the value of United States? | GT: 0.124 | Pred: print(12.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 46: Q: What's the average value of Canada, Belgium and France? | GT: 0.0277 | Pred: canada = 1.81\n",
            "belgium = 3.52\n",
            "france = 3.52\n",
            "average = (canada + belgium + france)/3\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 47: Q: What is the death rate in the age group 5-14 years old? | GT: 0.0034 | Pred: print(0.34)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 48: Q: Find the median value of all the bars? | GT: 0.68 | Pred: values = [1.56, 0.86, 0.77, 0.68, 0.6, 0.48, 0.34]\n",
            "values.sort()\n",
            "median = values[len(values) // 2]\n",
            "print(median)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 49: Q: Which place shows the highest death rate? | GT: Grenada | Pred: print(\"Grenada\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 50: Q: Is the value of death rate in Denmark more then Croatia? | GT: No | Pred: denmark_value = 0.03\n",
            "croatia_value = 0.1\n",
            "print(denmark_value > croatia_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 51: Q: How many categories are there in the chart? | GT: 3 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 52: Q: What's the average of two smallest bar? | GT: 70.535 | Pred: smallest_bar_1 = 34.58\n",
            "smallest_bar_2 = 106.49\n",
            "average = (smallest_bar_1 + smallest_bar_2) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 53: Q: How many bars are there in the graph? | GT: 2 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 54: Q: What is the total add up value of Both the bars? | GT: 59 | Pred: spain = 39\n",
            "canada = 20\n",
            "total = spain + canada\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 55: Q: What denotes the light blue color bar? | GT: United States | Pred: print(\"United States\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 56: Q: What's the average value of all bars in the chart? | GT: 126.41 | Pred: values = [13.76, 1.65, 363.82]\n",
            "average = sum(values) / len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 57: Q: What does the value 2122 represent? | GT: Incidence | Pred: print(\"Incidence\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 58: Q: What is the difference in the value between Incidence and Prevalence? | GT: 1092 | Pred: incidence = 2122\n",
            "prevalence = 1030\n",
            "difference = incidence - prevalence\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 59: Q: Which age group has the highest value? | GT: 20-24 years old | Pred: print(\"20-24 years old\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 60: Q: Find the average of the percentage value of bars greater than 1? | GT: 1.608 | Pred: values = [2, 1.82, 1.58, 1.39, 1.25, 0.77, 0.74]\n",
            "average = sum(values) / len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 61: Q: Which state shows the highest fertility rate? | GT: Malawi | Pred: print('Malawi -')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 62: Q: Is the value of Malawi greater then sum of Netherlands and Africa? | GT: Yes | Pred: Malawi = 7.16\n",
            "Netherlands = 4.54\n",
            "Africa = 6.14\n",
            "sum = Netherlands + Africa\n",
            "print(Malawi > sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 63: Q: What is the value of the largest bar? | GT: 1715 | Pred: print(1715)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 64: Q: What is the difference between the largest bar and the smallest bar? | GT: 1654 | Pred: largest_bar = 1715\n",
            "smallest_bar = 61\n",
            "difference = largest_bar - smallest_bar\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 65: Q: Which country has its value 5.97%? | GT: India | Pred: print(\"India\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 66: Q: Find the total percentage of the three countries having values lower than India? | GT: 0.07 | Pred: Hungary = 22.6\n",
            "Thailand = 18.81\n",
            "Egypt = 13.14\n",
            "total = Hungary + Thailand + Egypt\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 67: Q: What is the value of longest bar? | GT: 96 | Pred: print(94)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 68: Q: How many bars have value less then 1? | GT: 5 | Pred: bars = [1, 11, 3, 1, 0]\n",
            "count = 0\n",
            "for bar in bars:\n",
            "  if bar < 1:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 69: Q: Which country represent by pink bar? | GT: Ethiopia | Pred: print(\"Ethiopia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 70: Q: What is the difference between red and blue bar? | GT: 0.56 | Pred: red_bar = 80.22\n",
            "blue_bar = 42.61\n",
            "difference = red_bar - blue_bar\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 71: Q: How many response options are below 150 n mi? | GT: 2 | Pred: options = [72.1, 72.8, 138.8]\n",
            "print(len(options))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 72: Q: What is the average of '24 hours' and '48 hours'? | GT: 105.45 | Pred: print((72.1 + 138.8) / 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 73: Q: Which year mentioned in the heading of the chart? | GT: 1911 | Pred: print(\"1911\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 74: Q: How many times political competition data bigger than political participation? | GT: 7.02 | Pred: political_competition = 5.9\n",
            "political_participation = 0.84\n",
            "result = political_competition / political_participation\n",
            "print(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 75: Q: Find the value of green bar? | GT: 1.45 | Pred: print(\"1.45 million t\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 76: Q: How many times green bar greater than Agriculture bar? | GT: 8.53 | Pred: green_bar = 1.45\n",
            "agriculture_bar = 170000\n",
            "count = 0\n",
            "for i in [180000, 170000, 170000, 20000, 0]:\n",
            "  if i > agriculture_bar:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 77: Q: What is the value shown for Australia? | GT: 0.4368 | Pred: print(43.68)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 78: Q: What is the average of bottom three bars? | GT: 38.08 | Pred: bottom_three = [40.34, 30.22, 43.68]\n",
            "average = sum(bottom_three) / len(bottom_three)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 79: Q: What is color of the Age-standardized? | GT: cyan | Pred: print(\"teal\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 80: Q: What is the value of the 50-69 years old? | GT: 8.88 | Pred: print(8.88)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 81: Q: The value is 40.49, find the category? | GT: Kidney cancer | Pred: print(\"Kidney cancer\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 82: Q: How many times stomach cancer bigger than Kidney cancer data? | GT: 10.13 | Pred: # Stomach cancer data is 410.3\n",
            "# Kidney cancer data is 40.49\n",
            "# Calculate the ratio\n",
            "ratio = 410.3 / 40.49\n",
            "# Print the result\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 83: Q: Which two places mentioned in the chart? | GT: [Madagascar, Central Europe] | Pred: print([\"Madagascar\", \"Central Europe\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 84: Q: How much times Madagascar greater than Central europe data? | GT: 32 | Pred: Madagascar = 0.96\n",
            "Central_Europe = 0.03\n",
            "answer = Madagascar/Central_Europe\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 85: Q: What is the average maize yield in Syria? | GT: 3.251 | Pred: print(3.25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 86: Q: Find the ratio of highest value and average of two lowest values? | GT: 1.841359773 | Pred: highest_value = 3.25\n",
            "average_lowest = (1.03 + 2.5) / 2\n",
            "lowest_two_values = [1.03, 2.5]\n",
            "ratio = highest_value / average_lowest\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 87: Q: What is Female-to-male ratio to time devoted to unpaid care work in Italy? | GT: 3.37 | Pred: answer = 3.37\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 88: Q: What is the average of the values lower than 3 and greater than 2? | GT: 2.445 | Pred: values = [1.61, 2.22]\n",
            "average = sum(values) / len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 89: Q: What is the value of largest bar? | GT: 396 | Pred: print(398)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 90: Q: Is the add up value of Comoros,Nicargua,Australia,Belgium is gretaer then Laos? | GT: No | Pred: Laos = 398\n",
            "Comoros = 180\n",
            "Nicargua = 68\n",
            "Australia = 18\n",
            "Belgium = 14\n",
            "sum_up_value = Comoros + Nicargua + Australia + Belgium\n",
            "print(sum_up_value > Laos)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 91: Q: Which country has longest bar? | GT: Malta | Pred: print(\"Malta\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 92: Q: What is the difference of Sweden and Malta? | GT: 7.49 | Pred: Malta = 12.5\n",
            "Sweden = 5.01\n",
            "difference = Malta - Sweden\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 93: Q: How many colors are used in the graph? | GT: 1 | Pred: print(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 94: Q: What is the sum of largest and smallest bar? | GT: 159.85 | Pred: largest_bar = 137.65\n",
            "smallest_bar = 22.2\n",
            "sum = largest_bar + smallest_bar\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 95: Q: How many colors are represented in the bar?? | GT: 5 | Pred: print(5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 96: Q: What is the difference between Industry employment percentage in Iran and Kenya?? | GT: 26.38 | Pred: Iran = 34.5\n",
            "Kenya = 8.12\n",
            "difference = Iran - Kenya\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 97: Q: Which place shows the highest cases of guinea worm? | GT: South Sudan | Pred: print(\"South Sudan\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 98: Q: Is the sum of Senegal and Central African Republic more then Chad? | GT: No | Pred: Senegal = 4\n",
            "Central_African_Republic = 5\n",
            "Chad = 25\n",
            "sum_Senegal_Central_African_Republic = Senegal + Central_African_Republic\n",
            "print(sum_Senegal_Central_African_Republic > Chad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 99: Q: How many colors are represented in the bar?? | GT: 8 | Pred: print(8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 100: Q: What's the average value of first two bars in the chart?? | GT: 0.33 | Pred: print((0.35 + 0.31)/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 101: Q: What group has the highest death rate? | GT: 70+ years old | Pred: print(\"70+ years old\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 102: Q: What is the difference between the death rates of 5-14 ears old with the death rate of 70+ years old? | GT: 272.62 | Pred: death_rate_5_14 = 3.69\n",
            "death_rate_70_years_old = 275.75\n",
            "difference = death_rate_70_years_old - death_rate_5_14\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 103: Q: Which country represented by Brown bar? | GT: Bangladesh | Pred: print(\"Bangladesh\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 104: Q: What is the difference of largest and smallest bar? | GT: 409.13 | Pred: largest = 411.8\n",
            "smallest = 2.67\n",
            "difference = largest - smallest\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 105: Q: Which country is indicated by the middle bar? | GT: Namibia | Pred: print(\"Namibia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 106: Q: Total values of all the three bars lower than .02? | GT: No | Pred: print(\"Yes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 107: Q: Which country has longest bar? | GT: Iraq | Pred: print(\"Iraq\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 108: Q: Does the sum of smallest two bar is greater then the largest bar? | GT: No | Pred: smallest_bar_1 = 2229.38\n",
            "smallest_bar_2 = 13323.52\n",
            "largest_bar = 28735.32\n",
            "sum_of_smallest = smallest_bar_1 + smallest_bar_2\n",
            "print(sum_of_smallest > largest_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 109: Q: What is the color of Mexico bar? | GT: Pink | Pred: print(\"pink\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 110: Q: What is the sum of smallest three bar? | GT: 3.7 | Pred: smallest_three = [0.2, 0.3, 3.2]\n",
            "sum_of_smallest_three = sum(smallest_three)\n",
            "print(sum_of_smallest_three)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 111: Q: What is the highest value in the bar graph? | GT: 23 | Pred: print(23)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 112: Q: Is Croatia global hunger index extremely alarminhg? | GT: No | Pred: print(5 > 35)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 113: Q: How many colors are used in the graph? | GT: 1 | Pred: print(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 114: Q: What is the average of smallest two bars? | GT: 13 | Pred: smallest_bar1 = 7\n",
            "smallest_bar2 = 19\n",
            "average = (smallest_bar1 + smallest_bar2) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 115: Q: What denotes the green color bar ?? | GT: Sub-Saharan Africa | Pred: print(\"World\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 116: Q: Find out the average of the bottom three countries ?? | GT: 0.0593 | Pred: europe_and_northern_america = 6.8\n",
            "latin_america_and_the_caribbean = 5.7\n",
            "south_and_southern_asia = 5.3\n",
            "average = (europe_and_northern_america + latin_america_and_the_caribbean + south_and_southern_asia) / 3\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 117: Q: What country is represented by the Red bar? | GT: Libya | Pred: print(\"Libya\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 118: Q: What is the difference between the largest bar and the smallest bar? | GT: 0.092 | Pred: largest_bar = 67.5\n",
            "smallest_bar = 58.3\n",
            "difference = largest_bar - smallest_bar\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 119: Q: Which animal is represented by longest bar? | GT: Cattle | Pred: print(\"Cattle\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 120: Q: What is difference of value of Paddy rice and Wheat? | GT: 6.5 | Pred: Paddy_rice = 7.3\n",
            "Wheat = 0.8\n",
            "difference = Paddy_rice - Wheat\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 121: Q: How many region are shown in the chart? | GT: 7 | Pred: print(7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 122: Q: What the difference in value between Asia and Caribbean? | GT: 1.18 | Pred: asia = 61.21\n",
            "caribbean = 60.03\n",
            "difference = caribbean - asia\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 123: Q: What is the death rate from drug use disorders in Thailand? | GT: 0.77 | Pred: print(0.77)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 124: Q: Is the average value of Andean Latin America and Cambodia more than the value of Thailand? | GT: Yes | Pred: Andean_Latin_America = 1.47\n",
            "Cambodia = 0.39\n",
            "Thailand = 0.77\n",
            "average = (Andean_Latin_America + Cambodia) / 2\n",
            "if average > Thailand:\n",
            "  print(\"True\")\n",
            "else:\n",
            "  print(\"False\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 125: Q: What is the number of undernourished people in Southern Asia as of 2000 ( in millions)? | GT: 264.5 | Pred: print(264.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 126: Q: What is the sum of undernourished people in Low Income economies and Sub-Saharan Africa combined (in millions)? | GT: 341.9 | Pred: low_income = 161.1\n",
            "sub_saharan_africa = 180.8\n",
            "combined = low_income + sub_saharan_africa\n",
            "print(combined)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 127: Q: What is the value of Pink bar? | GT: 21524 | Pred: print(10427)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 128: Q: Does the Saudi Arabia and Australasia has same value ? | GT: No | Pred: print(\"No\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 129: Q: What does the color orange represent? | GT: Estimated number of polio cases | Pred: print(\"Estimated number of polio cases\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 130: Q: How many bar has the same value ? | GT: 2 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 131: Q: What does the lowest bar represent? | GT: Pre-demographic dividend | Pred: print(\"Pre-demographic dividend\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 132: Q: What is the difference of value  between Malaysia and Barbados? | GT: 10.18 | Pred: Malaysia = 26.6\n",
            "Barbados = 36.78\n",
            "difference = Barbados - Malaysia\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 133: Q: How many age group are shown the graph? | GT: 6 | Pred: print(6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 134: Q: What is the sum of lowest bar and top most bar in the grap? | GT: 61.23 | Pred: lowest_bar = 0\n",
            "top_most_bar = 61.23\n",
            "sum = lowest_bar + top_most_bar\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 135: Q: What is the % of people who are undernourished in Southern Asia as of 2000? | GT: 18.2 | Pred: print(18.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 136: Q: Is the sum of the % of people who are undernourished in Southern Asia and Eastern Asia more than that in Sub-Saharan Africa? | GT: Yes | Pred: southern_asia = 18.2\n",
            "eastern_asia = 14.7\n",
            "sub_saharan_africa = 28.4\n",
            "sum_of_southern_and_eastern_asia = southern_asia + eastern_asia\n",
            "print(sum_of_southern_and_eastern_asia > sub_saharan_africa)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 137: Q: What is the % of people who are worried about losing their job in Cyprus? | GT: 58.79 | Pred: print(58.79)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 138: Q: What is the difference in % between Poland and Australia for people who are worried about losing their job? | GT: 17.05 | Pred: Poland = 49.31\n",
            "Australia = 32.26\n",
            "difference = Poland - Australia\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 139: Q: In which country has the smallest value? | GT: Angola | Pred: print(\"South Sudan\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 140: Q: How many bars with the equal value in the bar graph? | GT: 2 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 141: Q: Which country recorded highest percentage in the chart ? | GT: Tanzania | Pred: print(\"Tanzania\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 142: Q: How many times Tanzania data bigger than Ethiopia data ? | GT: 3.5 | Pred: Tanzania_data = 55.5\n",
            "Ethiopia_data = 15.6\n",
            "answer = Tanzania_data / Ethiopia_data\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 143: Q: What's the value of smallest bar? | GT: 0.96 | Pred: print('0.96')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 144: Q: Does the difference of iDA only and Upper middle income is equal to the value of smallest bar? | GT: No | Pred: iDA_only = 2.36\n",
            "upper_middle_income = 1.87\n",
            "smallest_bar = 0.96\n",
            "\n",
            "print(iDA_only - upper_middle_income == smallest_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 145: Q: Which country has highest Pig meat yields ? | GT: United States | Pred: countries = ['United States', 'Canada', 'China', 'India']\n",
            "yields = [81.5, 76.5, 73.8, 66.1]\n",
            "highest_yield = max(yields)\n",
            "index_of_highest_yield = yields.index(highest_yield)\n",
            "print(countries[index_of_highest_yield])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 146: Q: What is the difference in Green and Purple bar? | GT: 5 | Pred: green_bar = 81.5\n",
            "purple_bar = 76.5\n",
            "difference = green_bar - purple_bar\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 147: Q: What's the value of largest bar? | GT: 270827 | Pred: print(270827)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 148: Q: Does the sum of smallest two bar is equal to 3rd smallest bar? | GT: No | Pred: smallest = 18103\n",
            "second_smallest = 38582\n",
            "third_smallest = 75131\n",
            "smallest_two = smallest + second_smallest\n",
            "third_smallest_bar = 75131\n",
            "print(smallest_two == third_smallest_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 149: Q: How many colors are there in the graph? | GT: 4 | Pred: print(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 150: Q: Does the sum of smallest two bar is greater then then the value of largest bar? | GT: Yes | Pred: smallest_bar_1 = 4.58\n",
            "smallest_bar_2 = 6.29\n",
            "largest_bar = 7.3\n",
            "sum_smallest_bars = smallest_bar_1 + smallest_bar_2\n",
            "print(sum_smallest_bars > largest_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 151: Q: What is the value of middle bar ? | GT: 81.71 | Pred: print(\"81.71% (2016)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 152: Q: What is ratio between Primary school and upper secondary ? | GT: 0.3493 | Pred: primary_school = 34.93\n",
            "upper_secondary = 100\n",
            "ratio = primary_school / upper_secondary\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 153: Q: what is orange bar represents ? | GT: Europe | Pred: print(\"Europe\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 154: Q: what is the sum of africa and pacific ? | GT: 0.07 | Pred: africa = 4\n",
            "pacific = 3\n",
            "sum = africa + pacific\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 155: Q: Which color bar resembles the name of a fruit? | GT: orange | Pred: print(\"Child Labor (All, World, ILO-IPEC)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 156: Q: What is the value of the Child Labor bar? | GT: 0.193 | Pred: print(\"21.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 157: Q: In chart Middle bar represents what ? | GT: Madagascar | Pred: print(\"Madagascar\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 158: Q: What is the average of all the numbers ? | GT: 1.55 | Pred: numbers = [1.69, 1.51, 1.45]\n",
            "average = sum(numbers) / len(numbers)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 159: Q: Which is the highest percentage of the value? | GT: 0.405 | Pred: print(\"Philippines\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 160: Q: What is the value of the United Kingdom? | GT: 0.354 | Pred: print(35.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 161: Q: What is the color of the shortest bar? | GT: Gray | Pred: print(\"5-14 years old\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 162: Q: Would the combined homicide rate for the 5-14 and Under 5's be bigger than All Ages? | GT: No | Pred: print(12.7 + 4.16 > 16.82)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 163: Q: How many lines are shown in the chart? | GT: 6 | Pred: print(6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 164: Q: When does the gap between Nigeria and India reach the largest value? | GT: 2021 | Pred: print(\"2021\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 165: Q: Which country has the highest value in 1979? | GT: Iceland | Pred: print(\"Ukraine\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 166: Q: Which country has the smallest fluctuations in the chart? | GT: South Korea | Pred: print(\"South Korea\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 167: Q: In which year was the death rate due to unsafe water sources is lowest in the Maldives? | GT: 2000 | Pred: print(\"2000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 168: Q: Which country saw the higher death rate due to unsafe water sources from 1990 to 2000 between Palestine and Norway? | GT: Palestine | Pred: print(\"Maldives\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 169: Q: The pink line in the chart belongs to which country data? | GT: France | Pred: print(\"Georgia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 170: Q: Find out Which country data is stable for the entire 3 years? | GT: France | Pred: print(\"Germany\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 171: Q: When did the line reach its peak? | GT: 1998 | Pred: print(\"1998\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 172: Q: During which period does the line have the greatest increase? | GT: 1998 | Pred: print(\"1998 to 2004\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 173: Q: Which two countries are being compared in the given line graph? | GT: [Africa, Northern America] | Pred: print([\"World\", \"Africa\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 174: Q: Which of the following countries saw a higher demand in education over the given years, Africa or North America? | GT: Africa | Pred: print(\"Africa\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 175: Q: What does Orange line represents? | GT: Urban | Pred: print(\"Urban\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 176: Q: What's the difference in the value of highest percentage value given in the chart and the percentage points where two lines cross? | GT: 0.3 | Pred: print(83-50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 177: Q: In which year the share of youth not in education is maximum� in Laos? | GT: 2017 | Pred: print(\"2017\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 178: Q: In how many years the share of youth not in education is more than 20 %? | GT: 4 | Pred: years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
            "count = 0\n",
            "for year in years:\n",
            "  if year == 2010 or year == 2011 or year == 2012 or year == 2013 or year == 2014 or year == 2015 or year == 2016 or year == 2017:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 179: Q: In which year the commercial bank branches are maximum in Senegal? | GT: 2009 | Pred: print(\"2009\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 180: Q: In how many years does the number of commercial bank branches are greater than 30 in Montenegro? | GT: 3 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 181: Q: What age group does the Red bar Show in the graph? | GT: 15-17 years | Pred: print(\"15-17 years\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 182: Q: Which among Red and Grey bar has the highest value in the year 2000? | GT: Red | Pred: print(\"Red\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 183: Q: Which year saw the maximum change in the death rate due to tuberculosis in the age group 70+ years old in Seria? | GT: 2010 | Pred: print(1995)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 184: Q: Which age group saw the maximum change in the death rate due to tuberculosis over the years? | GT: Under-5s | Pred: print(\"15-49 years old\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 185: Q: Which year recorded the least daily hempseed production in Europe? | GT: 1990 | Pred: print(\"1989\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 186: Q: Which of the following saw the higher daily hempseed production over the years, Europe or Europe, Western? | GT: Europe | Pred: print(\"Europe\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 187: Q: How many years shows the Unemployment rate in the graph? | GT: 9 | Pred: years = ['1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005']\n",
            "print(len(years))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 188: Q: In which year did the color green and orange bar intersect? | GT: 2005 | Pred: print(\"2004\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 189: Q: Which age group recorded the highest daily rates of bipolar disorder in Argentina? | GT: 15-49 years old | Pred: print(\"15-49 years old\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 190: Q: How many age groups are mentioned in the given graph? | GT: 4 | Pred: print(5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 191: Q: How many regions have more than 60 % proportions that applied for accreditation? | GT: 1 | Pred: proportions = {\n",
            "    'Southern Asia': 65,\n",
            "    'Eastern Asia (excluding Japan)': 65,\n",
            "    'Latin America and the Caribbean': 50,\n",
            "    'World': 45,\n",
            "    'Sub-Saharan Africa': 40\n",
            "}\n",
            "count = 0\n",
            "for region, proportion in proportions.items():\n",
            "    if proportion > 60:\n",
            "        count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 192: Q: Which region saw the highest proportion of accreditation over the given years? | GT: Southern Asia | Pred: print(\"Southern Asia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 193: Q: In which year the share of people having access to clean fuel for cooking is maximum in Bosnia and Herzegovina? | GT: 2013 | Pred: print(\"2013\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 194: Q: Which of the following countries has had higher access to clean fuels for cooking over the years, Latvia or Belize? | GT: Latvia | Pred: print(\"Latvia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 195: Q: Which year recorded the highest prevalence of Anemia in women in the Bahamas? | GT: 1990 | Pred: print(1990)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 196: Q: Which of the following countries recorded the higher prevalence of Anemia in women over the years, Zambia or Bahamas? | GT: Zambia | Pred: print(\"Zambia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 197: Q: Which year recorded the lowest mortality rate in the Caribbean? | GT: 1990 | Pred: print(1990)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 198: Q: In how many years has the mortality rate is greater than 10% in the Caribbean? | GT: 3 | Pred: years = [1965, 1970, 1975, 1980, 1985, 1990]\n",
            "count = 0\n",
            "for year in years:\n",
            "  if year > 10:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 199: Q: Which year does Czechia point? | GT: 1992 | Pred: print(\"1990 1992\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 200: Q: Between which, two years does the bar shows the lowest value? | GT: [1965, 1970] | Pred: print(\"1965 and 1970\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 201: Q: Which year recorded the maximum urban population living in slums in Kenya? | GT: 2000 | Pred: print(2000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 202: Q: Which year recorded the least urban population living in slums in Kenya? | GT: 1990 | Pred: print(1990)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 203: Q: What does country does the orange line represent? | GT: Tajikistan | Pred: print(\"Tajikistan\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 204: Q: what is the difference in Alcohol and drug use disorders in Tajikistan between 2000 and 2009? | GT: 0.005 | Pred: print(1.5 - 0.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 205: Q: How many drugs are shown in the graph? | GT: 4 | Pred: print(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 206: Q: When does the gap between Opioids and Cocaine reach the peak? | GT: 2014 | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 207: Q: In which year the home production time by male age group 25-54 is minimum? | GT: 1930 | Pred: print(1980)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 208: Q: In how many years the weekly production time by age group 55-64 is greater than 25 hours? | GT: 31 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 209: Q: Which country is represented by the blue color line? | GT: Russia | Pred: print(\"Russia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 210: Q: Which country has a higher share of the population using safely managed drinking water over the years? | GT: Bosnia and Herzegovina | Pred: print(\"Bosnia and Herzegovina\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 211: Q: Which year recorded the highest suicide rates by males in Portugal? | GT: 1996 | Pred: print(1996)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 212: Q: Which of the following sex recorded the higher suicide rates over the years, male or female? | GT: Male | Pred: print(\"Male\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 213: Q: Which country is represented by the red color line? | GT: United States Virgin Islands | Pred: print(\"United States Virgin Islands\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 214: Q: In how many countries the concentration of particulate matter is found to be more than 20 micrograms? | GT: 2 | Pred: countries = ['China', 'Cambodia', 'United States Virgin Islands', 'Kiribati']\n",
            "count = 0\n",
            "for country in countries:\n",
            "  if country == 'China':\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 215: Q: How many countries are represented on the graph? | GT: 2 | Pred: countries = ['Greece', 'India']\n",
            "print(len(countries))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 216: Q: How many years are Greece's population rate below 35% | GT: 1 | Pred: years = [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000]\n",
            "print(len(years))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 217: Q: Which country is represented by the red line? | GT: Kenya | Pred: print(\"Kenya\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 218: Q: Which country has an all-time lower share of children younger than 5 who are underweight for their age? | GT: Peru | Pred: print(\"Peru\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 219: Q: Which country is represented by the given line graph? | GT: Niger | Pred: print(\"Niger\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 220: Q: In which year did the line graph saw its lowest dip? | GT: 2013 | Pred: print(\"2008\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 221: Q: Is the starting value of the red graph the lowest value? | GT: Yes | Pred: print(\"No\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 222: Q: Is the value of the blue graph constantly increasing? | GT: Yes | Pred: print(\"No\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 223: Q: Which country has the highest rise in the number of poultry birds from 1961 to 1990? | GT: Cuba | Pred: print(\"Cuba\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 224: Q: In which year, the middle line (Uruguay) is lowest? | GT: 1975 | Pred: print(\"1961\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 225: Q: Which area/region is represented by the upper line? | GT: Bahrain | Pred: print(\"Bahrain\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 226: Q: Which bar has the lowest value? | GT: Lesotho | Pred: print('Lesotho')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 227: Q: Is the National GDP value lower than 7 billion in 1955? | GT: Yes | Pred: print(True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 228: Q: In which year National GDP value crossed 20 billion? | GT: 1974 | Pred: print(\"1973\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 229: Q: Which gender is represented by the red color line? | GT: Male | Pred: print(\"Male\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 230: Q: Which year recorded the highest number of cases of killing of male Journalists? | GT: 2018 | Pred: print(\"2016\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 231: Q: Which line has an all-time 'high share of the population with severe food insecurity than other lines? | GT: Low income | Pred: print('Low income')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 232: Q: Which line has the slightest change in the share of the population with severe food insecurity? | GT: Eastern Asia | Pred: print(\"Eastern Asia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 233: Q: Is the highest value of Myanmar greater than 30000? | GT: Yes | Pred: print(True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 234: Q: Is the Myanmar graph value in 1997 is the median value of this graph? | GT: Yes | Pred: # The Myanmar graph value in 1997 is 30000.\n",
            "median_value = 30000\n",
            "# Is the Myanmar graph value in 1997 the median value?\n",
            "print(median_value == 30000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 235: Q: Which country is used in the line graph? | GT: Guatemala | Pred: print(\"Guatemala\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 236: Q: Which year it is in peak? | GT: 2006 | Pred: print(\"2006\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 237: Q: Which region is represented by the given line graph? | GT: South Eastern Asia | Pred: print(\"South Eastern Asia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 238: Q: Which year recorded the lowest value Red List Index? | GT: 2019 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 239: Q: Which country is represented by the given line graph? | GT: Jamaica | Pred: print(\"Jamaica\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 240: Q: In how many years, the share of government expenditure is more than 10% in Jamaica? | GT: 4 | Pred: years = [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004]\n",
            "count = 0\n",
            "for year in years:\n",
            "  if year == 1990 or year == 1991 or year == 199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 241: Q: What is the value of drug use in the year 1990? | GT: 1000 | Pred: print(1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 242: Q: What is the approximate difference of values in the year 1990? | GT: 900 | Pred: print(1000-1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 243: Q: Which country is featured in the graph? | GT: Canada | Pred: print(\"Canada\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 244: Q: After which year does the line have the sharpest decrease? | GT: 2008 | Pred: print(2008)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 245: Q: Which country is represented in this graph? | GT: Australia | Pred: print(\"Australia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 246: Q: In what year did Australia reach its peak? | GT: 1980 | Pred: print(1980)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 247: Q: How many regions are represented? | GT: 5 | Pred: print(5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 248: Q: How many regions saw increases? | GT: 5 | Pred: regions = ['Palau', 'Cyprus', 'Montenegro', 'Bolivia', 'Cape Verde']\n",
            "increases = []\n",
            "for region in regions:\n",
            "    if region == 'Palau':\n",
            "        increases.append('Palau')\n",
            "    elif region == 'Cyprus':\n",
            "        increases.append('Cyprus')\n",
            "    elif region == 'Montenegro':\n",
            "        increases.append('Montenegro')\n",
            "    elif region == 'Bolivia':\n",
            "        increases.append('Bolivia')\n",
            "    elif region == 'Cape Verde':\n",
            "        increases.append('Cape Verde')\n",
            "print(len(increases))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 249: Q: In which year, the value of the red graph peaked? | GT: 2009 | Pred: print(\"2009\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 250: Q: In which year was the difference between the prevalence of obesity in adult males maximum in Sri Lanka and Czechia? | GT: 2009 | Pred: print(2009)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 251: Q: In which year, the value of Employment in the agriculture graph peaked? | GT: 1999 | Pred: print(1998)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 252: Q: For how many years, the value of the \"Employment in services\" graph smaller than 60%? | GT: 13 | Pred: years = [1991, 1994, 1996, 1998, 2000, 2002, 2005]\n",
            "print(len(years))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 253: Q: Which country is represented by blue color line? | GT: Korea | Pred: print(\"Korea\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 254: Q: Which year recorded the least number of Caesarean sections in the Czech Republic? | GT: 2006 | Pred: print(\"2006\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 255: Q: Is the crude oil import price greater than 25$/barrel in 1984? | GT: Yes | Pred: print('No')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 256: Q: In how many years has the crude oil import price smaller than 15$/barrel? | GT: 1 | Pred: years_smaller_than_15 = 0\n",
            "for year in range(1988, 2001):\n",
            "  if year == 1988:\n",
            "    continue\n",
            "  if year == 1990:\n",
            "    continue\n",
            "  if year == 1992:\n",
            "    continue\n",
            "  if year == 1994:\n",
            "    continue\n",
            "  if year == 1996:\n",
            "    continue\n",
            "  if year == 1998:\n",
            "    continue\n",
            "  if year == 2000:\n",
            "    continue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 257: Q: What's the percentage of Trump voters who are against Biden? | GT: 24 | Pred: answer = 24\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 258: Q: What's the ratio of Trump voters who are against Biden and Biden voters who are for Biden? | GT: 0.340972222 | Pred: trump_against_biden = 24\n",
            "biden_for = 33\n",
            "ratio = trump_against_biden / biden_for\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 259: Q: What's the percentage value of the topmost green bar? | GT: 60 | Pred: print(60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 260: Q: What's the ratio of Never/Rarely and Occasionally/Frequently in Luo? | GT: 0.085416667 | Pred: never_rarely_in_Luo = 40\n",
            "occasionally_frequently_in_Luo = 60\n",
            "ratio = never_rarely_in_Luo / occasionally_frequently_in_Luo\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 261: Q: What's the lowest value of the light blue bar? | GT: 8 | Pred: lowest_value = 5\n",
            "print(lowest_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 262: Q: What's the average of all the bars in Germany? | GT: 24.25 | Pred: germany_not_too_important = 30\n",
            "germany_somewhat_important = 37\n",
            "germany_very_important = 15\n",
            "average = (germany_not_too_important + germany_somewhat_important + germany_very_important) / 3\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 263: Q: 18, 22, _, 20, find the missed data? | GT: 40 | Pred: print(49)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 264: Q: What's the ratio(A:B) of the largest value and the rightmost value in WHO category? | GT: 0.084027778 | Pred: largest_value_who = 40\n",
            "rightmost_value_who = 20\n",
            "ratio = largest_value_who/rightmost_value_who\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 265: Q: What percent of US adults who say their state governments policies to control the spread of coronavirus are influence A Fair amount by evidence from public health experts ? | GT: 40 | Pred: print(40)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 266: Q: Is the A Great deal value of the state government more than Federal government ? | GT: Yes | Pred: state_great_deal = 43\n",
            "federal_great_deal = 26\n",
            "if state_great_deal > federal_great_deal:\n",
            "  print(\"Yes\")\n",
            "else:\n",
            "  print(\"No\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 267: Q: What's the highest value of gray bar? | GT: 61 | Pred: print(59)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 268: Q: What's the median value of the green bars? | GT: 19 | Pred: green_bars = [19, 13, 24]\n",
            "median_value = (green_bars[1] + green_bars[2])/2\n",
            "print(median_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 269: Q: What's the value of the green bar for 65+ age group? | GT: 58 | Pred: print(58)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 270: Q: How many values of green bar exceed 30? | GT: 3 | Pred: green_bars = [28, 37, 51, 58]\n",
            "count = 0\n",
            "for bar in green_bars:\n",
            "  if bar > 30:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 271: Q: What's the leftmost value of bar in \"All adults\" category? | GT: 48 | Pred: print(48)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 272: Q: What's the median value of all the bars in rightside? | GT: 50 | Pred: values = [50, 74, 29]\n",
            "values.sort()\n",
            "print(values[1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 273: Q: What is youtube Trust data? | GT: 17 | Pred: trust_data = {\n",
            "    \"YouTube\": [17, 36, 39],\n",
            "    \"LinkedIn\": [7, 18, 47],\n",
            "    \"Reddit\": [7, 24, 31],\n",
            "    \"Facebook\": [15, 59, 19],\n",
            "    \"Twitter\": [12, 48, 28],\n",
            "    \"Instagram\": [6, 42, 37]\n",
            "}\n",
            "print(trust_data[\"YouTube\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 274: Q: What is the average of all the Trust Data? | GT: 248.83 | Pred: trust_data = [17, 7, 7, 15, 12, 6]\n",
            "average_trust = sum(trust_data) / len(trust_data)\n",
            "print(average_trust)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 275: Q: How many consumers feel A lot confident about what they are buying? | GT: 37 | Pred: print(37)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 276: Q: What�s the difference between the maximum and the minimum value in the last bar? | GT: 49 | Pred: values = [10, 5, 4]\n",
            "max_value = max(values)\n",
            "min_value = min(values)\n",
            "difference = max_value - min_value\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 277: Q: What color represent Confidence in the bar? | GT: Green | Pred: color = \"green\"\n",
            "print(color)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 278: Q: Which region has the highest value that has No confidence in Mohammad bin Salman? | GT: Israel | Pred: data = {'Israel': 83, 'Tunisia': 69, 'Turkey': 68, 'Lebanon': 64, 'U.S.': 63}\n",
            "max_value = max(data.values())\n",
            "for key, value in data.items():\n",
            "    if value == max_value:\n",
            "        print(key)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 279: Q: which color shows As in the bar? | GT: gray | Pred: print(\"blue\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 280: Q: What is the total of Jordan in More, As, and less? | GT: 99 | Pred: more_jordan = 61\n",
            "as_jordan = 23\n",
            "less_jordan = 15\n",
            "total = more_jordan + as_jordan + less_jordan\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 281: Q: 46, 43, 41 which data is missed? | GT: 47 | Pred: print(\"Be held accountable by govt if they misuse users' data\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 282: Q: Is the sum of the highest value of navy blue bar and median of light blue bar greater than 100? | GT: No | Pred: highest_navy_blue = 47\n",
            "median_light_blue = 24\n",
            "sum_greater_than_100 = highest_navy_blue + median_light_blue\n",
            "print(sum_greater_than_100 > 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 283: Q: What's the percentage of men who have \"Should NOT be made legal\" opinions? | GT: 30 | Pred: print(30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 284: Q: Count the number of yellow bars with 30 values? | GT: 3 | Pred: bars = [30, 30, 33, 30, 33, 32, 30, 35, 31, 31]\n",
            "count = 0\n",
            "for bar in bars:\n",
            "  if bar == 30:\n",
            "    count = count + 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 285: Q: What percent of the Labour group shows the economic situation is Bad in Uk? | GT: 60 | Pred: print(60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 286: Q: What is the total of Bad and Good in the Remain? | GT: 100 | Pred: bad = 60\n",
            "good = 40\n",
            "total = bad + good\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 287: Q: How many of them say in West Germany that religion is very important in their lives? | GT: 27 | Pred: answer = 27\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 288: Q: What is the Ration of Somewhat in West Germany and East Germany? | GT: 1.393055556 | Pred: west_germany_somewhat = 33\n",
            "east_germany_somewhat = 26\n",
            "print(west_germany_somewhat)\n",
            "print(east_germany_somewhat)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 289: Q: What's the value of the blue bar in France? | GT: 76 | Pred: print(76)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 290: Q: Is the median of green bars greater than the median of the blue bar? | GT: No | Pred: green_bars = [56, 51, 45, 35, 33, 29, 28, 28, 28, 23, 23, 23, 17, 13, 36, 15]\n",
            "blue_bars = [42, 48, 48, 63, 62, 68, 64, 70, 71, 73, 76, 76, 78, 84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 291: Q: What's the maximum value in the brightest yellow bar? | GT: 53 | Pred: print(63)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 292: Q: What's the difference in the value of the total number of persons who want to improve the way government works and who have not? | GT: 33 | Pred: total_government_works_not = 43 + 23 + 21 + 13 + 33\n",
            "total_government_works_total = 66 + 43 + 23 + 21 + 13 + 33\n",
            "difference = total_government_works_total - total_government_works_not\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 293: Q: How many people in total think Chinese growth is a good thing for the US? | GT: 50 | Pred: answer = 50\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 294: Q: What's the average percentage for people between 18-49 who think Chinese growth is a good thing for the US? | GT: 53.5 | Pred: print((56 + 51) / 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 295: Q: How many rows of data are there | GT: 7 | Pred: print(10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 296: Q: For all Dem/Lean Dem, what is the difference in opinions between supporting 50s and the oldest age studied as the best age to be a president | GT: 44 | Pred: print(47-16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 297: Q: What's the percentage of white who oppose the death penalty for persons convicted of murder? | GT: 34 | Pred: print(34)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 298: Q: What's the ratio of medians of Oppose and Favor bars? | GT: 0.554166667 | Pred: oppose_median = 39\n",
            "favor_median = 54\n",
            "ratio = oppose_median / favor_median\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 299: Q: What's the percentage value of the blue bar in Greece? | GT: 87 | Pred: print(87)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 300: Q: Is the median of the green bar greater than the largest value of the gray bar? | GT: Yes | Pred: green_bar_values = [87, 72, 62, 56, 53, 46, 44, 31, 19, 17]\n",
            "gray_bar_values = [5, 14, 10, 24, 22, 16, 36, 33, 45, 68, 15, 31]\n",
            "gray_bar_max = max(gray_bar_values)\n",
            "median_green_bar = sorted(green_bar_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 301: Q: What's the percentage of adults who are not concerned about identity theft? | GT: 16 | Pred: print(16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 302: Q: What's the sum of all the gray bars whose value exceeds 15? | GT: 72 | Pred: gray_bars = [6, 16, 14, 18, 16, 22]\n",
            "sum_of_gray_bars = 0\n",
            "for bar in gray_bars:\n",
            "  if bar > 15:\n",
            "    sum_of_gray_bars += bar\n",
            "print(sum_of_gray_bars)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 303: Q: Which color represents Republican? | GT: Red | Pred: print(\"Republican\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 304: Q: What is the total of Republicans and Democrats in 2010? | GT: 87 | Pred: total = 22 + 65\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 305: Q: What's the lowest value of Mostly good bars? | GT: 21 | Pred: values = [35, 53, 21]\n",
            "min_value = min(values)\n",
            "print(min_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 306: Q: What's the median of all the right-side bars? | GT: 35 | Pred: right_side_bars = [35, 53, 21]\n",
            "right_side_bars.sort()\n",
            "print(right_side_bars[1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 307: Q: What's the NET value of the All Teens bar? | GT: 57 | Pred: print(57)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 308: Q: How many bars have a Very worried value is greater than its Somewhat Worried value? | GT: 1 | Pred: very_worried = [25, 22, 28, 20, 27, 37]\n",
            "somewhat_worried = [32, 29, 35, 31, 34, 36]\n",
            "count = 0\n",
            "for i in range(len(very_worried)):\n",
            "  if very_worried[i] > somewhat_worried[i]:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 309: Q: How much does Italy's government's responsibility had the highest percentage? | GT: 0.74 | Pred: print(74)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 310: Q: What is the difference between the government's responsibility of Sweden to the UK? | GT: 0.04 | Pred: government_responsibility_sweden = 53\n",
            "uk_responsibility = 49\n",
            "difference = government_responsibility_sweden - uk_responsibility\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 311: Q: What's the value of the 1st Longest bar in the graph? | GT: 25 | Pred: # The longest bar in the graph is the West bar.\n",
            "# The value of the West bar is 31.\n",
            "print(31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 312: Q: What's the total sum of immigrants of South and West? | GT: 8 | Pred: south_immigrants = 2\n",
            "west_immigrants = 6\n",
            "total_immigrants = south_immigrants + west_immigrants\n",
            "print(total_immigrants)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 313: Q: What does the Dark blue bar represent? | GT: A great deal | Pred: print(\"A great deal\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 314: Q: Is the sum of all values of \"None at all\" is greater than the largest value of the dark blue bar? | GT: No | Pred: none_at_all = [4, 3, 4, 6]\n",
            "sum_none_at_all = sum(none_at_all)\n",
            "largest_dark_blue_bar = 32\n",
            "print(sum_none_at_all > largest_dark_blue_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 315: Q: Which county plays the least important role in the world than it did 10 years ago? | GT: UK | Pred: print(\"UK\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 316: Q: What is the sum of the least and highest value in the graph? | GT: 0.91 | Pred: least_value = 21\n",
            "highest_value = 70\n",
            "sum = least_value + highest_value\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 317: Q: How many colors are shown in the graph? | GT: 4 | Pred: colors = ['Very', 'Somewhat', 'Not too', 'Not at all']\n",
            "print(len(colors))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 318: Q: Is the Very value in All voters more than Somewhat in All voters? | GT: No | Pred: all_voters_very = 57\n",
            "all_voters_somewhat = 34\n",
            "print(all_voters_very > all_voters_somewhat)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 319: Q: What's the color of the Rightmost bar? | GT: Green | Pred: print(\"None of their purchases\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 320: Q: Is the add-up the value of all Green segments is greater than the sum of all Dark blue segments? | GT: Yes | Pred: green_segments = [29, 24]\n",
            "dark_blue_segments = [18, 24]\n",
            "sum_green_segments = sum(green_segments)\n",
            "sum_dark_blue_segments = sum(dark_blue_segments)\n",
            "print(sum_green_segments > sum_green_segments)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 321: Q: Is the color of the middle bars gray? | GT: Yes | Pred: print(\"yes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 322: Q: Is the median of green bars greater than the largest value of the gray bar? | GT: No | Pred: green_bars = [78, 33, 27, 17, 14, 12]\n",
            "gray_bars = [9, 49, 42, 63, 61, 67]\n",
            "green_bars.sort()\n",
            "largest_gray_bar = max(gray_bars)\n",
            "print(green_bars[4] > largest_gray_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 323: Q: What percent of White believes that race or ethnicity should be a major factor in college admission decisions? | GT: 4 | Pred: print(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 324: Q: How many shades of Green does a bar show? | GT: 2 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 325: Q: In the chart, Too little 69 percentage refers to? | GT: Protect water quality of lakes, rivers, streams | Pred: print(\"Protect water quality of lakes, rivers, streams\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 326: Q: As per the study, if you ask 500 people,� how many will say Protect air quality- too little and Too much? | GT: 360 | Pred: protect_air_quality_too_little = 64\n",
            "protect_air_quality_too_much = 8\n",
            "total_protect_air_quality = protect_air_quality_too_little + protect_air_quality_too_much\n",
            "print(total_protect_air_quality)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 327: Q: What's the value of the rightmost bar in the middle? | GT: 50 | Pred: print(50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 328: Q: What's the ratio of two bars in the middle (A: B)? | GT: 0.042361111 | Pred: A = 50\n",
            "B = 63\n",
            "ratio = A/B\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 329: Q: What is the average between men and women? | GT: 67.5 | Pred: men = 63\n",
            "women = 72\n",
            "average = (men + women) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 330: Q: What is the average of everyone who is winning more than they are losing? | GT: 30.4 | Pred: winning_more_often = [29, 34, 25, 44, 20]\n",
            "average = sum(winning_more_often) / len(winning_more_often)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 331: Q: How many % of respondents from Mexico have confidence in President Trump? | GT: 5 | Pred: print(5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 332: Q: What is the ratio of people who have confidence in President Trump and those who don't in Venezuela? | GT: 0.884722222 | Pred: confidence_venezuela = 20\n",
            "no_confidence_venezuela = 74\n",
            "ratio = confidence_venezuela / no_confidence_venezuela\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 333: Q: What percent of High school or less says the country Has been about right when it comes to giving women equal rights with men? | GT: 46 | Pred: print(46)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 334: Q: Is the sum of Bachelors more than the sum of Women? | GT: Yes | Pred: bachelors = 58\n",
            "women = 57\n",
            "print(bachelors > women)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 335: Q: Who says Good more to the question? | GT: General public | Pred: print(\"General public\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 336: Q: How many times good is more than bad in General Public? | GT: 2.62 | Pred: good_general_public = 68\n",
            "bad_general_public = 26\n",
            "ratio = good_general_public / bad_general_public\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 337: Q: In which country, 16% of human rights organizations are primarily dedicated to promoting the interest of foreign groups? | GT: Kenya | Pred: print(\"Kenya\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 338: Q: Take the median of orange bars, multiply it by 3, is the result greater than the smallest value of the green bar? | GT: No | Pred: orange_bars = [16, 10, 25, 17]\n",
            "median_orange = sorted(orange_bars)[len(orange_bars) // 2]\n",
            "median_orange_times_3 = median_orange * 3\n",
            "green_bars = [74, 67, 61, 43]\n",
            "smallest_green_bar = min(green_bars)\n",
            "print(median_orange_times_3 > smallest_green_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 339: Q: How many colors are in the bar?? | GT: 3 | Pred: colors = 3\n",
            "print(colors)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 340: Q: What is the total distribution of adversary and serious problems?? | GT: 65 | Pred: adversary_total = 22\n",
            "serious_problems_total = 43\n",
            "total_problems = adversary_total + serious_problems_total\n",
            "print(total_problems)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 341: Q: What's the value of the top rightmost bar? | GT: 7 | Pred: print(7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 342: Q: What's the ratio of the smallest Gen X bar and second smallest Silent/Greatest bar? | GT: 1.00625 | Pred: smallest_gen_x = 26\n",
            "second_smallest_silent_greatest = 11\n",
            "ratio = smallest_gen_x / second_smallest_silent_greatest\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 343: Q: What's the percentage of U.S. adults who oppose more fracking? | GT: 53 | Pred: print(53)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 344: Q: Take the sum of the two smallest green bars, is it greater than the smallest blue bar? | GT: No | Pred: green_bars = [9, 14, 52, 54, 53, 57]\n",
            "blue_bars = [89, 83, 45, 43, 42, 41]\n",
            "smallest_green_bar = min(green_bars)\n",
            "smallest_blue_bar = min(blue_bars)\n",
            "print(smallest_green_bar + smallest_blue_bar > smallest_blue_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 345: Q: What's the value of the rightmost first bar from the bottom? | GT: 8 | Pred: print(8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 346: Q: What's the average of all the uppermost bars (round to one decimal place)? | GT: 32.7 | Pred: values = [41, 58, 30, 48, 46, 54]\n",
            "average = sum(values)/len(values)\n",
            "print(round(average, 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 347: Q: What input situation is represented by the biggest bar | GT: Click on links to news stories | Pred: print(\"Click on links to news stories\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 348: Q: What is the sum of the median often opinion and the biggest net opinion | GT: 88 | Pred: often_opinions = [26, 16, 11, 8, 6, 5, 3]\n",
            "net_opinions = [80, 58, 49, 37, 36, 31, 19]\n",
            "median_often = sorted(often_opinions)[len(often_opinions) // 2]\n",
            "biggest_net = max(net_opinions)\n",
            "print(median_often + biggest_net)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 349: Q: What represents the two bars in the chart?? | GT: [Oppose, Favor] | Pred: print([\"Oppose\", \"Favor\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 350: Q: What is the ratio between oppose and favor distribution for a ban on high-capacity ammunition clips?? | GT: 1.993055556 | Pred: oppose_ban_on_high_capacity_ammunition_clips = 47\n",
            "favor_ban_on_high_capacity_ammunition_clips = 50\n",
            "ratio = oppose_ban_on_high_capacity_ammunition_clips / favor_ban_on_high_capacity_ammunition_clips\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 351: Q: What is the value of Very opinion in Aug 2016? | GT: 49 | Pred: answer = 49\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 352: Q: What's the ratio of the largest bar and the sum of the two smallest bars? | GT: 2.588888889 | Pred: largest_bar = 62\n",
            "smallest_bar = [29, 31]\n",
            "sum_of_smallest = sum(smallest_bar)\n",
            "ratio = largest_bar / sum_of_smallest\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 353: Q: What's the value of the largest bar in Total? | GT: 53 | Pred: print(53)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 354: Q: How many bars have a value below 40? | GT: 6 | Pred: bars = [35, 23, 48, 68, 60, 74]\n",
            "count = 0\n",
            "for bar in bars:\n",
            "  if bar < 40:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 355: Q: What's the percentage of the total population that favors weakening the EU? | GT: 65 | Pred: answer = 65\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 356: Q: What are the top three groups that favor weakening the EU? | GT: [50+, Men, Secondary education or less] | Pred: print(['Men', 'Women', '18-34'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 357: Q: What's the percentage of Black saying it is very important that their children earn a college degree? | GT: 17 | Pred: print(17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 358: Q: Take \"Extremely important\" bar median and \"Very important\" bar median, divide larger value by smaller value, what's the result(only integer value)? | GT: 1 | Pred: extremely_important = [52, 62, 34]\n",
            "very_important = [34, 17, 32]\n",
            "median_extremely_important = sorted(extremely_important)[1]\n",
            "median_very_important = sorted(very_important)[1]\n",
            "result = (median_extremely_important + median_very_important)/2\n",
            "print(int(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 359: Q: How many colors are represented in the bar?? | GT: 3 | Pred: colors = 3\n",
            "print(colors)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 360: Q: What's the average of the two smallest green bar?? | GT: 0.5 | Pred: green_bar_1 = 9\n",
            "green_bar_2 = 11\n",
            "average = (green_bar_1 + green_bar_2) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 361: Q: How many categories are there in the chart?? | GT: 8 | Pred: categories = ['Rising prices', 'Crime', 'Gap between rich and poor', 'Lack of employment opportunities', 'Corrupt political leaders', 'Poor-quality schools', 'Traffic', 'Health care']\n",
            "print(len(categories))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 362: Q: What's the average of the two smallest bar?? | GT: 38.5 | Pred: smallest_bars = [38, 39]\n",
            "average = sum(smallest_bars) / len(smallest_bars)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 363: Q: Which two country is compared here? | GT: [Czech Republic, New Zealand] | Pred: print([\"Czech Republic\", \"New Zealand\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 364: Q: How many times  New Zealand greater than Czech Republic? | GT: 3.0659 | Pred: new_zealand = 27.9\n",
            "czech_republic = 9.1\n",
            "answer = new_zealand / czech_republic\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 365: Q: Which country is represented by longest bar? | GT: Japan | Pred: countries = ['New Zealand', 'India', 'Colombia', 'Korea', 'Japan']\n",
            "values = [0.5, 2.5, 4.2, 22.6, 47.5]\n",
            "max_value = max(values)\n",
            "print(countries[values.index(max_value)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 366: Q: What's the total add up value of japan and Colombia? | GT: 51.7 | Pred: japan = 47.5\n",
            "colombia = 4.2\n",
            "total = japan + colombia\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 367: Q: Which country has the largest bar? | GT: Denmark | Pred: bars = ['Turkey', 'China (People's Republic of)', 'South Africa', 'Denmark']\n",
            "values = [0.1, 3.1, 7.9, 29.3]\n",
            "max_value = max(values)\n",
            "print(bars[values.index(max_value)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 368: Q: How many countries have over 4 broad money? | GT: 2 | Pred: broad_money = [0.1, 3.1, 7.9, 29.3]\n",
            "count = 0\n",
            "for i in broad_money:\n",
            "  if i > 4:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 369: Q: What is the value Exports in Hungary? | GT: 4.5 | Pred: print(4.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 370: Q: Is the average value of these two bars greater than 3? | GT: No | Pred: bar1 = 1.2\n",
            "bar2 = 4.5\n",
            "average = (bar1 + bar2) / 2\n",
            "print(average > 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 371: Q: How many colors are represented in the bar? | GT: 2 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 372: Q: What's the average of two smallest bar? | GT: 40.9 | Pred: smallest_bar_1 = 25.7\n",
            "smallest_bar_2 = 56.1\n",
            "average = (smallest_bar_1 + smallest_bar_2) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 373: Q: Which country represented by Blue bar? | GT: Romania | Pred: print(\"Romania\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 374: Q: What is the average of all the three bars? | GT: 8.3 | Pred: print((3.0 + 8.9 + 13.0)/3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 375: Q: What's the color of smallest bar? | GT: Red | Pred: print(\"red\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 376: Q: What is the average value of both the bars? | GT: 6.3 | Pred: bar1 = 6.0\n",
            "bar2 = 6.6\n",
            "average = (bar1 + bar2) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 377: Q: What is the color of the highest bar? | GT: green | Pred: print('green')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 378: Q: What is the difference in Inward FDI stocks between Spain and Poland? | GT: 0.42 | Pred: spain_inward_fdi = 0.65\n",
            "poland_inward_fdi = 0.23\n",
            "difference = spain_inward_fdi - poland_inward_fdi\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 379: Q: What's the value of blue bar? | GT: 29 | Pred: answer = 29.0\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 380: Q: What's the add up value of Australia and France? | GT: 40.6 | Pred: Australia = 11.6\n",
            "France = 29.0\n",
            "Sum = Australia + France\n",
            "print(Sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 381: Q: How many color bars are there in the Graph? | GT: 3 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 382: Q: Is the difference of value of Austria and Ireland bar is greater then the value of United States bar? | GT: No | Pred: Austria = 4.8\n",
            "Ireland = 3.1\n",
            "United_States = 1.9\n",
            "difference = Austria - Ireland\n",
            "print(difference > United_States)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 383: Q: What color represent Norway? | GT: purple | Pred: print('Purple')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 384: Q: How many countries have long term interest rates over 5 percent? | GT: 3 | Pred: rates = [4.7, 5.5, 5.6, 6.0]\n",
            "count = 0\n",
            "for rate in rates:\n",
            "  if rate > 5:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 385: Q: Which country is represented by RED bar? | GT: Austria | Pred: print(\"Austria\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 386: Q: Does the difference in the value of largest two bars is half the value of smallest bar? | GT: No | Pred: largest_bar = 120\n",
            "second_largest_bar = 68\n",
            "smallest_bar = 64\n",
            "difference = largest_bar - second_largest_bar\n",
            "half_smallest_bar = smallest_bar / 2\n",
            "print(difference == half_smallest_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 387: Q: What is the color of the lowest value in the graph? | GT: Blue | Pred: print(\"blue\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 388: Q: What is the difference in the value of China and Tanzania? | GT: 0.4 | Pred: print(14.0 - 10.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 389: Q: How many color are shown in the chart? | GT: 4 | Pred: print(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 390: Q: Is the difference value of DAC Countries is more then Sweden? | GT: Yes | Pred: DAC Countries = [184, 0]\n",
            "Sweden = [1, 0]\n",
            "if DAC Countries[1] > Sweden[1]:\n",
            "  print(\"True\")\n",
            "else:\n",
            "  print(\"False\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 391: Q: What does the red bar represent? | GT: Russia | Pred: print(\"Russia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 392: Q: What's the difference between two bars? | GT: 0.044 | Pred: bar1 = 0.082\n",
            "bar2 = 0.126\n",
            "difference = bar2 - bar1\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 393: Q: Which country has the highest value of Reading performance? | GT: Finland | Pred: values = [371, 476, 498, 501, 520]\n",
            "max_value = max(values)\n",
            "index = values.index(max_value)\n",
            "countries = ['Indonesia', 'Lithuania', 'Germany', 'Denmark', 'Finland']\n",
            "print(countries[index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 394: Q: Is the median value of all bars greater than 500? | GT: No | Pred: bars = [371, 476, 498, 501, 520]\n",
            "bars.sort()\n",
            "median = bars[len(bars) // 2]\n",
            "print(median > 500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 395: Q: What is the Real GDP long-term forecast for Poland? | GT: 1.26M | Pred: print(\"1.26M\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 396: Q: Is the average of the two bar values as shown in the graph greater than 1? | GT: No | Pred: bar1 = 0.37\n",
            "bar2 = 1.26\n",
            "average = (bar1 + bar2) / 2\n",
            "print(average > 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 397: Q: Is there any value 50.2 in this graph? | GT: Yes | Pred: print(\"Yes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 398: Q: Is the median value of all the bars greater than 50.2? | GT: No | Pred: values = [37.3, 45.6, 50.2, 61.5, 72.9]\n",
            "values.sort()\n",
            "median = values[len(values) // 2]\n",
            "print(median > 50.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 399: Q: Which country has the highest interest rate? | GT: Korea | Pred: countries = ['Belgium', 'Ireland', 'Czech Republic', 'Korea']\n",
            "rates = [5.7, 5.9, 9.1, 13.3]\n",
            "max_rate = max(rates)\n",
            "print(countries[rates.index(max_rate)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 400: Q: How many countries fall below 6%? | GT: 2 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 401: Q: Which is the top place in the chart? | GT: School | Pred: print(\"School\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 402: Q: How many places in the chart have over 50% value? | GT: 3 | Pred: places_over_50 = ['School', 'Someone's house', 'Online (e.g., social media or gaming sites)', 'Sports, clubs, hobbies, other extracurricular activities']\n",
            "print(len(places_over_50))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 403: Q: What does the yellow bar represent? | GT: Distrust | Pred: print(\"Distrust\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 404: Q: What is the difference between maximum and minimum values of trust and distrust respectively? | GT: 41 | Pred: trust_values = [16, 45, 21, 10, 5, 34]\n",
            "distrust_values = [18, 4, 11, 18, 31, 34]\n",
            "max_trust = max(trust_values)\n",
            "min_distrust = min(distrust_values)\n",
            "difference = max_trust - min_distrust\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 405: Q: What % of UK residents believe in the use of force to defend Allies in case they are attacked by Russia? | GT: 0.49 | Pred: print(49)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 406: Q: In how many countries do more than 45% of the respondents believe that their country should defend allies in case they are attacked by Russia? | GT: 6 | Pred: should_not = [37, 36, 37, 34, 47, 53, 51, 58, 42]\n",
            "should = [56, 53, 49, 48, 48, 47, 40, 38, 48]\n",
            "count = 0\n",
            "for i in range(len(should_not)):\n",
            "  if should_not[i] > 45:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 407: Q: How many support Euro in Spain? | GT: 0.71 | Pred: print(71)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 408: Q: What is the difference in the support of Euro between Spain and Italy? | GT: 0.15 | Pred: print(71 - 56)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 409: Q: What is Republican data in Feb 2015 for mostly good? | GT: [12,63,23] | Pred: republican_feb_2015_mostly_good = 12\n",
            "print(republican_feb_2015_mostly_good)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 410: Q: What is the ratio between  Mostly good and Mostly bad in Democrat Feb 2015? | GT: 3.22222 | Pred: mostly_good = 29\n",
            "mostly_bad = 9\n",
            "ratio = mostly_good / mostly_bad\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 411: Q: What is total personal remittances paid by India (in million dollar)? | GT: 350.83 | Pred: print(350.83)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 412: Q: Is the sum of two smallest bar greater than largest bar? | GT: No | Pred: smallest_bar_1 = 46.54\n",
            "smallest_bar_2 = 176.6\n",
            "largest_bar = 350.83\n",
            "sum_of_two_smallest = smallest_bar_1 + smallest_bar_2\n",
            "print(sum_of_two_smallest > largest_bar)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 413: Q: Which country is represented by brown color bar? | GT: Cameroon | Pred: print(\"Cameroon\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 414: Q: What is the average of coffee yields by Congo and Cameroon? | GT: 0.51 | Pred: congo_yield = 0.72\n",
            "cameroon_yield = 0.3\n",
            "average_yield = (congo_yield + cameroon_yield) / 2\n",
            "print(average_yield)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 415: Q: What is the projected number of children per women in the Fast Track scenario? | GT: 1.92 | Pred: print(1.92)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 416: Q: What is the sum in the the projected number of children per women in all scenarios? | GT: 6.33 | Pred: print(2.3 + 2.11 + 1.92)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 417: Q: What country has the highest share that disagree that vaccines are important? | GT: Namibia | Pred: print(\"Namibia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 418: Q: What is the average among the two contries in the share that disagree that vaccines are important? | GT: 1.105 | Pred: print((1.45 + 0.76) / 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 419: Q: What country have the loewst suicide rate? | GT: Niger | Pred: print(\"Niger\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 420: Q: Is the suicide rate in Ukraine higer then the sum of the other four countries? | GT: No | Pred: if 34.3 > (8.8 + 8.5 + 4.9) or 34.3 > (8.8 + 8.5) or 34.3 > (8.8 + 8.5) or 34.3 > (8.8 + 8.5) or 34.3 > (8.8 + 8.5) or 34.3 > (8.8 + 8.5) or 34.3 > (8.8 + 8.5) or 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 421: Q: Which country has the largest bar? | GT: Nepal | Pred: print('Nepal')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 422: Q: Is the sum of Australasia and Switzerland larger than Nepal? | GT: No | Pred: Australasia = 299.32\n",
            "Switzerland = 355.07\n",
            "Nepal = 1599.01\n",
            "if Australasia + Switzerland > Nepal:\n",
            "    print('Yes')\n",
            "else:\n",
            "    print('No')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 423: Q: How many color bar are shown the graph? | GT: 5 | Pred: print(5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 424: Q: What is the total value of two least bar? | GT: 20.34 | Pred: print(8.24 + 12.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 425: Q: Which price is represented by brown color bar? | GT: Northwest Europe marker price | Pred: print(\"Japan steam coal import oil price\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 426: Q: What is the average price of Japan coking coal import cif and Japan steam spot cif? | GT: 177.625 | Pred: coking_price = 229.19\n",
            "steam_price = 136.21\n",
            "average_price = (coking_price + steam_price) / 2\n",
            "print(average_price)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 427: Q: What is red line represents? | GT: Germany | Pred: print(\"Norway\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 428: Q: Which country data shows a down trend? | GT: United States | Pred: print(\"United States\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 429: Q: In which year the percentage of daily smokers peaked in Luxembourg? | GT: 2019 | Pred: print(2017)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 430: Q: In which year, the percentage of daily smokers in Luxembourg is greater than Ireland? | GT: 2019 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 431: Q: Which country is represented by blue color line? | GT: Belgium | Pred: print(\"Sweden\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 432: Q: How many countries have more than 40k enterprises over the given years? | GT: 2 | Pred: print(2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 433: Q: How many countries are shown in the chart? | GT: 2 | Pred: countries = ['Latvia', 'Slovenia']\n",
            "print(len(countries))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 434: Q: When does the gap between two countries become biggest? | GT: 2012 | Pred: print(\"2013\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 435: Q: Which two countries are being compared in the given graph? | GT: [Argentina, Indonesia] | Pred: print([\"Argentina\", \"Indonesia\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 436: Q: Which year recorded the highest fertility rate in Indonesia? | GT: 1976 | Pred: print(\"1976\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 437: Q: Which country is represented by blue color line? | GT: Estonia | Pred: print(\"Latvia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 438: Q: Which country has highest government production costs over the given years? | GT: France | Pred: print(\"France\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 439: Q: Which country is in middle of Canad and Slovenia? | GT: United States | Pred: print(\"United States\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 440: Q: Is the median value of Slovenia data points greater than 40? | GT: Yes | Pred: slovenia_data = [17, 20, 32, 47, 55]\n",
            "slovenia_data.sort()\n",
            "median = slovenia_data[len(slovenia_data) // 2]\n",
            "print(median > 40)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 441: Q: Which country has the lowest household net worth over the years? | GT: Estonia | Pred: print(min([270, 260, 260, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 442: Q: In which year the value of red line is smaller than blue line? | GT: 2009 | Pred: print(\"2011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 443: Q: Is Austria represented by purple dotted line? | GT: Yes | Pred: print(\"Yes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 444: Q: Which country recorded smallest labour productivity value over the years? | GT: Slovenia | Pred: print(\"Slovenia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 445: Q: In which country has the highest peak in this bar graph? | GT: Switzerland | Pred: print(\"Switzerland\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 446: Q: What is the difference between the highest value and lowest value of switzerland? | GT: 4 | Pred: highest_value = 18\n",
            "lowest_value = 17\n",
            "difference = highest_value - lowest_value\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 447: Q: What country have the lowest value in national insurance market share? | GT: Iceland | Pred: print(\"Iceland\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 448: Q: Between what years Netherlands had the highest change in the value of national insurance market share? | GT: 2015 | Pred: print(\"2004\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 449: Q: Which country is represented by the given line graph? | GT: Canada | Pred: print(\"Canada\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 450: Q: Which year recorded the lowest net childcare costs in Canada? | GT: 2019 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 451: Q: In what year Poland achieved the highest value in pension funds' assets? | GT: 2013 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 452: Q: In what year Belgium passed Poland in the value of pension funds' assets? | GT: 2019 | Pred: print(\"2017\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 453: Q: Which country does the blue line represent? | GT: Canada | Pred: print(\"Canada\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 454: Q: When does the gap between Poland and Denmark become smallest? | GT: 2017 | Pred: print(\"2015\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 455: Q: Which country shows highest rise in the Short term interest rates from 1995 to 2000? | GT: Brazil | Pred: print('Brazil')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 456: Q: Which four countries data is compared in this graph? | GT: [Brazil, Slovenia, Switzerland, Japan] | Pred: countries = ['Brazil', 'Slovenia', 'Switzerland', 'Japan']\n",
            "print(countries)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 457: Q: Which country is represented by blue color line? | GT: New Zealand | Pred: print(\"New Zealand\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 458: Q: Between which two years , the GDP of New Zealand is maximum? | GT: 2009 | Pred: print(\"2009 and 2010\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 459: Q: Which country is represented by blue color line? | GT: France | Pred: print(\"Spain\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 460: Q: At how much points does lines representing Australia and France crosses each other? | GT: 1 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 461: Q: Which country does the red line refer to? | GT: Poland | Pred: print(\"Poland\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 462: Q: When does the difference between two countries become largest? | GT: 2019 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 463: Q: Which country does the red line represent? | GT: Netherlands | Pred: print(\"Netherlands\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 464: Q: During which time did tourism receipts and spending in Netherlands decline? | GT: 2014 | Pred: print(\"2015\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 465: Q: Who has the most oscars out of the the actors listed | GT: Katharine Hepburn | Pred: print('Anthony Pheburne')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 466: Q: How many oscars do jack nicolson and meryl streep have combined? | GT: 6 | Pred: # meryl streep has 3 oscars\n",
            "jack_nicolson_oscars = 3\n",
            "# jack nicolson_oscars + meryl_streep_oscars = 6\n",
            "print(jack_nicolson_oscars + meryl_streep_oscars)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 467: Q: How many distribution are there in the pie chart? | GT: 8 | Pred: print(8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 468: Q: Take highest percentage and lowest percentage (leave 0), add it and divide it by 2, what is the result? | GT: 17.5 | Pred: highest_percentage = 25\n",
            "lowest_percentage = 0\n",
            "result = (highest_percentage + lowest_percentage) / 2\n",
            "print(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 469: Q: What is very important percentage? | GT: 12 | Pred: answer = 12\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 470: Q: Assume total respondent as 1000, what is the sum of person will tell 'very Important' and 'important'? | GT: 620 | Pred: very_important = 12\n",
            "important = 50\n",
            "total = very_important + important\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 471: Q: Find out , who is referred in blue? | GT: 620 | Pred: print(\"Partner (husband, boyfriend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 472: Q: What percentage we get , if we add red and grey color? | GT: 27 | Pred: grey = 22.5\n",
            "red = 4.5\n",
            "total = grey + red\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 473: Q: Which country has the highest distribution of coal export in 2018? | GT: Indonesia | Pred: print(\"Australia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 474: Q: What is the sum total percentage of Canada and U.S country in 2018? | GT: 10 | Pred: canada = 3\n",
            "us = 7\n",
            "total = canada + us\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 475: Q: Pizza Hut : 765 ,  KFC : ?    ? | GT: 181 | Pred: print(KFC)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 476: Q: What is the ratio between KFC vs Taco Bell? | GT: 2.623 | Pred: ratio = 181 / 69\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 477: Q: What's the percentage market share of NEXANS for offshore wind farms in Europe in 2020? | GT: 27 | Pred: answer = 27\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 478: Q: Are the sum of NSW Technology and TFK Group segment greater than 50%? | GT: Yes | Pred: NSW_Technology = 11\n",
            "TFK_Group = 41\n",
            "sum_of_segments = NSW_Technology + TFK_Group\n",
            "if sum_of_segments > 50:\n",
            "  print(\"Yes\")\n",
            "else:\n",
            "  print(\"No\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 479: Q: What color represents Asia? | GT: Gray | Pred: print('gray')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 480: Q: What's the sum of percentage value of top two markets? | GT: 71 | Pred: top_two = [49, 22]\n",
            "sum = top_two[0] + top_two[1]\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 481: Q: Is the graph increasing or decreasing? | GT: Increasing | Pred: print(\"increasing\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 482: Q: In How many days, COVID rose to 1022? | GT: 7 | Pred: print(12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 483: Q: In which year the ratio of government expenditure to gross domestic product peak? | GT: 2020 | Pred: years = [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026]\n",
            "values = [20.73, 21.65, 21.34, 21.5, 22.7, 21.73, 20.84, 20.18, 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 484: Q: What is the average for the last 4 years? | GT: 19.79 | Pred: values = [20.18, 19.84, 19.6, 19.53]\n",
            "average = sum(values) / len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 485: Q: Which Sales share of Crocs worldwide in 2020 is highest? | GT: Wholesale | Pred: print(\"Wholesale 50%\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 486: Q: How much percentage is the Retail sales? | GT: 24.1 | Pred: percentage = 24.1\n",
            "print(percentage)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 487: Q: What's the percentage share of Ladies in Ross Stores sales in the U.S. in 2020? | GT: 23 | Pred: print(23)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 488: Q: Is the sum of yellow and green segment greater than Ladies segment? | GT: No | Pred: yellow = 12\n",
            "green = 9\n",
            "sum = yellow + green\n",
            "print(sum > ladies)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 489: Q: Which product has least percentage? | GT: Watches | Pred: print(\"Watches\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 490: Q: What is the difference between the two products? | GT: 64 | Pred: print(82 - 18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 491: Q: What is the color of smallest segment? | GT: Green | Pred: print(\"green\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 492: Q: What's the result after dividing gray segment with the smallest segment? | GT: 2.47 | Pred: gray_segment = 23.18\n",
            "smallest_segment = 9.37\n",
            "result = gray_segment / smallest_segment\n",
            "print(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 493: Q: How many troughs are there in the data line? | GT: 4 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 494: Q: Which year experienced the greatest improvement in poverty? | GT: 2005 | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 495: Q: What is the percentage of sales share of Domestics merchandise of Bed Bath & Beyond worldwide in the year 2020? | GT: 34 | Pred: print(34)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 496: Q: What is the difference between Home Furnishings and Domestics merchandise as a share of Bed Bath & Beyond sales worldwide in the year 2020? | GT: 31 | Pred: home_furnishings = 65\n",
            "domestics = 34\n",
            "difference = home_furnishings - domestics\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 497: Q: What's the most popular condition in the chart? | GT: Normal, healthy | Pred: answer = 'Normal, healthy'\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 498: Q: What's the sum of conditions that have more weights than expected? | GT: 55.8 | Pred: overweight = 36.9\n",
            "normal_healthy = 43.1\n",
            "thin_healthy = 0.9\n",
            "too_thin = 0.2\n",
            "sum_more_weights = overweight + normal_healthy + thin_healthy + too_thin\n",
            "print(sum_more_weights)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 499: Q: What is the sum of the middle two bars? | GT: 59 | Pred: middle_two_bars = [31, 28]\n",
            "sum_middle_two_bars = sum(middle_two_bars)\n",
            "print(sum_middle_two_bars)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 500: Q: From 2010 to 2012, which year saw the biggest change in bankruptcies? | GT: 2011 | Pred: print(\"2012\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 501: Q: The bar chart covers how many years? | GT: 6 | Pred: years = ['2015', '2016', '2017', '2018', '2019', '2020']\n",
            "print(len(years))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 502: Q: What is the median of the three least raised biotech venture capitals? | GT: 12000 | Pred: venture_capital = [12000, 9800, 13500, 20500, 18000, 18100]\n",
            "venture_capital.sort()\n",
            "median = venture_capital[len(venture_capital) // 2]\n",
            "print(median)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 503: Q: What is the value when the tallest bar is divided by the shortest bar? | GT: 14.33 | Pred: tallest_bar = 43\n",
            "shortest_bar = 3\n",
            "result = tallest_bar / shortest_bar\n",
            "print(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 504: Q: What is the difference in percentage between the most and the second most adopted eating habits? | GT: 18 | Pred: most_adopted = 43\n",
            "second_most_adopted = 25\n",
            "difference = most_adopted - second_most_adopted\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 505: Q: What is the percentage value of total government expenditure in Country Japan ? | GT: 23.6 | Pred: print(23.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 506: Q: Is the sum value  of country Germany and Ireland more then Costa Rica ? | GT: No | Pred: germany = 20\n",
            "ireland = 20.2\n",
            "costa_rica = 27.8\n",
            "sum_germany_ireland = germany + ireland\n",
            "print(sum_germany_ireland > costa_rica)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 507: Q: Which has the lowest Radio device ownership among 15-39 year-olds in the United States in 2017? | GT: A portable AM/FM radio | Pred: print(\"A portable AM/FM radio\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 508: Q: What is the difference between the highest and the lowest Radio device ownership among 15-39-year olds in the United States in 2017? | GT: 71 | Pred: highest = 87\n",
            "lowest = 16\n",
            "difference = highest - lowest\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 509: Q: How many types have been considered? | GT: 4 | Pred: print(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 510: Q: What is the sum of Black and white? | GT: 56.01 | Pred: black = 26.88\n",
            "white = 29.13\n",
            "sum = black + white\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 511: Q: Which has the lowest Revenue of selected home and garden products retailers in Germany in 2013? | GT: Max Bahr | Pred: answer = \"Max Bahr\"\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 512: Q: What is the difference between the highest and the lowest in Revenue of selected home and garden products retailers in Germany in 2013? | GT: 1.3 | Pred: revenue = [2, 1.7, 1.5, 1.4, 0.7]\n",
            "print(max(revenue) - min(revenue))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 513: Q: Which channel has a share of 4.28? | GT: ABC News | Pred: shares = [11.13, 7.51, 6.59, 4.28, 4.24, 3.76, 2.87, 2.77, 2.28]\n",
            "shares.sort()\n",
            "print(shares[4])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 514: Q: How many channels have higher than 5 million? | GT: 3 | Pred: shares = [11.13, 7.51, 6.59, 4.28, 4.24, 3.76, 2.87, 2.77, 2.28]\n",
            "count = 0\n",
            "for share in shares:\n",
            "    if share > 5:\n",
            "        count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 515: Q: What does the grey color indicate? | GT: All households | Pred: print(\"All households\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 516: Q: By how much Pensioners is higher than long term unemployed? | GT: 6680 | Pred: pensioners = 21948\n",
            "long_term_unemployed = 15268\n",
            "print(pensioners - long_term_unemployed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 517: Q: What is the colour of Overall score in bar chart? | GT: gray | Pred: print('grey')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 518: Q: In which category the index score value is 1? | GT: Legislators, senior officials and managers | Pred: categories = ['Accumulated earned income*', 'Labor force participation', 'Professional and technical workers', 'Legislators, senior officials and managers', 'Overall score**']\n",
            "index_scores = [0.56, 0.62, 0.99, 1, 0.75]\n",
            "answer = []\n",
            "for i in range(len(index_scores)):\n",
            "  if index_scores[i] == 1:\n",
            "    answer.append(categories[i])\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 519: Q: By how much is 2 persons higher than that of 1 person? | GT: 34960 | Pred: answer = 88715 - 53755\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 520: Q: What is the median value? | GT: 37700 | Pred: values = [53755, 88715, 37700, 28270, 10235]\n",
            "values.sort()\n",
            "print(values[2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 521: Q: Which product has the highest value? | GT: Flash/NV | Pred: print('Flash/NV')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 522: Q: What is the sum value  of product Logic and Foundry? | GT: 27.2 | Pred: Logic = 5.5\n",
            "Foundry = 21.7\n",
            "sum = Logic + Foundry\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 523: Q: What type of store sells  snowboarding boots for the highest price? | GT: Specialty shop | Pred: print(\"Chain store\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 524: Q: What is the average price for snowboard boots? (in dolalrs)? | GT: 158.58 | Pred: print(\"171.19\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 525: Q: What years are the starting years on this graph? | GT: 2010/11 | Pred: years = ['2010/11', '2011/12', '2012/13', '2013/14', '2014/15', '2015/16', '2016/17']\n",
            "print(years)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 526: Q: What is the average of all the years? | GT: 19287.4285 | Pred: values = [19285, 19511, 19631, 19407, 18713, 19376, 19089]\n",
            "average = sum(values) / len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 527: Q: Which opinion has the highest share? | GT: Nothing at all | Pred: print(\"Nothing at all\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 528: Q: What is the sum of the two medians? | GT: 47 | Pred: median1 = 24\n",
            "median2 = 23\n",
            "sum = median1 + median2\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 529: Q: What has the second least reviews? | GT: YellowPages.com | Pred: print(\"YellowPages.com\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 530: Q: Which site is three times than yellowpages? | GT: Industry specific | Pred: sites = ['Google', 'Yelp', 'Facebook', 'Industry specific', 'Consumer Affairs', 'YellowPages.com', 'None of these']\n",
            "values = [81, 59, 49, 36, 21, 12, 5]\n",
            "result = []\n",
            "for i in range(len(sites)):\n",
            "  if values[i] != 0:\n",
            "    result.append(sites[i])\n",
            "print(result)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 531: Q: Which product have the highest value of market share? | GT: Stockings | Pred: products = ['Socks', 'Knee-high stockings', 'Children socks', 'Cotton socks', 'Stockings']\n",
            "values = [4, 9, 13, 19, 55]\n",
            "highest_value_index = values.index(max(values))\n",
            "print(products[highest_value_index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 532: Q: What is the sum of cotton socks and children socks? | GT: 32 | Pred: socks = 4\n",
            "childrens_socks = 13\n",
            "sum = socks + childrens_socks\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 533: Q: How many number of golfers are there in 2016? | GT: 463952 | Pred: print(463952)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 534: Q: By how much percentage is 2017 higher than 2018? | GT: 7166 | Pred: answer = (468570 - 461404) / 461404 * 100\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 535: Q: Which repsone has the biggest slice of the graph? | GT: As much as before the lockdown | Pred: print(\"As much as before the lockdow...\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 536: Q: What is the color of the smallest slice? | GT: Red | Pred: print('red')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 537: Q: What is the patient spending for a 400 dollar insulin if the patient is in deductible phase in the US as of 2017? | GT: 408 | Pred: print(408)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 538: Q: What is the value of the highest bar? | GT: 408 | Pred: print(408)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 539: Q: What is the revenue of travel agencies? | GT: 270.3 | Pred: print(270.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 540: Q: What is the difference between the food service and accommodation? | GT: 3986.8 | Pred: food_service = 4848.1\n",
            "accommodation = 861.3\n",
            "difference = food_service - accommodation\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 541: Q: WHat is the highest value? | GT: 37 | Pred: values = [11, 32, 37, 20]\n",
            "highest_value = max(values)\n",
            "print(highest_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 542: Q: What is the ratio of No change to not sure? | GT: 1.6 | Pred: no_change = 32\n",
            "not_sure = 20\n",
            "ratio = no_change / not_sure\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 543: Q: Which year has 2.03%? | GT: 2016 | Pred: answer = \"2016\"\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 544: Q: What is the average of all the years? | GT: 2.07 | Pred: years = [2.58, 2.63, 2.03, 1.86, 1.75, 1.6]\n",
            "average = sum(years) / len(years)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 545: Q: What year is represented in the graph? | GT: 2014 | Pred: print(\"2021\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 546: Q: What is the difference between Carex and Palmolive? | GT: 24.3 | Pred: carex_sales_value = 15.2\n",
            "palmolive_sales_value = -9.1\n",
            "difference = carex_sales_value - palmolive_sales_value\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 547: Q: How many years have the same emission rate of 25%? | GT: 3 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 548: Q: What is the ratio of least and highest rates? | GT: 0.444444444 | Pred: least = 20\n",
            "highest = 45\n",
            "ratio = least / highest\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 549: Q: What is the percentage of rheumatologists in the U.S. who worked at a Hospital as of 2019? | GT: 15 | Pred: print(\"15\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 550: Q: What is the percentage of rheumatologists in the U.S. who either worked at a Hospital  or an Office-based solo practice as of 2019? | GT: 27 | Pred: print(15+12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 551: Q: Which year has the highest value? | GT: 2013 | Pred: print(2013)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 552: Q: How many years have consumption higher than 3%? | GT: 5 | Pred: consumption = [2.01, 2.82, 3.05, 3.24, 3.16, 3.11, 3.16, 2.77, 2.53, 2.59]\n",
            "count = 0\n",
            "for c in consumption:\n",
            "  if c > 3:\n",
            "    count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 553: Q: Which colored segment occupies more than half the pie chart? | GT: blue | Pred: print(\"Accessories\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 554: Q: Which sales is larger, Accessories or all other product segments combined? | GT: Accessories | Pred: accessories = 52.8\n",
            "apparel = 19.3\n",
            "footwear = 19.8\n",
            "licensing_revenue = 3.6\n",
            "home = 0.5\n",
            "licenced_product = 4\n",
            "sales = accessories + apparel + footwear + licensing_revenue + home\n",
            "print(sales)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 555: Q: Which represents 1%? | GT: Both scared and optimistic | Pred: print(\"Both scared and optimistic\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 556: Q: How many people scared? | GT: 58 | Pred: print(58)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 557: Q: Which period crossed 100 billions? | GT: Q3 '12 | Pred: print(\"Q1 '13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 558: Q: What is the value of the highest point? | GT: 181.95 | Pred: print(181.95)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 559: Q: Which has the percentage higher than 50%? | GT: Photos | Pred: percentages = [11, 17, 72]\n",
            "answer = [x for x in percentages if x > 50]\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 560: Q: What is the ratio of Videos and Carousel? | GT: 1.545454545 | Pred: videos = 17\n",
            "carousel = 11\n",
            "ratio = videos / carousel\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 561: Q: Which country has the least amount of seats? | GT: USA | Pred: print(\"USA\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 562: Q: What percentage of seats does PH hold? | GT: 50.9 | Pred: print(\"113\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 563: Q: what age group contributes highest revenue? | GT: 45-64 | Pred: print('45-64')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 564: Q: What's the percentage of revenue contributes by people under 44? | GT: 40.3 | Pred: print(32.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 565: Q: Which adults in the United States  has the least number of use of internet in 2021? | GT: 65+ years | Pred: answer = \"65+ years\"\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 566: Q: Which age group has highest share of population in 2021? | GT: 18 to 29 years | Pred: print(\"18 to 29 years\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 567: Q: Which year has the lowest company sales and revenue streams? | GT: 2020 | Pred: print(\"2020\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 568: Q: What is the difference in company sales and revenue streams between 2013 and 2020 in US dollars? | GT: 16.3 | Pred: print(138.79 + 137.96 + 135.73 + 149.18 + 145.59 + 147.05 + 137.24 + 122.49 - 138.79 - 137.96 - 135.73 - 149.18 - 145.59 - 147.05 - 137.24 - 122.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 569: Q: What sex contributes to more cases? | GT: Female | Pred: print(\"Male\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 570: Q: What the difference between percentage of female and male in the chart? | GT: 2.2 | Pred: female = 51.1\n",
            "male = 48.9\n",
            "difference = female - male\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 571: Q: Which country has the highest number of deaths caused by major droughts worldwide from 1900-2016? | GT: China (1928) | Pred: print(\"China (1928)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 572: Q: What's the total number of  deaths caused by major droughts worldwide in Sudan at 1983? | GT: 250000 | Pred: total_deaths = 150000 + 100000\n",
            "print(total_deaths)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 573: Q: What did the majority of people respond with? | GT: Yes | Pred: print(\"Yes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 574: Q: How many people didn't respond with yes? | GT: 38.6 | Pred: no_yes = 61.4 - 61.4\n",
            "print(no_yes)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 575: Q: What is the budgeted public sector expenditure on Transport in 2019  (in billion GBP)? | GT: 44 | Pred: print(44)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 576: Q: What is the total budgeted public sector expenditure on Transport and Defense (in billion GBP)? | GT: 99 | Pred: transport = 54\n",
            "defense = 55\n",
            "total = transport + defense\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 577: Q: Which of these countries is the leading country in clothing experience in 2019? | GT: China* | Pred: print(\"China*\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 578: Q: What is the average value of share of clothing exports between India and Turkey? | GT: 3.35 | Pred: india_share = 3.5\n",
            "turkey_share = 3.2\n",
            "average = (india_share + turkey_share) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 579: Q: What growth rate has the second highest bar? | GT: 10k-100k | Pred: print('16')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 580: Q: What was the combined growth rate for 1m-10m and 10m+? | GT: 28.6 | Pred: growth_rate_1m_10m = 14\n",
            "growth_rate_10m = 14.6\n",
            "total_growth = growth_rate_1m_10m + growth_rate_10m\n",
            "print(total_growth)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 581: Q: What purpose was the third most popular? | GT: Business and professional | Pred: print(\"Visiting friends and relatives, health, religion, other\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 582: Q: What was the combined percentage of the business and professional and not specified purposes? | GT: 17 | Pred: percentage_business_and_professional = 11\n",
            "percentage_not_specified = 6\n",
            "total_percentage = percentage_business_and_professional + percentage_not_specified\n",
            "print(total_percentage)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 583: Q: What year did Roche spend the most in? | GT: 2020 | Pred: print(\"2020\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 584: Q: What was the increase in spending from 2015 to 2020? | GT: 3428 | Pred: spending_2015 = 9581\n",
            "spending_2020 = 13009\n",
            "increase = spending_2020 - spending_2015\n",
            "print(increase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 585: Q: What distribution channel has the 3rd biggest piece? | GT: Connected fitness | Pred: answer = 'Direct to consumer'\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 586: Q: What percentage did both wholesale and direct to consumer distribution channels account for? | GT: 94 | Pred: print(\"53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 587: Q: What is the net sales of General Mills wordwide in 2018(in million U.S. dollars)? | GT: 15740 | Pred: print(15740)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 588: Q: What is the sum of net sales of General Mills when it was highest and lowest? | GT: 33530 | Pred: sales = [17910, 17630, 16563, 15620, 15740, 16865, 17626.6]\n",
            "print(max(sales) + min(sales))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 589: Q: What is the percentage of people choose to celebrating Easter this year ? | GT: 79 | Pred: print(79)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 590: Q: What is the percentage difference of people choosing yes and no? | GT: 58 | Pred: percentage_yes = 79\n",
            "percentage_no = 21\n",
            "difference = percentage_yes - percentage_no\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 591: Q: What is the percentage of billionaires globally in the 50-70 age group? | GT: 50.3 | Pred: print(\"50.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 592: Q: What is the difference between the percentage of billionaires in two age groups, one with the lowest and the other with the highest number of billionaires? | GT: 40.5 | Pred: print(50.3 - 9.8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 593: Q: 40% of which group answered YES? | GT: Baby Boomers (49-67) | Pred: answer = \"Baby Boomers (49-67)\"\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 594: Q: What is the difference between the two groups who answered YES by highest and lowest percentage? | GT: 5 | Pred: answer = 40 - 35\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 595: Q: What is the percentage revenue share of the LVMH Group worldwide in 2020 from the United States? | GT: 24 | Pred: print(24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 596: Q: What is the total percentage revenue share of the LVMH Group worldwide in 2020 from Asia and Japan? | GT: 41 | Pred: Asia = 34\n",
            "Japan = 7\n",
            "total = Asia + Japan\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 597: Q: What is the sales share of Target for the Food & Beverages segment in 2020? | GT: 20 | Pred: print(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 598: Q: What is the sum of the sales share of Food & Beverages and Beauty & household essentials segment in 2020? | GT: 46 | Pred: food_beverage = 20\n",
            "beauty = 26\n",
            "sum = food_beverage + beauty\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 599: Q: Which year has the highest number of fatalities? | GT: 2006 | Pred: print(2006)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 600: Q: What is the average of all fatalities in all years? | GT: 14.07 | Pred: fatalities = [31, 15, 12, 17, 8, 12, 9, 15, 4, 16, 18, 16, 18, 6]\n",
            "average = sum(fatalities) / len(fatalities)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 601: Q: What is the unemployment rate for individuals aged 15 to 24 years in Singapore in the year 2016? | GT: 9.12 | Pred: print(9.12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 602: Q: What is the increase in the unemployment rate for individuals aged 15 to 24 years in Singapore between the year 2014 and 2015? | GT: 0.6 | Pred: print(9.34 - 8.74)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 603: Q: How many Facebook fans (in millions) does Mango have? | GT: 11.68 | Pred: print(11.68)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 604: Q: What is the total number of Facebook fans (in millions) that BOSS and ROLEX have? | GT: 16.06 | Pred: fans_boss = 8.48\n",
            "fans_rollex = 7.58\n",
            "total_fans = fans_boss + fans_rollex\n",
            "print(total_fans)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 605: Q: What is the highest value of the monthly average earnings per hour of all employees in the US  between May 2020 and May 2021? | GT: 30.33 | Pred: print(30.33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 606: Q: What is the difference in the monthly average earnings per hour of all employees in the US  between May 2020 and May 2021 | GT: 0.59 | Pred: print(30.33 - 29.74)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 607: Q: Which film genre is most popular in the United Kingdom as of October 2013? | GT: Action/thriller | Pred: print(\"Action/thriller\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 608: Q: What is the difference between the most popular and least popular film genres in the United Kingdom (UK) as of October 2013? | GT: 27 | Pred: most_popular = 55\n",
            "least_popular = 28\n",
            "difference = most_popular - least_popular\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 609: Q: What is the revenue of Brandstätter Group in 2009 (in million euros)? | GT: 474 | Pred: print(474)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 610: Q: What is the average revenue of Brandstätter Group from 2008 to 2009 (in million euros)? | GT: 463 | Pred: revenue_2008 = 452\n",
            "revenue_2009 = 474\n",
            "average_revenue = (revenue_2008 + revenue_2009) / 2\n",
            "print(average_revenue)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 611: Q: What is the value (in billion euros) of the Ingenico Group S.A - Worldline SA deal in Europe? | GT: 9.2 | Pred: print(9.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 612: Q: What is the sum total of the value (in billion euros) of the top two deals in Europe in 2020 in terms of deal value? | GT: 48.3 | Pred: deals = [31.1, 17.2, 11.5, 9.2, 7.6, 6.1, 6, 5.7, 5.5, 5.5]\n",
            "deals.sort(reverse=True)\n",
            "total = deals[0] + deals[1]\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 613: Q: Which category of age does yellow indicate? | GT: 30-39 years | Pred: print(\"20-29 years\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 614: Q: What is the difference between the highest and lowest people infection? | GT: 34.5 | Pred: highest = 34.9\n",
            "lowest = 0.4\n",
            "difference = highest - lowest\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 615: Q: What is the profit percentage  of Europe? | GT: 37 | Pred: print(37)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 616: Q: What is the difference between maximum profit contribution and minimum profit contribution? | GT: 21 | Pred: regions = ['North America', 'Europe', 'South America']\n",
            "profits = [21, 37, 42]\n",
            "max_profit = max(profits)\n",
            "min_profit = min(profits)\n",
            "difference = max_profit - min_profit\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 617: Q: What is the number of fatalities in 2016? | GT: 563 | Pred: print(563)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 618: Q: What is the average of 2017, 2018, 2019? | GT: 632.66 | Pred: numbers = [602, 675, 621]\n",
            "average = sum(numbers) / len(numbers)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 619: Q: What is the percentage of nickel imports in Canada? | GT: 42 | Pred: print(\"42\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 620: Q: What is the total number of percentage in Canada and Russia? | GT: 50 | Pred: percentage_canada = 42\n",
            "percentage_russia = 8\n",
            "total_percentage = percentage_canada + percentage_russia\n",
            "print(total_percentage)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 621: Q: What's the highest Share of Puma's net sales worldwide in 2020, by segment? | GT: Footwear | Pred: print('Footwear')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 622: Q: What's the total of apparel and footwear, Share of Puma's net sales worldwide in 2020, by segment | GT: 82.9 | Pred: apparel = 37.7\n",
            "footwear = 45.2\n",
            "total = apparel + footwear\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 623: Q: What is distribution of potash reserves in Germany in 2019? | GT: 4.2 | Pred: print('4.2')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 624: Q: What is the sum of China and Russia in the  potash reserves worldwide in 2019? | GT: 26.4 | Pred: China = 9.7\n",
            "Russia = 16.7\n",
            "sum = China + Russia\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 625: Q: In which year the line on the graph saw its peak point? | GT: 2000 | Pred: peak_year = '2003'\n",
            "print(peak_year)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 626: Q: What is the difference between the  employees between the years when the percentage of employees were maximum and minimum? | GT: 10.59 | Pred: maximum = 37.99\n",
            "minimum = 27.4\n",
            "difference = maximum - minimum\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 627: Q: What color does Green indicate? | GT: Perfumes | Pred: print(\"Other*\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 628: Q: WHat is the difference between hair care and makeup? | GT: 6.12 | Pred: hair_care = 15.2\n",
            "makeup = 21.32\n",
            "difference = hair_care - makeup\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 629: Q: What is the number of passengers entry and exit in Victoria? | GT: 73.56 | Pred: print(73.56)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 630: Q: What is the sum of highest value and lowest value of blue bar ?? | GT: 119.43 | Pred: highest_value = 86.9\n",
            "lowest_value = 32.53\n",
            "sum = highest_value + lowest_value\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 631: Q: What is the maximum percentage of frequency of instagram? | GT: 97 | Pred: print(97)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 632: Q: Daily, how many percentage of people use Instagram? | GT: 63 | Pred: answer = 63\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 633: Q: In which year the line graph saw its peak? | GT: 2019 | Pred: years = [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
            "values = [38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 634: Q: What is the difference between maximum and minimum average annual wage over the years? | GT: 6229 | Pred: maximum = 44689\n",
            "minimum = 38460\n",
            "difference = maximum - minimum\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 635: Q: What is the maximum number of freelance workers? | GT: 59 | Pred: numbers = [53, 53.7, 55, 57.3, 56.7, 57, 59]\n",
            "print(max(numbers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 636: Q: Which year has the least number of workers? | GT: 2014 | Pred: print(2014)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 637: Q: How many colors are there in the pie chart ? | GT: 4 | Pred: print(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 638: Q: What value we get if we add blue and red color? | GT: 42 | Pred: blue = 18\n",
            "red = 23\n",
            "total = blue + red\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 639: Q: How many years has the metric tons surpassed 125,000? | GT: 6 | Pred: years = ['FY 2013', 'FY 2014', 'FY 2015', 'FY 2016', 'FY 2017', 'FY 2018', 'FY 2019', 'FY 2020']\n",
            "production_volumes = [125.79, 128.37, 119.75, 153.08, 148.87, 157.02, 156.45,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 640: Q: What is the difference between the first and last year's results? | GT: 2.95 | Pred: first_year = 125.79\n",
            "last_year = 122.84\n",
            "difference = first_year - last_year\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 641: Q: How many bars are shown in the charts ? | GT: 10 | Pred: print(9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 642: Q: What is the sum of Chief executives and senior officials  and Marketing and sales directors ? | GT: 2976.1 | Pred: answer = 1538.7 + 1437.4\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 643: Q: What is the highest surgical cosmetic procedures worldwide in 2019? | GT: Breast augmentation | Pred: print(\"Liposuction\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 644: Q: What si the difference between the highest and lowest projected surgical cosmetic procedures? | GT: 1347066 | Pred: highest = 1795551\n",
            "lowest = 448485\n",
            "print(highest - lowest)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 645: Q: Which year has the highest number of all-electric car registrations in Italy from 2015 to 2020? | GT: 2020 | Pred: print(\"2020\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 646: Q: What is the average of 1st highest value and 2nd highest value in blue bar? | GT: 21557 | Pred: values = [1484, 1403, 2016, 5012, 10577, 32538]\n",
            "values.sort(reverse=True)\n",
            "first_highest = values[0]\n",
            "second_highest = values[1]\n",
            "average = (first_highest + second_highest) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 647: Q: What is the value of grey sector? | GT: 22.8 | Pred: print(22.8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 648: Q: What is the sum of natural gas and oil? | GT: 54.4 | Pred: natural_gas = 22.8\n",
            "oil = 31.6\n",
            "sum = natural_gas + oil\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 649: Q: Does the life expectancy increase or decrease over time? | GT: increasing | Pred: print(\"increase\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 650: Q: What is the average life expectancy between 2008 and 2018? | GT: 58.56 | Pred: life_expectancy_2008 = 55.17\n",
            "life_expectancy_2009 = 55.96\n",
            "life_expectancy_2010 = 56.73\n",
            "life_expectancy_2011 = 57.46\n",
            "life_expectancy_2012 = 58.15\n",
            "life_expectancy_2013 = 58.8\n",
            "life_expectancy_2014 = 59.4\n",
            "life_expectancy_2015 =\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 651: Q: What is the value of highest blue bar? | GT: 30 | Pred: print(30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 652: Q: What is the sum all the blue bar? | GT: 38 | Pred: bar1 = 30\n",
            "bar2 = 7\n",
            "bar3 = 1\n",
            "sum = bar1 + bar2 + bar3\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 653: Q: Which color segment is the third smallest? | GT: gray | Pred: segments = ['200,000 and over', '150,000 to 199,999', '100,000 to 149,999', '75,000 to 99,999', '50,000 to 74,999', '1,500 to 24,999', 'Under 15,000', '25,000 to 34,999', '35,00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 654: Q: What is the maximum of the income range represented by the biggest segment? | GT: 149999 | Pred: income_ranges = [13.6, 4.8, 6.8, 10.5, 18.8, 13.5, 16.3]\n",
            "print(max(income_ranges))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 655: Q: What energy source has the largest share? | GT: Hard coal | Pred: print('Hard coal')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 656: Q: what's the combined share of top three energy sources? | GT: 81.2 | Pred: hard_coal = 45.7\n",
            "conventional_oil = 17.7\n",
            "conventional_natural_gas = 17.8\n",
            "combined_share = hard_coal + conventional_oil + conventional_natural_gas\n",
            "print(combined_share)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 657: Q: What is the value for Lago d'lseo? | GT: 251 | Pred: print(251)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 658: Q: What is the sum of Lago di Bolsena and Lago di Bracciano ? | GT: 306 | Pred: sum = 160 + 146\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 659: Q: What is the percentage value for soybean ? | GT: 48.2 | Pred: print(48.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 660: Q: What is the sum , if we add  soybean and corn percentage ? | GT: 80.2 | Pred: soybean = 48.2\n",
            "corn = 32\n",
            "sum = soybean + corn\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 661: Q: Which country has the maximum revenue share? | GT: North America | Pred: print(\"North America\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 662: Q: What is the sum of Latin America, EMEA and Asia-pacific? | GT: 31 | Pred: Latin_America = 4\n",
            "EMEA = 13\n",
            "Asia_pacific = 14\n",
            "sum = Latin_America + EMEA + Asia_pacific\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 663: Q: What is the third data value in the blue bar ? left to right | GT: 4.7 | Pred: print(4.7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 664: Q: How many quarters the exchange rate is above 4.5 value? | GT: 5 | Pred: quarters_above_4_5 = 0\n",
            "quarters = [4.25, 4.56, 4.7, 4.7, 4.6, 4.6, 4.4]\n",
            "for q in quarters:\n",
            "  if q > 4.5:\n",
            "    quarters_above_4_5 += 1\n",
            "print(quarters_above_4_5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 665: Q: In the pie chart, what blue color denotes ? | GT: Gucci | Pred: print(\"Gucci\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 666: Q: If we add Gucci and Saint Laurent percentage, write the result? | GT: 73 | Pred: gucci = 59\n",
            "saint_laurent = 14\n",
            "print(gucci + saint_laurent)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 667: Q: What color is the Reward-based slice? | GT: gray | Pred: print('gray')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 668: Q: What 2 slices make up over 75% of the crowdfunding total? | GT: [Equity-based crowdfunding, Real estate crowdfunding] | Pred: print([\"Real estate crowdfunding...\", \"Equity-based crowdfunding...\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 669: Q: What is the ratio of the navy blue bar over the gray bar? | GT: 2.6 | Pred: ratio = 26 / 10\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 670: Q: What is the value of the Yes opinion adds to the difference between No answer and No? | GT: 80 | Pred: no_answer = 10\n",
            "no = 26\n",
            "yes = 64\n",
            "difference = no_answer - no\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 671: Q: What does the light blue part represent? | GT: Fresh milk and cream | Pred: print(\"Fresh milk and cream\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 672: Q: What's the difference between other dairy products and Fresh milk and cream? | GT: 36 | Pred: other_dairy_products = 68\n",
            "fresh_milk_and_cream = 32\n",
            "difference = other_dairy_products - fresh_milk_and_cream\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 673: Q: What is the Net non-performing assets in 2018? | GT: 931.08 | Pred: print(931.08)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 674: Q: Which year has seen a increase in Net non -performing assets? | GT: 2018 | Pred: print(\"FY 2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 675: Q: What is the percentage value of purchases by people from 16-24 years old? | GT: 17 | Pred: answer = 17\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 676: Q: What's the percentage value of purchases by people over 55 years old? | GT: 22 | Pred: answer = 8\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 677: Q: Which country has the highest consumption? | GT: Cyprus | Pred: print(\"Cyprus\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 678: Q: Which country has 0.3 difference when compared with Poland? | GT: Austria | Pred: print(\"Austria\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 679: Q: What is the percentage value for \"Never\" Category? | GT: 36 | Pred: answer = 36\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 680: Q: What is the average of 'once a week' and ' once a month' ? | GT: 9 | Pred: avg = (10 + 8) / 2\n",
            "print(avg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 681: Q: Which year represents the highest expenditure? | GT: 2028 | Pred: expenditures = [1368.4, 1600.1, 1713.4, 1590.4, 1520.3, 1557.4, 1680.9, 3237.9]\n",
            "highest_expenditure = max(expenditures)\n",
            "index = expenditures.index(highest_expenditure)\n",
            "years = [2012, 2013, 2014, 2015, 2016, 2017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 682: Q: What is the median of 2014, 2015 and 2016? | GT: 1590.4 | Pred: values = [1713.4, 1590.4, 1520.3]\n",
            "values.sort()\n",
            "median = values[1]\n",
            "print(median)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 683: Q: Has any category reached 70% of all respondents? | GT: No | Pred: print('Yes')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 684: Q: What percentage believe the government is slightly or not at all corrupt? | GT: 11 | Pred: slightly = 9\n",
            "not_at_all = 2\n",
            "total = slightly + not_at_all\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 685: Q: What year has the lowest point on this graph? | GT: 2000 | Pred: print(2000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 686: Q: What is the average for the last 5 years? | GT: 77.8 | Pred: values = [78, 81, 77, 77, 77]\n",
            "average = sum(values) / len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 687: Q: How many people use youtube daily? | GT: 21 | Pred: print(21)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 688: Q: What is the ratio of the people who use youtube monthly to less often? | GT: 1 | Pred: youtube_monthly = 2\n",
            "less_often = 2\n",
            "ratio = youtube_monthly / less_often\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 689: Q: Which two market shares have been taken? | GT: [Investment funds, Discretionary mandate assets] | Pred: print(\"Investment fund...\")\n",
            "print(\"Discretionary mandate asset...\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 690: Q: Which is the highest among the two? | GT: Investment funds | Pred: print(\"Investment fund...\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 691: Q: Which group has the majority exports? | GT: Manufactures | Pred: print(\"Manufactures\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 692: Q: What does the sum of Agricultural and fuesl and mining products amount to? | GT: 24.6 | Pred: agricultural_products = 10.3\n",
            "fuels_and_mining_products = 14.3\n",
            "sum_of_products = agricultural_products + fuels_and_mining_products\n",
            "print(sum_of_products)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 693: Q: Which date the line chart have vertical rise? | GT: Mar 31 '20 | Pred: print('Mar 31 '20')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 694: Q: What is the ratio between the last two data? | GT: 0.099009901 | Pred: data = [950000, 94015]\n",
            "ratio = data[0] / data[1]\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 695: Q: Which colored segment makes a right angle? | GT: blue | Pred: print(\"Strongly disagree\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 696: Q: Sum the three biggest opinions and then divide the result by the average opinion.? | GT: 3.8 | Pred: opinion_1 = 35\n",
            "opinion_2 = 10\n",
            "opinion_3 = 25\n",
            "average = (opinion_1 + opinion_2 + opinion_3) / 3\n",
            "print((opinion_1 + opinion_2 + opinion_3) / 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 697: Q: Which year has the least receipts? | GT: 11/12 | Pred: year_with_lowest_receipts = [63, 47, 64, 65, 72, 66, 71, 62, 61, 65]\n",
            "min_receipts = min(year_with_lowest_receipts)\n",
            "index = year_with_lowest_receipts.index(min_receipts)\n",
            "year = ['10/11', '11/12', '12/13', '13/14', '14/15', '15/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 698: Q: What is the average of values above 70? (in million U.S. dollars)? | GT: 71.5 | Pred: values = [71, 72]\n",
            "average = sum(values)/len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 699: Q: Which region had maximum number of Gucci stores in 2016? | GT: Emerging countries | Pred: regions = ['Western Europe', 'North America', 'Japan', 'Emerging countries']\n",
            "values = [113, 120, 71, 72]\n",
            "max_value = max(values)\n",
            "region_index = values.index(max_value)\n",
            "print(regions[region_index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 700: Q: What is the difference between maximum number of Gucci stores operated in Emerging Countries over the years and minimum number of stores operated in Western Europe over the years? | GT: 123 | Pred: stores_emerging = [183, 207, 218, 216, 222, 198, 209, 212]\n",
            "stores_europe = [109, 117, 122, 120, 119, 107, 107, 99]\n",
            "max_stores = max(stores_emerging)\n",
            "min_stores = min(stores_europe)\n",
            "difference = max_stores - min_stores\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 701: Q: In which year was the number of Starbucks stores the highest? | GT: 2019 | Pred: stores = [118, 178, 234, 231, 262, 274, 284, 300, 397, 462, 549, 364, 377, 409, 432, 444]\n",
            "years = [2005, 2006, 2007, 2008, 2009, 2010, 2011,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 702: Q: What is the highest difference between the number of Licensed stores and Number of Company-operated stores of Starbucks? | GT: 743 | Pred: differences = [abs(432-118), abs(508-178), abs(234-627), abs(231-775), abs(262-799), abs(274-836), abs(300-874), abs(397-940), abs(462-1009), abs(349-1035), abs(377-1083), abs(409-1109), abs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 703: Q: In Red line chart there is a same percentage value in two years, what is that percentage? | GT: 46 | Pred: percentage_values = [58, 42, 46, 46, 53, 61]\n",
            "print(percentage_values[3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 704: Q: In year 2021, what is the highest percentage value shown? | GT: 95 | Pred: print(95)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 705: Q: What player has the smallest light blue bar? | GT: Gareth Bale (Real Madrid) | Pred: print('Mohamed Salah (Liverpool)')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 706: Q: What was the combined number for Manchester United players? | GT: 61 | Pred: print(28+6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 707: Q: The rate of homicide in Canada and the United States are  available from which year ? | GT: 2000 | Pred: print(\"2000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 708: Q: What is the difference in the highest value of homicide in United States to lowest value in Canada ? | GT: 4.33 | Pred: highest_value_in_Canada = 5.8\n",
            "lowest_value_in_Canada = 1.46\n",
            "difference = highest_value_in_Canada - lowest_value_in_Canada\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 709: Q: What's the percentage value of Hispanic respondents who think movies are very important for avoiding racial stereotypes? | GT: 20 | Pred: print(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 710: Q: What's the total of all the bars of Hispanic respondents? | GT: 99 | Pred: total = 20 + 22 + 21 + 15\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 711: Q: What is the category which value is 73 and 27 percentage ? | GT: British Columbia | Pred: answer = \"British Columbia\"\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 712: Q: What is the ratio between concerned and not concerned in Atlantic ? | GT: 3.16 | Pred: concerned_atlantic = 76\n",
            "not_concerned_atlantic = 24\n",
            "ratio = concerned_atlantic / not_concerned_atlantic\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 713: Q: Find the missing category in the series,  Republicans, Independents, Total ? | GT: Democrats | Pred: print(\"Democrats\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 714: Q: In Total, Assume 39% equals to 1000 respondents, 57% equals to what?  round off to whole number | GT: 1462 | Pred: print(1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 715: Q: How many years are represented in the data? | GT: 3 | Pred: print(3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 716: Q: What is the average monthly income for informal workers? | GT: 764.666666 | Pred: total = 762 + 767 + 765\n",
            "average = total / 3\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 717: Q: Which sector has the highest 'family administration'? | GT: Building | Pred: data = {'Agriculture': {'family administration': 50, 'Family with 100% enterprise control': 29.1}, 'Building': {'family administration': 78.4, 'Family with 100% enterprise control': 49.6}, 'Industry': {'family administration': 75.3, 'Family with 100% enterprise control': 44.7}, 'Services': {'family administration': 61.9, 'Family with 100% enterprise control': 36.5}, 'Utility': {'family administration':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 718: Q: What is the average for industry? | GT: 60 | Pred: industry_administration = 75.3\n",
            "industry_family_with_100_enterprise_control = 44.7\n",
            "average = (industry_administration + industry_family_with_100_enterprise_control) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 719: Q: What's the percentage value of White female presidents? | GT: 33 | Pred: percentage_value = 33\n",
            "print(percentage_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 720: Q: Is the average of Black and Hispanic female presidents 43? | GT: Yes | Pred: black_female = 43\n",
            "hispanic_female = 43\n",
            "average = (black_female + hispanic_female) / 2\n",
            "print(average == 43)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 721: Q: Who is playing more mobile games in several times a day ? | GT: Female | Pred: print(\"Male\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 722: Q: What is the ratio between several times a day vs several times a week in male category? | GT: 2.576923077 | Pred: several_times_a_day_male = 67\n",
            "several_times_a_week_male = 26\n",
            "ratio = several_times_a_day_male / several_times_a_week_male\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 723: Q: Which colored bars trump other bars for all years | GT: navy blue | Pred: print(\"65 years and older\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 724: Q: The maximum of 0-14 age group minus the mode of 65 years and older equals to what | GT: 40.92 | Pred: maximum_0_14 = 41.94\n",
            "mode_65_and_older = 2.65\n",
            "print(maximum_0_14 - mode_65_and_older)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 725: Q: Which has the least value? | GT: Perks such as elite status | Pred: values = [53, 59, 26, 30, 17, 7, 8, 3, 4, 6]\n",
            "min_value = min(values)\n",
            "print(min_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 726: Q: Which option has an increasing order of Air to hotel to car? | GT: The lowest negotiable rate | Pred: air = [53, 26, 17]\n",
            "hotel = [59, 30, 8]\n",
            "car = [63, 23, 7]\n",
            "for i in range(len(air)):\n",
            "  if air[i] < hotel[i]:\n",
            "    continue\n",
            "  else\n",
            "    increasing_order = True\n",
            "print(increasing_order)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 727: Q: The two data lines intersect after which year | GT: 2015 | Pred: print(\"2015\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 728: Q: What is the peak robbery number minus the least theft number | GT: 11.01 | Pred: robbery_values = [7, 5.39, 4.36, 5.47, 7.76, 12.04, 17.57, 15.63, 26.54]\n",
            "theft_values = [22.15, 21.97, 19.02, 17.95, 15.53, 19.19, 17.57, 15.63, 15.72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 729: Q: What does the tallest bar represent | GT: No | Pred: print(\"55-64\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 730: Q: What is the maximum Yes opinion minus the mode of Don't know opinion | GT: 35 | Pred: yes_opinions = [32, 49, 37, 24, 17]\n",
            "dont_know_opinions = [57, 40, 14, 82, 72]\n",
            "print(max(yes_opinions) - min(dont_know_opinions))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 731: Q: Which gender spend more times playing games in the year 2014? | GT: Male | Pred: print(\"Male\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 732: Q: What is the sum value of Male and female in the year 2012? | GT: 11 | Pred: male_2012 = 6.6\n",
            "female_2012 = 4.4\n",
            "sum_2012 = male_2012 + female_2012\n",
            "print(sum_2012)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 733: Q: What is the total in 2016? | GT: 94.53 | Pred: print(94.53)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 734: Q: What is the difference between male and female in 2008? | GT: 3.94 | Pred: print(44.67 - 40.73)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 735: Q: What is the highest number of respondents in Hazardous waste? | GT: 29 | Pred: numbers = [28, 24, 20, 23, 24, 29, 28, 25, 25, 29]\n",
            "print(max(numbers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 736: Q: What is the difference betweeen respondents of Non-hazardous waste between 2017 and 2008? | GT: 25 | Pred: print(276-251)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 737: Q: What is the percentage of Processor market share in the year end March 2018? | GT: 40.6 | Pred: print(40.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 738: Q: What is the sum total of all type in the year to end June 2018? | GT: 99.9 | Pred: processor_2018 = 38\n",
            "memory_2018 = 23.4\n",
            "network_2018 = 17.1\n",
            "peripheral_2018 = 14.4\n",
            "other_2018 = 17.2\n",
            "total_2018 = processor_2018 + memory_2018 + network_2018 + peripheral_2018 + other_2018\n",
            "print(total_2018)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 739: Q: What is the smallest value represented | GT: 9 | Pred: smallest_value = 43\n",
            "print(smallest_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 740: Q: What is the difference between the average of Asian/Asian American and American | GT: 2.67 | Pred: asian_american = [18, 22, 19]\n",
            "american = [69, 28, 14]\n",
            "average_asian_american = sum(asian_american)/len(asian_american)\n",
            "average_american = sum(american)/len(american)\n",
            "difference = average_american - average_asian_american\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 741: Q: In which period the disapproval rate was maximum? | GT: February 26-27, 2015 | Pred: disapprove_rate = [51, 53, 50, 51, 44, 46, 46]\n",
            "max_disapprove_index = disapprove_rate.index(max(disapprove_rate))\n",
            "periods = ['January 29-30, 2015', 'February 26-27, 2015', 'March 30-31, 2015', 'April 29-30, 2015', 'May 28-29,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 742: Q: What is the difference between the highest disapproval and lowest approval? | GT: 21 | Pred: highest_disapproval = 51\n",
            "lowest_approval = 38\n",
            "difference = highest_disapproval - lowest_approval\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 743: Q: which year was the highest revenue in pharmacy sector obtained | GT: 2017 | Pred: revenue_2015 = 65.5\n",
            "revenue_2016 = 67.6\n",
            "revenue_2017 = 70.7\n",
            "revenue_2018 = 69.2\n",
            "revenue_2019 = 66.6\n",
            "revenue_2020 = 65.4\n",
            "revenue_2021 = 64.1\n",
            "revenue_2022 = 63.3\n",
            "revenue_2023 = 62.4\n",
            "revenue_2024 = 61.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 744: Q: what is the difference between the highest and smallest pharmacy service | GT: 10.1 | Pred: pharmacy_services = [65.5, 67.6, 70.7, 69.2, 66.6, 65.4, 64.1, 63.3, 62.4, 61.5, 60.6]\n",
            "print(max(pharmacy_services) - min(pharmacy_services))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 745: Q: In which year was the percentage of employment in  Industry the highest? | GT: 2013 | Pred: years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
            "industry = [18.44, 18.55, 18.22, 18.64, 18.43, 17.84, 17.46, 17.48,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 746: Q: In which year was the employment between Agriculture and Industry the least? | GT: 2020 | Pred: agriculture = [5.59, 5.49, 5.55, 4.45, 4.54, 4.24, 3.96, 3.76, 4.03, 3.94, 3.83]\n",
            "industry = [18.44, 18.55, 18.22, 18.64, 18.43, 17.84, 17.46, 17.48,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 747: Q: what is the highest number of the high school female student that have been cyber bullied lifetime | GT: 38.7 | Pred: print(38.7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 748: Q: what is the sum of the high school  that have been bullied in lifetime Both male and female | GT: 72.8 | Pred: high_school_bullied_lifetime_male = 34.1\n",
            "high_school_bullied_lifetime_female = 38.7\n",
            "sum = high_school_bullied_lifetime_male + high_school_bullied_lifetime_female\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 749: Q: which age group has the highest number of people using Facebook messanger? | GT: 18-29 | Pred: facebook_messenger = [73, 66, 43]\n",
            "max_index = facebook_messenger.index(max(facebook_messenger))\n",
            "age_groups = ['18-29', '30-59', '60+']\n",
            "print(age_groups[max_index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 750: Q: What is the total percentage of both people using Facebook and WhatsApp at 60+ | GT: 49 | Pred: facebook_at_60_plus = 43\n",
            "whatsapp_at_60_plus = 6\n",
            "total_percentage = facebook_at_60_plus + whatsapp_at_60_plus\n",
            "print(total_percentage)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 751: Q: What type of building has the highest  Construction costs of buildings in Ontario, Canada in 2020? | GT: Health care - ambulatory care | Pred: print(\"Health care - ambulatory care\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 752: Q: What's the highest total Health care Construction costs of buildings in Ontario, Canada in 2020 | GT: 9550 | Pred: print(6160+5460+3950+3060+2970)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 753: Q: What's the highest Distribution of employment by economic sector in 2010 | GT: Services | Pred: print(72.97)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 754: Q: What's the average of Distribution of employment by economic sector from 2010 | GT: 33.3 | Pred: print((72.97 + 72.97 + 72.75 + 72.73 + 72.47 + 72.96 + 73.05 + 73.36 + 73.44 + 73.61 + 73.66) / 11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 755: Q: which value has the highest GBP? | GT: Direct and indirect value | Pred: values = [21, 37, 26, 46]\n",
            "highest_value = max(values)\n",
            "print(highest_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 756: Q: What is the the differencebetween GBP in 2014? | GT: 20 | Pred: value_2014 = 46\n",
            "value_2009 = 37\n",
            "difference = value_2014 - value_2009\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 757: Q: which year did the grey bar had the less sales? | GT: 2013 | Pred: print(\"2013/14\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 758: Q: what is the addition of the blue bar in the year 2010 and 2012 | GT: 10 | Pred: blue_bar_2010 = 5\n",
            "blue_bar_2012 = 5\n",
            "total = blue_bar_2010 + blue_bar_2012\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 759: Q: which age group had the highest number of yes | GT: 18-34 years | Pred: print(\"65+ years\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 760: Q: what is the number of yes subtracted from the first age group and the last age group? | GT: 6 | Pred: first_age_yes = 53\n",
            "first_age_no = 47\n",
            "last_age_yes = 47\n",
            "last_age_no = 53\n",
            "answer = (last_age_yes - first_age_yes) + (first_age_no - last_age_no)\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 761: Q: When did sales of beer lowest? | GT: 2010/11 | Pred: print(\"2012/13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 762: Q: what is the difference in sales of beer in the year 2013 and 2011 | GT: 0.5 | Pred: sales_2013 = 8.5\n",
            "sales_2011 = 7\n",
            "difference = sales_2013 - sales_2011\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 763: Q: which year  has the highest single | GT: 2018 | Pred: print(2006)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 764: Q: what is the sum of the highest and smallest number of the single  in all the year | GT: 77.8 | Pred: highest = 47.4\n",
            "smallest = 37.6\n",
            "print(highest + smallest)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 765: Q: Which year has the maximum percentage of people with age group 0-14 ? | GT: 2010 | Pred: years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020]\n",
            "percentages = [15.05, 15.05, 14.96, 14.82, 14.68, 14.56, 14.36, 14.2,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 766: Q: What is the difference between maximum percentage of people of age group 15-64 and minimum percentage of people of age group 0-14 over the years? | GT: 52.13 | Pred: maximum_15_64 = 64.85\n",
            "minimum_0_14 = 13.66\n",
            "difference = maximum_15_64 - minimum_0_14\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 767: Q: How much percentage of males in chins smoked in the year 2014? | GT: 49.2 | Pred: print(49.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 768: Q: In which year the difference between the male and female who smokes in China is minimum? | GT: 2016 | Pred: male_smokes = [56, 53.3, 50.9, 50.1, 50.1, 49.6, 49.2, 48.7, 48.4]\n",
            "female_smokes = [3.2, 2.7, 2.3, 2.2, 2.2, 2.1, 2, 1.9]\n",
            "years = [2000, 2005, 2010, 2011,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 769: Q: How much percentage of Apple Pay payments are already accepted as of December 2018? | GT: 50 | Pred: print(50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 770: Q: What is the difference between the minimum already accepted payment method and maximum accept within 2 years method? | GT: 19 | Pred: min_already_accepted = 20\n",
            "max_accept_within_2_years = 36\n",
            "difference = max_accept_within_2_years - min_already_accepted\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 771: Q: What is the percentage of avid male sports fans? | GT: 39 | Pred: print(45)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 772: Q: What is the difference between minimum percentage of male and maximum percentage of female sports fans? | GT: 32 | Pred: male_min = 39\n",
            "female_max = 49\n",
            "difference = female_max - male_min\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 773: Q: What is the largest growth segment for Revenue share between 2009 and 2020? | GT: Outdoor/Fitness | Pred: revenue_share_2009 = 70\n",
            "revenue_share_2010 = 62\n",
            "revenue_share_2011 = 58\n",
            "revenue_share_2012 = 55\n",
            "revenue_share_2013 = 49\n",
            "revenue_share_2014 = 43\n",
            "revenue_share_2015 = 37\n",
            "revenue_share_2016 = 29\n",
            "revenue_share_2017 = 24\n",
            "revenue_share_2018 = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 774: Q: What is the average growth in Aviation between 2012 and 2013? | GT: 12 | Pred: growth_2012_2013 = 11 - 13\n",
            "print(growth_2012_2013)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 775: Q: Which is the most famous cross platform mobile framework used by developers? | GT: React Native | Pred: print(\"React Native\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 776: Q: What is the percentage  difference between the highest Flutter users and the minimum Dojo users over the years? | GT: 38 | Pred: highest_flutter = 39\n",
            "min_dojo = 4\n",
            "difference = highest_flutter - min_dojo\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 777: Q: Whats the percentage of in sexy attire for those 13-20 year old in movies? | GT: 37.3 | Pred: answer = 37.3\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 778: Q: What's the total percentage of sexy attire for those 13-20 year old in movies? | GT: 37.3 | Pred: total_percentage = 37.3 + 35.6 + 25.2\n",
            "print(total_percentage)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 779: Q: Which age group is \"very likely\" to subscribe to Disney's new online video streaming service? | GT: 30-44 | Pred: print(\"18-29\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 780: Q: Which age group has the minimum difference between \"Not likely at all\" and \"Very likely\" to subscribe to Disney's new online video streaming service? | GT: 65+ | Pred: differences = [abs(24-16), abs(21-17), abs(23-8), abs(39-4), abs(48-13), abs(62-9)]\n",
            "min_difference = min(differences)\n",
            "index = differences.index(min_difference)\n",
            "age_groups = ['18-29', '30-44', '45-54', '55-64', '65+']\n",
            "print(age_groups[index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 781: Q: What is the median weekly earnings of a full time wage and salary worker in 2020 in the US who has a Bachelors's Degree and is male? | GT: 990 | Pred: print(990)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 782: Q: For which of the degrees is there the biggest gap between the median weekly earnings of full-time wage and salary workers in 2020 in the US? | GT: Some college or associate's degree | Pred: print(\"Advanced degree\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 783: Q: What percentage of people were employed in agriculture in 2015? | GT: 18.01 | Pred: print(\"18.01\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 784: Q: How many more people were employed in services than in agriculture in 2020? | GT: 48.62 | Pred: services_2020 = 64.07\n",
            "agriculture_2020 = 15.45\n",
            "difference = services_2020 - agriculture_2020\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 785: Q: What was the total population of women in 2018? | GT: 99.64 | Pred: print(\"99.13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 786: Q: How many more men were there than women in 2018? | GT: 2.6 | Pred: print(\"99.13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 787: Q: What was the 3rd most popular item in 2013? | GT: Shoes | Pred: print(\"Shoes\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 788: Q: What was the difference in the popularity of Clothes from 2013 to 2014? | GT: 0 | Pred: clothes_2013 = 91\n",
            "clothes_2014 = 91\n",
            "difference = clothes_2013 - clothes_2014\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 789: Q: What year was the price of germanium metal the highest? | GT: 2014 | Pred: print(2014)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 790: Q: What was the difference in price for germanium metal and germanium dioxide in 2020? | GT: 280 | Pred: print(1000 - 720)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 791: Q: What is the percentage of households with Stand-alone air conditioning in Canada in 2015? | GT: 18 | Pred: print(18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 792: Q: Which year has the minimum difference between the percentage of households with central air conditioning and Stand-alone air conditioning? | GT: 2013 | Pred: central_air_conditioning = [37, 39, 42]\n",
            "stand_alone_air_conditioning = [18, 18, 18]\n",
            "differences = [central_air_conditioning[i] - stand_alone_air_conditioning[i] for i in range(len(central_air_conditioning))]\n",
            "min_difference = min(differences)\n",
            "index = differences.index(min_difference)\n",
            "year = 2013 + index\n",
            "print(year)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 793: Q: Which tour operators in Europe had highest revenue in 2014? | GT: TUI | Pred: print(\"TUI\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 794: Q: What is the difference between highest revenue of Thomas cook and lowest revenue of Kuoni  over the years ? | GT: 6.6 | Pred: highest_revenue_thomas_cook = 11.3\n",
            "lowest_revenue_kuoni = 4.7\n",
            "difference = highest_revenue_thomas_cook - lowest_revenue_kuoni\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 795: Q: What is the percentage share of children participating in gym, gymnastics, trampolining or climbing frame in the last 4 weeks in England in the year 2016 among 11-15 year olds? | GT: 30.4 | Pred: print(30.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 796: Q: What is the difference in the percentage between the share share of children participating in gym, gymnastics, trampolining or climbing frame in the last 4 weeks in England among 5-10 year olds between the years 2012 and 2013? | GT: 2 | Pred: print(15.6-11.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 797: Q: What is the average of all the light blue bars? | GT: 6.83 | Pred: light_blue_bars = [5.5, 5.5, 7.5, 7.5, 7.5, 7.5]\n",
            "average = sum(light_blue_bars) / len(light_blue_bars)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 798: Q: Which year(s) had the greatest difference between the soft drink price and hot dog price? | GT: [2010/11, 2011/12, 2012/13] | Pred: print(2012/13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 799: Q: Are all the grey bars below 30%? | GT: No | Pred: print('Yes')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 800: Q: What is the percent average of the respondents not being a fan at all across all age groups? | GT: 28 | Pred: not_being_fan_at_all = [27, 22, 30, 33]\n",
            "average_not_being_fan_at_all = sum(not_being_fan_at_all) / len(not_being_fan_at_all)\n",
            "print(average_not_being_fan_at_all)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 801: Q: What age group was most in favor if repealing the 8th amendment? | GT: 25-34 | Pred: print(\"18-24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 802: Q: How many more people in the 50-64 group refused to vote than the 35-49 group? | GT: 3 | Pred: refused_50_64 = 37\n",
            "refused_35_49 = 26\n",
            "print(refused_50_64 - refused_35_49)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 803: Q: What is the percentage of art buyers who bought art online in 2020? | GT: 67 | Pred: print(67)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 804: Q: What is the average percentage of art buyers who bought art online from 2018 to 2019? | GT: 43.5 | Pred: average = (43 + 57) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 805: Q: what is the highest value in blue bar ? | GT: 47 | Pred: blue_bar_values = [19, 18, 11, 20, 41]\n",
            "highest_value = max(blue_bar_values)\n",
            "print(highest_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 806: Q: What is the sum of highest value and lowest value of blue bar ? | GT: 59 | Pred: highest_value = 41\n",
            "lowest_value = 11\n",
            "sum = highest_value + lowest_value\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 807: Q: What is the Agriculture percentage in 2015 | GT: 7.94 | Pred: agriculture_percentage = [8.61, 8.89, 8.37, 8.05, 7.5, 7.94, 7.69, 6.87, 6.97, 6.75]\n",
            "print(agriculture_percentage[4])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 808: Q: What is the difference between Agriculture and industry in 2020 | GT: 17.21 | Pred: Agriculture_2020 = 6.51\n",
            "Industry_2020 = 23.72\n",
            "Difference = Agriculture_2020 - Industry_2020\n",
            "print(Difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 809: Q: The shortest light blue bar minus the tallest grey bar yields what value?? | GT: 545 | Pred: shortest_light_blue_bar = 2330\n",
            "tallest_grey_bar = 1785\n",
            "final_answer = shortest_light_blue_bar - tallest_grey_bar\n",
            "print(final_answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 810: Q: Is the sum of all the  WarnerMedia's global revenue for advertising from 2018 to 2019? | GT: 6896 | Pred: print(2330 + 4566)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 811: Q: Which gender distribution of passengers is highest in Luton? | GT: Male | Pred: print('Male, 49%)'\n",
            "print('Female, 49%')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)')\n",
            "print('Male, 51%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 812: Q: What is the average of males in Gatwick and Stansted? | GT: 52 | Pred: gatwick_male = 51\n",
            "stansted_male = 53\n",
            "average = (gatwick_male + stansted_male) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 813: Q: In which year the sales of dietary supplements was  minimum? | GT: 2014 | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 814: Q: What is the difference between minimum dietary supplements sold over the years and maximum tonics sold over the years? | GT: 37.6 | Pred: dietary_supplements_2014 = 48.8\n",
            "tonics_2014 = 8.6\n",
            "dietary_supplements_2016 = 53.6\n",
            "tonics_2016 = 9.5\n",
            "dietary_supplements_2018 = 62.1\n",
            "tonics_2018 = 10.4\n",
            "dietary_supplements_2020 = 58.1\n",
            "tonics_2020 = 11.2\n",
            "dietary_supplements_\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 815: Q: Which has the least wholesale unit sales in the U.S overall? | GT: Smart home controllers | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 816: Q: What is the average wholesale unit devices of Smart home devices? | GT: 27.85 | Pred: average = (20.7 + 24.9 + 29.9 + 35.9) / 4\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 817: Q: Which color does men indicate in the graph? | GT: light blue | Pred: print(\"blue\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 818: Q: What is the difference between the lowest in men and women? | GT: 7.5 | Pred: men_lowest = 20.7\n",
            "women_lowest = 23.2\n",
            "print(men_lowest - women_lowest)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 819: Q: Which gender has the highest life expectancy? | GT: female | Pred: print('female')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 820: Q: What is the average life expectancy of female from 2015 to 2018? | GT: 67.83 | Pred: life_expectancy_2015 = 67.54\n",
            "life_expectancy_2016 = 67.74\n",
            "life_expectancy_2017 = 67.93\n",
            "life_expectancy_2018 = 68.11\n",
            "average = (life_expectancy_2015 + life_expectancy_2016 + life_expectancy_2017 + life_expectancy_2018)/4\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 821: Q: What is the value of the highest bar in the chart ? | GT: 5.9 | Pred: print(5.9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 822: Q: What is the total value of 13-17 years old who using Facebook ? | GT: 1.6 | Pred: total_13_17 = 0.8 + 0.8\n",
            "print(total_13_17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 823: Q: How much did Peter Dinklage earn both by net worth and earnings per episode? | GT: 16.05 | Pred: print(\"16\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 824: Q: What is the average of net worth of the first three actors in the graph? | GT: 15 | Pred: net_worth_actors = [6, 6, 9]\n",
            "average_net_worth = sum(net_worth_actors) / len(net_worth_actors)\n",
            "print(average_net_worth)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 825: Q: What does the light blue color indicate? | GT: Beer* | Pred: print(\"Beer*\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 826: Q: What is the average of Hot dog? | GT: 4.625 | Pred: hot_dog_sales = [4.5, 4.25, 4.5, 4.75, 4.5, 4.75]\n",
            "average = sum(hot_dog_sales) / len(hot_dog_sales)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 827: Q: How many new cancer cases are there in male ? | GT: 970250 | Pred: print(970250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 828: Q: What is the difference between the genders in the all category? | GT: 1289590 | Pred: new_cases_female = 927910\n",
            "new_cases_male = 970250\n",
            "deaths_female = 289150\n",
            "deaths_male = 319420\n",
            "deaths_all = 608570\n",
            "difference = new_cases_all - (new_cases_female + new_cases_male)\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 829: Q: How many payment methods are considered in the graph? | GT: 5 | Pred: payment_methods = [\"Cash\", \"Account\", \"Mobile\", \"PayPal\", \"Debit/credit card\"]\n",
            "print(len(payment_methods))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 830: Q: What is the average of cash payments? | GT: 38.5 | Pred: cash_payments = [39, 9, 57, 31, 83]\n",
            "average_cash_payments = sum(cash_payments) / len(cash_payments)\n",
            "print(average_cash_payments)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 831: Q: In which year the white members were maximum? | GT: 1995 | Pred: years = [1995, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010]\n",
            "white_members = [299, 278, 277, 277, 277, 271, 264, 276, 283, 288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 832: Q: In which year the difference between white and black members is maximum? | GT: 2010 | Pred: white_members = [299, 278, 276, 277, 277, 271, 264, 276, 283, 288, 288, 291]\n",
            "black_members = [59, 55, 55, 54, 52, 50, 46, 47, 49, 47, 47, 48]\n",
            "differences = [abs(white_members[i\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 833: Q: The shortest light blue bar minus the tallest dark blue bar yields what value? | GT: 17 | Pred: shortest_light_blue_bar = 21\n",
            "tallest_dark_blue_bar = 38\n",
            "answer = shortest_light_blue_bar - tallest_dark_blue_bar\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 834: Q: What is the difference between the highest and the lowest respondents who were satisfied with their sex life in the  United Kingdom (UK) in 2017 for male? | GT: 17 | Pred: highest = 38\n",
            "lowest = 21\n",
            "difference = highest - lowest\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 835: Q: What's the Economic growth forecast after the COVID-19 outbreak in Denmark in 2020? | GT: 1.5 | Pred: print(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 836: Q: What's the total Economic growth forecast after the COVID-19 outbreak in Denmark in 2020 | GT: 2.5 | Pred: forecast_pre_covid = 1.5\n",
            "forecast_post_covid = 1\n",
            "total_forecast = forecast_pre_covid + forecast_post_covid\n",
            "print(total_forecast)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 837: Q: What is the highest share in 2013? | GT: 75.9 | Pred: print(75.9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 838: Q: What is the difference of shares of Private motor insurers? | GT: 4 | Pred: private_motor_insurers_2013 = 56\n",
            "private_motor_insurers_2014 = 52\n",
            "difference = private_motor_insurers_2013 - private_motor_insurers_2014\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 839: Q: What is the second lowest bar value in the blue bar? | GT: 59 | Pred: bars = [75, 68, 59, 53]\n",
            "bars.sort()\n",
            "print(bars[2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 840: Q: Find  the sum of the value between 50 to 60 in the chart. | GT: 112 | Pred: answer = 59 + 66\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 841: Q: What is the lowest value in dark blue bar? | GT: 21 | Pred: values = [25, 50, 34, 32, 21, 43, 37, 30]\n",
            "print(min(values))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 842: Q: What is the total of japan bar? | GT: 29 | Pred: japan_essential = 8\n",
            "japan_high_priority = 21\n",
            "total = japan_essential + japan_high_priority\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 843: Q: How many Non blacks have no opinion? | GT: 18 | Pred: print(17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 844: Q: Which race has the highest value? | GT: Blacks | Pred: print(\"Major factor\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 845: Q: Which year have blue bar with value 71.7? | GT: 2015 | Pred: years = ['2012', '2013', '2014', '2015', '2016']\n",
            "blue_bars = [35.6, 48.3, 58.6, 71.7, 99.5]\n",
            "print(years[blue_bars.index(71.7)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 846: Q: What is the sum of the 2012 two bars? | GT: 66.4 | Pred: bar1 = 35.6\n",
            "bar2 = 30.8\n",
            "sum = bar1 + bar2\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 847: Q: Which year the blue bar is above 5? | GT: 2020 | Pred: years = [2016, 2017, 2018, 2019, 2020]\n",
            "online_bars = [2.79, 3.13, 3.48, 3.77, 5.76]\n",
            "print(years[online_bars.index(max(online_bars))])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 848: Q: What is the sum of all blue bars? | GT: 18.93 | Pred: blue_bars = [2.79, 3.13, 3.48, 3.77, 5.76]\n",
            "sum_blue_bars = sum(blue_bars)\n",
            "print(sum_blue_bars)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 849: Q: Which category have the highest value of blue bar? | GT: Pollution of drinking water | Pred: blue_bars = [66, 63, 69, 55, 56, 75]\n",
            "max_value = max(blue_bars)\n",
            "index = blue_bars.index(max_value)\n",
            "categories = ['Global warming or climate change', 'Air pollution', 'Pollution of rivers, lakes and reservoirs', 'Extinction of plants and animal species', 'Loss of tropical rain forests', 'Pollution of drinking water']\n",
            "print(categories[index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 850: Q: what is sum of the value in extinction of plants and animal species? | GT: 79 | Pred: extinction_plants_and_animal_species = 24\n",
            "sum = 69 + extinction_plants_and_animal_species\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 851: Q: What is the highest percentage in the blue line? | GT: 58 | Pred: highest_percentage = 58\n",
            "print(highest_percentage)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 852: Q: What is the difference between first and last data in black line (somewhat concerned)? | GT: 13 | Pred: first_data = 41\n",
            "last_data = 28\n",
            "difference = first_data - last_data\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 853: Q: What is the blue bar value in 2020? | GT: 716.55 | Pred: print(716.55)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 854: Q: What is the average of 2019 and 2020 blue bar? | GT: 711.92 | Pred: blue_2019 = 707.29\n",
            "blue_2020 = 716.55\n",
            "average = (blue_2019 + blue_2020) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 855: Q: What is the highest value in dark blue bar? | GT: 240 | Pred: values = [89, 206, 232, 195, 207, 240]\n",
            "max_value = max(values)\n",
            "print(max_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 856: Q: What is the sum of first data and last data in the chart? | GT: 247 | Pred: first_data = 7\n",
            "last_data = 240\n",
            "sum = first_data + last_data\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 857: Q: What is the sum of the two smallest bars? | GT: 30 | Pred: smallest_bar_1 = 17\n",
            "smallest_bar_2 = 19\n",
            "sum_of_smallest_bars = smallest_bar_1 + smallest_bar_2\n",
            "print(sum_of_smallest_bars)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 858: Q: What is the difference between the largest and the smallest navy blue bar? | GT: 49 | Pred: bars = [70, 71, 42, 47, 47, 56, 60, 66]\n",
            "max_value = max(bars)\n",
            "min_value = min(bars)\n",
            "difference = max_value - min_value\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 859: Q: What percentage is shown by navy blue bar? | GT: 50 | Pred: print(50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 860: Q: What is the average value of male and female reason? | GT: 46 | Pred: male = 42\n",
            "female = 50\n",
            "average = (male + female) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 861: Q: Which device has the least traffic? | GT: Tablet | Pred: devices = [\"Smartphone\", \"Desktop\", \"Tablet\"]\n",
            "traffic = [33, 42, 47]\n",
            "min_traffic = min(traffic)\n",
            "index = traffic.index(min_traffic)\n",
            "print(devices[index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 862: Q: Which year has the maximum traffic of smartphones? | GT: 2017 | Pred: smartphone_2015 = 33\n",
            "smartphone_2016 = 42\n",
            "smartphone_2017 = 47\n",
            "max_smartphone = max(smartphone_2015, smartphone_2016, smartphone_2017)\n",
            "if max_smartphone == smartphone_2015:\n",
            "    print(\"2015\")\n",
            "elif max_smartphone == smartphone_2016:\n",
            "    print(\"2016\")\n",
            "else:\n",
            "    print(\"2017\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 863: Q: How many millennial are Aware(net)? | GT: 91 | Pred: aware = 91\n",
            "not_aware = 9\n",
            "total_aware = aware + not_aware\n",
            "print(total_aware)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 864: Q: What is the sum of the people of Boomers and Generation X who have used this service? | GT: 22 | Pred: Boomers_used = 80\n",
            "Generation_X_used = 72\n",
            "total_used = Boomers_used + Generation_X_used\n",
            "print(total_used)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 865: Q: What is the highest value of the light blue bar? | GT: 4.2 | Pred: print(4.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 866: Q: What is the value of shortest light blue bar? | GT: 2.5 | Pred: answer = 2.5\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 867: Q: In 18-29 age group, what is the percentage value of very interested respondents? | GT: 13 | Pred: percentage_very_interested_18_29 = 13\n",
            "print(percentage_very_interested_18_29)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 868: Q: What is the difference between highest and lowest value of red bar? | GT: 15 | Pred: highest_red_bar = 62\n",
            "lowest_red_bar = 47\n",
            "difference = highest_red_bar - lowest_red_bar\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 869: Q: How man years does the graph represent? | GT: 11 | Pred: years = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020*']\n",
            "print(len(years))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 870: Q: What is the average from 2010 to 2015 in import value? | GT: 361048.33 | Pred: import_values = [335, 352, 352, 343, 326, 313]\n",
            "average = sum(import_values) / len(import_values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 871: Q: Which color represents the navy blue line? | GT: Male | Pred: print(\"Male\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 872: Q: What is the sum of total in year, 2017 and 2018? | GT: 21.14 | Pred: total_2017 = 10.51\n",
            "total_2018 = 10.63\n",
            "sum_total = total_2017 + total_2018\n",
            "print(sum_total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 873: Q: Find out which category shows 1.8, 2 ,2.3 in the chart 2017,2018,2019 respectively? | GT: Heart | Pred: print([\"Liver\", \"Heart\", \"Pancreas\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 874: Q: Find the average of all the bars in Kidney category? | GT: 9.2 | Pred: Kidney_values = [8.2, 9.5, 10.2]\n",
            "average = sum(Kidney_values) / len(Kidney_values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 875: Q: How many respondents are not sure? | GT: 29 | Pred: not_sure = [8, 12, 19, 10, 9]\n",
            "answer = not_sure.index(min(not_sure)) + 1\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 876: Q: What is the value of the highest bar? | GT: 42 | Pred: print(42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 877: Q: Which color does light blue indicate? | GT: Male | Pred: print(\"Male\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 878: Q: For which social network, the percentage is minimum between male and female? | GT: Twitter | Pred: male_percentages = [46.6, 35.9, 57.6, 51.9, 44, 9]\n",
            "female_percentages = [66.7, 34.9, 47.7, 67.9, 40.3, 45.5]\n",
            "min_percentage_index = female_percentages.index(min(female_percentages))\n",
            "social_network = ['Snapchat', 'Twitter', 'Facebook', 'Instagram', 'Google+', 'Pinterest']\n",
            "print(social_network\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 879: Q: Which skin  has a least difference between male and female? | GT: Other nonepithelial skin | Pred: male_cases = [62260, 5860]\n",
            "female_cases = [43850, 3350]\n",
            "differences = []\n",
            "for i in range(len(male_cases)):\n",
            "  differences.append(abs(male_cases[i] - female_cases[i]))\n",
            "min_difference = min(differences)\n",
            "index = differences.index(min_difference)\n",
            "print([male_cases[index], female_cases[index]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 880: Q: What is the average number of skin cancers in male? | GT: 34060 | Pred: male_melanoma = 62260\n",
            "male_other_noncancer = 5860\n",
            "average = (male_melanoma + male_other_noncancer) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 881: Q: which justice has highest very favorable percentage? | GT: Ruth Bader Ginsburg | Pred: print('Brett Kavanaugh')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 882: Q: What's the percentage of people that are at least somewhat favorable toward Brett Kavanaugh? | GT: 32 | Pred: favorable_percentages = [15, 17, 12, 14, 19, 16, 25, 16, 11, 17, 19]\n",
            "count = 0\n",
            "for percentage in favorable_percentages:\n",
            "    if percentage >= 10:\n",
            "        count += 1\n",
            "percentage_not_sure = 0\n",
            "for percentage in favorable_percentages:\n",
            "    if percentage == 32:\n",
            "        percentage_not_sure += 1\n",
            "percentage_very_unfavorable = 0\n",
            "for percentage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 883: Q: Which year has a value of above 20000? | GT: 2028 | Pred: values = [20751, 12784, 12334, 12486, 8201, 8041, 9523, 6103, 5802, 7129, 5648]\n",
            "years = [2028, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 884: Q: What is the total spending in Medicaid? | GT: 28728 | Pred: spending_2017 = 8041\n",
            "spending_2018 = 8201\n",
            "spending_2028 = 12486\n",
            "total_spending = spending_2017 + spending_2018 + spending_2028\n",
            "print(total_spending)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 885: Q: What is the value of dark blue bar in 2015? | GT: 10832 | Pred: print(10832)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 886: Q: What is the sum of blue bar of 2008 and 2015? | GT: 157073 | Pred: blue_bar_2008 = 44742\n",
            "blue_bar_2015 = 112331\n",
            "sum = blue_bar_2008 + blue_bar_2015\n",
            "print(sum)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 887: Q: How many color bars shown in the chart? | GT: 5 | Pred: print(15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 888: Q: Subtract the value of green bar from red bar in the judges and politicians category and sum the result? | GT: 26 | Pred: green_bar_judges = 11\n",
            "red_bar_politicians = 27\n",
            "answer = green_bar_judges - red_bar_politicians\n",
            "answer = answer + red_bar_politicians\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 889: Q: Which is highest percentage value in green bar? | GT: 33 | Pred: green_bar_values = [10, 11, 8, 10, 10]\n",
            "highest_value = max(green_bar_values)\n",
            "print(highest_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 890: Q: What is the difference between highest blue bar and highest green bar? | GT: 28 | Pred: highest_blue_bar = 60\n",
            "highest_green_bar = 10\n",
            "difference = highest_blue_bar - highest_green_bar\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 891: Q: How many dark blue bar crossed 50 mark? | GT: 2 | Pred: # 1 dark blue bar crossed 50 mark \n",
            "answer = 1\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 892: Q: What is the difference between two bars in For clarity category? | GT: 39 | Pred: difference = 51 - 12\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 893: Q: Which category has value of 30% in 2017/18? | GT: 11-15 years | Pred: print(\"11-15 years\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 894: Q: What is the difference between the ages in 2014/15? | GT: 21.2 | Pred: print(50.6 - 29.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 895: Q: What is the value of frozen fruits? | GT: 24 | Pred: print(24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 896: Q: What is the total value of fresh and shelf-stable vegetables? | GT: 42 | Pred: fresh_vegetables = 10\n",
            "shelf_stable_vegetables = 32\n",
            "total = fresh_vegetables + shelf_stable_vegetables\n",
            "print(total)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 897: Q: Which region the females value shows 10.4 and males value as 3.8? | GT: London | Pred: regions = [\"Yorkshire and the Humber\", \"London\", \"East\", \"North East\", \"South West\", \"South East\", \"West Midlands\", \"North West\", \"East Midlands\"]\n",
            "females = [10.8, 10.4, 10, 9.4, 8.4, 8.2, 8.2, 8.1, 6.9]\n",
            "males = [5.1, 3.8, 4.1, 5.5, 3, 3.7, 3.8, 3,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 898: Q: What is the average  of females value in the first five region,  from Yorkshire and the humber to south west? | GT: 9.8 | Pred: females_values = [10.8, 10.4, 10, 9.4, 8.4]\n",
            "average = sum(females_values[:5]) / len(females_values[:5])\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 899: Q: Find the lowest value in the dark blue bar? | GT: 130 | Pred: values = [253, 227, 236, 130, 193, 178, 196, 174, 246, 227, 19]\n",
            "min_value = min(values)\n",
            "print(min_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 900: Q: What is the average of last 3 year in Danish citizenship? | GT: 1972 | Pred: danish_citizenship = [2113, 2083, 1762]\n",
            "average = sum(danish_citizenship) / len(danish_citizenship)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 901: Q: How much is the e commerce sales for companies under 50 employees in 2019? | GT: 35.6 | Pred: print(42.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 902: Q: How much is the e commerce sales for companies under 250 employees in 2019? | GT: 83.4 | Pred: print(52.53)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 903: Q: What is the percentage share of Industry in GDP in 2015? | GT: 13.65 | Pred: industry = [13.21, 11.97, 12.61, 12.93, 13.33, 14.51, 13.65, 13.66, 14.37, 14.27]\n",
            "print(industry[6])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 904: Q: What is the difference between highest and lowest agriculture share? | GT: 12.3 | Pred: highest_agriculture_share = 48.61\n",
            "lowest_agriculture_share = 42.6\n",
            "difference = highest_agriculture_share - lowest_agriculture_share\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 905: Q: What is the prevelance of dietary supplements in men of age group 31-50 between 2003 and 2006 in the US? | GT: 44 | Pred: print(44)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 906: Q: What is the average prevelance of dietary supplements in people of age group 19-30 between 2003 and 2006 in the US? | GT: 39.5 | Pred: prevalence_19_30 = [36, 43, 44, 55]\n",
            "average = (prevalence_19_30[0] + prevalence_19_30[1] + prevalence_19_30[2] + prevalence_19_30[3]) / 4\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 907: Q: What is the biggest value among all the bars? | GT: 37 | Pred: values = [24, 32, 37, 35, 33, 33]\n",
            "max_value = max(values)\n",
            "print(max_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 908: Q: What is the difference between the modes of Somewhat interested and that of Don't know? | GT: 27 | Pred: somewhat_interested = 37 + 35 + 22 + 33\n",
            "dont_know = 6\n",
            "difference = somewhat_interested - dont_know\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 909: Q: What is the number of viewers in 2005? | GT: 8.1 | Pred: viewers = [10.8, 9.1, 8.2, 8.1, 8, 8]\n",
            "print(viewers[3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 910: Q: What is the difference between the rating and viewers in 2013? | GT: 3.4 | Pred: rating_2013 = 4.6\n",
            "viewers_2013 = 8\n",
            "difference = rating_2013 - viewers_2013\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 911: Q: Which sector is largest in 2021? | GT: TLC network systems | Pred: sectors = ['Devices & systems', 'Network systems', 'Software & ICT solutions', 'ICT services', 'Digital advertisement & content']\n",
            "values = [19.1, 7.7, 8.2, 12.8, 13.6]\n",
            "max_value = max(values)\n",
            "index = values.index(max_value)\n",
            "print(sectors[index])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 912: Q: What is the market size of top 3 sectors in 2021? | GT: 51.2 | Pred: devices_2021 = 19\n",
            "software_ict_2021 = 8.2\n",
            "digital_content_2021 = 12.8\n",
            "top_3_2021 = [devices_2021, software_ict_2021, digital_content_2021]\n",
            "print(top_3_2021[0] + top_3_2021[1] + top_3_2021[2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 913: Q: Which generation enjoy social media the least? | GT: Boomers | Pred: print(\"Generation X\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 914: Q: What's the percentage of boomers who never use social media? | GT: 48 | Pred: print(48)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 915: Q: Identify what is referred  61% and 55%? | GT: Hardware | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 916: Q: How much percentage points increased in services from 2014 to 2020? | GT: 3.4 | Pred: services_2020 = 24.4\n",
            "services_2014 = 21\n",
            "increased = services_2020 - services_2014\n",
            "percentage_increased = (increased / services_2014) * 100\n",
            "print(percentage_increased)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 917: Q: Identify the category in y-axis, where the bar value is 8,5,12,20 %? | GT: Chinese language TV | Pred: print(\"Chinese language TV\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 918: Q: What is the average all grey bar (2 to 5 hours data)? | GT: 12.4 | Pred: # The grey bar values for 2 to 5 hours are: 1, 1, 1, 1, 1.\n",
            "# Calculate the average\n",
            "average = (1 + 1 + 1 + 1 + 1) / 5\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 919: Q: What is the highest value of Moscow? | GT: Moscow | Pred: print(33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 920: Q: What is the ratio between sales and average bill in 'Across Russia'? | GT: 0.4333 | Pred: sales_Across_Russia = 6.5\n",
            "average_bill_Across_Russia = 15\n",
            "ratio = sales_Across_Russia / average_bill_Across_Russia\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 921: Q: In which year there was more usage of internet everyday among individual? | GT: 2019 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 922: Q: what is the sum total of usage of internet every day and  often/sometime among individual in the year 2013 ? | GT: 73 | Pred: total_2013 = 57 + 16\n",
            "print(total_2013)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 923: Q: Which opinion has the least difference between 2011 and 2012? | GT: Important | Pred: # The difference between 2011 and 2012 for \"Very unimportant\" is 10 - 9 = 1\n",
            "# The difference between 2011 and 2012 for \"Unimportant\" is 26 - 20 = 6\n",
            "# The difference between 2011 and 2012 for \"Important\" is 42 - 42 = 0\n",
            "# The difference between 2011 and 2012 for \"Very important\" is 22 - 27 = -5\n",
            "# The\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 924: Q: How many opinions have a percentage of equal or above 20%? | GT: 3 | Pred: percentages = [9, 26, 42, 22]\n",
            "count = 0\n",
            "for percentage in percentages:\n",
            "    if percentage >= 20:\n",
            "        count += 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 925: Q: Which color shows the highest value? | GT: yellow | Pred: print(\"Strongly agree (6)\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 926: Q: What is the difference between the red and green color? | GT: 4 | Pred: red = 13\n",
            "green = 17\n",
            "difference = green - red\n",
            "print(difference)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 927: Q: In the chart, Lesbian women data shows 28 and gay men data shows 9, find that category? | GT: Dating | Pred: print(\"Stay on top of what is happening in the LGBT community\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 928: Q: Use Gay men data from Dating, Hook up and Entertainment and Find the average of this data ? | GT: 34.66 | Pred: gay_men_data = [30, 30, 46]\n",
            "average = (gay_men_data[0] + gay_men_data[1] + gay_men_data[2])/3\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 929: Q: Which is the lowest unpaid internships by sector in US? | GT: Government | Pred: print(\"Government\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 930: Q: What is the average unpaid internships ? | GT: 34 | Pred: unpaid_internships = [62, 33, 31]\n",
            "average = sum( unpaid_internships) / len(unpaid_internships)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 931: Q: What is the highest percentage recorded in Happy with current Hours? | GT: 69 | Pred: data = [69, 63, 63, 56, 54, 52, 47, 46, 40]\n",
            "print(max(data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 932: Q: What is the average of all the blue bar data? | GT: 54.44 | Pred: blue_bar_data = [69, 63, 63, 56, 54, 52, 47, 46, 40]\n",
            "average = sum(blue_bar_data) / len(blue_bar_data)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 933: Q: Which political party dominated in all the segment ? | GT: Democratic | Pred: print(\"Democratic\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 934: Q: What is the average percentage of Republican ? | GT: 41.75 | Pred: republican_percentages = [28, 43, 47, 49]\n",
            "average = sum(republican_percentages) / len(republican_percentages)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 935: Q: How many bars ( combined) in the chart ? | GT: 12 | Pred: bars_positive = 11 + 69 + 59 + 58 + 57 + 54 + 52 + 44 + 37 + 36 + 33\n",
            "bars_negative = 28 + 31 + 40 + 42 + 47 + 52 + 56 + 61 + 64 + 66 + 64\n",
            "total_bars = bars_positive + bars_negative\n",
            "print(total_bars)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 936: Q: Find the average of this three factor in Positive data, Medical care, Rights of women and Protection against the Taliban? | GT: 51 | Pred: Positive_data = 58\n",
            "Medical_care = 54\n",
            "Rights_of_women = 52\n",
            "Protection_against_the_Taliban = 47\n",
            "average = (Positive_data + Medical_care + Rights_of_women + Protection_against_the_Taliban) / 4\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 937: Q: Which age range has more population than others? | GT: 25-59 years | Pred: print('25-59 years')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 938: Q: In which age range is the gender gap the largest? | GT: 25-59 years | Pred: print('25-59 years')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 939: Q: Which year does the purple color indicate? | GT: 2019 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 940: Q: What is the ratio of fixed broadband in the years 2018 and 2019? | GT: 1 | Pred: fixed_broadband_2018 = 94\n",
            "fixed_broadband_2019 = 98\n",
            "ratio = fixed_broadband_2018 / fixed_broadband_2019\n",
            "print(ratio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 941: Q: What is the number of Macy's stores  worldwide in the year 2018? | GT: 649 | Pred: answer = 649\n",
            "print(answer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 942: Q: What is the total of Macy's, Bloomingdale's and Bluemercury brand stores worldwide in the 2019? | GT: 839 | Pred: total_stores = 613 + 171 + 55\n",
            "print(total_stores)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 943: Q: WHich period has the least e-reader owners? | GT: November 2010 | Pred: print(\"65 and older\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 944: Q: WHat is the total value of 30-49 age group? | GT: 41 | Pred: total_value = 5 + 12\n",
            "print(total_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 945: Q: In which period, there should be a referendum is high ? | GT: Jul 25-26 | Pred: print(\"Jul 5-6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 946: Q: How many periods represent least difference between should and should not? | GT: 3 | Pred: periods = ['Jan 9-10', 'Jan 15-16', 'Mar 5-6', 'Mar 26-27', 'Apr 9-10', 'May 13-14', 'Jun 11-12', 'Jun 19-20', 'Jul 5-6', 'Jul 10-11', 'Jul 16-17', 'Jul 25-26']\n",
            "differences = []\n",
            "for i in range(len(periods)):\n",
            "  differences.append(abs(int(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 947: Q: Which segments has the higher average, general merchandisers or grocers? | GT: General Merchandisers | Pred: grocers_tickets = [46, 46, 45, 46, 46, 44, 50, 53]\n",
            "general_merchandise_tickets = [49, 48, 50, 52, 49, 46, 46, 46]\n",
            "highest_grocers_index = grocers_tickets.index(max(grocers_tickets))\n",
            "highest_general_merchandise_index = general_merchandise_tickets.index(max(general_merchandise_tickets))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 948: Q: What is the average for general merchandisers? | GT: 46.75 | Pred: general_merchandise_values = [46, 46, 45, 46, 46, 44, 46, 53]\n",
            "average = sum(general_merchandise_values) / len(general_merchandise_values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 949: Q: How many genders have been considered? | GT: 2 | Pred: life_expectancy_female = [68.09, 68.56, 69.01, 69.44, 69.84, 70.23, 70.59, 70.93, 71.26, 71.59, 71.9]\n",
            "life_expectancy_male = [65.42, 65.86, 66.29, 66.7, 67.09, 67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 950: Q: What is the average of highest values of male and female? | GT: 70.445 | Pred: highest_male = 68.99\n",
            "highest_female = 71.9\n",
            "average = (highest_male + highest_female) / 2\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 951: Q: Which data line experienced the biggest changes across all years? | GT: Europe, Middle East and Africa | Pred: print(\"Latin America\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 952: Q: For North America and Asia Pacific regions, which revenue average across all years is bigger? | GT: North America | Pred: # The revenue average across all years for North America is 16.69.\n",
            "# The revenue average across all years for Asia Pacific is 16.09.\n",
            "print(\"North America\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 953: Q: Are the bars sorted in increasingly or decreasingly from left to right? | GT: decreasing | Pred: bars = [47.6, 43.03, 37.2, 29.22]\n",
            "increasing = True\n",
            "for bar in bars:\n",
            "  if bar < bars[1]:\n",
            "    increasing = False\n",
            "  else:\n",
            "    bars.sort()\n",
            "print(increasing)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 954: Q: Which two firms have above 90 billion U.S. dollars total revenue? | GT: [Deloitte, PwC] | Pred: print([\"PwC\", \"Deloitte\"])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 955: Q: Which sector has the tallest bars in all years? | GT: Services | Pred: services = [45.98, 45.03, 45.44, 46.3, 46.7, 47.82, 47.75, 47.89, 48.81, 49.88]\n",
            "years = [2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 956: Q: In which year the GDP of the services sector was maximum and the GDP of the Industry was minimum? | GT: 2019 | Pred: services_maximum = max([45.98, 45.03, 45.44, 46.3, 46.7, 47.82, 47.75, 47.89, 48.81, 49.88])\n",
            "industry_minimum = min([31.12, 30.73, 30.16, 29.4, 28.4, 27.66, 27.35, 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 957: Q: Which viewer type does of the upper bar in the stacked bars represent? | GT: Occasional viewers | Pred: print('Oasional viewers')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 958: Q: In how many years the number of eSports enthusiasts is above 200 in this graph? | GT: 3 | Pred: years = ['2019', '2020', '2021', '2024*']\n",
            "count = 0\n",
            "for year in years:\n",
            "  if year == '2024':\n",
            "    continue\n",
            "  else:\n",
            "    count = count + 1\n",
            "print(count)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 959: Q: What's the color of the tallest bar in this graph? | GT: Red | Pred: print(\"red\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 960: Q: On average, which candidate had the lowest share of votes among all the military personnel in this graph? | GT: Hillary Clinton | Pred: # The lowest share of votes among all the military personnel is 34% for \"Veteran\" category.\n",
            "# The lowest share of votes among all the military personnel is 34% for \"Veteran\" category.\n",
            "print(\"34\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 961: Q: Who portrayed Jon Snow? | GT: Kit Harington | Pred: print(\"Nikolaj Coster-Waldau\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 962: Q: Who played Mother of Dragons Daenerys Targaryen? | GT: Emilia Clarke | Pred: print(\"Emilia Clarke\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 963: Q: What was the estimated net worth of Peter Dinklage and Nikolaj Coster-Waldau? | GT: 16 | Pred: print(\"16\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 964: Q: What is the most popular cross-platform mobile framwork used by global developers? | GT: React Native | Pred: print(\"React Native\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 965: Q: When did the population of the Dominican Republic begin to increase? | GT: 2008 | Pred: print(\"2008\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 966: Q: What was the population of the Dominican Republic in 2018? | GT: 10.63 | Pred: print(\"10.63\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 967: Q: Which Supreme Court justice did 32 percent of respondents not know if they had a favorable or unfavorable opinion of? | GT: Brett Kavanaugh | Pred: print(\"Brett Kavanaugh\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 968: Q: When did the population of Antigua & Barbuda begin to increase? | GT: 2008 | Pred: print(\"2008\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 969: Q: How many Macy's branded stores did Macy's operate in 2020? | GT: 572 | Pred: print(\"572\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 970: Q: How many Bluemercury stores did Macy's operate in 2020? | GT: 162 | Pred: print(\"162\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 971: Q: What was the average ticket in general merchandisers and grocers during the week of February 25 to March 2, 2020? | GT: 53 | Pred: print(\"53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 972: Q: What was the average transaction value in grocers in prior weeks? | GT: 49 | Pred: print(\"50\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 973: Q: What was the average transaction value in general merchandisers and grocers in prior weeks? | GT: 46 | Pred: print(\"45\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 974: Q: How much did a 24 ounce beer cost in the 2012-13 season? | GT: 6.25 | Pred: print(\"6.25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 975: Q: What did the majority of people who immigrated to Greenland in 2020 have? | GT: Danish citizenship | Pred: print(\"Danish citizenship\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 976: Q: What does the vast majority of the population of Greenland have? | GT: Danish citizenship | Pred: print(\"Danish citizenship\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 977: Q: What is included in the statistics for people originating from Greenland moving back home to Greenland as well as Danish people born in Denmark moving to | GT: Danish citizenship | Pred: print(\"Foreign citizenship\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 978: Q: What is the forecast for the ICT sector in Italy in 2020? | GT: 2022 | Pred: print(\"19.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 979: Q: What was the revenue of the software and ICT solutions sector in 2019? | GT: 12.3 | Pred: print(\"7.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 980: Q: What generation was most satisfied with their sex life? | GT: Millennials | Pred: print(\"Gen Z\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 981: Q: What generation was least satisfied with their sex life? | GT: Boomers | Pred: print(\"Gen X\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 982: Q: What percentage of females were satisfied with their sex life in 2017? | GT: 37 | Pred: print(\"38\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 983: Q: What percentage of voters with less than high school education voted for the democratic candidate? | GT: 72 | Pred: print(\"72\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 984: Q: How many drug recall enforcement reports did the FDA issue for over-the-counter drugs in 2015? | GT: 39 | Pred: print(\"39\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 985: Q: How many drug recall enforcement reports were issued for prescription drugs in 2015? | GT: 195 | Pred: print(\"195\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 986: Q: What was the highest rate of thyroid cancer among men in the North East in 2018? | GT: 5.5 | Pred: print(\"5.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 987: Q: What was the only airport with a noticeable difference in the gender of its passengers? | GT: Heathrow | Pred: print(\"Manchester\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 988: Q: In what year did the popularity of internet connection technologies increase in Great Britain? | GT: 2013 | Pred: print(\"2013\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 989: Q: Which motorcycle brand offered the greatest profit returns according to dealers? | GT: Harley Davidson | Pred: print(\"Harley Davidson\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 990: Q: Which tour operator topped the list of Europe's leading tour operators in 2014? | GT: Thomas Cook | Pred: print(\"TUI\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 991: Q: How much revenue did TUI have in 2012 and 2014? | GT: 18.7 | Pred: print(\"18.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 992: Q: How many smart home devices were sold to dealers in the United States in 2014? | GT: 20.7 | Pred: print(\"20.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 993: Q: Which candidate did 34 percent of military voters vote for? | GT: Hillary Clinton | Pred: print(\"Hillary Clinton\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 994: Q: What rating does the 2013 All-Star game have? | GT: 4.6 | Pred: print(\"4.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 995: Q: How many homicides occurred in Canada per 100,000 residents in 2019? | GT: 1.8 | Pred: print(\"1.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 996: Q: What was the second-most-shared news page on Facebook in January 2017? | GT: CNN | Pred: print(\"CNN\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 997: Q: How many times was The Daily Mail's video shared on Facebook in January 2017? | GT: 11.13 | Pred: print(\"11.13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 998: Q: How did Belize score in estimated earned income? | GT: 0.56 | Pred: print(\"0.56\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 999: Q: What was the average retail price of snowboard boots in specialty shops in the United States in 2015/16? | GT: 179.62 | Pred: print(\"179.62\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1000: Q: What online review site did 59 percent of respondents say they had visited to conduct research on a local business? | GT: Yelp | Pred: print(\"Yelp\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1001: Q: How many seats did Pakatan Harapan win? | GT: 113 | Pred: print(\"79\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1002: Q: How many road fatalities were there in Portugal in 2007? | GT: 974 | Pred: print(\"974\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1003: Q: How many road fatalities were there in Portugal in 2019? | GT: 621 | Pred: print(\"621\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1004: Q: Where did 42 percent of nickel imports into the U.S. come from between 2016 and 2019? | GT: Canada | Pred: print(\"Canada\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1005: Q: What country had the world's largest potash reserves in 2019? | GT: Canada | Pred: print(\"Belarus\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1006: Q: What percentage of potash reserves did Canada have in 2019? | GT: 27.8 | Pred: print(\"27.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1007: Q: Who is the most successful actress in the history of the Academy Awards? | GT: Katharine Hepburn | Pred: print(\"Catherine Hepburn\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1008: Q: What is the deepest lake in Italy? | GT: Lago Maggiore | Pred: print(\"Lago di Como\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1009: Q: What is the average EUR/PLN exchange rate at the end of 2020? | GT: 4.25 | Pred: values = [4.56, 4.7, 4.7, 4.6, 4.6, 4.4]\n",
            "average = sum(values) / len(values)\n",
            "print(average)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1010: Q: What brand generated 59 percent of Kering Group's global revenue in 2020? | GT: Gucci | Pred: print(\"Gucci\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1011: Q: What percentage of Kering Group's global revenue did Gucci generate in 2020? | GT: 59 | Pred: print(\"59\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1012: Q: When was Kuwait's domestic travel and tourism expenditure first measured? | GT: 2012 | Pred: print(\"2012\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1013: Q: How many Kuwaiti dinars will domestic travel expenditure in Kuwait be by 2028? | GT: 3237.9 | Pred: print(\"3237.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1014: Q: What was the most popular fashion brand on Facebook as of January 2021? | GT: Louis Vuitton | Pred: print(\"Louis Vuitton\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1015: Q: What was the second most popular fashion brand on Facebook in 2021? | GT: Dior | Pred: print(\"Dior\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1016: Q: How many fans did Louis Vuitton have on Facebook as of January 2021? | GT: 24.07 | Pred: print(\"24.07\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1017: Q: How many fans did Dior have on Facebook as of January 2021? | GT: 17.64 | Pred: print(\"17.64\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1018: Q: What was the average hourly earnings for all employees on private nonfarm payrolls in the United States in May 2021? | GT: 30.33 | Pred: print(\"30.33\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1019: Q: Which station was the busiest in the financial year of 2019/20? | GT: Waterloo | Pred: print(\"Waterloo\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1020: Q: How many Taco Bell stores did Yum! Brands have in Spain at the end of the third quarter of 2020? | GT: 69 | Pred: print(\"69\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1021: Q: Which accounting firm was the biggest of the Big Four accounting firms in 2020? | GT: Deloitte | Pred: print(\"Deloitte\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1022: Q: What was Deloitte's total revenue in dollars in 2020? | GT: 47.6 | Pred: print(\"47.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1023: Q: Since what year has the number of freelancers in the U.S. been increasing? | GT: 2014 | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1024: Q: Which liquid soap brand has managed to maintain positive sales growth over the specified time period? | GT: Carex | Pred: print(\"Radox\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1025: Q: What is the projected amount of flash memory capital expenditures in the United States in 2018? | GT: 31.1 | Pred: print(\"31.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1026: Q: What was the market share of cotton socks in Italy in 2016? | GT: 19 | Pred: print(\"19\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1027: Q: How much was the internal travel and tourism consumption in the U.S. Virgin Islands in 2013? | GT: 3.24 | Pred: print(\"3.24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1028: Q: What is the 2019 revenue of the U.S. Virgin Islands tourism industry? | GT: 2.59 | Pred: print(\"2.59\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1029: Q: What was the net sales share of Capri Holdings' footwear segment in fiscal year 2020? | GT: 19.8 | Pred: print(\"19.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1030: Q: As of the third quarter of 2014, Twitter timelines had generated more than how many views? | GT: 180.64 | Pred: print(\"180.64\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1031: Q: What percentage of people infected with the coronavirus were female? | GT: 51.1 | Pred: print(\"51.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1032: Q: What percentage of pet store revenue did shoppers between 45 and 64 account for in 2021? | GT: 45.2 | Pred: print(\"45.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1033: Q: What percentage of pet store revenue did 25-44-year-olds generate in 2021? | GT: 32.3 | Pred: print(\"32.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1034: Q: What percentage of all underlying attributable profit for Banco Santander is attributed to South America? | GT: 42 | Pred: print(\"42\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1035: Q: What percentage of Puma's sales were footwear in 2020? | GT: 45.2 | Pred: print(\"45.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1036: Q: How much did Puma's footwear sales exceed in 2018? | GT: 45.2 | Pred: print(\"45.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1037: Q: What percentage of L'Oral's global consolidated sales did skin care account for in 2020? | GT: 39.48 | Pred: print(\"39.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1038: Q: How much did marketing and sales directors earn per week? | GT: 1437.4 | Pred: print(\"1430.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1039: Q: How much did marketing and sales directors earn per week? | GT: 1437.4 | Pred: print(\"1430.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1040: Q: How much did marketing and sales directors earn per week? | GT: 1437.4 | Pred: print(\"1430.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1041: Q: What percentage of the world's total energy supply was nuclear energy in 2018? | GT: 4.9 | Pred: print(\"1.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1042: Q: What was the TIV of Australian arms exports to the United States in 2018? | GT: 30 | Pred: print(\"30\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1043: Q: What percentage of U.S. families had an annual income between 35,000 and 49,999 U.S. dollars? | GT: 10.5 | Pred: print(\"10.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1044: Q: What percentage of global non-renewable energy reserves did conventional natural gas account for in 2018? | GT: 17.8 | Pred: print(\"17.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1045: Q: How much did accounts with 1,000 to 10,000 followers increase their followers on average? | GT: 12.6 | Pred: print(\"15.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1046: Q: What percentage of global inbound tourism did business and professional travel account for in 2019? | GT: 11 | Pred: print(\"11\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1047: Q: What percentage of global clothing exports did China have in 2019? | GT: 30.8 | Pred: print(\"30.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1048: Q: How many Swiss francs did Roche spend on research and development in 2020? | GT: 13009 | Pred: print(\"13009\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1049: Q: How much revenue did General Motors generate in the 2020 fiscal year? | GT: 122.49 | Pred: print(\"122.49\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1050: Q: What was General Mills' global net sales in dollars in 2020? | GT: 17910 | Pred: print(\"17626.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1051: Q: How much was the government spending on health in 2020? | GT: 178 | Pred: print(\"178\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1052: Q: What was the global adoption rate for biotech soybean in 2019? | GT: 48.2 | Pred: print(\"48.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1053: Q: What was the value of reward-based crowdfunding deals in 2018? | GT: 175.4 | Pred: print(\"62.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1054: Q: What was the total transaction value of equity-based crowdfunding in the United States in 2018? | GT: 278.1 | Pred: print(\"62.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1055: Q: What was the value of the net non-performing assets of private banks in India in fiscal year 2020? | GT: 561.23 | Pred: print(\"561.23\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1056: Q: What was the market share of discretionary mandate assets in Europe at the end of 2018? | GT: 45.4 | Pred: print(\"33.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1057: Q: What was LVMH Group's global revenue share from the United States in 2020? | GT: 24 | Pred: print(\"24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1058: Q: What percentage of 18 to 29 year olds were internet users in the United States in 2021? | GT: 99 | Pred: print(\"99\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1059: Q: How much was Playmobil's revenue in 2004? | GT: 361 | Pred: print(\"359\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1060: Q: What percentage of all U.S. goods exports were agricultural products in 2018? | GT: 10.3 | Pred: print(\"10.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1061: Q: How many people applied for universal credit in the two weeks prior to March 31, 2020? | GT: 950000 | Pred: print(\"950000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1062: Q: How many people applied for universal credit in the two weeks leading up to January 9, 2020? | GT: 94015 | Pred: print(\"94015\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1063: Q: How many dollars were the gate receipts of the Chicago Bulls in the 2019/20 season? | GT: 65 | Pred: print(\"65\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1064: Q: What was Austria's average annual wage from 2000 to 2019? | GT: 44689 | Pred: print(\"44689\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1065: Q: What was Austria's average annual wage in 2010? | GT: 42295 | Pred: print(\"41806\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1066: Q: What percentage of Bed Bath & Beyond's global sales did home furnishings account for in fiscal year 2020? | GT: 65.3 | Pred: print(\"65\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1067: Q: How much venture capital did the biotechnology industry raise in 2020? | GT: 18100 | Pred: print(\"18100\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1068: Q: What was Hornbach's sales revenue in 2013? | GT: 2 | Pred: print(\"2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1069: Q: What was OBI's revenue in 2013? | GT: 1.7 | Pred: print(\"1.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1070: Q: What was the market share of non-alcoholic beer in Italy in 2019? | GT: 1.6 | Pred: print(\"1.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1071: Q: What was the initial estimate for Denmark's economy growth? | GT: 1.5 | Pred: print(\"1.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1072: Q: What was the growth rate for Europe? | GT: 0.8 | Pred: print(\"1.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1073: Q: What was the sales of imported beer in Ontario in dollars in 2020? | GT: 716.55 | Pred: print(\"716.55\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1074: Q: What percentage of the global microprocessor market did processor sales account for in the year to end June 2019? | GT: 38.6 | Pred: print(\"38.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1075: Q: What was WarnerMedia's revenue in the previous year? | GT: 7736 | Pred: print(\"2330\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1076: Q: What was the approval rating in July 2015? | GT: 38 | Pred: print(\"38\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1077: Q: What percentage of respondents were pleased with Theresa May's work as Prime Minister as of November 2016? | GT: 46 | Pred: print(\"38\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1078: Q: How much money did businesses with 1000+ employees generate in e-commerce sales in 2019? | GT: 196.2 | Pred: print(\"176.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1079: Q: What was Nigeria's male population in 2019? | GT: 101.83 | Pred: print(\"101.83\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1080: Q: What was Nigeria's female population in 2019? | GT: 99.13 | Pred: print(\"99.13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1081: Q: What was the share of SME companies with family management in Italy in 2018? | GT: 78.4 | Pred: print(\"75.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1082: Q: What percentage of SMEs in 2018 were completely controlled by family administration? | GT: 50 | Pred: print(\"56.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1083: Q: How much did the sales value of frozen fruit grow in 2020 compared to the same period of the previous year? | GT: 24 | Pred: print(\"24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1084: Q: How much did the sales of frozen vegetables grow by compared to the previous year? | GT: 19 | Pred: print(\"19\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1085: Q: How many men were in Greenland between 2021 and 2021? | GT: 15047 | Pred: print(\"15047\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1086: Q: How many women were in Greenland in 2021? | GT: 13394 | Pred: print(\"1383\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1087: Q: How many men lived in Greenland in 2021? | GT: 1501 | Pred: print(\"15047\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1088: Q: What percentage of female respondents said they were avid sports fans? | GT: 12 | Pred: print(\"12\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1089: Q: How many cancer cases were there among women in the U.S. in 2021? | GT: 927910 | Pred: print(\"927910\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1090: Q: What percentage of 18 to 29 year olds said they would cancel Netflix? | GT: 49 | Pred: print(\"40\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1091: Q: How many men were using Facebook in January 2018? | GT: 5.9 | Pred: print(\"0.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1092: Q: What percentage of Chinese women smoked tobacco products in 2016? | GT: 1.9 | Pred: print(\"1.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1093: Q: What percentage of respondents said they were now using this channel as a result of the coronavirus? | GT: 21 | Pred: print(\"19\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1094: Q: According to the source, global consumer dietary supplement sales in 2020 are expected to be around how many U.S. dollars? | GT: 62.1 | Pred: print(\"62.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1095: Q: What percentage of art buyers bought art online in the past 12 months? | GT: 67 | Pred: print(\"67\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1096: Q: What percentage of women aged between 40 and 64 were shown in what is described as'sexy attire'? | GT: 25.2 | Pred: print(\"25.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1097: Q: According to a study conducted in 2019, what percentage of 13 to 20 year old females in the top grossing films of 2018 were shown in what is | GT: 37.3 | Pred: print(\"37.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1098: Q: How many eSports enthusiasts are expected to be around by 2024? | GT: 285.7 | Pred: print(\"285.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1099: Q: How many people are forecast to be occasional viewers of eSports by 2024? | GT: 291.6 | Pred: print(\"291.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1100: Q: What percentage of the whole accident, health and medical insurance market was covered by the five leading companies as of end of 2014? | GT: 75.9 | Pred: print(\"77.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1101: Q: How much money are consumers expected to spend over the course of the Black Friday weekend in 2020? | GT: 7.5 | Pred: print(\"5.76\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1102: Q: How much of the Black Friday weekend will be spent online? | GT: 5.76 | Pred: print(\"5.76\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1103: Q: What percentage of students were offered a full-time job after completing an unpaid internship in the Government? | GT: 31 | Pred: print(\"31\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1104: Q: What was the direct value of the fashion industry measured at in 2014? | GT: 26 | Pred: print(\"26\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1105: Q: How much space did Amazon use in North America in 2012? | GT: 35.6 | Pred: print(\"35.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1106: Q: What was the total space of Amazon fulfillment centers in North America in 2016? | GT: 99.5 | Pred: print(\"99.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1107: Q: What was the prevalence of asthma in Spain in 2015? | GT: 1.58 | Pred: print(\"1.58\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1108: Q: What was the prevalence of asthma in the UK in 2015? | GT: 4.67 | Pred: print(\"4.67\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1109: Q: How many stores did Nordstrom operate as of January 30, 2021? | GT: 369 | Pred: print(\"369\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1110: Q: Who was the market leader in terms of mobile data traffic for the given time period? | GT: Telenor | Pred: print(\"Telenor\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1111: Q: What segment of the mobile data traffic in Serbia experienced a decrease in market share? | GT: VIP | Pred: print(\"Telekom Srbija\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1112: Q: What was Telenor's market share in 2012? | GT: 45.2 | Pred: print(\"45.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1113: Q: Which country is projected to have the highest projected median age by 2050? | GT: Republic of Korea | Pred: print(\"Republic of Korea\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1114: Q: What was the inflation rate in Curacao in 2018? | GT: 2.6 | Pred: print(\"2.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1115: Q: What was the second most common type of masjid in the UK in 2017? | GT: Barelvi | Pred: print(\"Baraka\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1116: Q: How many masjids were associated with Deobandi in 2017? | GT: 797 | Pred: print(\"797\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1117: Q: What was the only masjid in the United Kingdom associated with in 2017? | GT: Ibadi | Pred: print(\"Ibadi\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1118: Q: What was the percentage of employees that were members of a trade union in Scotland in 2018? | GT: 28.2 | Pred: print(\"28.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1119: Q: What was the total number of visitors to the Palace of Versailles in 2014? | GT: 7.7 | Pred: print(\"7.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1120: Q: What team had a brand value of 187 million dollars in 2012? | GT: Los Angeles Dodgers | Pred: print(\"Los Angeles Dodgers\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1121: Q: What was the brand value of the Los Angeles Dodgers in 2012? | GT: 187 | Pred: print(\"187\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1122: Q: What was the most followed Overwatch League team on Twitter as of February 2018? | GT: San Francisco Shock | Pred: print(\"San Francisco Shock\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1123: Q: How many followers did the Dallas Fuel team have? | GT: 78.2 | Pred: print(\"78.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1124: Q: When was the last time the leather and related products industry was in the UK? | GT: 2008 | Pred: print(\"2008\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1125: Q: What was the annual personnel cost of the leather and related products industry in 2016? | GT: 275.8 | Pred: print(\"275.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1126: Q: What was the value of commercial and industrial loans of FDIC-insured commercial banks in dollars in 2019? | GT: 2.16 | Pred: print(\"2.16\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1127: Q: How much revenue did Nutrien report in 2020? | GT: 20908 | Pred: print(\"20908\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1128: Q: What was the value of the currency component of M1 in dollars in 2018? | GT: 1522 | Pred: print(\"1522\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1129: Q: What is the estimated urea production capacity addition in the United States in 2017? | GT: 2.7 | Pred: print(\"2.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1130: Q: How much was Armani Junior's worldwide sales in 2008? | GT: 47.9 | Pred: print(\"53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1131: Q: How many dollars did Under Armour's apparel segment generate in the United States in 2020? | GT: 2882.56 | Pred: print(\"2882.56\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1132: Q: What was the average age of a person born in Chile in 2016? | GT: 79.5 | Pred: print(\"81.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1133: Q: What was the life expectancy of women in Chile in 2016? | GT: 81.9 | Pred: print(\"81.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1134: Q: How many of The Cheesecake Factory's employees were employed in its restaurants? | GT: 41000 | Pred: print(\"41781\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1135: Q: What percentage of the British adult population owns an eReader? | GT: 28 | Pred: print(\"23\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1136: Q: How many people have been tested for the coronavirus? | GT: 1334817 | Pred: print(\"1334817\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1137: Q: When did the Cold War end? | GT: 1991 | Pred: print(\"1989\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1138: Q: What percentage of the UK's GDP was spent on defense in 2018? | GT: 2.1 | Pred: print(\"1.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1139: Q: What percentage of the UK's GDP was spent on the military in 1984? | GT: 5.5 | Pred: print(\"5.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1140: Q: What was the average score for political parties in the United States in 2013? | GT: 4.1 | Pred: print(\"4.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1141: Q: How many home runs has Al Kaline hit? | GT: 399 | Pred: print(\"399\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1142: Q: How many international trips were made by air in Hungary in 2019? | GT: 2.56 | Pred: print(\"2.56\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1143: Q: How many international trips were made on land in 2019? | GT: 5.25 | Pred: print(\"5.25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1144: Q: What was Nexon's revenue in 2020? | GT: 293 | Pred: print(\"293\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1145: Q: What was Nexon's revenue in the previous year? | GT: 248.5 | Pred: print(\"248.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1146: Q: How much did the sales of cat treats amount to in 2010? | GT: 0.45 | Pred: print(\"0.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1147: Q: How many FTSE 100 companies had female executives in June 2019? | GT: 25 | Pred: print(\"25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1148: Q: What was the number of active subscribers for ALBtelecom in 2015? | GT: 648079 | Pred: print(\"648079\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1149: Q: How many students were registered in Switzerland in 2018/19? | GT: 313128 | Pred: print(\"315940\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1150: Q: What was the number of registered students in Switzerland in 2001/02? | GT: 160484 | Pred: print(\"163581\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1151: Q: How many pharmacists were there in Germany in 2000? | GT: 48058 | Pred: print(\"48103\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1152: Q: How many pharmacists were there in Germany in 2018? | GT: 54493 | Pred: print(\"44714\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1153: Q: How many people visit Kokkejaelvel every day? | GT: 27006 | Pred: print(\"27006\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1154: Q: In what year was there 36.7 million cable TV households in Central and Eastern Europe? | GT: 2011 | Pred: print(\"2011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1155: Q: How many cable TV households were in Central and Eastern Europe in 2011? | GT: 36.7 | Pred: print(\"36.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1156: Q: What was the most important import partner for Angola in 2019? | GT: China | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1157: Q: What was the most expensive vacation rental destination in the United States as of June 2014? | GT: Martha's Vineyard | Pred: print(\"Martha's Vineyard\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1158: Q: How much did private sector employment in Alberta grow in 2018? | GT: 1.4 | Pred: print(\"1.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1159: Q: How much did The Twilight Saga: New Moon gross in the U.S. in January 2018? | GT: 296.62 | Pred: print(\"296.62\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1160: Q: How many domestic vacations were taken in Great Britain in 2019? | GT: 60.45 | Pred: print(\"60.45\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1161: Q: What was Conair's market share for beard and mustache trimmers in 2008? | GT: 30 | Pred: print(\"30\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1162: Q: What was the Ministry of Justice's budget between 2010/11 and 2015/16? | GT: 9.03 | Pred: print(\"7.35\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1163: Q: What was the budget for the Ministry of Justice in 2018/19? | GT: 8.05 | Pred: print(\"8.05\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1164: Q: What was the budget for the Ministry of Justice in 2009/10? | GT: 9.03 | Pred: print(\"9.11\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1165: Q: Which sanitary napkin vendor had a sales growth of 0.7 percent in 2012? | GT: Procter & Gamble | Pred: print(\"Procter & Gamble\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1166: Q: What was the sales growth of Procter & Gamble in 2012? | GT: 0.7 | Pred: print(\"0.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1167: Q: What was the value of the personalized medicine market in dollars in 2015? | GT: 1260 | Pred: print(\"1260\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1168: Q: How many children were adopted in Norway in 2019? | GT: 332 | Pred: print(\"332\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1169: Q: How many children were adopted in Norway in 2009? | GT: 591 | Pred: print(\"591\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1170: Q: What percentage of all UAVs traded came from the UK between 2010 and 2014? | GT: 33.9 | Pred: print(\"33.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1171: Q: How many dollars did the U.S. home improvement industry generate from short-term online sales in 2013? | GT: 27 | Pred: print(\"27\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1172: Q: What percentage of the cloud infrastructure services market did Amazon hold in the first quarter of 2020? | GT: 32 | Pred: print(\"32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1173: Q: How many deaths were due to homicide in Andalusia in 2019? | GT: 61 | Pred: print(\"61\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1174: Q: Which autonomous community in Spain had the highest number of deaths due to homicide? | GT: Andalusia | Pred: print(\"Andalusia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1175: Q: How much did the U.S. export aerospace products worth in dollars in 2019? | GT: 137.73 | Pred: print(\"137.73\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1176: Q: By 2020, the distance traveled by passengers on the London Underground declined to what? | GT: 11.8 | Pred: print(\"11.8 billion kilometers\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1177: Q: What was the total distance traveled by passengers on the London Underground in 2018? | GT: 12.6 | Pred: print(\"12.16\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1178: Q: What percentage of Nigeria's GDP did the oil sector contribute in the first months of 2021? | GT: 9.25 | Pred: print(\"9.25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1179: Q: What percentage of Nigeria's GDP did the oil industry contribute between October and December 2020? | GT: 5.87 | Pred: print(\"8.93\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1180: Q: Where did most Polish emigrants move to in 2019? | GT: Ukraine | Pred: print(\"Ukraine\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1181: Q: How many Polish emigrants moved to Germany in 2019? | GT: 6677 | Pred: print(\"6677\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1182: Q: What country did most Polish emigrants move to in 2019? | GT: Germany | Pred: print(\"Ukraine\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1183: Q: What was LafargeHolcim Ltd's net sales in Swiss francs in the fiscal year of 2019? | GT: 26.72 | Pred: print(\"26.72\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1184: Q: What was the net sales of LafargeHolcim Ltd in dollars in the fiscal year of 2019? | GT: 27.47 | Pred: print(\"26.72\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1185: Q: What was the youth unemployment rate in Oman in 2020? | GT: 13.75 | Pred: print(\"13.75\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1186: Q: Which country had the highest number of cars owned by car sharing companies in 2014? | GT: Germany | Pred: print(\"Germany\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1187: Q: How many car sharing vehicles were in Spain in 2014? | GT: 300 | Pred: print(\"300\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1188: Q: What was the ratio of females to males in tertiary education in Vietnam in 2005? | GT: 0.71 | Pred: print(\"0.71\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1189: Q: What was the ratio of females to males in tertiary education in Vietnam in 2016? | GT: 1.24 | Pred: print(\"1.24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1190: Q: How many animal food manufacturing establishments were in Ontario as of December 2020? | GT: 129 | Pred: print(\"129\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1191: Q: In what year did the number of employees at Total increase? | GT: 2008 | Pred: print(\"2015\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1192: Q: How much did TUI AG spend on wages and salaries in 2020? | GT: 1871.6 | Pred: print(\"1871.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1193: Q: Which club sold the most expensive match-day ticket for the 2017/2018 season? | GT: Charlton | Pred: print(\"Charlton\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1194: Q: How many cubic meters of natural gas was produced in the Netherlands in 2019? | GT: 28.1 | Pred: print(\"28.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1195: Q: What was the Gini Index score in the United Kingdom in 2020? | GT: 36.3 | Pred: print(\"36.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1196: Q: As of March 2020, how many enterprises had a turnover of more than 5 million British pounds? | GT: 15 | Pred: print(\"5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1197: Q: How much money did Hillary Clinton receive as of November 2016? | GT: 316688599 | Pred: print(\"316688599\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1198: Q: What was the revenue of Uber in Latin America from July to September 2020? | GT: 320 | Pred: print(\"320\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1199: Q: How many dollars did retail sales of cannabis reach in Canada in December of 2020? | GT: 298.44 | Pred: print(\"298.44\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1200: Q: What was the revenue of the fitness market in Germany in 2014? | GT: 5510 | Pred: print(\"4700\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1201: Q: What was the inflation rate in Timor-Leste in 2019? | GT: 0.89 | Pred: print(\"0.89\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1202: Q: What percentage of cosmetic surgery procedures took place in Mexico in 2018? | GT: 4.5 | Pred: print(\"4.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1203: Q: What is the second most popular surname in Denmark? | GT: Jensen | Pred: print(\"Jensen\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1204: Q: What was the most common surname in Denmark as of January 2021? | GT: Nielsen | Pred: print(\"Nielsen\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1205: Q: How many hours were watched on Twitch in May 2021? | GT: 91.9 | Pred: print(\"91.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1206: Q: What was the value of the pizza delivery market in the UK at the end of 2017? | GT: 6.2 | Pred: print(\"2.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1207: Q: What was the estimated value of the UK pizza delivery market at the end of 2017? | GT: 2.1 | Pred: print(\"2.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1208: Q: What was the most common passenger car in the UK at the end of 2018? | GT: Ford Fiesta | Pred: print(\"Ford Fiesta\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1209: Q: What country was the greatest enemy of the United States in 2001? | GT: Iraq | Pred: print(\"Iran\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1210: Q: Who was the most valuable player at the 2018 FIFA World Cup? | GT: Sergej Milinkovic-Savic | Pred: print(\"Sergej Milkkovic-Savic\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1211: Q: What was the market value of Sergej Milinkovic-Savic? | GT: 90 | Pred: print(\"90\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1212: Q: What was the penetration rate for the insurance sector in Spain in 2017? | GT: 5.45 | Pred: print(\"5.45\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1213: Q: What was the highest penetration rate for the insurance sector in Spain in 2016? | GT: 5.22 | Pred: print(\"5.71\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1214: Q: What was the value of the U.S. vision care market in dollars in 2019? | GT: 37466 | Pred: print(\"37466\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1215: Q: Since when has the plant load factor of all power stations in the UK fluctuated? | GT: 2010 | Pred: print(\"2010\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1216: Q: What was the PLF of all power stations in the UK in 2019? | GT: 35.4 | Pred: print(\"35.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1217: Q: How many passengers used metro systems in the Asia-Pacific region in 2017? | GT: 26.69 | Pred: print(\"21.92\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1218: Q: What percentage of people in the UK planned to spend 5-10 pounds on a Halloween costume? | GT: 21.9 | Pred: print(\"21.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1219: Q: How much revenue did Angry Birds generate in the most recent fiscal year? | GT: 272.3 | Pred: print(\"272.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1220: Q: How many early voting votes were cast in Florida? | GT: 5208155 | Pred: print(\"4684595\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1221: Q: What is the percentage of jobs that Northern Ireland and the South West region are expected to lose? | GT: 1.2 | Pred: print(\"1.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1222: Q: What is the name of the French shipping company with the largest chartered fleet? | GT: Mediterranean Shg Co | Pred: print(\"Mediterranean Shg Co\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1223: Q: Which company had the largest chartered fleet of container ships in 2021? | GT: CMA CGM Group | Pred: print(\"Mediterranean Shg Co\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1224: Q: What was Algeria's GDP in dollars in 2020? | GT: 144.29 | Pred: print(\"144.29\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1225: Q: What was the global net sales of Tapestry Incorporated in 2020? | GT: 4961.4 | Pred: print(\"4961.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1226: Q: What was the number of Instagram users in South Africa in April 2020? | GT: 4.31 | Pred: print(\"5.79\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1227: Q: How many Instagram users were there in South Africa as of April 2021? | GT: 5.79 | Pred: print(\"5.79\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1228: Q: What was the infant mortality rate in Bahrain in 2019? | GT: 5.9 | Pred: print(\"5.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1229: Q: How much revenue did Whistles generate between 2016 and 2017? | GT: 68.5 | Pred: print(\"68.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1230: Q: What was the turnover of Whistles in pounds in the last decade? | GT: 73.4 | Pred: print(\"73.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1231: Q: What was Whistles turnover in 2016? | GT: 33 | Pred: print(\"58.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1232: Q: How much money was generated by sports equipment retailing in Austria in 2015? | GT: 1841.1 | Pred: print(\"1841.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1233: Q: How many hate crimes were classified as incite to violence? | GT: 310 | Pred: print(\"310\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1234: Q: What was Bolivia's spending on health a year earlier? | GT: 6.49 | Pred: print(\"6.49\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1235: Q: What percentage of Bolivia's GDP was spent on health in 2018? | GT: 6.3 | Pred: print(\"6.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1236: Q: How many people died in the American Civil War? | GT: 620000 | Pred: print(\"620000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1237: Q: What is Sweden's size? | GT: 447430 | Pred: print(\"447430\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1238: Q: What is Norway's surface area? | GT: 625217 | Pred: print(\"625217\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1239: Q: What is the surface area of Denmark? | GT: 42920 | Pred: print(\"42920\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1240: Q: What is Iceland's surface area? | GT: 103000 | Pred: print(\"103000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1241: Q: What was the infant mortality rate in Malawi in 2019? | GT: 30.9 | Pred: print(\"30.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1242: Q: In what year did customers spend an estimated 72.3 billion U.S. dollars on in-app purchases, subscriptions, and premium apps? | GT: 2020 | Pred: print(\"2020\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1243: Q: How much money did customers spend in the Apple App Store in 2020? | GT: 72.3 | Pred: print(\"72.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1244: Q: In what year did the Sun have the highest reach among selected UK newspapers? | GT: 2013 | Pred: print(\"2005\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1245: Q: What was the revenue of the Arizona Cardinals in 2019? | GT: 422 | Pred: print(\"422\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1246: Q: What percentage of visitors from Sweden and Poland were female? | GT: 35 | Pred: print(\"35\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1247: Q: How much did Yahoo pay for Tumblr? | GT: 1100 | Pred: print(\"1100\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1248: Q: How much money did the Olympic Games in Rio contribute to the IFs in 2016? | GT: 540 | Pred: print(\"540\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1249: Q: How much were the gate receipts of the St. Louis Cardinals in 2019? | GT: 138 | Pred: print(\"138\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1250: Q: How many people will live in the administrative area of Shanghai municipality in 2035? | GT: 24.86 | Pred: print(\"34.34\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1251: Q: What was the value of imports in U.S. dollars in 2020? | GT: 2808.95 | Pred: print(\"2808.95\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1252: Q: What was the value of U.S. international exports in dollars in 2020? | GT: 2127.25 | Pred: print(\"2127.25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1253: Q: How much freight was transported in Russia between 2006 and 2019? | GT: 4300741 | Pred: print(\"4253573\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1254: Q: What percentage of Malaysians said they had been stocking up eggs during the COVID-19 outbreak? | GT: 83 | Pred: print(\"83\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1255: Q: What was the market share of supermarkets in Italy in 20120? | GT: 29.3 | Pred: print(\"29.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1256: Q: What market share accounted for 29.3 percent of Italy's total domestic consumption in 20120? | GT: Supermarkets | Pred: print(\"Supermarkets\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1257: Q: How many cases of racist incidents were recorded in 2019/20? | GT: 76070 | Pred: print(\"76070\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1258: Q: How many cases of racist incidents were recorded in 2018/19? | GT: 75479 | Pred: print(\"75479\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1259: Q: What percentage of Spain's exports came from France in 2019? | GT: 15 | Pred: print(\"15\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1260: Q: Which country was Spain's most important export partner in 2019? | GT: France | Pred: print(\"France\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1261: Q: What was the lowest rate of living in Nuevo Le3n? | GT: 3.1 | Pred: print(\"3.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1262: Q: What was the net sales of adidas Group in 2020? | GT: 19844 | Pred: print(\"19844\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1263: Q: What was the infant mortality rate in Lesotho in 2019? | GT: 68.1 | Pred: print(\"68.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1264: Q: Who is the career assists leader of the Houston Rockets? | GT: James Harden | Pred: print(\"James Harden\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1265: Q: What country is the largest importer of the Russian car brand? | GT: Latvia | Pred: print(\"Latvia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1266: Q: How many cars were exported to Lithuania in 2018? | GT: 132 | Pred: print(\"132\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1267: Q: What country is the largest importer of the Russian car brand? | GT: Latvia | Pred: print(\"Latvia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1268: Q: Which country ranked second in the importation of LADA cars in 2018? | GT: Slovakia | Pred: print(\"Slovakia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1269: Q: How many LADA passenger cars were exported from Russia to Latvia in 2018? | GT: 3213 | Pred: print(\"3213\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1270: Q: What percentage of German consumers favored traditional retail trade when it came to grocery shopping? | GT: 93.2 | Pred: print(\"93.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1271: Q: In what year did pirate attacks increase against ships worldwide? | GT: 2020 | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1272: Q: How many ships were attacked by pirates in 2019? | GT: 162 | Pred: print(\"162\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1273: Q: How many ships were attacked by pirates in 2020? | GT: 195 | Pred: print(\"195\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1274: Q: What was Oceania's population density per square kilometer in 2018? | GT: 4.9 | Pred: print(\"4.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1275: Q: What was the most densely populated region of the world in 2018? | GT: Asia | Pred: print(\"Asia\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1276: Q: What was the average daily rate of hotels in Berlin in dollars in the first quarter of 2017? | GT: 129 | Pred: print(\"129\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1277: Q: What was the average price of one barrel of Brent Crude oil in May 2021? | GT: 68.53 | Pred: print(\"68.53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1278: Q: What was the FMCG brand with the highest penetration rate in the UK in 2020? | GT: Heinz | Pred: print(\"Heinz\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1279: Q: What was the infant mortality rate in Argentina in 2019? | GT: 8.2 | Pred: print(\"8.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1280: Q: What was the revenue for the chemical industry in the second quarter of 2020? | GT: 7443160 | Pred: print(\"7468000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1281: Q: What was the revenue for the chemical industry in the second quarter of 2015? | GT: 9392733 | Pred: print(\"9271600\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1282: Q: What was the number of defendants charged in 2017? | GT: 412 | Pred: print(\"412\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1283: Q: What was the number of defendants charged in 2013? | GT: 89 | Pred: print(\"89\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1284: Q: How many days of rainfall did Paris have in January? | GT: 11 | Pred: print(\"11\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1285: Q: Who emerged as the leading advisor to M&A deals in Norway in 2016? | GT: PwC | Pred: print(\"PwC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1286: Q: How many deals did PwC have in 2016? | GT: 20 | Pred: print(\"20\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1287: Q: Who is the career points leader of the Dallas Mavericks? | GT: Dirk Nowitzki | Pred: print(\"Dirk Nowitzki\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1288: Q: What was Nexon's operating income in the previous quarter? | GT: 4.52 | Pred: print(\"54.73\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1289: Q: What was Nexon's operating income in the fourth quarter of 2020? | GT: 15.59 | Pred: print(\"43.32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1290: Q: How much did hand sanitizer sales grow in the week ending March 14, 2020? | GT: 735 | Pred: print(\"735\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1291: Q: What ethnicity were 23.6 percent of Groupon leadership employees? | GT: Asian | Pred: print(\"Asian\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1292: Q: What is the third largest city on this list? | GT: Seville | Pred: print(sorted([80, 70, 60, 60, 50, 50, 40, 40, 35, 35, 33, 31, 30, 30, 30, 30, 30, 30, 30, 28, 27, 27, 27, 26, 25, 25])[-3])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1293: Q: What was the total number of bank branches in Italy in 2020? | GT: 23481 | Pred: print(\"23481\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1294: Q: What was the total number of bank branches in Italy in 2011? | GT: 33607 | Pred: print(\"33607\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1295: Q: What public issuer had about 9.4 million viewers in the considered time range? | GT: Rai | Pred: print(\"Rai\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1296: Q: How many viewers did Sky have in the prime time slot? | GT: 1800153 | Pred: print(\"1800153\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1297: Q: How many spectators did Flamengo have per game in 2019? | GT: 55191 | Pred: print(\"55191\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1298: Q: What was the number of pharmacists employed in the health sector in Belgium in 2018? | GT: 14280 | Pred: print(\"14030\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1299: Q: What was the worldwide revenue of Canada Goose in the 2020 financial year? | GT: 958.1 | Pred: print(\"186.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1300: Q: How much of Canada Goose's revenue was generated in the United States? | GT: 279 | Pred: print(\"279\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1301: Q: How much was Svenska Spel AB's turnover in Swedish kronor in February 2021? | GT: 8579 | Pred: print(\"8579\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1302: Q: What was Rederi AB Gotland's turnover in February 2021? | GT: 2509 | Pred: print(\"2509\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1303: Q: How many companies did Google acquire in 2014? | GT: 36 | Pred: print(\"36\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1304: Q: What was Germany's total value of paints in dollars in 2019? | GT: 3700 | Pred: print(\"3700\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1305: Q: What was the most popular social media platform in Germany as of the 3rd quarter of 2020? | GT: WhatsApp | Pred: print(\"WhatsApp\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1306: Q: What percentage of internet-users said they used WhatsApp in the 3rd quarter of 2020? | GT: 87 | Pred: print(\"87\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1307: Q: What was the least used social media platform in Germany? | GT: Tumblr | Pred: print(\"Tumblr\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1308: Q: How many upper secondary general schools were there in Finland in 2020? | GT: 335 | Pred: print(\"335\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1309: Q: How many universities were there in Finland in 2020? | GT: 13 | Pred: print(\"13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1310: Q: What was the average annual total income per household of those in the top decile group? | GT: 186600 | Pred: print(\"186160\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1311: Q: What was the group share of net income for Thales in 2005? | GT: 334 | Pred: print(\"334\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1312: Q: How much did Dollar General's seasonal products sales amount to in dollars in 2020? | GT: 4083.65 | Pred: print(\"2215.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1313: Q: How much money did the apparel segment of Dollar General generate in 2020? | GT: 1506.1 | Pred: print(\"2.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1314: Q: Which country was Pakistan's most important import partner in 2019? | GT: China | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1315: Q: What year was the value of blockchain in the agriculture and food market? | GT: 2017 | Pred: print(\"2017\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1316: Q: What was the global market value of blockchain in the food and agriculture market in 2017? | GT: 32.2 | Pred: print(\"32.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1317: Q: How many homicides were reported in Denmark in 2020? | GT: 49 | Pred: print(\"49\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1318: Q: How many international stores did Skechers have in 2019? | GT: 199 | Pred: print(\"199\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1319: Q: How many mobile subscribers does Indonesia have? | GT: 171 | Pred: print(\"171\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1320: Q: What was the average ticket price for Dallas Stars games in 2005/06? | GT: 36.36 | Pred: print(\"36.36\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1321: Q: How much revenue did Vodafone Germany generate in the financial year 2020/21? | GT: 11.52 | Pred: print(\"11.52\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1322: Q: Since what year has the homicide rate in Venezuaela been increasing? | GT: 2017 | Pred: print(\"2016\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1323: Q: What was the homicide rate in 2017? | GT: 81.4 | Pred: print(\"89\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1324: Q: How many Democratic senators make up the 116th Congress? | GT: 45 | Pred: print(\"2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1325: Q: How many Republican senators are in the 116th Congress? | GT: 53 | Pred: print(\"2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1326: Q: What website had about 423.43 million mobile visits in September 2019? | GT: ebay Kleinanzeigen | Pred: print(\"ebay Kleinanzeigen\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1327: Q: How many mobile visits did ebay Kleinanzeigen have in September 2019? | GT: 423.43 | Pred: print(\"423.43\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1328: Q: What was the leading lobbying firm in the United States in 2020? | GT: Akin, Gump et al | Pred: print(\"Akin, Gump et al\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1329: Q: How much money did Brownsteing, Hyatt spend in 2020? | GT: 48.37 | Pred: print(\"48.37\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1330: Q: How much was Akin, Gump et al's expenses in 2020? | GT: 49.87 | Pred: print(\"49.87\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1331: Q: Which country was the leading global exporter of avocados in 2019? | GT: Mexico | Pred: print(\"Mexico\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1332: Q: What was Mexico's export value in dollars in 2019? | GT: 2789.67 | Pred: print(\"2789.67\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1333: Q: Which country has the largest bismuth reserves? | GT: China | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1334: Q: What was Europe's total FDI inflows in 2012? | GT: 293.5 | Pred: print(\"293.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1335: Q: What was the revenue of LVMH's perfumes and cosmetics segment in 2020? | GT: 5248 | Pred: print(\"5248\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1336: Q: What was the population of Papua New Guinea in 2020? | GT: 8.78 | Pred: print(\"8.78\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1337: Q: How many sound recording studios were in Nashville in 2016? | GT: 74 | Pred: print(\"75\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1338: Q: What is the name of the mobile eSports platform? | GT: Skillz | Pred: print(\"Discord\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1339: Q: What is the projected expenditure on food in the Ukraine in 2016? | GT: 20327.7 | Pred: print(\"20327.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1340: Q: How many Carrabba's Italian Grill restaurants were there in 2020? | GT: 220 | Pred: print(\"25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1341: Q: What was the name of the most number of restaurants owned by Bloomin' Brands, Inc. in 2020? | GT: Outback Steakhouse | Pred: print(\"Outback Steakhouse\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1342: Q: What is North America's CAGR from 2017 to 2022? | GT: 36 | Pred: print(\"36\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1343: Q: What was the value of U.S. exports to Mexico in 2020? | GT: 212.67 | Pred: print(\"312.67\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1344: Q: What was Maxis Bhd's mobile revenue in 2015? | GT: 8246 | Pred: print(\"8177\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1345: Q: What was Maxis Bhd's mobile revenue forecast to be valued at in 2019? | GT: 8362 | Pred: print(\"8362\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1346: Q: What was the value of the lottery in 1982? | GT: 1.69 | Pred: print(\"0.77\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1347: Q: How much money did state and local governments collect in 2019? | GT: 28.86 | Pred: print(\"28.86\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1348: Q: What is the expected CAGR of food intolerance for the period 2011-2015? | GT: 10 | Pred: print(\"10\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1349: Q: How much did travel and tourism contribute to the Greek economy in 2017? | GT: 14 | Pred: print(\"14\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1350: Q: What was the total value of merger and acquisition deals in the minerals and mining sector in 2018? | GT: 77.8 | Pred: print(\"77.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1351: Q: Which car took the first place in terms of road handling quality? | GT: Porsche | Pred: print(\"Porsche\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1352: Q: What was the first language spoken by 288 thousand people in Finland? | GT: Swedish | Pred: print(\"Swedish\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1353: Q: How many people in Finland speak Finnish? | GT: 4811.1 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1354: Q: How many people spoke other languages in Finland in 2020? | GT: 432.85 | Pred: print(\"415\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1355: Q: How much offshore gas is expected to be produced in the U.S. in 2050? | GT: 1.56 | Pred: print(\"1.56\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1356: Q: When is the projection of the total number of people enrolled in health insurance exchanges? | GT: 2025 | Pred: print(\"2025\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1357: Q: How many people are expected to enroll in health insurance exchanges by 2018? | GT: 25 | Pred: print(\"25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1358: Q: How much value did the mining industry add to Minnesota's GDP in 2012? | GT: 4.06 | Pred: print(\"4.06\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1359: Q: What was Nokia's net sales in 2020? | GT: 21.87 | Pred: print(\"21.87\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1360: Q: What is the biggest city in Canada? | GT: Toronto | Pred: print(\"Toronto\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1361: Q: How many people lived in Toronto in 2014? | GT: 6.06 | Pred: print(\"6.06\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1362: Q: How many Bloomingdale's outlets were there in 2020? | GT: 19 | Pred: print(\"19\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1363: Q: How many Bloomingdale's stores did Macy's have in 2020? | GT: 35 | Pred: print(\"19\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1364: Q: What was online sales growth in the last quarter of 2013? | GT: 23.5 | Pred: print(\"23.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1365: Q: How much did the national media take in the 2013/14 season? | GT: 560 | Pred: print(\"560\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1366: Q: What was the share of six-year-olds using social media in Sweden in 2018? | GT: 89 | Pred: print(\"83\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1367: Q: What was the share of Swedish social media users in the third quarter of 2020? | GT: 89 | Pred: print(\"89\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1368: Q: What was the estimated total revenue of integrated production and distribution companies in 2019? | GT: 8.47 | Pred: print(\"8.47\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1369: Q: What was the value of petroleum revenue tax in 2008/09? | GT: 2567 | Pred: print(\"2567\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1370: Q: What was the fertility rate in Senegal in 2018? | GT: 4.63 | Pred: print(\"4.63\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1371: Q: What percentage of the global animal health market volume did companion animals generate in 2018? | GT: 38 | Pred: print(\"38\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1372: Q: What was Nebraska's unemployment rate in 2020? | GT: 4.2 | Pred: print(\"4.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1373: Q: Which online shoe and clothing shop provided the simplest experiences and communications among all tested brands? | GT: Google | Pred: print(\"Google\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1374: Q: How much money did corporations make in the fourth quarter of 2020? | GT: 2294.3 | Pred: print(\"2262.28\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1375: Q: What was the market share of fresh fruit juice in 2018? | GT: 36.2 | Pred: print(\"36.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1376: Q: What was the share of diesel car sales in Italy in 2019? | GT: 56 | Pred: print(\"41\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1377: Q: What was Ireland's share of diesel car sales in 2015? | GT: 46 | Pred: print(\"71\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1378: Q: Which country is the healthiest? | GT: Spain | Pred: print(\"Spain\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1379: Q: What is Spain's health grade? | GT: 92.75 | Pred: print(\"92.75\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1380: Q: What was the global production volume of dates in 2019? | GT: 9.07 | Pred: print(\"9.07\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1381: Q: What was the production volume of dates in 2017? | GT: 8.4 | Pred: print(\"8.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1382: Q: What country had the highest gender pay gap among the countries surveyed? | GT: Brazil | Pred: print(\"Brazil\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1383: Q: What was Whirlpool's index score? | GT: 114.2 | Pred: print(\"114.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1384: Q: What percentage of PV inverter market shipments did Huawei account for in 2018? | GT: 22 | Pred: print(\"22\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1385: Q: When was Kawasaki HI's fiscal year of research and development? | GT: 2004 | Pred: print(\"2004\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1386: Q: How much Japanese yen did Kawasaki incur in research and development expenses in the fiscal year of 2013? | GT: 40.3 | Pred: print(\"40.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1387: Q: What company had a 21.2 percent share of the Indonesian mobile phone market in the first quarter of 2015? | GT: Samsung | Pred: print(\"Samsung\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1388: Q: How many new stores did Coffee Republic open in 2016? | GT: 123 | Pred: print(\"123\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1389: Q: What was the previous year's value of Hugo Boss' EBITDA? | GT: 707 | Pred: print(\"707\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1390: Q: What was Hugo Boss' EBITDA in 2020? | GT: 230 | Pred: print(\"230\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1391: Q: What Asian nation had the largest amount of travel and tourism industry employees in 2019? | GT: India | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1392: Q: How many people worked in China's travel and tourism industry in 2019? | GT: 29089 | Pred: print(\"29089\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1393: Q: Which European country took the highest place in the ranking? | GT: Germany | Pred: print(\"United Kingdom\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1394: Q: What percentage of Medicare beneficiaries had cancer in 2014? | GT: 13 | Pred: print(\"13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1395: Q: What was the leading country in passenger car production in 2020? | GT: China | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1396: Q: How many passenger car units were produced in China in 2020? | GT: 21.39 | Pred: print(\"21.39\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1397: Q: How many cars were produced in Japan in 2020? | GT: 8.33 | Pred: print(\"8.33\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1398: Q: How many cases of COVID-19 were there in the United Arab Emirates as of November 4, 2020? | GT: 137310 | Pred: print(\"137310\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1399: Q: What was the birth rate in Italy in 2019? | GT: 417614 | Pred: print(\"420543\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1400: Q: How many births were registered in Italy in 2010? | GT: 549794 | Pred: print(\"554981\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1401: Q: How much money did nonprofit organizations report to the IRS in 2016? | GT: 2.62 | Pred: print(\"2.62\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1402: Q: Which state produced the most sunflower seeds in South Africa in 2019 and 2020? | GT: Free State | Pred: print(\"Free State\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1403: Q: What was the domestic passenger load factor in Russia in September 2016? | GT: 82.1 | Pred: print(\"82.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1404: Q: What was the value of gross non-performing assets at Kotak Mahindra Bank in Indian rupees in fiscal year 2020? | GT: 54.88 | Pred: print(\"54.88\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1405: Q: What was the value of non-performing assets filed by Kotak Mahindra Bank in the previous fiscal year? | GT: 47.89 | Pred: print(\"38.25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1406: Q: How much revenue did Napster generate in 2019? | GT: 106.3 | Pred: print(\"106.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1407: Q: What is Google's market share in India? | GT: 95.45 | Pred: print(\"95.45\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1408: Q: How many hospital beds did Japan have per 10,000 inhabitants in 2012? | GT: 137 | Pred: print(\"137\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1409: Q: What was the average selling price of a smartphone in Pakistan in 2016? | GT: 121 | Pred: print(\"121\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1410: Q: What was the highest grossing film in the UK in January of 2020? | GT: Star Wars: Episode IX - The Rise of Skywalker | Pred: print(\"Star Wars: Episode IX - The Rise of Skywalker\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1411: Q: What was the highest grossing film in January of 2020? | GT: 1917 | Pred: print(\"Star Wars: Episode IX - The Rise of Skywalker\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1412: Q: What security company grew by 1,194 percent between 2016 and 2019? | GT: Exabeam | Pred: print(\"KnowBe4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1413: Q: What is the second largest investment firm in the world? | GT: State Street | Pred: print(\"State Street\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1414: Q: What is the largest asset manager headquartered in the UK? | GT: Legal & General | Pred: print(\"BlackRock\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1415: Q: What was the leading investment firm in the UK in 2019? | GT: BlackRock | Pred: print(\"BlackRock\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1416: Q: What was Finland's retail trade index point in 2012? | GT: 107.2 | Pred: print(\"107.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1417: Q: What year did Finland's sales volume decline? | GT: 2018 | Pred: print(\"2012\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1418: Q: What was Finland's annual trade index as of 2019? | GT: 98.8 | Pred: print(\"98.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1419: Q: What was Jumia's gross merchandise volume in the previous quarter? | GT: 187.3 | Pred: print(\"292.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1420: Q: How much did Jumia generate in gross merchandise volume in the last quarter of 2020? | GT: 231.1 | Pred: print(\"231.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1421: Q: What was the Gini coefficient of the Dominican Republic in 2015? | GT: 47.1 | Pred: print(\"47.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1422: Q: What was the net revenue of Electronic Arts in the second quarter of 2021? | GT: 1346 | Pred: print(\"1346\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1423: Q: How many dollars does Guatemala spend each year? | GT: 3.73 | Pred: print(\"4.02\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1424: Q: What was the average daily rate of hotels in San Francisco in the United States in the first quarter of 2017? | GT: 338 | Pred: print(\"338\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1425: Q: What was China's export value in dollars in 2018? | GT: 26588 | Pred: print(\"26588\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1426: Q: Which country was the second largest exporter of construction in 2018? | GT: China | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1427: Q: What percentage of Malaysia's GDP was non-financial corporate debt in 2017? | GT: 105.4 | Pred: print(\"98.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1428: Q: What percentage of Italians believed Facebook to be responsible for spreading false or inaccurate information regarding the coronavirus? | GT: 79 | Pred: print(\"79\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1429: Q: In what year did the percentage of adult internet users in the United States begin to increase? | GT: 2000 | Pred: print(\"2000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1430: Q: Watches and jewelry had a share of what percentage of the global luxury goods market in 2007? | GT: 16.2 | Pred: print(\"16\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1431: Q: Watches and jewelry had a share of what percentage in the global luxury goods market in 2007? | GT: 18.2 | Pred: print(16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1432: Q: What was the revenue in the technical consumer goods market by the end of Q1 2020? | GT: 13.86 | Pred: print(\"13.86\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1433: Q: What was the highest grossing movie of 2017? | GT: Star Wars: The Last Jedi | Pred: print(\"Star Wars: The Last Jedi\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1434: Q: What was the domestic box office revenue of Star Wars: The Last Jedi? | GT: 620.18 | Pred: print(\"620.18\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1435: Q: What was the net sales of Brunswick Corporation in 2019? | GT: 4347.5 | Pred: print(\"4115\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1436: Q: What was the previous year's sales of Brunswick Corporation? | GT: 4108.4 | Pred: print(\"4101\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1437: Q: How many Abercrombie & Fitch stores were open worldwide in 2020? | GT: 735 | Pred: print(\"735\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1438: Q: What percentage of their weekly household expenditure did households in the eight decile group spend on medical products? | GT: 0.7 | Pred: print(\"0.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1439: Q: What was the youth unemployment rate in Bolivia in 2019? | GT: 6.7 | Pred: print(\"6.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1440: Q: What was the PLF of nuclear stations in 2019? | GT: 62.9 | Pred: print(\"62.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1441: Q: When did the plant load factor of nuclear stations in the UK begin to fluctuate? | GT: 2010 | Pred: print(\"2010\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1442: Q: What was the revenue of News Corp. in 2017? | GT: 8139 | Pred: print(\"8139\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1443: Q: What was Trinidad & Tobago's internal tourism consumption in dollars in 2019? | GT: 1.91 | Pred: print(\"1.91\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1444: Q: What was the total attendance during the 2019/2020 season? | GT: 3.45 | Pred: print(\"3.45\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1445: Q: In what year did Argos start making multichannel retail sales? | GT: 2009 | Pred: print(\"2009\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1446: Q: What year did Southwest Airlines' net income end? | GT: 2020 | Pred: print(\"2020\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1447: Q: What year was Southwest Airlines Co.'s last fiscal year? | GT: 2010 | Pred: print(\"2010\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1448: Q: What company had the highest percentage of smartphone device visits? | GT: Telco | Pred: print(\"Telko\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1449: Q: Who is the career points leader of the Minnesota Timberwolves? | GT: Kevin Garnett | Pred: print(\"Kevin Garnett\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1450: Q: What was the crude birth rate in North Korea in 2018? | GT: 13.89 | Pred: print(\"13.89\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1451: Q: What percentage of total mobile service revenue did mobile data account for in the UK in 2015? | GT: 27.6 | Pred: print(\"27.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1452: Q: How many new movies were released in 2003? | GT: 528 | Pred: print(\"528\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1453: Q: What was the unemployment rate in 1990? | GT: 5.6 | Pred: print(\"5.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1454: Q: What was the unemployment rate in 2020? | GT: 8.1 | Pred: print(\"8.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1455: Q: What was Malaysia's most important export partner in 2019? | GT: Singapore | Pred: print(\"Singapore\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1456: Q: What percentage of Malaysia's exports came from Singapore in 2019? | GT: 13 | Pred: print(\"13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1457: Q: In what year did Vanuatu's real GDP grow by 2.9 percent? | GT: 2016 | Pred: print(\"2018\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1458: Q: What percentage did Vanuatu's real GDP grow by in 2018? | GT: 2.9 | Pred: print(\"2.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1459: Q: What was the abandonment rate in the fourth quarter of 2015? | GT: 75.6 | Pred: print(\"75.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1460: Q: What was the abandonment rate in the previous quarter? | GT: 77.3 | Pred: print(\"75\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1461: Q: How many more people came to Ontario from other provinces than left Ontario between July 1, 2019 and June 30, 2020? | GT: 363 | Pred: print(\"658\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1462: Q: What was the average wage in 2019 in Italy? | GT: 30028 | Pred: print(\"29720\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1463: Q: What was the increase in foot traffic in Costco stores in week 11 of 2020? | GT: 36.71 | Pred: print(\"36.71\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1464: Q: What was the total number of M&A deals in Croatia in 2020? | GT: 43 | Pred: print(\"43\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1465: Q: What was the population of Malawi in 2016? | GT: 18.63 | Pred: print(\"18.63\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1466: Q: How much were the gate receipts of the Minnesota Twins in 2019? | GT: 79 | Pred: print(\"79\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1467: Q: What was the turnover of clothing stores in 2019? | GT: 41140 | Pred: print(\"41140\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1468: Q: In what province were there two roasted nut and peanut butter manufacturing establishments? | GT: British Columbia | Pred: print(\"Alberta\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1469: Q: How many roasted nut and peanut butter manufacturing establishments were there in Ontario as of December 2020? | GT: 11 | Pred: print(\"11\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1470: Q: In what year is the Middle East expected to become an LNG consumer? | GT: 2021 | Pred: print(\"2022\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1471: Q: How many metric tons of LNG is driven by markets in Asia Pacific? | GT: 326 | Pred: print(\"329.12\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1472: Q: How much did Canada's ICT sector's GDP contribution grow by in 2019? | GT: 4.9 | Pred: print(\"1.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1473: Q: What company publishes hundreds of audiobooks per year? | GT: Hachette Book Group | Pred: print(\"Penguin Random House\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1474: Q: What publisher publishes 70 thousand digital books each year? | GT: Penguin Random House | Pred: print(\"Simon & Schuster\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1475: Q: What year was Bridgestone's fiscal year for research and development? | GT: 2009 | Pred: print(\"2009\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1476: Q: How many Japanese yen did Bridgestone spend on research and development in 2018? | GT: 103551 | Pred: print(\"103551\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1477: Q: Who has the most hits in Detroit Tigers franchise history? | GT: Ty Cobb | Pred: print(\"Ty Cobb\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1478: Q: Which country came in second in fish and fishery exports? | GT: China | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1479: Q: What was the export value of the European Union's fish and fishery products in US dollars in 2019? | GT: 36.2 | Pred: print(\"36.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1480: Q: What season was the Buffalo Sabres franchise in? | GT: 2005/06 | Pred: print(\"2005/06\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1481: Q: What was Missouri's GDP in 2020? | GT: 277.35 | Pred: print(\"273.35\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1482: Q: What was Missouri's GDP in dollars in 2018? | GT: 287.66 | Pred: print(\"284.74\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1483: Q: What was Iowa's highest unemployment rate in 2009? | GT: 6.4 | Pred: print(\"6.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1484: Q: What was Iowa's unemployment rate in 2020? | GT: 5.3 | Pred: print(\"5.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1485: Q: What was Iowa's unemployment rate in 2009? | GT: 2.8 | Pred: print(\"2.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1486: Q: What was Google's ranking out of 100 ACSI index points in 2020? | GT: 79 | Pred: print(\"79\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1487: Q: What was the average R&D expenditure for all manufacturing industries between 2003 and 2017? | GT: 14933 | Pred: print(\"14933\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1488: Q: What percentage of COVID-19 cases were in the U.S. as of June 28, 2021? | GT: 18.97 | Pred: print(\"18.97\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1489: Q: How much did Slovakia's domestic banks' assets amount to in 2016? | GT: 12 | Pred: print(\"11.81\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1490: Q: What was the population density of Missouri in 2018? | GT: 89.1 | Pred: print(\"89.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1491: Q: What was the net income of Z Holdings Corporation in fiscal year 2019? | GT: 88.02 | Pred: print(\"86.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1492: Q: What percentage of Africa's MRO market did engine maintenance account for in 2017? | GT: 32 | Pred: print(\"32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1493: Q: In what year did the population of Guyana begin to increase? | GT: 2008 | Pred: print(\"2008\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1494: Q: What percentage of all vinyl album sales did rock vinyl account for in 2018? | GT: 41.7 | Pred: print(\"41.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1495: Q: What was the average cost of overnight accommodation in Los Angeles in July 2017? | GT: 256 | Pred: print(\"252\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1496: Q: What was the Polish gender equality index score between 2005 and 2019? | GT: 55.2 | Pred: print(\"55.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1497: Q: How many Zara stores did the Inditex Group have in the United States in 2020? | GT: 99 | Pred: print(\"99\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1498: Q: How many new hotels opened in the European hotel market in 2013? | GT: 223 | Pred: print(\"223\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1499: Q: How many new hotels were forecast to open in 2016? | GT: 216 | Pred: print(\"216\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1500: Q: What was the year-end value of the S&P Case Shiller National Home Price Index in 2020? | GT: 236.31 | Pred: print(\"236.31\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1501: Q: Who was the most searched politician worldwide in 2020? | GT: Donald Trump | Pred: print(\"Donald Trump\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1502: Q: What was the maximum monthly search volume? | GT: 90.22 | Pred: print(\"90.22\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1503: Q: How many boys participated in high school baseball in the 2018/19 season? | GT: 482740 | Pred: print(\"482740\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1504: Q: What was the fertility rate in Poland in 2018? | GT: 1.46 | Pred: print(\"1.46\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1505: Q: How much did revenues of AWS grow in the most recent quarter? | GT: 32 | Pred: print(\"31.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1506: Q: What percentage of respondents said that a major reason for not attending an arts event was that the entry fee was too much? | GT: 36.7 | Pred: print(\"36.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1507: Q: What was the average ticket price for Baltimore Ravens games in 2020? | GT: 110.53 | Pred: print(\"110.53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1508: Q: What was the issuing volume between January and August 2017 at the New York Stock Exchange? | GT: 22.2 | Pred: print(\"22.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1509: Q: What was the percentage of school children who read eBooks outside of class in 2016? | GT: 11.1 | Pred: print(\"11.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1510: Q: Which team has won the most League Cup titles? | GT: Liverpool FC | Pred: print(\"Liverpool FC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1511: Q: What is the total value of the TV broadcasting deals of the Premier League in Singapore? | GT: 297 | Pred: print(\"297\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1512: Q: How much revenue did the Premier League generate from its marketing of TV broadcasting rights from 2010 to 2012? | GT: 651 | Pred: print(\"651\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1513: Q: How many Mercedes cars were sold in Greece in 2019? | GT: 4524 | Pred: print(\"4524\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1514: Q: How many Mercedes cars were sold in Greece in 2019? | GT: 4524 | Pred: print(\"4524\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1515: Q: How much money did the global oil and gas industry spend in 2009? | GT: 315030.7 | Pred: print(\"315030.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1516: Q: How many hours per day did people with less than a high school diploma spend on leisure and sports activities? | GT: 5.98 | Pred: print(\"5.98\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1517: Q: How much did Katrina's insured losses amount to? | GT: 82.39 | Pred: print(\"82.39\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1518: Q: What percentage of the top 400 charities and NPOs used Facebook for their organization? | GT: 92 | Pred: print(\"92\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1519: Q: What did 92 percent of the top 400 charities and NPOs use for their organization? | GT: Facebook | Pred: print(\"Facebook\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1520: Q: What was the average amount of damages from a targeted cyber attack on a business? | GT: 5.9 | Pred: print(\"4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1521: Q: How many cases of ESRD were treated per million people in Greece in 2016? | GT: 251 | Pred: print(\"251\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1522: Q: What was the estimated incidence rate of treated end-stage renal disease in Taiwan in 2016? | GT: 493 | Pred: print(\"493\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1523: Q: Which country had the largest army in northern and western Europe in the mid-eighteenth century? | GT: France | Pred: print(\"Austria\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1524: Q: Who was one of the strongest military powers of the 1700s? | GT: Britain | Pred: print(\"Austria\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1525: Q: What was the youth unemployment rate in Namibia in 2020? | GT: 41.17 | Pred: print(\"41.17\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1526: Q: What was the value of end-user payments for NC software in 2013? | GT: 1.64 | Pred: print(\"1.64\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1527: Q: How many Coppa Italia titles did Juventus FC win? | GT: 13 | Pred: print(\"13\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1528: Q: Which Italian football team won the most Coppa Italia competitions in 2020? | GT: Juventus FC | Pred: print(\"Juventus FC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1529: Q: What was the number of Hollister retail stores worldwide in 2020? | GT: 497 | Pred: print(\"497\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1530: Q: What was the total amount of student loan debt in England in 2020? | GT: 121.81 | Pred: print(\"116.84\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1531: Q: What was the total amount of student loan debt in England in 2020? | GT: 121.81 | Pred: print(\"116.84\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1532: Q: What was the gross wages index in industry and services in Italy in the fourth quarter of 2020? | GT: 118.3 | Pred: print(\"118.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1533: Q: What was the occupational injury death rate for workers aged 65 and older in 2019? | GT: 9.4 | Pred: print(\"9.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1534: Q: What was the total amount of charitable donations reported by Canadian tax filers in 2019? | GT: 10309.3 | Pred: print(\"10309.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1535: Q: What percentage of Panama's GDP did government expenditure amount to in 2020? | GT: 28.61 | Pred: print(\"26.96\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1536: Q: What was the number of JBS employees worldwide in 2019? | GT: 242105 | Pred: print(\"242105\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1537: Q: How many employees did JBS have a year earlier? | GT: 230086 | Pred: print(\"230086\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1538: Q: What was the tax revenue in the Netherlands between 2009 and 2019? | GT: 188887 | Pred: print(\"205852\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1539: Q: How much did the Maldives' gross domestic product grow in 2019? | GT: 6.99 | Pred: print(\"6.99\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1540: Q: What was the brand value of the UEFA Champions League in 2017? | GT: 185 | Pred: print(\"185\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1541: Q: What was the average ticket price for Seattle Seahawks games in 2020? | GT: 117.86 | Pred: print(\"117.86\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1542: Q: How many people visited Yosemite National Park in 2016? | GT: 5.03 | Pred: print(\"5.03\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1543: Q: How many visitors did Yosemite National Park see in 2020? | GT: 2.27 | Pred: print(\"2.27\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1544: Q: What was the square footage of Burlington stores in FY2019? | GT: 47449 | Pred: print(\"47449\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1545: Q: What percentage of respondents aged 19-30 listed the ability to excel or develop in their field as the most important factor? | GT: 77 | Pred: print(\"77\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1546: Q: What was the minimum wage in 2019? | GT: 7.25 | Pred: print(\"7.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1547: Q: Where were 47 percent of Minecraft's console games sold? | GT: Latin America | Pred: print(\"Latin America\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1548: Q: What percentage of Minecraft's console games were sold in Latin America? | GT: 47 | Pred: print(\"47\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1549: Q: What percentage of respondents rated Merrell's quality as extremely positive? | GT: 83 | Pred: print(\"83\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1550: Q: What percentage of U.S. users had their mobile payment charges added to their phone bill? | GT: 3.3 | Pred: print(\"3.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1551: Q: What is the only Finnish university where most of the students were men? | GT: National Defence University | Pred: print(\"University of Helsinki\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1552: Q: Which soccer club ranked fourth in the Serie A rankings? | GT: Genoa CFC | Pred: print(\"Genoa CFC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1553: Q: How many Serie A championships did Internazionale Milano win? | GT: 18 | Pred: print(\"18\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1554: Q: Which soccer club has won the most Serie A titles? | GT: Juventus FC | Pred: print(\"Juventus FC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1555: Q: How many metric tons of emissions did Dow Chemical avoid in 2005? | GT: 224 | Pred: print(\"224\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1556: Q: How many metric tons of greenhouse gases did Dow Chemical emit in 2005? | GT: 47 | Pred: print(\"224\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1557: Q: How much CO2 did agriculture emit in Finland in 2018? | GT: 6.6 | Pred: print(\"6.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1558: Q: How many times has Iker Casillas appeared in the Champions League? | GT: 181 | Pred: print(\"181\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1559: Q: Who follows Iker Casillas in appearances in the Champions League? | GT: Cristiano Ronaldo | Pred: print(\"Cristiano Ronaldo\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1560: Q: What was the average ticket price for Minnesota Vikings games in 2020? | GT: 108.79 | Pred: print(\"108.79\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1561: Q: What was the most popular social media for Dutch Millennials in 2020? | GT: Instagram | Pred: print(\"WhatsApp\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1562: Q: How many marriages took place in Luxembourg in 2019? | GT: 2019 | Pred: print(\"2143\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1563: Q: What was the average annual wine consumption per resident in the United States in 2018? | GT: 2.95 | Pred: print(\"2.95\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1564: Q: What is the expected number of inbound visitors in the Netherlands in 2020? | GT: 20.1 | Pred: print(\"7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1565: Q: How many international travelers did the Netherlands welcome in 2019? | GT: 20.1 | Pred: print(\"20.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1566: Q: In what year did Walmart have a stable gross profit margin? | GT: 2006 | Pred: print(\"2011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1567: Q: What was Walmart's global profit margin in fiscal year 2021? | GT: 24.3 | Pred: print(\"24.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1568: Q: What was China's share in global gross domestic product in 2020? | GT: 18.34 | Pred: print(\"18.34\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1569: Q: What was the estimated international sales of Debenhams? | GT: 442.1 | Pred: print(\"444.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1570: Q: What was Debenhams revenue in the UK in the year ending September 1st 2018? | GT: 1832.7 | Pred: print(\"1832.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1571: Q: What percentage of Spotify's revenues went towards royalty payments in 2020? | GT: 74.44 | Pred: print(\"74.44\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1572: Q: How many people had access to the internet by the end of 2020? | GT: 988.99 | Pred: print(\"988.99\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1573: Q: What was the average amount people gave in the month prior to being asked to donate to charity in England in 2019/20? | GT: 24 | Pred: print(\"24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1574: Q: What was the price index of machinery and equipment in Canada in 2016? | GT: 128.4 | Pred: print(\"128.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1575: Q: How many Easter bunnies were produced in Germany in 2019? | GT: 220 | Pred: print(\"220\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1576: Q: How many people worked in the food and drink retailing sector in the first quarter of 2017? | GT: 1.12 | Pred: print(\"1.12\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1577: Q: How many players did Juventus FC have as of October 2020? | GT: 23 | Pred: print(\"23\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1578: Q: What is the Serie A soccer club with the highest number of players? | GT: Genoa CFC | Pred: print(\"Genoa CFC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1579: Q: Which football club had the lowest number of footballers as of October 2020? | GT: Juventus FC | Pred: print(\"Juventus FC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1580: Q: What is the projected number of World of Warcraft subscribers in 2023? | GT: 4.46 | Pred: print(\"4.45\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1581: Q: How many global subscribers did World of Warcraft have in 2015? | GT: 5.5 | Pred: print(\"5.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1582: Q: What was the average face amount of individual life insurance policies purchased in the United States in 2018? | GT: 168 | Pred: print(\"168\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1583: Q: What was the average face amount of individual life insurance policies purchased in the United States in 2018? | GT: 168 | Pred: print(\"168\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1584: Q: What percentage of all households in New Orleans, Louisiana were one-person households in 2019? | GT: 46.81 | Pred: print(\"46.81\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1585: Q: How many smartphone users are expected to be in Germany by 2024? | GT: 75.6 | Pred: print(\"75.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1586: Q: What was the total value of the global data visualization market in 2017? | GT: 4.51 | Pred: print(\"4.51\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1587: Q: What is the market expected to grow to by 2023? | GT: 7.76 | Pred: print(\"7.76\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1588: Q: Who has the most RBI in Pittsburgh Pirates franchise history? | GT: Willie Stargell | Pred: print(\"Willie Stargell\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1589: Q: What was Malaysia's share in the global gross domestic product adjusted for Purchasing Power Parity in 2019? | GT: 0.7 | Pred: print(\"0.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1590: Q: How many immigrants lived in Mongolia in 2010? | GT: 16 | Pred: print(\"16\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1591: Q: How many people died as a result of intentional homicide in Haiti in 2018? | GT: 743 | Pred: print(\"743\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1592: Q: In what year was the app sensor market forecast to be worth 5.6 billion U.S. dollars? | GT: 2017 | Pred: print(\"2012\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1593: Q: How much is the app sensor market expected to be worth by 2017? | GT: 5600 | Pred: print(\"5600\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1594: Q: What was the U.S. notebook market penetration in 2010? | GT: 63 | Pred: print(\"63\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1595: Q: How many infant deaths were there in Canada in 2019? | GT: 345 | Pred: print(\"345\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1596: Q: What was the global number of Inditex employees in 2020? | GT: 144116 | Pred: print(\"144116\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1597: Q: How much revenue did Digital Bros generate in fiscal 2020? | GT: 133.22 | Pred: print(\"133.22\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1598: Q: What year was Audi's last fiscal year? | GT: 2002 | Pred: print(\"2002\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1599: Q: When did Audi's total assets end? | GT: 2020 | Pred: print(\"2020\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1600: Q: What was Audi's total assets in the fiscal year of 2020? | GT: 67229 | Pred: print(\"67229\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1601: Q: How many direct operated stores did Tod's Group control in 2019? | GT: 137 | Pred: print(\"137\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1602: Q: What was Pakistan's gross domestic product in dollars in 2020? | GT: 262.8 | Pred: print(\"262.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1603: Q: What was Nicaragua's unemployment rate in 2020? | GT: 7.36 | Pred: print(\"7.36\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1604: Q: What was Kentucky's GDP in 2020? | GT: 183.8 | Pred: print(\"183.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1605: Q: What was Kentucky's GDP in dollars in 2018? | GT: 190.81 | Pred: print(\"190.81\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1606: Q: How many men were admitted to hospital as a result of a road traffic accident in Scotland in 2019/20? | GT: 613 | Pred: print(\"180\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1607: Q: What was the GVA of the financial and insurance services sector in 2019? | GT: 125910 | Pred: print(\"132981\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1608: Q: What was the GVA of the financial and insurance services sector in 2019? | GT: 125910 | Pred: print(\"132981\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1609: Q: Where was the 2014 FIFA World Cup held? | GT: Brazil | Pred: print(\"Brazil\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1610: Q: What is the combined market/transfer value of the Spanish squad? | GT: 622 | Pred: print(\"622\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1611: Q: What was the net banking income of European banks in 2013? | GT: 700 | Pred: print(\"700\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1612: Q: When was Faurecia's global OEM automotive parts sales first reported? | GT: 2001 | Pred: print(\"2001\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1613: Q: What was Faurecia's global sales in dollars in 2019? | GT: 19900 | Pred: print(\"20011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1614: Q: How much of the EU budget came from VAT resources in 2013? | GT: 9.4 | Pred: print(\"9.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1615: Q: What was the average price per 1,000 cubic feet of natural gas in 2020? | GT: 10.84 | Pred: print(\"10.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1616: Q: What was the population of Dallas-Fort Worth-Arlington in the previous year? | GT: 7573990 | Pred: print(\"7659441\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1617: Q: What was the population of Dallas-Fort Worth-Arlington in 2020? | GT: 7694138 | Pred: print(\"7659901\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1618: Q: In what year did the child mortality rate drop to its lowest ever? | GT: 2020 | Pred: print(\"1960\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1619: Q: What was Nigeria's most popular social media in the third quarter of 2020? | GT: WhatsApp | Pred: print(\"WhatsApp\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1620: Q: What percentage of Nigerians use Facebook and Youtube? | GT: 81.6 | Pred: print(\"86.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1621: Q: What percentage of Nigerians use Facebook and Youtube? | GT: 86.2 | Pred: print(\"86.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1622: Q: How much revenue did Zynga generate in the first quarter of 2021? | GT: 680.3 | Pred: print(\"680.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1623: Q: How much revenue did Zynga generate in the first quarter of 2021? | GT: 616 | Pred: print(\"680.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1624: Q: How many femicide victims were registered in Veracruz? | GT: 84 | Pred: print(\"84\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1625: Q: How many widowed people were there in Canada in 2020? | GT: 1.95 | Pred: print(\"1.95\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1626: Q: How many widowed people lived in Canada in 2000? | GT: 1.55 | Pred: print(\"1.55\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1627: Q: What was the total number of participants in lacrosse in 2018? | GT: 2.1 | Pred: print(\"2.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1628: Q: What country has the largest population in Africa? | GT: Nigeria | Pred: print(\"Nigeria\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1629: Q: What was the infant mortality rate in the Kyrgyz Republic in 2019? | GT: 16.4 | Pred: print(\"16.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1630: Q: Which country was the most popular long-haul summer holiday destination in 2015? | GT: Spain | Pred: print(\"France\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1631: Q: What neighbor country received roughly four percent of the long-haul Dutch tourists in 2015? | GT: Belgium | Pred: print(\"Belgium\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1632: Q: Which country was the most popular destination to spend a long-haul summer holiday in 2015? | GT: France | Pred: print(\"France\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1633: Q: What is the only intercontinental country in the top 10 long haul summer destinations? | GT: Great Britain | Pred: print(\"United States\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1634: Q: What percentage of Dutch long-haul summer holiday tourists come from the United States? | GT: 2.5 | Pred: print(\"2.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1635: Q: What was Turkey's poverty headcount ratio in 2018? | GT: 14.4 | Pred: print(\"14.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1636: Q: What was the lowest value of French imports from Russia in 2016? | GT: 6119 | Pred: print(\"6119\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1637: Q: What was the highest value of French imports from Russia in 2011? | GT: 19346 | Pred: print(\"19346\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1638: Q: What was the annual value of French imports from Russia in 2019? | GT: 9158 | Pred: print(\"9158\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1639: Q: What percentage of Beiersdorf employees were employed in Europe by the end of the 2020 fiscal year? | GT: 56.8 | Pred: print(\"56.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1640: Q: What was the percentage of foreign nationals in Luxembourg in 2019? | GT: 47.42 | Pred: print(\"47.42\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1641: Q: What was the highest rating for En Punto con Denise Maerker? | GT: 11.8 | Pred: print(\"11.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1642: Q: How many criminal offences were solved in the same year? | GT: 313438 | Pred: print(\"525092\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1643: Q: How many criminal offences were reported to the authorities in 2020? | GT: 543429 | Pred: print(\"539032\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1644: Q: What was the value of U.S. textile and apparel exports to Germany in dollars in 2020? | GT: 314.75 | Pred: print(\"314.75\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1645: Q: What was the estimated market value of edible insects in 2018? | GT: 406.32 | Pred: print(\"406.32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1646: Q: What was the average electricity supply price in Brazil in June 2019? | GT: 497.65 | Pred: print(\"497.65\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1647: Q: How much did the population of Latin America & Caribbean grow in 2019? | GT: 0.93 | Pred: print(\"0.93\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1648: Q: How many passenger cars were sold in Pakistan between July 2018 and June 2019? | GT: 207630 | Pred: print(\"207630\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1649: Q: How much money did Universal spend on '1917'? | GT: 10.41 | Pred: print(\"10.41\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1650: Q: How much money did Universal spend on 'Dolittle'? | GT: 5.77 | Pred: print(\"5.77\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1651: Q: What is the name of the tax deferred pension plan available to self-employed individuals or unincorporated businesses for retirement purposes? | GT: KEOGH | Pred: print(\"401K, 403B, Thrift Plans\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1652: Q: What was eBay's net revenue in the prior year? | GT: 8636 | Pred: print(\"8636\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1653: Q: How much was eBay's net revenue in the most recent fiscal year? | GT: 9927 | Pred: print(\"10271\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1654: Q: What was the brand value of Chelsea FC in dollars in 2019? | GT: 1085 | Pred: print(\"1083\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1655: Q: What was the value of the Minnesota Vikings in 2020? | GT: 2950 | Pred: print(\"2950\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1656: Q: How much did Zygmunt Wilf pay for the Minnesota Vikings in 2005? | GT: 604 | Pred: print(\"658\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1657: Q: What country had the second largest share of the global blood plasma market? | GT: China | Pred: print(\"China\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1658: Q: Which country was responsible for five percent of the global blood plasma market? | GT: Germany | Pred: print(\"Germany\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1659: Q: When did the number of ATM-related physical attacks increase? | GT: 2014 | Pred: print(\"2017\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1660: Q: In what year did the number of hospitals in Hungary begin to stabilize? | GT: 2000 | Pred: print(\"2000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1661: Q: What was the peak number of hospitals between 2004 and 2005? | GT: 182 | Pred: print(\"182\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1662: Q: How many hospitals were there in Hungary in 2018? | GT: 165 | Pred: print(\"165\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1663: Q: What is OPEC's average share of global natural gas reserves? | GT: 35.5 | Pred: print(\"35.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1664: Q: What percentage of respondents purchased Kent brand cigarettes in the last three to twelve months of 2013? | GT: 9 | Pred: print(\"9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1665: Q: What is the estimated global demand for ethylene by 2022? | GT: 185 | Pred: print(\"185\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1666: Q: What was the global demand for ethylene in 2017? | GT: 152 | Pred: print(\"152\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1667: Q: What was the government spending in France in 2019? | GT: 1349.03 | Pred: print(\"1367.25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1668: Q: What was the government revenue in France in 2019? | GT: 1275.06 | Pred: print(\"1367.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1669: Q: What was the unemployment rate in Sierra Leone in 2020? | GT: 4.44 | Pred: print(\"4.44\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1670: Q: What percentage of votes did Alberto Fernandez get? | GT: 48.1 | Pred: print(\"48.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1671: Q: What was Austrian sales of Ford cars in 2017? | GT: 20748 | Pred: print(\"20748\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1672: Q: How many Ford cars were sold in Austria in 2011? | GT: 23678 | Pred: print(\"23678\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1673: Q: What was the price of one thousand board feet of Western hemlock in 2015? | GT: 69.04 | Pred: print(\"550\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1674: Q: What was the total sales of sanitary napkins/tampons in the United States in 2018? | GT: 2.8 | Pred: print(\"2.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1675: Q: What was the dollar sales of sanitary napkins and liners in the United States in 2018? | GT: 1.76 | Pred: print(\"1.76\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1676: Q: What percentage of Antigua and Barbuda's total employment did tourism contribute to in 2019? | GT: 90.7 | Pred: print(\"90.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1677: Q: What was the total contribution of travel and tourism to employment in the whole Caribbean region in 2019? | GT: 15.2 | Pred: print(\"15.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1678: Q: What was Aruba's contribution share in 2019? | GT: 84.3 | Pred: print(\"84.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1679: Q: What was the total sales of office supplies, stationery, and gift stores in the United States a year earlier? | GT: 30.32 | Pred: print(\"30.06\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1680: Q: How much did office supplies, stationery, and gift store sales in the U.S. in 2019? | GT: 28.92 | Pred: print(\"28.92\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1681: Q: How many carvedilol prescriptions were there in 2018? | GT: 22.78 | Pred: print(\"22.74\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1682: Q: What was the national debt of the United States of America in dollars in September of 2020? | GT: 26945.39 | Pred: print(\"27131\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1683: Q: How many people in Indonesia had access to the internet in 2019? | GT: 184.94 | Pred: print(\"184.94\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1684: Q: By 2025, how many people are expected to access the internet in Indonesia? | GT: 256.37 | Pred: print(\"256.37\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1685: Q: How many Brazilian reals were estimated to be needed for the Carnival in Rio de Janeiro in 2020? | GT: 70 | Pred: print(\"70\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1686: Q: How many reals would come from the city government's budget? | GT: 42 | Pred: print(\"42\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1687: Q: What was the GDP of Germany in 2018? | GT: 3386000 | Pred: print(\"3386000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1688: Q: What country had the highest GDP in 2018? | GT: Germany | Pred: print(\"Germany\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1689: Q: Which country came in second among the countries shown in this graph? | GT: Mexico | Pred: print(\"Mexico\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1690: Q: What was the estimated value of the Cincinnati Reds in 2021? | GT: 1085 | Pred: print(\"1085\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1691: Q: What percentage of respondents identified the problems with integrating systems and operations as the main obstacle on the way to smooth integration? | GT: 29 | Pred: print(\"29\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1692: Q: What percentage of Venezuela's GDP did Venezuela's military budget account for in 2017? | GT: 2.2 | Pred: print(\"2.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1693: Q: How many Swiss Francs did Rolex sell in 2013? | GT: 4300 | Pred: print(\"4300\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1694: Q: What was the leading Swiss watch brand in 2013? | GT: Rolex | Pred: print(\"Rolex\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1695: Q: Who has the most hits in Pittsburgh Pirates franchise history? | GT: Roberto Clemente | Pred: print(\"Roberto Clemente\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1696: Q: How much money did Madison Square Garden Company generate in annual revenue in 2020? | GT: 603.32 | Pred: print(\"603.32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1697: Q: By what year did Brunei expect to have a population over 65? | GT: 2040 | Pred: print(\"2040\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1698: Q: What was the percentage of Brunei's population older than 65 in 2020? | GT: 5.6 | Pred: print(\"5.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1699: Q: What was the average retail price for 2.5 kilograms of flour in Canada in February 2021? | GT: 4.42 | Pred: print(\"4.49\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1700: Q: What was the crude birth rate in the Congo in 2019? | GT: 40.64 | Pred: print(\"40.64\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1701: Q: In the previous reporting year, how many fire-related deaths were there in Great Britain? | GT: 317 | Pred: print(\"399\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1702: Q: How many fire-related deaths occurred in Great Britain in 2019/20? | GT: 286 | Pred: print(\"317\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1703: Q: What was the initial forecast for smartphone shipments in 2020? | GT: 6.4 | Pred: print(\"6.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1704: Q: What is the predicted decrease in smartphone shipment value in 2020? | GT: 6.4 | Pred: print(\"47.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1705: Q: How many job openings were there in April of 2021? | GT: 8.29 | Pred: print(\"9.29\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1706: Q: How many job openings were there by the last business day of April 2021? | GT: 9.29 | Pred: print(\"9.29\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1707: Q: What was the operating income of the Brooklyn Nets in the 2019/20 season? | GT: 44 | Pred: print(\"44\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1708: Q: What was the most-followed brand on Facebook in Hong Kong as of March 2021? | GT: Blackview | Pred: print(\"Blackview\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1709: Q: How many fans did Blackview have in Hong Kong as of March 2021? | GT: 1714353 | Pred: print(\"1714353\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1710: Q: In what year did online sales make up 0.4 percent of food and grocery retail sales? | GT: 2013 | Pred: print(\"2013\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1711: Q: What percentage of food and grocery retail sales did online sales make up in 2013? | GT: 0.4 | Pred: print(\"0.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1712: Q: What percentage of online sales is expected to increase to by 2018? | GT: 0.7 | Pred: print(\"0.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1713: Q: What was the population of the Minneapolis-St. Paul-Bloomington metropolitan area in 2020? | GT: 3639892 | Pred: print(\"3605555\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1714: Q: What was the population of the Minneapolis-St. Paul-Bloomington metropolitan area in the previous year? | GT: 3611648 | Pred: print(\"3553551\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1715: Q: What was the Barclays Premier League's brand value in 2012? | GT: 4170 | Pred: print(\"4170\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1716: Q: What country had 41,320 cubic meters of renewable water resources per capita in 2017? | GT: Brazil | Pred: print(\"Brazil\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1717: Q: How many mobile subscriptions were registered for every 100 people in South Africa between 2000 and 2019? | GT: 165.6 | Pred: print(\"165.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1718: Q: What was the number of domestic tourist arrivals in Belgium in 2020? | GT: 4632153 | Pred: print(\"4699000\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1719: Q: How many Dutch tourists arrived in Belgium in 2020? | GT: 736926 | Pred: print(\"482300\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1720: Q: What religion made up 93 percent of the population in the Middle East and North Africa in 2010? | GT: Muslims | Pred: print(\"Muslims\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1721: Q: When was the last fiscal year of ServiceMaster Global Holdings? | GT: 2014 | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1722: Q: How many Swedish kronor were intended expenses for Christmas in 2018? | GT: 5860 | Pred: print(\"3660\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1723: Q: Who is the career rushing leader of the Kansas City Chiefs? | GT: Jamaal Charles | Pred: print(\"Jamaal Charles\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1724: Q: How much did the sales of gardening equipment grow in the first six months of 2015? | GT: 5.3 | Pred: print(\"5.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1725: Q: What year was the highest number of gang-related homicides in the US? | GT: 2007 | Pred: print(\"2012\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1726: Q: Who is the career rushing leader of the New England Patriots? | GT: Sam Cunningham | Pred: print(\"Sam Cunningham\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1727: Q: What was the percentage of baptized children in Norrbotten county in 2020? | GT: 41.5 | Pred: print(\"41.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1728: Q: What percentage of children were baptized in Stockholm in 2020? | GT: 30.7 | Pred: print(\"30.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1729: Q: How many people used a foodbank in 2008/09? | GT: 25899 | Pred: print(\"25899\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1730: Q: How many dollars did PR agencies generate with media relations services in 2019? | GT: 764 | Pred: print(\"9203\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1731: Q: How much money did full public relations services bring in in 2019? | GT: 764 | Pred: print(\"0.94\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1732: Q: What was the percentage of support for the SDP in May 2019? | GT: 17.7 | Pred: print(\"17.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1733: Q: How many followers did Charli D'Amelio have on the TikTok app? | GT: 72.5 | Pred: print(\"72.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1734: Q: What percentage of hedge fund investments did fund of hedge funds managers account for in August 2018? | GT: 43 | Pred: print(\"43\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1735: Q: When did the combined operating revenue of U.S. airlines begin to increase? | GT: 2015 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1736: Q: How much operating revenue did U.S. airlines generate in 2020 due to the coronavirus pandemic? | GT: 130.69 | Pred: print(\"130.69\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1737: Q: What was the combined operating revenue of U.S. airlines in 2019? | GT: 248 | Pred: print(\"248\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1738: Q: What was the sales of Outback Steakhouse in the United States in 2014? | GT: 2.48 | Pred: print(\"2.48\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1739: Q: What full service chain's U.S. sales reached approximately 2.48 billion U.S. dollars in 2014? | GT: Outback Steakhouse | Pred: print(\"Outback Steakhouse\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1740: Q: What was the average passenger revenue per passenger-mile in 2018? | GT: 40.7 | Pred: print(\"41.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1741: Q: What was the value of passenger revenue per passenger-mile in the year after 2018? | GT: 41.7 | Pred: print(\"41.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1742: Q: Which soap bar brand managed to maintain a positive sales growth over the time period? | GT: Dove | Pred: print(\"Simple\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1743: Q: What was the youth unemployment rate in the United States in 2020? | GT: 8.94 | Pred: print(\"8.94\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1744: Q: How many movie theaters visited Russia in the week ending June 16, 2021? | GT: 2.6 | Pred: print(\"2.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1745: Q: What was the weekly attendance of Russian cinemas during the New Year's holidays? | GT: 7.4 | Pred: print(\"7.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1746: Q: Which country had the highest pedestrian death rate out of all the countries of the UK? | GT: Romania | Pred: print(\"Austria\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1747: Q: How many Formula One races has Red Bull Racing won? | GT: 64 | Pred: print(\"64\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1748: Q: Who is the career assists leader of the Golden State Warriors? | GT: Guy Rodgers | Pred: print(\"Guy Rodgers\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1749: Q: What was the year with the highest number of arrests for public drunkenness? | GT: 2007 | Pred: print(\"2007\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1750: Q: Which state had the highest number of turkeys raised in 2018? | GT: Minnesota | Pred: print(\"Minnesota\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1751: Q: Which state was the leading producer of turmeric in India in 2018? | GT: Telangana | Pred: print(\"Telangana\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1752: Q: How many games have Clemens and Young won? | GT: 192 | Pred: games_clemens = 192\n",
            "games_young = 192\n",
            "total_games = games_clemens + games_young\n",
            "print(total_games)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1753: Q: What was India's revenue from international tourism in 2019? | GT: 30.06 | Pred: print(\"30.06\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1754: Q: What was India's revenue from international tourism in 2010? | GT: 14.49 | Pred: print(\"14.49\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1755: Q: How much was merchandise imported to the United States from China in 2019? | GT: 17.18 | Pred: print(\"17.18\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1756: Q: In March 2018, what was the average waiting time for treatment in the UK? | GT: 64 | Pred: print(\"64\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1757: Q: As of March 2020, how many enterprises had between 50 and 99 employees? | GT: 10 | Pred: print(\"10\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1758: Q: In what year did 328 subsea wells come onstream or start achieving first production? | GT: 2014 | Pred: print(\"2014\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1759: Q: What was Rothschild's M&A deal count in 2016? | GT: 101 | Pred: print(\"101\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1760: Q: Which company was ranked as the leading financial advisor with an M&A deal count amounting to 101 in 2016? | GT: Rothschild | Pred: print(\"Rothschild\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1761: Q: What was the net revenue of Goldman Sachs in dollars in 2020? | GT: 44.56 | Pred: print(\"44.56\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1762: Q: Which state had the lowest income distribution inequality? | GT: Tlaxcala | Pred: print(\"Mexico City\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1763: Q: What was the Gini coefficient of Mexico City above the national average? | GT: 0.47 | Pred: print(\"0.53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1764: Q: What was the value of the harvested area of rice crops in Thailand in 2020? | GT: 56.83 | Pred: print(\"56.83\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1765: Q: What was the size of the harvested area of rice crops in Thailand in 2019? | GT: 54.11 | Pred: print(\"54.11\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1766: Q: What percentage of industrial NC software seats did Dassault Syst mes provide in 2013? | GT: 5.6 | Pred: print(\"5.6\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1767: Q: What was the population density per square kilometer in the United States in 2018? | GT: 35.71 | Pred: print(\"35.71\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1768: Q: How many retail stores did Herm s operate in 2020? | GT: 306 | Pred: print(\"306\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1769: Q: How many cases of COVID-19 were confirmed in Denmark as of March 23, 2020? | GT: 564 | Pred: print(\"564\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1770: Q: Where did 298 of Denmark's confirmed cases originate from? | GT: Austria | Pred: print(\"Austria\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1771: Q: How much ad-supported revenue did Spotify generate in the most recent fiscal year? | GT: 745 | Pred: print(\"555\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1772: Q: How much has premium revenue grown by since 2017? | GT: 7135 | Pred: print((6000 - 3000)/3000*100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1773: Q: How much premium revenue did Spotify generate in the most recent fiscal year? | GT: 7135 | Pred: print(\"7212\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1774: Q: What was Russia's fertility rate in 2020? | GT: 1.74 | Pred: print(\"1.74\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1775: Q: What was the average number of children born per one woman in the urban area? | GT: 1.43 | Pred: print(\"1.44\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1776: Q: In what year was a national average of existing office space available in the Netherlands? | GT: 2015 | Pred: print(\"2007\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1777: Q: What was the value of money market funds as of December 2020? | GT: 49.26 | Pred: print(\"49.67\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1778: Q: How much money did the US Chamber of Commerce spend in the 2016 election cycle? | GT: 20355534 | Pred: print(\"2035554\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1779: Q: By what year is it expected that consumer sales of cannabidiol will reach around 1.8 billion U.S. dollars? | GT: 2022 | Pred: print(\"2022\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1780: Q: How many people in Catalonia were vaccinated against influenza in 2017-2018? | GT: 725635 | Pred: print(\"725635\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1781: Q: How many daily active users did Douyin have in comparison to the period prior to the epidemic? | GT: 81.92 | Pred: print(\"81.92\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1782: Q: How many people were killed in motor vehicle accidents in Luxembourg in 2010? | GT: 32 | Pred: print(\"32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1783: Q: How many road fatalities occurred in Luxembourg in 2009? | GT: 48 | Pred: print(\"48\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1784: Q: How many wins have the New England Patriots had during the postseason? | GT: 37 | Pred: print(\"37\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1785: Q: What was the value of UK exports to the EU in 2019? | GT: 294.3 | Pred: print(\"294.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1786: Q: How much British pounds worth of goods and services did the UK export to the EU in 2015? | GT: 225.5 | Pred: print(\"225.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1787: Q: Which region had the highest number of cases of coronavirus? | GT: Lombardy | Pred: print(\"Lombardy\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1788: Q: How much did adjusted U.S. retail e-commerce sales amount to in the first quarter of 2021? | GT: 215035 | Pred: print(\"216507\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1789: Q: How many TV households were in the Middle East and Africa in 2012? | GT: 65 | Pred: print(\"65\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1790: Q: How many metric tons of fresh vegetables did India produce in 2019? | GT: 132.03 | Pred: print(\"132.03\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1791: Q: What was the benchmark index of commercial rents during the 1st quarter of 2020? | GT: 116.23 | Pred: print(\"116.16\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1792: Q: What was the value of imports of synthetic resins and rubbers in Canada in 2019? | GT: 8624 | Pred: print(\"303\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1793: Q: How much did the real hourly earnings of all employees in the United States decrease in May 2021? | GT: 0.2 | Pred: print(\"0.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1794: Q: What was the payroll of the Red Sox in 2020? | GT: 95 | Pred: print(\"95\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1795: Q: What was the second most popular newspaper in the UK? | GT: The Times | Pred: print(\"The Guardian\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1796: Q: What was the most popular newspaper in the UK in the fourth quarter of 2020? | GT: Metro | Pred: print(\"Metro\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1797: Q: What was the second most popular newspaper in the UK? | GT: The Guardian | Pred: print(\"The Guardian\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1798: Q: Which country had the largest loss of sales due to counterfeit sporting goods? | GT: France | Pred: print(\"Malta\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1799: Q: How much did the French sporting goods sector lose in 2015? | GT: 82 | Pred: print(\"82\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1800: Q: What was the value of private equity investments as of 2016? | GT: 87.23 | Pred: print(\"87.23\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1801: Q: What was the total value of private equity investments in 2007? | GT: 443.81 | Pred: print(\"443.81\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1802: Q: What was Brazil's national gross income per person in the previous year? | GT: 9130 | Pred: print(\"9130\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1803: Q: What was Brazil's gross income per capita in 2019? | GT: 9130 | Pred: print(\"9130\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1804: Q: How much money did travel and tourism directly contribute to the North East Asian economy in 2017? | GT: 573.7 | Pred: print(\"573.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1805: Q: How much money did Snap spend on sales and marketing in 2015? | GT: 555.47 | Pred: print(\"27.22\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1806: Q: How many international tourists and non-resident Indians arrived in India in 2019? | GT: 17.91 | Pred: print(\"17.91\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1807: Q: What percentage of GDP did the national debt of the Philippines amount to in 2020? | GT: 47.07 | Pred: print(\"47.07\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1808: Q: Who is the career passing leader of the Philadelphia Eagles? | GT: Donovan McNabb | Pred: print(\"Donovan McNabb\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1809: Q: How many enterprises made games and toys in the Netherlands in 2017? | GT: 432 | Pred: print(\"432\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1810: Q: How many points does Ronan O'Gara have for the Irish national rugby team? | GT: 93 | Pred: print(\"93\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1811: Q: Who holds the record for most points scored at the Rugby World Cup? | GT: Ronan O'Gara | Pred: print(\"Ronan O'Gara\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1812: Q: What percentage of the Aosta Valley population had risky alcohol consumption? | GT: 23 | Pred: print(\"23\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1813: Q: What was the total revenue of Bartlett Tree Experts in 2020? | GT: 352 | Pred: print(\"352\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1814: Q: What was the inflation rate in the Central African Republic in 2020? | GT: 2.3 | Pred: print(\"3.34\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1815: Q: What was Deutsche Telekom's revenue in Germany in 2020? | GT: 24.63 | Pred: print(\"24.74\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1816: Q: What was the percentage of female managing directors working at Barclays in 2017? | GT: 14 | Pred: print(\"14\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1817: Q: What was the production value of the Romanian textile manufacturing sector in 2015? | GT: 1286.2 | Pred: print(\"1286.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1818: Q: What was the value of the Nashville Predators in dollars in 2020? | GT: 435 | Pred: print(\"435\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1819: Q: What percentage of COVID-19 patients died after contracting the virus? | GT: 65.7 | Pred: print(\"65.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1820: Q: What was the brand value of HSBC in 2015? | GT: 27.3 | Pred: print(\"27.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1821: Q: How many dollars did Callaway Golf spend on research and development in 2020? | GT: 46.3 | Pred: print(\"46.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1822: Q: How much was proposed for military crisis management in 2021? | GT: 59 | Pred: print(\"410\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1823: Q: How much did the Defense Forces pay in 2021? | GT: 815 | Pred: print(\"1485\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1824: Q: What accounts for the largest part of the 2021 budget? | GT: HX Fighter Program | Pred: print('Squadron 2020')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1825: Q: What was the GDP of Massachusetts in dollars in the previous year? | GT: 519.96 | Pred: print(\"519.96\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1826: Q: What was the GDP of Massachusetts in 2020? | GT: 500.24 | Pred: print(\"500.24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1827: Q: What was Egypt's birth rate per one thousand inhabitants in 2013? | GT: 28.52 | Pred: print(\"28.52\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1828: Q: What was the crude birth rate in Egypt in 2019? | GT: 25.71 | Pred: print(\"25.71\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1829: Q: What was Egypt's birth rate per one thousand inhabitants in 2013? | GT: 28.52 | Pred: print(\"28.52\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1830: Q: What was Coca Cola's market share in Egypt in 2010? | GT: 32 | Pred: print(\"32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1831: Q: How many home runs has Frank Thomas hit? | GT: 448 | Pred: print(\"448\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1832: Q: Who has hit the most home runs in Chicago White Sox franchise history? | GT: Frank Thomas | Pred: print(\"Frank Thomas\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1833: Q: What is the name of the Haitian youtube news channel? | GT: Tele Image Valerio Saint-Louis | Pred: print(\"Tele Image Valerio Saint-Louis\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1834: Q: What is the name of the comedy channel in Haiti? | GT: Komedyen Lakay Official | Pred: print(\" komedyen Lakay Official\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1835: Q: How many views did Tele Image Valerio Saint-Louis have in Haiti as of March 2021? | GT: 83.02 | Pred: print(\"83.02\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1836: Q: How many fans did the USA Today profile have on Facebook? | GT: 4824550 | Pred: print(\"4824550\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1837: Q: How many dollars did Callaway Golf report in golf club sales in 2020? | GT: 787.1 | Pred: print(\"787.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1838: Q: What is the estimated amount of eSports sponsorship and advertising spending in the United States in 2023? | GT: 634.03 | Pred: print(\"634.03\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1839: Q: What was the estimated amount of sponsorship and advertising spending on the eSports market in 2017? | GT: 124.41 | Pred: print(\"124.41\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1840: Q: What was the percentage of energy from renewable sources in Poland from 2006 to 2015? | GT: 6.9 | Pred: print(\"6.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1841: Q: What was the market share of Zurich Insurance Group in 2019? | GT: 3.7 | Pred: print(\"3.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1842: Q: For every male participant, how many females were in the labor force in Bangladesh in 2016? | GT: 0.53 | Pred: print(\"0.53\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1843: Q: What was Zimbabwe's youth unemployment rate in 2020? | GT: 8.07 | Pred: print(\"8.09\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1844: Q: What was Lloyds Banking Group's cost to income ratio in 2019? | GT: 48.5 | Pred: print(\"48.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1845: Q: How many people lived in Region Nordjylland in 2021? | GT: 589936 | Pred: print(\"341221\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1846: Q: How many people lived in Hovedstaden in the first quarter of 2021? | GT: 1846023 | Pred: print(\"1717111\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1847: Q: What was the franchise value of the Denver Broncos in 2020? | GT: 3200 | Pred: print(\"3200\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1848: Q: What was the monthly CPI for lamb and goat meat in Italy at the beginning of the year 2015? | GT: 101.7 | Pred: print(\"101.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1849: Q: What was the monthly CPI for lamb and goat meat in November 2020? | GT: 104.5 | Pred: print(\"104.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1850: Q: How much money did the convenience store industry generate from fuel sales in 2011? | GT: 486.9 | Pred: print(\"486.9\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1851: Q: How much did the 2016 Olympic Summer Games licensing revenue amount to? | GT: 31 | Pred: print(\"31\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1852: Q: What percentage of vote shares did the Conservative Party gain? | GT: 5.5 | Pred: print(\"5.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1853: Q: What percentage of e-commerce visits via tablet devices were converted into purchases in the second quarter of 2020? | GT: 3.32 | Pred: print(\"3.32\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1854: Q: How many stores did Dillard's operate in 2020? | GT: 282 | Pred: print(\"282\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1855: Q: What was Five Below's net sales per store a year earlier? | GT: 2.2 | Pred: print(\"2.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1856: Q: What country had the largest Snapchat user base in the world? | GT: India | Pred: print(\"India\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1857: Q: How many users did Snapchat have in the United States as of April 2021? | GT: 108.65 | Pred: print(\"108.65\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1858: Q: What percentage of white respondents said they see the Confederate flag as a symbol of racism? | GT: 25 | Pred: print(\"25\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1859: Q: What was Kuwait's infant mortality rate per 1,000 live births in 2019? | GT: 6.8 | Pred: print(\"6.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1860: Q: How many people committed suicide by throwing themselves in front of a train in 2006? | GT: 24 | Pred: print(\"24\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1861: Q: How many dollars did Foot Locker generate in the United States in 2020? | GT: 5581 | Pred: print(\"5581\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1862: Q: What percentage of the gross domestic product did Mexico spend in 2020? | GT: 29.12 | Pred: print(\"29.12\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1863: Q: What was the lowest production of duck foie gras in 2017? | GT: 11519 | Pred: print(\"11451\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1864: Q: How many ducks were euthanized due to the H5N8 virus? | GT: 11519 | Pred: print(\"1519\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1865: Q: What was the average amount of duck foie gras produced in France between 2007 and 2015? | GT: 18602 | Pred: print(\"19189\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1866: Q: How much money did Etsy invest in its advertising in 2016? | GT: 442.2 | Pred: print(\"54.34\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1867: Q: What was the most frequently used social network in Canada? | GT: Instagram | Pred: print(\"Facebook\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1868: Q: What was the most frequently used social network in Canada? | GT: Facebook | Pred: print(\"Facebook\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1869: Q: How much did Alphabet spend on lobbying in 2020? | GT: 8.85 | Pred: print(\"8.85\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1870: Q: How much did J.K. Rowling earn from June 2018 to June 2019? | GT: 92 | Pred: print(\"92\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1871: Q: What was Vodafone Germany's EBITDA in 2020/21? | GT: 5.63 | Pred: print(\"5.63\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1872: Q: What was the previous year's EBITDA? | GT: 5.08 | Pred: print(\"5.08\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1873: Q: What percentage of Google's revenue was generated in the UK in 2015? | GT: 10 | Pred: print(\"10\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1874: Q: Which country has the most markets? | GT: France | Pred: print('Germany')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1875: Q: What was the highest salary in the cruise industry in 2019? | GT: 9.93 | Pred: print(\"9.93\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1876: Q: How much did the cruise industry pay in employee wages in 2009? | GT: 5.48 | Pred: print(\"5.48\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1877: Q: How much was the expenses of the Green Bay Packers in 2017? | GT: 376.1 | Pred: print(\"376.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1878: Q: What percentage of all legal abortions in Alabama were performed on Hispanic women in 2018? | GT: 5.1 | Pred: print(\"5.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1879: Q: What was the import trade value of bamboo and rattan furniture in the United States in 2015? | GT: 21.07 | Pred: print(\"21.07\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1880: Q: What was the import trade value of bamboo and rattan furniture between 2015 and 2016? | GT: 18.7 | Pred: print(\"18.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1881: Q: How much did the import trade value of bamboo and rattan furniture increase between 2011 and 2016? | GT: 21.07 | Pred: print(\"18.7\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1882: Q: What was the revenue from video analytics in 2015? | GT: 858 | Pred: print(\"858\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1883: Q: What religion were about 116,000 Canadian citizens, permanent and non-permanent residents of Prince Edward Island identified as in 2011? | GT: Christian | Pred: print(\"Christian\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1884: Q: When did the value of gross written premiums by life insurance companies on the domestic market in Malta increase? | GT: 2012 | Pred: print(\"2011\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1885: Q: What was the peak value of gross written premiums in Malta in 2018? | GT: 415 | Pred: print(\"415\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1886: Q: What was the value of life insurance premiums in 2019? | GT: 378 | Pred: print(\"378\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1887: Q: How many UCI beds were there in Mexico City in April of 2020? | GT: 453 | Pred: print(\"891\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1888: Q: How many adult intensive care units were in Mexico City in April 2020? | GT: 891 | Pred: print(\"891\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1889: Q: Which social media site accounted for 57.52 percent of all social media site visits in Canada in May 2021? | GT: Facebook | Pred: print(\"Facebook\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1890: Q: Who is the career touchdown leader of the Atlanta Falcons? | GT: Roddy White | Pred: print(\"Roddy White\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1891: Q: How many career touchdowns has Roddy White scored? | GT: 63 | Pred: print(\"63\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1892: Q: What percentage of Rio 2016 viewers were women? | GT: 22 | Pred: print(\"22\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1893: Q: What percentage of India's GDP did military expenditure amount to in 2019? | GT: 2.4 | Pred: print(\"2.4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1894: Q: What was Ethiopia's share in the global gross domestic product adjusted for Purchasing Power Parity in 2020? | GT: 0.22 | Pred: print(\"0.22\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1895: Q: How much revenue did A.P. M ller - Maersk A/S generate from its ocean segment in 2020? | GT: 29.18 | Pred: print(\"29.18\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1896: Q: How much money did pirates receive in ransom for the release of the oil tanker Savina Caylyn? | GT: 11.5 | Pred: print(\"11.5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1897: Q: Which beer brand topped the beer production volume in Germany in 2016? | GT: Krombacher | Pred: print(\"Oetinger\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1898: Q: How much did Manchester United's operating expenses in 2020 amount to? | GT: 645.88 | Pred: print(\"522.2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1899: Q: What percentage of the Dominican Republic's GDP would be lost as a result of the COVID-19 pandemic? | GT: 0.8 | Pred: print(\"6.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1900: Q: What percentage of the Dominican Republic's GDP would be affected by the COVID-19 pandemic? | GT: 6.1 | Pred: print(\"6.1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1901: Q: What percentage of Netflix subscribers said they would keep the service if the monthly price increased by five dollars per month? | GT: 53 | Pred: print(\"99\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1902: Q: Which candidate received the most donations from the oil and gas industry? | GT: Hillary Clinton | Pred: print(\"Marco Rubio\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1903: Q: When is the forecasted year with the highest consumption volume? | GT: 2020 | Pred: print('2020')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1904: Q: What is the average annual consumption of biodiesel in OECD countries? | GT: 21759.24 | Pred: print(\"20755\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1905: Q: In what year did the turnover of the retail sale of leisure products increase to 6.7 billion British pounds? | GT: 2017 | Pred: print(\"2017\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1906: Q: What percentage of 17 year olds attended school? | GT: 93.3 | Pred: print(\"93.3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1907: Q: What percentage of 14 year olds were schooled in 2017-2018? | GT: 98.8 | Pred: print(\"98.8\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1908: Q: What was Sweden's per capita gross domestic product in kronor in 2019? | GT: 488 | Pred: print(\"488\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1909: Q: What was the value of the gross domestic product in Sweden in kronor in 2019? | GT: 488 | Pred: print(\"488\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1910: Q: In what year did the per capita gross domestic product reach its highest value? | GT: 2019 | Pred: print(\"2019\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1911: Q: What was the population of Eswatini in 2017? | GT: 1.1 | Pred: print(\"1.09\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1912: Q: What was the inflation rate in Suriname in 2019? | GT: 4.39 | Pred: print(\"6.94\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1913: Q: What was the share of consumers who wrote checks in 2018? | GT: 31 | Pred: print(\"31\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1914: Q: How many specialised stores were there in the UK in March of 2020? | GT: 15 | Pred: print(\"240\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1915: Q: Which country is the most active in CAR cell therapy trials? | GT: China | Pred: print(\"United States\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1916: Q: What was the most valuable British-Dutch oil and gas company in 2021? | GT: Shell | Pred: print(\"Shell\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1917: Q: What was the only brand in the top ten with headquarters outside of the UK? | GT: Shell | Pred: print(\"Shell\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1918: Q: What was the second most valuable oil and gas company in the UK in 2021? | GT: BP | Pred: print(\"BP\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1919: Q: Where did migrants arrive from January to December 2018? | GT: Pozzallo | Pred: print(\"Pozzallo\")\n",
            "Sample 1920: Q: Which country ranked second in the Italian migration chart? | GT: Lampedusa | Pred: print(\"Lampedusa\")\n",
            "\n",
            "==============================\n",
            "ChartGemma SOTA Results (first 25)\n",
            "==============================\n",
            "Total samples: 1920\n",
            "Exact Accuracy: 0.0000\n",
            "Relaxed Accuracy: 0.5969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4HOPPw0tn7GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Baseline: CLIP --> LLM"
      ],
      "metadata": {
        "id": "m5SN8JbdY10e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from datasets import load_dataset\n",
        "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1️⃣ Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2️⃣ Load CLIP\n",
        "clip_model_name = \"openai/clip-vit-base-patch32\"\n",
        "clip_model = CLIPModel.from_pretrained(clip_model_name).to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(clip_model_name)\n",
        "\n",
        "# 3️⃣ Load Qwen (frozen)\n",
        "qwen_model_name = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
        "qwen_tokenizer = AutoTokenizer.from_pretrained(qwen_model_name)\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(qwen_model_name, device_map=\"auto\").to(device)\n",
        "qwen_model.eval()\n",
        "for param in qwen_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 4️⃣ Projection layer: CLIP embedding -> Qwen embedding\n",
        "clip_embed_dim = clip_model.config.projection_dim\n",
        "qwen_embed_dim = qwen_model.config.hidden_size\n",
        "image_proj = nn.Linear(clip_embed_dim, qwen_embed_dim, device=device, dtype=qwen_model.dtype)\n",
        "optimizer = torch.optim.Adam(image_proj.parameters(), lr=1e-4)\n",
        "\n",
        "# 5️⃣ Load ChartQA val subset (first 25 for example)\n",
        "dataset = load_dataset(\"HuggingFaceM4/ChartQA\")[\"val\"]#.select(range(25))\n",
        "dataset = [dict(ex) for ex in dataset]\n",
        "\n",
        "dataset_train = load_dataset(\"HuggingFaceM4/ChartQA\")[\"train\"]#.select(range(3000))\n",
        "#dataset_train = [dict(ex) for ex in dataset_train]\n",
        "\n",
        "# 6️⃣ Training: regress projected CLIP embedding to Qwen embedding of question\n",
        "loss_fn = nn.MSELoss()\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for ex in tqdm(dataset_train, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        image_obj = ex[\"image\"]\n",
        "        question = ex[\"query\"]\n",
        "\n",
        "        # ---- CLIP image embedding ----\n",
        "        if isinstance(image_obj, str):\n",
        "            image = Image.open(image_obj).convert(\"RGB\")\n",
        "        else:\n",
        "            image = image_obj.convert(\"RGB\")\n",
        "\n",
        "        clip_inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            clip_output = clip_model.get_image_features(**clip_inputs)\n",
        "            if isinstance(clip_output, torch.Tensor):\n",
        "                clip_emb = clip_output\n",
        "            elif hasattr(clip_output, \"pooler_output\"):\n",
        "                clip_emb = clip_output.pooler_output\n",
        "            elif hasattr(clip_output, \"image_embeds\"):\n",
        "                clip_emb = clip_output.image_embeds\n",
        "            else:\n",
        "                raise ValueError(\"Cannot extract tensor from CLIP output\")\n",
        "        clip_emb = clip_emb.to(dtype=image_proj.weight.dtype, device=device)\n",
        "        proj_emb = image_proj(clip_emb)  # [1, qwen_embed_dim]\n",
        "\n",
        "        # ---- Qwen embedding of question ----\n",
        "        token_ids = qwen_tokenizer(question, return_tensors=\"pt\").input_ids.to(device)\n",
        "        with torch.no_grad():\n",
        "            qwen_embeddings = qwen_model.get_input_embeddings()(token_ids).mean(dim=1)  # average over tokens\n",
        "\n",
        "        # ---- Compute loss & update projection ----\n",
        "        loss = loss_fn(proj_emb, qwen_embeddings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} avg loss: {total_loss/len(dataset):.4f}\")\n",
        "\n",
        "# 7️⃣ Inference: use projected image embedding as prefix for question\n",
        "def run_clip_qwen(image_obj, question):\n",
        "    if isinstance(image_obj, str):\n",
        "        image = Image.open(image_obj).convert(\"RGB\")\n",
        "    else:\n",
        "        image = image_obj.convert(\"RGB\")\n",
        "\n",
        "    clip_inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        clip_output = clip_model.get_image_features(**clip_inputs)\n",
        "        if isinstance(clip_output, torch.Tensor):\n",
        "            clip_emb = clip_output\n",
        "        elif hasattr(clip_output, \"pooler_output\"):\n",
        "            clip_emb = clip_output.pooler_output\n",
        "        elif hasattr(clip_output, \"image_embeds\"):\n",
        "            clip_emb = clip_output.image_embeds\n",
        "        clip_emb = clip_emb.to(dtype=image_proj.weight.dtype, device=device)\n",
        "        proj_emb = image_proj(clip_emb).unsqueeze(1)  # [1,1,qwen_embed_dim]\n",
        "\n",
        "    # Text embeddings\n",
        "    token_ids = qwen_tokenizer(f\"Question: {question}, You are a chart question-answering assistant. Use the chart to respond to the question with the final answer only, no explanations.\", return_tensors=\"pt\").input_ids.to(device)\n",
        "    text_emb = qwen_model.get_input_embeddings()(token_ids).to(dtype=image_proj.weight.dtype, device=device)\n",
        "\n",
        "    # Concatenate image + text\n",
        "    inputs_embeds = torch.cat([proj_emb, text_emb], dim=1)\n",
        "\n",
        "    # Generate answer\n",
        "    with torch.no_grad():\n",
        "        outputs = qwen_model.generate(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            max_new_tokens=32,\n",
        "            num_beams=4,\n",
        "            eos_token_id=qwen_tokenizer.eos_token_id,\n",
        "        )\n",
        "    answer = qwen_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# 8️⃣ Test baseline\n",
        "exact_correct = 0\n",
        "relaxed_correct = 0\n",
        "\n",
        "for i, ex in enumerate(dataset):\n",
        "    image_obj = ex[\"image\"]\n",
        "    question = ex[\"query\"]\n",
        "    gt_answer = ex[\"label\"][0]\n",
        "\n",
        "    try:\n",
        "        pred_answer = run_clip_qwen(image_obj, question)\n",
        "    except Exception as e:\n",
        "        pred_answer = \"\"\n",
        "        print(f\"[WARN] Error on sample {i}: {e}\")\n",
        "\n",
        "    # Exact match\n",
        "    if pred_answer.lower() == gt_answer.lower():\n",
        "        exact_correct += 1\n",
        "\n",
        "    # Relaxed match: numeric closeness (5%) or substring\n",
        "    try:\n",
        "        gt_val = float(gt_answer)\n",
        "        pred_val = float(pred_answer)\n",
        "        if abs(pred_val - gt_val) / max(gt_val, 1e-6) <= 0.05:\n",
        "            relaxed_correct += 1\n",
        "    except:\n",
        "        if gt_answer.lower() in pred_answer.lower():\n",
        "            relaxed_correct += 1\n",
        "\n",
        "    print(f\"Sample {i+1}: Q: {question} | GT: {gt_answer} | Pred: {pred_answer}\")\n",
        "\n",
        "total = len(dataset)\n",
        "print(\"\\n==============================\")\n",
        "print(\"CLIP → Qwen PROJECTION RESULTS\")\n",
        "print(\"==============================\")\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact Accuracy: {exact_correct/total:.4f}\")\n",
        "print(f\"Relaxed Accuracy: {relaxed_correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "47cefe835b51453aa82878817e1a2e97",
            "1eaaad436be848758a2acbd013c8d3f7",
            "ceeb2ca7883a49618e8c311fef55928d",
            "7b556dec590a4e81b96b9f9fbd27ac2f",
            "54c9c44ddf054550bdfacd9b2974a591",
            "6c91efab70c8417393c2c3688afbf0b4",
            "29477b94e84a49fea68f8fca0ab6f2af",
            "34cae60601bb4d23b8832776e5e80062",
            "9affc34b1e1f428bbf8200fa956b9f21",
            "51f5b16315bd47c0838201cc27eed6e1",
            "d2158320534849af99ca56b9ad1a0685",
            "b8378a0ee82441c2ba5bb282a717eac5",
            "3d3110050d994f2fb251372a22d5fb16",
            "4fffef4cc7044fefbf15505d15b167ad",
            "00b6367a685045cc81ac39f550e025d5",
            "6469f7de07c345528b6385a72065a0a7",
            "3e3d5a84b85f4d55a5d210d684a76f67",
            "cd67eb9fab5c407f8c1c1bd4bf08cca4",
            "25d67078a6e041a9bab9573a1061bf77",
            "7616f5e8611f4b61a650043886bc6f57",
            "b7fd36b24c78407ab2bc0fc4314a5a6f",
            "a8f669de74a94c51b641c28378efd79e",
            "3f7d2e8f2dcd4b0d868ad5a91a4311db",
            "7e3021fc128e4cd3949e9146899a89e6",
            "6ec79224dcbd4b1ab9a4d1a8601f5f88",
            "64c873c30cb240318ee8352da5d7a097",
            "45758b22aa0b4f739693062bf31f5cff",
            "4ef250968e3e489ba0642be9a35dcc88",
            "0233a41b85de4eeea54763c7f51cc9b8",
            "79f2769370b54fc6b53af91b566c279b",
            "b5cd86537ddd4374a462ece8648b3f59",
            "9831ae2a9d054c42acbd7aa956f4f6a3",
            "a9477676d5a04a3eb24132a5c47f7bb4",
            "516c3a706fff4adbb748f70594cdfd69",
            "b07bc360d51044ad86b28bcd902532c3",
            "dad7d7fc16cb4f3d8524353372ad5652",
            "64d7d685e42345c099482579b225ab29",
            "631bf725caa24a82b2b400a16b0cbead",
            "d3461752cfca46ed8102ea8f6aedb5f0",
            "261df6c768044d7ab07e82a85782562a",
            "3f7f3b31357b430f97920fda64ceaae8",
            "82019471e964461bbf15a646b2806329",
            "fb73ee49018440b38f4c308ac734b0e7",
            "c37625107d2b4b9f91b6800760dfa0d6",
            "3a1c9c2d6bc64021a852fbfcd99f3aaa",
            "b573354988a0416daee4a01d01162b85",
            "0ef59b2447894ccda38838005271baf9",
            "4c1bf70ba9964160860b998b10db536d",
            "bba6f11047c3435bbbd9f3dafc71b8eb",
            "f8919d4fd0d743578bcc54aa9e70117f",
            "7b3bd40c4e6c41fa9df35124c963b614",
            "155be15a14044a1aaca52ad70f63c0fe",
            "c648c277e9d34c83b1ecf7716e486d1d",
            "75478a5bee0e46f5a5e33b87df91df9b",
            "d605822ba8c94a34be9164252ba33fcb",
            "1f2b955aa0344c5e8f3cc9cea4466139",
            "3f60565f17164a7e8dcecf87c49cee9d",
            "11d5316e8e2c4b85b034256ca9f80744",
            "907c0ec9321b4650930d87a4f6d0b969",
            "2f13a575784840c199e41a708b799d19",
            "770486e0430f4ed09113259648aaa37b",
            "6d2cf1d5ed6d493d9caf6d88ac53bf84",
            "84d2cb6a54754c2fa92ce2bb7d925d7c",
            "f6e399e179ab4005b43a69b35effb943",
            "696cdb6374b9484783866a7a9975d383",
            "58fbea18476a49c3940867b1ac3b6bbf",
            "0240ecc2162f4980a0c055c8aafd867e",
            "962c12ffa14a4fc8b5346ceba9102a10",
            "344e73fe41c04f819d2efae81006ec91",
            "ba214048317c4b2e84393b01cc61583c",
            "25538e69bd1e474698ca59e9bc438b49",
            "0a5003637468480eb615685849f942d3",
            "2ed8c75322114478bde1ba4d04ac0b34",
            "c8268e25b0b74de883a00d71c9521248",
            "1ac7bc9027954bebbe4648bb09814178",
            "7b5a17b31dd046509bf502290f846ff1",
            "b492841b4c6f4b02a41cb1bf9a2474c9",
            "5036dc9f02c74bd09d9480064d830615",
            "140cbc23c4364ffea5f089c0b4af6272",
            "fea6d7eb309a42ce9f0375807ad8e6f0",
            "b03b097803c14b7182e95a371e124c5e",
            "426f664a18e94a1790af0bdf762c0276",
            "1b6ba34fddc34d0ca53210d724a4ef7d",
            "dca68de6f666442491f168b16b8ae08a",
            "e520946e825747699bf6a31cdef5f545",
            "8f56884ca72143c1b00253e63be91383",
            "0f4418fbc72049c7a4a49ec2695033d8",
            "969889f994a747cba69d099e516ab439",
            "6d2ef200c2b343feb2aa3180cd4f12e1",
            "9b6ab56c1af74e83a266cd8e0159ac9f",
            "1f45918e65fc46b7ad60e09b822fc768",
            "b18e1e9ed38845dd87b7e62cdb98a09d",
            "b78fedbe8ba74c1db7a0f4372b656fb3",
            "8556e508cc754b109701464509aff597",
            "4aca0a95b4d9427baddeacaecd3dfcc1",
            "7e2acc94172d4f67b6f886fd84de00ff",
            "c4234648e2e342ba8fc41e20a03afb35",
            "270a3c8e2cee4a37aa3d3c65f9b484ee",
            "4374ae5e07154a2bb19864e3268d0f21",
            "0e1edec1aa354681bd27c3545886b33b",
            "9a8909c170854780b70e622a22e21ab4",
            "8946d4575c3d46e9927be0a239180390",
            "e2ffb0f025984d62934fc4e5b637989a",
            "dc3d4faae0014b789a44768120fe735f",
            "f629845f4a694b66bb75ae8f7d5b977e",
            "d8a45d46d19c4a42a06578d4a52632a7",
            "015be046593346d780785714254db505",
            "f557561c2d5f41fa8ab3a06129139606",
            "b8a0b8d8e77448998011f7a38d3b83d7",
            "f4ab29ce7425493dac98575490f023f2",
            "63a4a07987bf4c19b7ec266e47419066",
            "fa544ac4405546bbaeffdc1b9244a668",
            "04d64188c18e408594135c6f60f1dee8",
            "a8b167128d1f449892595b807a5c4499",
            "71896c82b1b64684b0e58506e2366a75",
            "7a20d120d4264f7a8c9070877fe5e492",
            "5553535ba4254de99cb505f642c8495e",
            "94549d944ee94c1ea705b424654970ea",
            "5b3cdbd536634b7fbca59b9afa787ce4",
            "9cbc6b05e657412f9e167e0b6e778831",
            "c32980cfcf774ea7902cdd09a1c0bb4f",
            "2cda345c012e47a0873371fe348b6055",
            "3b2ece92b7eb4218b599e4e8cd9bf1cd",
            "e33975eddc654b38aaa866ec5f6cbe89",
            "07e7a703754f44bd9e63719f9d50e773",
            "c0532e53876a47ad8a147b801f37a258",
            "83db858ccb3d40d6a2fcd864bb08f056",
            "9b22294387274db9b6c29630e7418a27",
            "c9ca73f11bf149469c9707de3594d632",
            "1636b0f66d7345558a74a0aae802e77e",
            "9b12f6fda31c46ffa3e0bb6d6d4ea2f1",
            "14a17c23fe0a44c397fb39b30f03edb9",
            "5c1b29de9d5c4466a83768bb8140624c",
            "871645fcd3e94a34bda09441fa7588d8",
            "5e474a10dd0143469a79c8e931242cc6",
            "8d2230caec94469ea6b45ad63a7c5236",
            "f5200584dac24072ad828e66fd68fa55",
            "b98b393921d94b6ca6953a257f2a0fff",
            "f3bfdecb1873485b800a1663272fb2bd",
            "1594fd0a2e2343d6b356d9d05f639158",
            "7948996ade35468590180d4983bf2ffe",
            "6da0287a2651460bb93c1a32988a632d",
            "977bd136b5c2457694ec471624daf211",
            "f871aec396dc4cfb9773c500cdd3ed18",
            "8fc080a673eb41a48a4eb86797beda00",
            "c2f23b46cd764b0a9f1f7fcd3a59fe7b",
            "9fe7a276d4514cbc9b2cfead8ace9b1b",
            "bbd8da75e20f424da7c5bc34696ab5b0",
            "14809a2d922c485f9474528a3719eaf0",
            "b25287172d5a4e6b9807632d204770c8",
            "425222ce878747299b14dfd9cfab3c33",
            "b93be3bdcbc742da8d651bf5d921cbe5",
            "e5272a25544043ab80e5a49a6aecbfc8",
            "91f111af841944ec95884b9fec4f29f5",
            "17927b5bfc0c424aac7b7ef26b08db63",
            "dc1c33834b184a24bea03b574837d2fb",
            "b2c5d432eda447e5a646a25815574762",
            "7ce07e0d4f274905a3328303a13a09f6",
            "641288fa97b6419c8df11c5b3b8e553b",
            "18afdae5a65245ae886ce0413013004a",
            "9e5ed36d3a80492787ab9be3c6382b8d",
            "d436cceb712749dca3aa2a388b135013",
            "93bd1034494b462aa2e6ea9b2863c626",
            "71c80c8c67c6458b9924f3f5082d9088",
            "e9e4323b67044e22b875b5e5b65b1e0b",
            "e83d74989a85461d97228746b9307e61",
            "d154e4e785ba4359b6fddd4b604a39fd",
            "07fd5d4d7df84777a41c652e6ea0af4c",
            "094143792b2e435986635f120032ae69",
            "a8ee0650bb9c4993aa2176922f36afda",
            "5e4d6b9fc9d34d9bac17950d59368107",
            "698dacf08578425daac9463a4be57f82",
            "5390213f3b9942dab5edaaf23eefc60f",
            "46c56ee255e4427aa0509665b6adee75",
            "5b3b22da1ef64e4da4fc57feb6c07468",
            "4e47a2548b994ec3826525f5f268b984",
            "1966cfec66194355a6991cd229af9020",
            "b8e188fa504546c785b0354f8a9bdef9",
            "d7e389c7eaca493fa21a2f9c8d4157e8",
            "7b7acec4e8c545b5a30432b18bf82293",
            "b34999df81b544bf9d527437b7918998",
            "8b21c7b91f23488caadac22317da4069",
            "1f95843f3bbb4257a0aa5b6f2db7e1a9",
            "742268e024334d7791c952af71c063db",
            "4cd85a6e3106445689d076c9e610f28e",
            "e50ec3842451441ba539203d142b3400",
            "98adfb90bbad4587a0fe6d3593ceaa67",
            "473e456f64f1417cb0342245d5deeaac",
            "7578c37dd0824631a63e333b26b1a3a6",
            "dbe4b07bb5fb4c58b09c38db54678cbc",
            "eb376badb6164738bd837aaa2e585639",
            "d9dc7d824f7246ea8ffb7dde04583b1b",
            "c854bef519b640fba1546f0f449984ca",
            "4396a49fcadc47d1a610e53aa3cc6791",
            "6de076c2b5a04fffb0d9ba9c5e4384c0",
            "a85cb1449c3a4f6dbd96de35489ce619",
            "ee87a70d176d4ade9f5708d9eb2d5633",
            "d92da2f51ca1477588bd9e8175ebe40d",
            "9dcad1322f584fe4be3c5dbd0dc28f5c",
            "4361cdfa1fb54e14af52881d3ceff81a",
            "6b841700d4204ebfa79212b6de9d8df6",
            "8ba41e21adb640b4bc167943c768901e",
            "728f56649c6b47509500cc485f3059e9",
            "1389d4495eaf44ca93aff51f1acc5904",
            "0942697bf8e74b8699c2059c319bdac6",
            "673e92b8b5014aa0bf2ea536d5036d40",
            "35522276fda94a19817bf681a4e41e07",
            "b0b51864294e46988ccaf7d208d54dbf",
            "865c5be7e4794d5682106f032e128b23",
            "3af5e191d8c94b90b421207dfd8bb0f2",
            "55ebb7a9535e4669a5fbee4d9b732bd7",
            "486947efabaa4f60b777216f481aaede",
            "ea58db00e31d4d5eb155ba97061bad24",
            "55f3e8e70edc4877802090baf6ad1bf9",
            "b795c31068ab4cb2b452e46a996436fc",
            "76f8671ce1ea4f368761839d097d51b8",
            "feb578a7d8c342139b350b0e2bf91581",
            "92539627e5ca4e2bb8262f0752c54ef8",
            "883220be21cd41e8a3ca187b99d83d32",
            "66a1c21dd64942b9ba4861e3e201b8b4",
            "a055e9b6e3a9403facfa5f15960474eb",
            "b8c66b8c9fc54454822d8aff582ee504",
            "51bbd850b50b43679584e6c940df3374",
            "1e88890974eb4a258a09cc1912ffc721",
            "9a9227ff02784e6d86d375e4aac6ccbb",
            "f797bab8a5e14a93a4b3e3c2f1c87fa9",
            "258ba2e2bcc9491cb633f9e1bbde9fa6",
            "e228627dea7941cd8cff0a6ceff47d5f",
            "70aa36e6dcd04793849a76db7ca44bb5",
            "d1f5e912c5cf408b8e59ba99a6e75d29",
            "c3f3f3bad55d4e3083bb049080ee1544",
            "add47dd08300451b8fd7a114aa25ded4",
            "3fe965be919f403aa784c0c653583a93",
            "523f163ab3164d0f96b8368197f2f3b0",
            "491bd943bcfa43d796541c54e1ab31cb",
            "4a96f70b64db463eac9fd4187d7f03ea",
            "4a4fda8e000f4162b7092cbef623cd6d",
            "38489a114b6a4ed49d2afc3131416a53",
            "d34879aaffb34827a771ac0e523597ba",
            "9060c58be93d497b82482f7ac7728a16",
            "e17aac387ee240cc9057a4dc3552ae58",
            "92df41774cd648bbb19999682d1cb20e",
            "2bede184af3d4045acfb907601311afe",
            "ca99fe0d35d7432ea3c426d81cf806c3",
            "660fa5c8411d48a49c850e5f8e79a0fd",
            "c6c46d01835b43ef89b2bb592908fd7b",
            "79286da9a5454e69a325ebc48e2894d0",
            "adef94f03d734b80840ba007a294ebb3",
            "ab54aa8faa374459ba20f57c0ef924f1",
            "83c08a342b9d4f9b82d410ad135d4985",
            "f699bd486adf4321b16751c29d600471",
            "0a989b3d84794f0696a7159199979f52",
            "93333e3f94e4434d8cf91a015e250d5c",
            "1d5b06efa5cd4262be14e0e53c0d89b9",
            "e05e1a52513249bfa9d067d8374f56a2",
            "8383039e69794cc1b52f3d2c3f312212",
            "e8d7cfb16222472fb2f7c1969f14b43c",
            "73b5aae0af4443869fd95a0c346276d5",
            "cf4fbe6b42db4080872d549ae3918f83",
            "40211c7c69c04aee95a429a320f8043d",
            "f2db94d408ff4ac29504cf23a4ec9fff",
            "87ef5fc2d87647f08a5b39f325371596",
            "27f8b46607524a568ceff79fcb290dc7",
            "bded3e7a0d384a87ab444dfa93678380",
            "f294b07243054a48a0d42ee4630e49d7",
            "8e74cef6e79349e3a593a9db0f02cdf3",
            "3dec9c62a1a845da80113e6388c39c7c",
            "281d1f6024de4ac99b34a447b0c1dfc2",
            "e150e29276514ff8bd532aa4326f187c",
            "121ab8a342db4cd6b57fb0760941cbe2",
            "52108163e3034c7f87a5f09c893e3273",
            "48a30cfed4dd467aac899b3c8cdca3d7",
            "bf4f697f16f34941bac8a4cc05c2ca2c",
            "2e1aee1628a1490895f29d485baab37d",
            "88cc8b668fce486086af76b8c5ca6dad",
            "f132b60b69f34e5bb777a346e9197d4d",
            "b86d818afbd643588a095406aa09f29e",
            "039209e37f4f45ec90beee4169d7cbd3",
            "6a0c9e6c2e274734b4d722b75537d575",
            "223bca825c1a40cbaf20fbd38d9dbda7",
            "38533e82c0f44ee790567ca4dcd437a3",
            "ce926e0472904dd7aecb76f8c0c1b9b2",
            "1076fdaf2730453e80d4a00607d2ff5d",
            "e926f07b05e340ebab4c2fcac6270792",
            "18aa7d34da404d3ab87b07c779dbbe3f",
            "07ab87f09c3c40a5bf241ba484c86d73",
            "d2b2d84218f644d59104d04c6a1d1eb6",
            "46ad75ee97cd4163abeb454fbc7c699a",
            "26e6693ecbb048fab5e500a1be6fb87e",
            "4b6268c092d9467ca638313aefa9c40f",
            "46208855a18e4faf94fcfbda35cb0e88",
            "e5086c3136224051982916f7dfb302ed",
            "bf067a7e58d0449795bb8ab1a4018477",
            "0902abad8646456ebd7d232a49ecf9cc",
            "be28e42a6a694fe18cb4817149d02f1c",
            "a474d7caff814e209bd4b942893a1706",
            "d4c003fc96b64823a75eb16991325c78",
            "0ed5c3e762614393be5b9def9230d4ea",
            "923e5d1aded94dfeba1a684de3022019",
            "b67b20daf51a45c281816f69e347f83d",
            "56665084a0ed4d1a9e4926997c6f490b",
            "4d3de7733c214d5b998785d48c3ea558",
            "c403d936b97c4d6e8d6776fad8096a6d",
            "03410086a4b8456cbc1fe715c9c5fb69",
            "9711471a95f24851be316d2dbb284679",
            "c57ef0aa05e9427f8eacd78b8899bf29",
            "0649d3db45644ac2ae02b24679f470b6",
            "1f2c719aef524583a638d303152e4075",
            "48b81a50e9e04c4e8d457796a80051a3",
            "f9adf81376584383b8e3e6b6cf9a6b9e",
            "4e158289052b485293911c7946a5ac5f",
            "2571fd553db746d99f6c585bb2d4e53b",
            "4be15da9b0fb4bf19af94970e2e9aeab",
            "415bf2a3e6304d66bb2d9dd6935d6577",
            "ec4d1b6d6c48498696035134cc56c887",
            "6ef0d392398c4d8a9575e459a7cfa6d8",
            "e80dbf0186754d87bf321099f549cd58",
            "5c4a145de0714ae48e7d933bb89c5523",
            "56ad08ef36d04de08753ddc574494d86"
          ]
        },
        "id": "R7Zdf6PoYggv",
        "outputId": "3b7fd816-51d1-439a-92b1-9f57a9114fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47cefe835b51453aa82878817e1a2e97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8378a0ee82441c2ba5bb282a717eac5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f7d2e8f2dcd4b0d868ad5a91a4311db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CLIPModel LOAD REPORT from: openai/clip-vit-base-patch32\n",
            "Key                                  | Status     |  | \n",
            "-------------------------------------+------------+--+-\n",
            "vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
            "text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "516c3a706fff4adbb748f70594cdfd69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a1c9c2d6bc64021a852fbfcd99f3aaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The image processor of type `CLIPImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f2b955aa0344c5e8f3cc9cea4466139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0240ecc2162f4980a0c055c8aafd867e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5036dc9f02c74bd09d9480064d830615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d2ef200c2b343feb2aa3180cd4f12e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e1edec1aa354681bd27c3545886b33b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63a4a07987bf4c19b7ec266e47419066"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cda345c012e47a0873371fe348b6055"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c1b29de9d5c4466a83768bb8140624c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f871aec396dc4cfb9773c500cdd3ed18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17927b5bfc0c424aac7b7ef26b08db63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e83d74989a85461d97228746b9307e61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1966cfec66194355a6991cd229af9020"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "473e456f64f1417cb0342245d5deeaac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dcad1322f584fe4be3c5dbd0dc28f5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3af5e191d8c94b90b421207dfd8bb0f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/852 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a055e9b6e3a9403facfa5f15960474eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00003-49492f364babfa(…):   0%|          | 0.00/219M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "add47dd08300451b8fd7a114aa25ded4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00003-7302bae5e425bb(…):   0%|          | 0.00/311M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bede184af3d4045acfb907601311afe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00003-194c9400785577(…):   0%|          | 0.00/315M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d5b06efa5cd4262be14e0e53c0d89b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/val-00000-of-00001-0f11003c77497969(…):   0%|          | 0.00/50.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f294b07243054a48a0d42ee4630e49d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001-e2cd0b7a0f9eb20(…):   0%|          | 0.00/68.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f132b60b69f34e5bb777a346e9197d4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/28299 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2b2d84218f644d59104d04c6a1d1eb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating val split:   0%|          | 0/1920 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ed5c3e762614393be5b9def9230d4ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48b81a50e9e04c4e8d457796a80051a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1/5:  26%|██▌       | 7237/28299 [02:46<08:33, 41.04it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7242/28299 [02:46<08:30, 41.27it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7247/28299 [02:46<08:32, 41.09it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7252/28299 [02:47<08:36, 40.77it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7257/28299 [02:47<08:31, 41.10it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7262/28299 [02:47<08:30, 41.19it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7267/28299 [02:47<08:40, 40.39it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7272/28299 [02:47<08:50, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7276/28299 [02:47<08:56, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7280/28299 [02:47<09:06, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7284/28299 [02:47<09:09, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7289/28299 [02:48<08:56, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7294/28299 [02:48<08:49, 39.69it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7299/28299 [02:48<08:42, 40.16it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7304/28299 [02:48<08:41, 40.28it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7309/28299 [02:48<08:33, 40.84it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7314/28299 [02:48<08:34, 40.77it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7319/28299 [02:48<08:34, 40.75it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7324/28299 [02:49<15:18, 22.84it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7328/28299 [02:49<13:45, 25.41it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7332/28299 [02:49<12:27, 28.05it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7336/28299 [02:49<11:25, 30.57it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7340/28299 [02:49<10:40, 32.72it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7344/28299 [02:49<10:15, 34.07it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7348/28299 [02:49<10:02, 34.77it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7352/28299 [02:49<09:47, 35.65it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7356/28299 [02:50<09:57, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7360/28299 [02:50<09:50, 35.49it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7364/28299 [02:50<09:35, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7368/28299 [02:50<09:23, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7372/28299 [02:50<09:25, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7376/28299 [02:50<09:27, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7380/28299 [02:50<09:24, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7384/28299 [02:50<09:19, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7388/28299 [02:50<09:17, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7392/28299 [02:50<09:13, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7396/28299 [02:51<09:23, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7400/28299 [02:51<09:35, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7404/28299 [02:51<09:39, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7408/28299 [02:51<09:49, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7412/28299 [02:51<09:56, 35.03it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7416/28299 [02:51<09:44, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7420/28299 [02:51<10:31, 33.07it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7424/28299 [02:51<10:32, 33.03it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▌       | 7428/28299 [02:52<10:07, 34.36it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7432/28299 [02:52<10:02, 34.63it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7436/28299 [02:52<10:00, 34.72it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7440/28299 [02:52<09:46, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7444/28299 [02:52<09:46, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7448/28299 [02:52<09:37, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7452/28299 [02:52<09:34, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7456/28299 [02:52<09:41, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7460/28299 [02:52<10:04, 34.47it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7464/28299 [02:53<09:48, 35.40it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7468/28299 [02:53<09:39, 35.95it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7472/28299 [02:53<09:36, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7476/28299 [02:53<09:36, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7481/28299 [02:53<09:11, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7485/28299 [02:53<09:19, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7489/28299 [02:53<09:18, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7494/28299 [02:53<08:57, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  26%|██▋       | 7498/28299 [02:53<08:58, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7502/28299 [02:54<08:53, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7506/28299 [02:54<09:01, 38.37it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7510/28299 [02:54<08:56, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7515/28299 [02:54<08:40, 39.96it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7520/28299 [02:54<08:37, 40.14it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7525/28299 [02:54<08:36, 40.20it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7530/28299 [02:54<08:33, 40.45it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7535/28299 [02:54<08:32, 40.48it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7540/28299 [02:54<08:37, 40.12it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7545/28299 [02:55<08:34, 40.38it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7550/28299 [02:55<08:39, 39.94it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7554/28299 [02:55<08:47, 39.30it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7558/28299 [02:55<09:15, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7562/28299 [02:55<09:13, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7566/28299 [02:55<09:17, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7570/28299 [02:55<09:16, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7574/28299 [02:55<09:14, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7579/28299 [02:56<08:58, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7583/28299 [02:56<08:59, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7587/28299 [02:56<09:05, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7592/28299 [02:56<08:49, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7596/28299 [02:56<08:57, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7600/28299 [02:56<09:05, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7604/28299 [02:56<09:12, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7608/28299 [02:56<09:06, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7612/28299 [02:56<09:07, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7616/28299 [02:56<09:05, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7620/28299 [02:57<09:01, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7625/28299 [02:57<08:46, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7630/28299 [02:57<08:33, 40.26it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7635/28299 [02:57<08:34, 40.19it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7640/28299 [02:57<08:26, 40.78it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7645/28299 [02:57<08:33, 40.24it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7650/28299 [02:57<08:52, 38.76it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7654/28299 [02:57<09:15, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7659/28299 [02:58<08:58, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7663/28299 [02:58<08:58, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7668/28299 [02:58<08:41, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7672/28299 [02:58<08:46, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7676/28299 [02:58<08:59, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7681/28299 [02:58<08:44, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7686/28299 [02:58<08:36, 39.91it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7690/28299 [02:58<08:42, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7694/28299 [02:58<08:46, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7699/28299 [02:59<08:37, 39.80it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7704/28299 [02:59<08:29, 40.41it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7709/28299 [02:59<08:26, 40.69it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7714/28299 [02:59<08:46, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7718/28299 [02:59<08:50, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7723/28299 [02:59<08:36, 39.84it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7728/28299 [02:59<08:31, 40.25it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7733/28299 [02:59<08:26, 40.57it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7738/28299 [03:00<08:34, 39.99it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7743/28299 [03:00<08:41, 39.42it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7747/28299 [03:00<08:56, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7752/28299 [03:00<08:44, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7757/28299 [03:00<08:28, 40.40it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7762/28299 [03:00<08:38, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7766/28299 [03:00<08:59, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7770/28299 [03:00<08:57, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7775/28299 [03:01<08:48, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  27%|██▋       | 7779/28299 [03:01<08:48, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7783/28299 [03:01<08:44, 39.10it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7787/28299 [03:01<08:53, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7791/28299 [03:01<09:12, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7795/28299 [03:01<09:06, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7799/28299 [03:01<08:57, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7803/28299 [03:01<08:54, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7807/28299 [03:01<08:57, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7811/28299 [03:01<09:18, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7815/28299 [03:02<09:07, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7819/28299 [03:02<09:09, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7823/28299 [03:02<08:59, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7828/28299 [03:02<08:48, 38.73it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7833/28299 [03:02<08:36, 39.65it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7837/28299 [03:02<09:05, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7841/28299 [03:02<08:57, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7845/28299 [03:02<09:20, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7850/28299 [03:02<08:58, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7854/28299 [03:03<09:08, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7858/28299 [03:03<09:48, 34.74it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7863/28299 [03:03<09:20, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7867/28299 [03:03<09:14, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7871/28299 [03:03<09:18, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7876/28299 [03:03<08:59, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7880/28299 [03:03<08:57, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7885/28299 [03:03<08:41, 39.16it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7889/28299 [03:04<08:41, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7893/28299 [03:04<08:45, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7897/28299 [03:04<08:45, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7901/28299 [03:04<09:02, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7905/28299 [03:04<09:02, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7910/28299 [03:04<08:41, 39.13it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7915/28299 [03:04<08:32, 39.78it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7919/28299 [03:04<08:36, 39.47it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7923/28299 [03:04<08:44, 38.83it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7927/28299 [03:05<09:11, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7931/28299 [03:05<08:59, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7936/28299 [03:05<08:42, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7940/28299 [03:05<08:44, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7944/28299 [03:05<08:46, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7948/28299 [03:05<08:45, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7952/28299 [03:05<09:04, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7957/28299 [03:05<08:48, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7962/28299 [03:05<08:46, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7966/28299 [03:06<08:51, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7970/28299 [03:06<08:56, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7975/28299 [03:06<08:42, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7979/28299 [03:06<09:09, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7983/28299 [03:06<09:50, 34.40it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7988/28299 [03:06<09:17, 36.42it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7993/28299 [03:06<08:52, 38.14it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 7997/28299 [03:06<09:14, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8001/28299 [03:06<09:07, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8005/28299 [03:07<09:10, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8009/28299 [03:07<08:59, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8014/28299 [03:07<08:47, 38.49it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8019/28299 [03:07<08:37, 39.20it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8024/28299 [03:07<08:29, 39.83it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8029/28299 [03:07<08:22, 40.33it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8034/28299 [03:07<08:19, 40.59it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8039/28299 [03:07<08:19, 40.59it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8044/28299 [03:08<08:18, 40.61it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8049/28299 [03:08<08:15, 40.84it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8054/28299 [03:08<08:16, 40.74it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8059/28299 [03:08<08:16, 40.75it/s]\u001b[A\n",
            "Epoch 1/5:  28%|██▊       | 8064/28299 [03:08<08:09, 41.34it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8069/28299 [03:08<08:09, 41.34it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8074/28299 [03:08<08:03, 41.85it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8079/28299 [03:08<08:08, 41.35it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8084/28299 [03:09<08:11, 41.15it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8089/28299 [03:09<08:10, 41.16it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8094/28299 [03:09<08:24, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8099/28299 [03:09<08:22, 40.17it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8104/28299 [03:09<08:19, 40.45it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8109/28299 [03:09<08:23, 40.12it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8114/28299 [03:09<08:18, 40.47it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8119/28299 [03:09<08:25, 39.88it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8123/28299 [03:10<08:59, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8128/28299 [03:10<08:50, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▊       | 8132/28299 [03:10<08:47, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8136/28299 [03:10<08:53, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8140/28299 [03:10<09:04, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8145/28299 [03:10<08:44, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8150/28299 [03:10<08:29, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8154/28299 [03:10<08:39, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8158/28299 [03:10<09:07, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8162/28299 [03:11<09:06, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8166/28299 [03:11<08:59, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8170/28299 [03:11<08:52, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8175/28299 [03:11<08:38, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8180/28299 [03:11<08:23, 39.94it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8184/28299 [03:11<08:30, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8188/28299 [03:11<08:33, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8192/28299 [03:11<08:32, 39.25it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8196/28299 [03:11<08:44, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8200/28299 [03:12<08:42, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8204/28299 [03:12<08:57, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8208/28299 [03:12<09:03, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8212/28299 [03:12<08:52, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8216/28299 [03:12<08:50, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8220/28299 [03:12<08:44, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8224/28299 [03:12<08:38, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8229/28299 [03:12<08:31, 39.27it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8234/28299 [03:12<08:24, 39.79it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8238/28299 [03:13<08:27, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8242/28299 [03:13<08:32, 39.16it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8246/28299 [03:13<08:47, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8250/28299 [03:13<08:53, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8254/28299 [03:13<16:53, 19.78it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8258/28299 [03:13<15:16, 21.86it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8263/28299 [03:14<12:48, 26.06it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8267/28299 [03:14<11:34, 28.84it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8271/28299 [03:14<11:02, 30.22it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8276/28299 [03:14<10:03, 33.19it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8281/28299 [03:14<09:24, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8286/28299 [03:14<09:00, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8290/28299 [03:14<09:41, 34.42it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8295/28299 [03:14<09:11, 36.25it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8299/28299 [03:14<08:58, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8303/28299 [03:15<09:05, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8307/28299 [03:15<08:58, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8311/28299 [03:15<09:23, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8315/28299 [03:15<09:30, 35.03it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8320/28299 [03:15<09:03, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8324/28299 [03:15<08:58, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8329/28299 [03:15<08:37, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8333/28299 [03:15<09:34, 34.78it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8338/28299 [03:16<09:22, 35.48it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8342/28299 [03:16<09:34, 34.76it/s]\u001b[A\n",
            "Epoch 1/5:  29%|██▉       | 8346/28299 [03:16<09:51, 33.71it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8350/28299 [03:16<09:52, 33.66it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8354/28299 [03:16<09:30, 34.93it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8358/28299 [03:16<09:15, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8362/28299 [03:16<09:03, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8366/28299 [03:16<08:58, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8371/28299 [03:16<08:38, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8375/28299 [03:17<08:35, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8379/28299 [03:17<08:39, 38.37it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8383/28299 [03:17<08:41, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8387/28299 [03:17<08:40, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8391/28299 [03:17<09:24, 35.24it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8395/28299 [03:17<09:36, 34.52it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8399/28299 [03:17<09:28, 35.01it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8403/28299 [03:17<09:24, 35.27it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8407/28299 [03:17<09:30, 34.88it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8411/28299 [03:18<09:15, 35.83it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8415/28299 [03:18<09:01, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8419/28299 [03:18<08:55, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8423/28299 [03:18<08:46, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8428/28299 [03:18<08:27, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8433/28299 [03:18<08:23, 39.48it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8437/28299 [03:18<08:22, 39.52it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8442/28299 [03:18<08:17, 39.90it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8447/28299 [03:18<08:15, 40.09it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8452/28299 [03:19<08:18, 39.80it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8456/28299 [03:19<08:21, 39.59it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8460/28299 [03:19<08:29, 38.97it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8464/28299 [03:19<08:25, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8468/28299 [03:19<08:49, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8472/28299 [03:19<08:45, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8476/28299 [03:19<08:42, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8481/28299 [03:19<08:31, 38.72it/s]\u001b[A\n",
            "Epoch 1/5:  30%|██▉       | 8486/28299 [03:20<08:22, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8490/28299 [03:20<08:21, 39.49it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8494/28299 [03:20<08:31, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8498/28299 [03:20<08:36, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8502/28299 [03:20<08:32, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8506/28299 [03:20<09:05, 36.27it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8511/28299 [03:20<08:39, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8516/28299 [03:20<08:24, 39.18it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8520/28299 [03:20<08:27, 39.00it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8525/28299 [03:21<08:20, 39.48it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8529/28299 [03:21<08:38, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8534/28299 [03:21<08:26, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8538/28299 [03:21<08:28, 38.88it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8542/28299 [03:21<08:42, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8546/28299 [03:21<09:02, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8550/28299 [03:21<09:11, 35.78it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8554/28299 [03:21<09:06, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8559/28299 [03:21<08:46, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8563/28299 [03:22<08:45, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8567/28299 [03:22<08:39, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8571/28299 [03:22<08:32, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8575/28299 [03:22<08:36, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8580/28299 [03:22<08:26, 38.93it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8585/28299 [03:22<08:16, 39.74it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8589/28299 [03:22<08:19, 39.47it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8594/28299 [03:22<08:07, 40.43it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8599/28299 [03:22<08:03, 40.73it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8604/28299 [03:23<08:01, 40.89it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8609/28299 [03:23<08:01, 40.88it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8614/28299 [03:23<08:08, 40.28it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8619/28299 [03:23<08:09, 40.17it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8624/28299 [03:23<08:07, 40.38it/s]\u001b[A\n",
            "Epoch 1/5:  30%|███       | 8629/28299 [03:23<08:21, 39.20it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8633/28299 [03:23<08:23, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8637/28299 [03:23<08:23, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8641/28299 [03:24<08:26, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8645/28299 [03:24<08:22, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8650/28299 [03:24<08:16, 39.61it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8654/28299 [03:24<08:17, 39.50it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8658/28299 [03:24<08:40, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8662/28299 [03:24<08:58, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8666/28299 [03:24<08:59, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8670/28299 [03:24<09:25, 34.73it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8674/28299 [03:24<09:15, 35.34it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8678/28299 [03:25<08:59, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8682/28299 [03:25<09:04, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8686/28299 [03:25<08:56, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8690/28299 [03:25<09:02, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8694/28299 [03:25<08:48, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8698/28299 [03:25<08:42, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8703/28299 [03:25<08:24, 38.86it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8707/28299 [03:25<08:26, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8711/28299 [03:25<08:35, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8716/28299 [03:26<08:21, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8720/28299 [03:26<08:19, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8724/28299 [03:26<08:28, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8728/28299 [03:26<08:23, 38.83it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8732/28299 [03:26<08:25, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8736/28299 [03:26<08:39, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8740/28299 [03:26<08:42, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8744/28299 [03:26<09:00, 36.16it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8749/28299 [03:26<08:34, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8754/28299 [03:27<08:19, 39.10it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8758/28299 [03:27<08:17, 39.32it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8763/28299 [03:27<08:09, 39.95it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8768/28299 [03:27<08:00, 40.68it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8773/28299 [03:27<07:59, 40.75it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8778/28299 [03:27<08:20, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8782/28299 [03:27<08:18, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8786/28299 [03:27<08:19, 39.06it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8790/28299 [03:27<08:25, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8794/28299 [03:28<08:21, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8798/28299 [03:28<08:46, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8802/28299 [03:28<08:37, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8806/28299 [03:28<08:35, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8810/28299 [03:28<08:28, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8814/28299 [03:28<08:25, 38.52it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8818/28299 [03:28<08:40, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8822/28299 [03:28<08:34, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8826/28299 [03:28<08:34, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8831/28299 [03:28<08:19, 39.01it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8835/28299 [03:29<08:32, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8839/28299 [03:29<08:43, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███       | 8843/28299 [03:29<08:36, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8847/28299 [03:29<08:34, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8851/28299 [03:29<08:31, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8855/28299 [03:29<08:44, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8859/28299 [03:29<09:26, 34.31it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8863/28299 [03:29<09:10, 35.32it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8867/28299 [03:29<09:04, 35.69it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8871/28299 [03:30<08:54, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8875/28299 [03:30<09:03, 35.72it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8879/28299 [03:30<08:57, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8884/28299 [03:30<08:37, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8889/28299 [03:30<08:24, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8894/28299 [03:30<08:14, 39.20it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8899/28299 [03:30<08:04, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8903/28299 [03:30<08:29, 38.10it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8907/28299 [03:31<08:28, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  31%|███▏      | 8911/28299 [03:31<08:26, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8915/28299 [03:31<08:35, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8920/28299 [03:31<08:16, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8924/28299 [03:31<08:14, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8928/28299 [03:31<08:37, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8932/28299 [03:31<08:36, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8936/28299 [03:31<08:34, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8940/28299 [03:31<08:54, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8944/28299 [03:32<08:50, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8948/28299 [03:32<08:44, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8952/28299 [03:32<08:38, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8956/28299 [03:32<08:37, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8960/28299 [03:32<08:35, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8964/28299 [03:32<08:37, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8968/28299 [03:32<09:00, 35.80it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8972/28299 [03:32<08:43, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8976/28299 [03:32<08:54, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8980/28299 [03:33<08:45, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8985/28299 [03:33<08:27, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8990/28299 [03:33<08:15, 38.97it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8995/28299 [03:33<08:04, 39.82it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 8999/28299 [03:33<08:05, 39.79it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9003/28299 [03:33<08:29, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9008/28299 [03:33<08:19, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9012/28299 [03:33<08:24, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9016/28299 [03:33<08:43, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9021/28299 [03:34<08:22, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9025/28299 [03:34<08:17, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9029/28299 [03:34<08:15, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9034/28299 [03:34<08:05, 39.66it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9038/28299 [03:34<08:20, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9042/28299 [03:34<08:16, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9047/28299 [03:34<08:04, 39.72it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9052/28299 [03:34<08:01, 39.99it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9056/28299 [03:34<08:06, 39.58it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9060/28299 [03:35<08:06, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9064/28299 [03:35<08:11, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9068/28299 [03:35<08:10, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9072/28299 [03:35<08:20, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9076/28299 [03:35<08:27, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9080/28299 [03:35<08:31, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9084/28299 [03:35<09:00, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9088/28299 [03:35<09:05, 35.20it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9092/28299 [03:35<08:56, 35.79it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9096/28299 [03:36<08:50, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9100/28299 [03:36<08:59, 35.56it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9104/28299 [03:36<08:59, 35.59it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9108/28299 [03:36<08:50, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9112/28299 [03:36<08:42, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9116/28299 [03:36<08:36, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9121/28299 [03:36<08:16, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9125/28299 [03:36<08:20, 38.35it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9129/28299 [03:36<08:20, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9133/28299 [03:37<08:18, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9137/28299 [03:37<08:23, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9141/28299 [03:37<08:33, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9145/28299 [03:37<08:46, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9149/28299 [03:37<08:54, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9153/28299 [03:37<08:56, 35.67it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9157/28299 [03:37<08:42, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9162/28299 [03:37<08:22, 38.10it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9166/28299 [03:37<08:20, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9171/28299 [03:38<08:12, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9175/28299 [03:38<08:23, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9179/28299 [03:38<15:31, 20.52it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9184/28299 [03:38<12:54, 24.69it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9188/28299 [03:38<11:33, 27.54it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9192/28299 [03:38<11:17, 28.21it/s]\u001b[A\n",
            "Epoch 1/5:  32%|███▏      | 9196/28299 [03:39<10:29, 30.35it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9200/28299 [03:39<10:02, 31.71it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9204/28299 [03:39<09:29, 33.51it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9208/28299 [03:39<09:14, 34.44it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9212/28299 [03:39<09:08, 34.78it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9216/28299 [03:39<08:47, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9221/28299 [03:39<08:23, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9226/28299 [03:39<08:10, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9231/28299 [03:39<08:03, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9236/28299 [03:40<07:58, 39.86it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9241/28299 [03:40<07:48, 40.66it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9246/28299 [03:40<07:52, 40.29it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9251/28299 [03:40<07:59, 39.74it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9256/28299 [03:40<07:52, 40.28it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9261/28299 [03:40<07:49, 40.55it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9266/28299 [03:40<07:47, 40.73it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9271/28299 [03:40<07:57, 39.88it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9276/28299 [03:41<07:52, 40.24it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9281/28299 [03:41<07:58, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9285/28299 [03:41<08:15, 38.35it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9289/28299 [03:41<08:14, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9293/28299 [03:41<08:17, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9297/28299 [03:41<08:30, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9302/28299 [03:41<08:12, 38.57it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9306/28299 [03:41<08:14, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9310/28299 [03:41<08:11, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9314/28299 [03:42<08:09, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9319/28299 [03:42<07:58, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9323/28299 [03:42<08:00, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9328/28299 [03:42<07:55, 39.87it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9332/28299 [03:42<08:05, 39.06it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9336/28299 [03:42<08:02, 39.32it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9340/28299 [03:42<08:01, 39.37it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9344/28299 [03:42<08:08, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9348/28299 [03:42<08:13, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9352/28299 [03:43<08:35, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9356/28299 [03:43<08:25, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9360/28299 [03:43<08:27, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9364/28299 [03:43<08:28, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9368/28299 [03:43<08:31, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9372/28299 [03:43<08:31, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9376/28299 [03:43<08:29, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9380/28299 [03:43<08:22, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9384/28299 [03:43<08:23, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9388/28299 [03:43<08:25, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9392/28299 [03:44<08:25, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9396/28299 [03:44<08:21, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9400/28299 [03:44<08:23, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9404/28299 [03:44<08:32, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9409/28299 [03:44<08:14, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9413/28299 [03:44<08:18, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9417/28299 [03:44<08:23, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9421/28299 [03:44<08:21, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9426/28299 [03:44<08:08, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9430/28299 [03:45<08:03, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9435/28299 [03:45<07:58, 39.42it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9439/28299 [03:45<08:03, 39.00it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9443/28299 [03:45<08:04, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9448/28299 [03:45<07:56, 39.54it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9452/28299 [03:45<08:10, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9456/28299 [03:45<08:50, 35.49it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9461/28299 [03:45<08:28, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9465/28299 [03:46<08:30, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9469/28299 [03:46<08:31, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9473/28299 [03:46<08:24, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  33%|███▎      | 9477/28299 [03:46<08:23, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9481/28299 [03:46<09:12, 34.09it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9485/28299 [03:46<08:49, 35.52it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9489/28299 [03:46<08:45, 35.80it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9493/28299 [03:46<08:37, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9497/28299 [03:46<09:12, 34.00it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9501/28299 [03:47<09:01, 34.73it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9505/28299 [03:47<08:51, 35.39it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9509/28299 [03:47<09:09, 34.20it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9513/28299 [03:47<08:50, 35.44it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9517/28299 [03:47<09:07, 34.28it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9521/28299 [03:47<08:54, 35.10it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9525/28299 [03:47<09:00, 34.75it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9529/28299 [03:47<08:52, 35.27it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9533/28299 [03:47<08:43, 35.83it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9537/28299 [03:48<08:53, 35.17it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9541/28299 [03:48<09:18, 33.56it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9545/28299 [03:48<09:00, 34.69it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▎      | 9550/28299 [03:48<08:34, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9554/28299 [03:48<08:23, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9558/28299 [03:48<08:44, 35.73it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9562/28299 [03:48<08:34, 36.41it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9566/28299 [03:48<09:19, 33.47it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9571/28299 [03:49<08:42, 35.81it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9576/28299 [03:49<08:20, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9580/28299 [03:49<08:18, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9585/28299 [03:49<08:05, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9589/28299 [03:49<08:03, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9594/28299 [03:49<07:50, 39.74it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9598/28299 [03:49<07:54, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9602/28299 [03:49<07:57, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9606/28299 [03:49<07:59, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9610/28299 [03:50<07:57, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9615/28299 [03:50<07:48, 39.88it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9619/28299 [03:50<07:50, 39.70it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9624/28299 [03:50<07:44, 40.25it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9629/28299 [03:50<07:41, 40.49it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9634/28299 [03:50<08:21, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9639/28299 [03:50<08:02, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9644/28299 [03:50<07:51, 39.56it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9649/28299 [03:50<07:47, 39.87it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9654/28299 [03:51<07:51, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9658/28299 [03:51<08:14, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9663/28299 [03:51<08:02, 38.60it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9667/28299 [03:51<08:02, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9671/28299 [03:51<08:12, 37.81it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9675/28299 [03:51<08:12, 37.81it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9680/28299 [03:51<07:56, 39.07it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9684/28299 [03:51<08:01, 38.69it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9688/28299 [03:52<08:00, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9693/28299 [03:52<07:48, 39.73it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9697/28299 [03:52<07:47, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9702/28299 [03:52<07:44, 40.00it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9707/28299 [03:52<07:42, 40.16it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9712/28299 [03:52<07:45, 39.93it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9717/28299 [03:52<07:41, 40.29it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9722/28299 [03:52<07:36, 40.66it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9727/28299 [03:52<07:34, 40.83it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9732/28299 [03:53<07:38, 40.54it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9737/28299 [03:53<07:38, 40.46it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9742/28299 [03:53<07:38, 40.49it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9747/28299 [03:53<07:43, 40.04it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9752/28299 [03:53<07:36, 40.60it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9757/28299 [03:53<07:42, 40.07it/s]\u001b[A\n",
            "Epoch 1/5:  34%|███▍      | 9762/28299 [03:53<07:47, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9766/28299 [03:53<07:52, 39.26it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9770/28299 [03:54<07:55, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9774/28299 [03:54<07:59, 38.60it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9778/28299 [03:54<08:01, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9782/28299 [03:54<08:03, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9786/28299 [03:54<07:57, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9790/28299 [03:54<07:57, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9794/28299 [03:54<08:06, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9799/28299 [03:54<07:50, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9804/28299 [03:54<07:43, 39.88it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9809/28299 [03:55<07:40, 40.15it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9814/28299 [03:55<07:41, 40.04it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9818/28299 [03:55<07:48, 39.45it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9822/28299 [03:55<07:52, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9826/28299 [03:55<08:02, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9830/28299 [03:55<08:07, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9835/28299 [03:55<07:54, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9840/28299 [03:55<07:46, 39.55it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9845/28299 [03:55<07:40, 40.09it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9850/28299 [03:56<07:36, 40.38it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9855/28299 [03:56<07:36, 40.40it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9860/28299 [03:56<07:39, 40.12it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9865/28299 [03:56<07:37, 40.29it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9870/28299 [03:56<07:38, 40.20it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9875/28299 [03:56<07:35, 40.41it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9880/28299 [03:56<07:34, 40.49it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9885/28299 [03:56<07:38, 40.15it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9890/28299 [03:57<07:38, 40.17it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9895/28299 [03:57<07:40, 39.98it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9899/28299 [03:57<07:48, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▍      | 9903/28299 [03:57<08:01, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9907/28299 [03:57<08:12, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9911/28299 [03:57<08:10, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9915/28299 [03:57<08:10, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9919/28299 [03:57<08:07, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9924/28299 [03:57<07:50, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9928/28299 [03:58<08:04, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9932/28299 [03:58<08:09, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9936/28299 [03:58<08:14, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9940/28299 [03:58<08:11, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9944/28299 [03:58<08:08, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9948/28299 [03:58<08:03, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9952/28299 [03:58<08:00, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9956/28299 [03:58<07:56, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9960/28299 [03:58<07:51, 38.86it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9964/28299 [03:59<07:58, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9968/28299 [03:59<07:56, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9972/28299 [03:59<08:01, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9976/28299 [03:59<08:06, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9980/28299 [03:59<08:08, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9985/28299 [03:59<07:47, 39.16it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9990/28299 [03:59<07:42, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 9995/28299 [03:59<07:37, 40.00it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10000/28299 [03:59<07:35, 40.14it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10005/28299 [04:00<07:32, 40.43it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10010/28299 [04:00<07:32, 40.44it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10015/28299 [04:00<07:31, 40.49it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10020/28299 [04:00<07:31, 40.51it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10025/28299 [04:00<07:26, 40.93it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10030/28299 [04:00<07:24, 41.06it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10035/28299 [04:00<07:31, 40.47it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10040/28299 [04:00<07:27, 40.79it/s]\u001b[A\n",
            "Epoch 1/5:  35%|███▌      | 10045/28299 [04:01<07:29, 40.58it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10050/28299 [04:01<07:33, 40.22it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10055/28299 [04:01<07:31, 40.39it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10060/28299 [04:01<07:36, 39.97it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10064/28299 [04:01<07:41, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10068/28299 [04:01<07:45, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10072/28299 [04:01<07:47, 39.00it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10076/28299 [04:01<07:51, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10080/28299 [04:01<07:54, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10084/28299 [04:02<07:57, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10089/28299 [04:02<07:39, 39.62it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10093/28299 [04:02<07:39, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10098/28299 [04:02<07:31, 40.33it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10103/28299 [04:02<07:31, 40.32it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10108/28299 [04:02<13:33, 22.36it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10113/28299 [04:03<11:36, 26.12it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10118/28299 [04:03<10:18, 29.40it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10123/28299 [04:03<09:25, 32.12it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10127/28299 [04:03<09:01, 33.55it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10132/28299 [04:03<08:28, 35.71it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10137/28299 [04:03<08:07, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10142/28299 [04:03<07:50, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10147/28299 [04:03<07:41, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10152/28299 [04:04<07:42, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10157/28299 [04:04<07:44, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10162/28299 [04:04<07:38, 39.56it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10167/28299 [04:04<07:29, 40.35it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10172/28299 [04:04<07:25, 40.69it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10177/28299 [04:04<07:28, 40.39it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10182/28299 [04:04<07:32, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10187/28299 [04:04<07:41, 39.25it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10191/28299 [04:05<07:41, 39.20it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10195/28299 [04:05<07:42, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10199/28299 [04:05<07:42, 39.13it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10203/28299 [04:05<07:45, 38.90it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10207/28299 [04:05<07:42, 39.10it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10211/28299 [04:05<07:41, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10216/28299 [04:05<07:29, 40.20it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10221/28299 [04:05<07:31, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10225/28299 [04:05<07:35, 39.65it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10229/28299 [04:05<07:38, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10233/28299 [04:06<07:49, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10237/28299 [04:06<07:50, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10242/28299 [04:06<07:34, 39.72it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10247/28299 [04:06<07:26, 40.41it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10252/28299 [04:06<07:31, 39.99it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▌      | 10256/28299 [04:06<07:36, 39.52it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10260/28299 [04:06<07:36, 39.50it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10264/28299 [04:06<07:40, 39.16it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10268/28299 [04:06<07:47, 38.56it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10272/28299 [04:07<07:45, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10276/28299 [04:07<07:47, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10280/28299 [04:07<07:48, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10284/28299 [04:07<07:50, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10288/28299 [04:07<07:47, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10293/28299 [04:07<07:39, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10297/28299 [04:07<07:43, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10302/28299 [04:07<07:35, 39.48it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10307/28299 [04:07<07:30, 39.97it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10311/28299 [04:08<07:31, 39.88it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10316/28299 [04:08<07:28, 40.06it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10320/28299 [04:08<07:29, 39.99it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10324/28299 [04:08<07:39, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  36%|███▋      | 10329/28299 [04:08<07:31, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10333/28299 [04:08<07:32, 39.73it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10337/28299 [04:08<07:36, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10341/28299 [04:08<07:40, 38.98it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10345/28299 [04:08<07:45, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10350/28299 [04:09<07:35, 39.44it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10355/28299 [04:09<07:31, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10359/28299 [04:09<07:32, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10363/28299 [04:09<07:33, 39.55it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10367/28299 [04:09<07:39, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10371/28299 [04:09<07:41, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10375/28299 [04:09<07:37, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10380/28299 [04:09<07:29, 39.85it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10384/28299 [04:09<07:31, 39.65it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10389/28299 [04:10<07:21, 40.54it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10394/28299 [04:10<07:21, 40.56it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10399/28299 [04:10<07:18, 40.78it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10404/28299 [04:10<07:17, 40.87it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10409/28299 [04:10<07:28, 39.92it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10413/28299 [04:10<07:36, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10417/28299 [04:10<07:43, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10421/28299 [04:10<07:41, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10425/28299 [04:10<07:48, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10429/28299 [04:11<07:50, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10433/28299 [04:11<07:49, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10438/28299 [04:11<07:38, 38.97it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10442/28299 [04:11<07:35, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10447/28299 [04:11<07:24, 40.15it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10452/28299 [04:11<07:23, 40.27it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10457/28299 [04:11<07:17, 40.81it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10462/28299 [04:11<07:17, 40.78it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10467/28299 [04:12<07:13, 41.09it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10472/28299 [04:12<07:09, 41.47it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10477/28299 [04:12<07:10, 41.37it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10482/28299 [04:12<07:17, 40.74it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10487/28299 [04:12<07:14, 41.00it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10492/28299 [04:12<07:13, 41.12it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10497/28299 [04:12<07:12, 41.16it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10502/28299 [04:12<07:16, 40.73it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10507/28299 [04:12<07:16, 40.72it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10512/28299 [04:13<07:10, 41.30it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10517/28299 [04:13<07:07, 41.57it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10522/28299 [04:13<07:18, 40.55it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10527/28299 [04:13<07:22, 40.17it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10532/28299 [04:13<07:28, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10537/28299 [04:13<07:22, 40.14it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10542/28299 [04:13<07:19, 40.42it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10547/28299 [04:13<07:20, 40.29it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10552/28299 [04:14<07:19, 40.33it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10557/28299 [04:14<07:16, 40.62it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10562/28299 [04:14<07:15, 40.74it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10567/28299 [04:14<07:12, 40.97it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10572/28299 [04:14<07:12, 41.01it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10577/28299 [04:14<07:14, 40.79it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10582/28299 [04:14<07:17, 40.54it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10587/28299 [04:14<07:14, 40.74it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10592/28299 [04:15<07:16, 40.54it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10597/28299 [04:15<07:20, 40.19it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10602/28299 [04:15<07:19, 40.31it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10607/28299 [04:15<07:15, 40.60it/s]\u001b[A\n",
            "Epoch 1/5:  37%|███▋      | 10612/28299 [04:15<07:19, 40.22it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10617/28299 [04:15<07:25, 39.73it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10622/28299 [04:15<07:19, 40.24it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10627/28299 [04:15<07:27, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10632/28299 [04:16<07:22, 39.96it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10637/28299 [04:16<07:18, 40.23it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10642/28299 [04:16<07:30, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10646/28299 [04:16<07:32, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10650/28299 [04:16<07:38, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10654/28299 [04:16<07:39, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10658/28299 [04:16<07:38, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10662/28299 [04:16<07:39, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10666/28299 [04:16<07:42, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10670/28299 [04:17<07:41, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10674/28299 [04:17<07:41, 38.23it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10678/28299 [04:17<07:39, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10682/28299 [04:17<07:38, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10686/28299 [04:17<07:36, 38.59it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10690/28299 [04:17<07:39, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10694/28299 [04:17<07:36, 38.59it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10699/28299 [04:17<07:28, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10703/28299 [04:17<07:27, 39.31it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10707/28299 [04:18<07:33, 38.76it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10711/28299 [04:18<07:35, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10716/28299 [04:18<07:23, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10721/28299 [04:18<07:16, 40.27it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10726/28299 [04:18<07:12, 40.66it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10731/28299 [04:18<07:14, 40.39it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10736/28299 [04:18<07:20, 39.84it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10740/28299 [04:18<07:29, 39.07it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10745/28299 [04:18<07:23, 39.61it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10749/28299 [04:19<07:28, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10754/28299 [04:19<07:23, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10758/28299 [04:19<07:22, 39.66it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10763/28299 [04:19<07:15, 40.27it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10768/28299 [04:19<07:18, 39.97it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10772/28299 [04:19<07:24, 39.43it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10776/28299 [04:19<07:28, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10780/28299 [04:19<07:30, 38.88it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10784/28299 [04:19<07:27, 39.11it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10788/28299 [04:20<07:27, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10792/28299 [04:20<07:25, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10797/28299 [04:20<07:21, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10801/28299 [04:20<07:24, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10805/28299 [04:20<07:29, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10809/28299 [04:20<07:28, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10813/28299 [04:20<07:27, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10818/28299 [04:20<07:21, 39.55it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10822/28299 [04:20<07:29, 38.85it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10826/28299 [04:21<07:38, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10830/28299 [04:21<07:41, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10834/28299 [04:21<07:42, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10838/28299 [04:21<07:44, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10842/28299 [04:21<07:46, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10846/28299 [04:21<07:48, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10850/28299 [04:21<07:48, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10854/28299 [04:21<07:42, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10858/28299 [04:21<07:46, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10862/28299 [04:22<07:44, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10866/28299 [04:22<07:46, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10870/28299 [04:22<07:46, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10874/28299 [04:22<08:17, 35.01it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10878/28299 [04:22<08:04, 35.94it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10882/28299 [04:22<07:55, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10886/28299 [04:22<07:46, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10890/28299 [04:22<08:03, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  38%|███▊      | 10894/28299 [04:22<08:06, 35.77it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10898/28299 [04:23<08:03, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10902/28299 [04:23<08:02, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10906/28299 [04:23<08:26, 34.34it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10910/28299 [04:23<08:24, 34.47it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10914/28299 [04:23<08:19, 34.81it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10918/28299 [04:23<08:06, 35.72it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10923/28299 [04:23<07:46, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10927/28299 [04:23<07:37, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10931/28299 [04:23<08:07, 35.60it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10935/28299 [04:24<07:53, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10940/28299 [04:24<07:35, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10944/28299 [04:24<07:33, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10948/28299 [04:24<07:34, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10953/28299 [04:24<07:20, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10958/28299 [04:24<07:11, 40.22it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▊      | 10963/28299 [04:24<07:16, 39.70it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 10968/28299 [04:24<07:09, 40.34it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 10973/28299 [04:25<07:21, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 10978/28299 [04:25<07:10, 40.24it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 10983/28299 [04:25<07:09, 40.32it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 10988/28299 [04:25<07:20, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 10992/28299 [04:25<07:37, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 10996/28299 [04:25<08:17, 34.78it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11000/28299 [04:25<08:03, 35.81it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11004/28299 [04:25<08:02, 35.88it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11008/28299 [04:25<08:06, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11012/28299 [04:26<07:55, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11016/28299 [04:26<07:44, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11020/28299 [04:26<07:52, 36.57it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11024/28299 [04:26<08:11, 35.16it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11029/28299 [04:26<07:49, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11033/28299 [04:26<14:11, 20.29it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11037/28299 [04:27<12:19, 23.33it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11041/28299 [04:27<11:13, 25.63it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11046/28299 [04:27<09:45, 29.47it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11051/28299 [04:27<08:47, 32.72it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11055/28299 [04:27<08:24, 34.21it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11060/28299 [04:27<07:54, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11064/28299 [04:27<07:49, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11068/28299 [04:27<07:45, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11073/28299 [04:27<07:23, 38.83it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11077/28299 [04:28<07:26, 38.55it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11082/28299 [04:28<07:14, 39.66it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11087/28299 [04:28<07:15, 39.52it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11091/28299 [04:28<07:23, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11096/28299 [04:28<07:14, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11100/28299 [04:28<07:17, 39.31it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11105/28299 [04:28<07:08, 40.14it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11110/28299 [04:28<07:14, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11114/28299 [04:29<07:24, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11118/28299 [04:29<07:29, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11123/28299 [04:29<07:15, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11127/28299 [04:29<07:22, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11132/28299 [04:29<07:12, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11137/28299 [04:29<07:06, 40.26it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11142/28299 [04:29<07:21, 38.86it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11146/28299 [04:29<07:19, 39.07it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11150/28299 [04:29<07:26, 38.37it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11155/28299 [04:30<07:18, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11159/28299 [04:30<07:25, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11164/28299 [04:30<07:16, 39.26it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11168/28299 [04:30<07:14, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11172/28299 [04:30<07:27, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  39%|███▉      | 11177/28299 [04:30<07:16, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11182/28299 [04:30<07:05, 40.18it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11187/28299 [04:30<07:03, 40.40it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11192/28299 [04:30<07:11, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11197/28299 [04:31<07:07, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11202/28299 [04:31<07:14, 39.36it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11206/28299 [04:31<07:14, 39.30it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11210/28299 [04:31<07:17, 39.02it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11215/28299 [04:31<07:09, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11219/28299 [04:31<07:42, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11223/28299 [04:31<07:56, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11227/28299 [04:31<07:47, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11231/28299 [04:32<07:54, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11235/28299 [04:32<07:56, 35.79it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11239/28299 [04:32<07:43, 36.79it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11243/28299 [04:32<07:43, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11247/28299 [04:32<08:31, 33.31it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11251/28299 [04:32<08:36, 32.99it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11255/28299 [04:32<08:18, 34.22it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11259/28299 [04:32<07:59, 35.52it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11263/28299 [04:32<07:46, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11267/28299 [04:33<07:48, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11271/28299 [04:33<07:48, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11275/28299 [04:33<07:44, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11279/28299 [04:33<07:49, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11283/28299 [04:33<07:53, 35.95it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11287/28299 [04:33<07:55, 35.76it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11291/28299 [04:33<07:56, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11295/28299 [04:33<07:45, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11299/28299 [04:33<07:39, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11303/28299 [04:34<07:31, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11307/28299 [04:34<07:38, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11311/28299 [04:34<08:07, 34.88it/s]\u001b[A\n",
            "Epoch 1/5:  40%|███▉      | 11316/28299 [04:34<07:39, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11321/28299 [04:34<07:25, 38.10it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11325/28299 [04:34<07:33, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11330/28299 [04:34<07:20, 38.49it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11335/28299 [04:34<07:08, 39.55it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11339/28299 [04:34<07:11, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11343/28299 [04:35<07:13, 39.10it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11347/28299 [04:35<07:32, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11351/28299 [04:35<07:40, 36.79it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11355/28299 [04:35<07:34, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11359/28299 [04:35<07:29, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11363/28299 [04:35<08:10, 34.52it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11367/28299 [04:35<08:05, 34.85it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11371/28299 [04:35<08:04, 34.96it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11375/28299 [04:35<07:48, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11379/28299 [04:36<07:41, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11383/28299 [04:36<07:35, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11387/28299 [04:36<07:30, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11392/28299 [04:36<07:17, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11397/28299 [04:36<07:06, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11401/28299 [04:36<07:13, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11406/28299 [04:36<07:06, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11410/28299 [04:36<07:11, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11414/28299 [04:36<07:15, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11419/28299 [04:37<07:04, 39.76it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11424/28299 [04:37<07:00, 40.13it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11429/28299 [04:37<07:20, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11433/28299 [04:37<07:30, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11437/28299 [04:37<07:29, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11441/28299 [04:37<07:27, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11445/28299 [04:37<07:24, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11449/28299 [04:37<07:27, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11453/28299 [04:38<07:37, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11457/28299 [04:38<07:52, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  40%|████      | 11461/28299 [04:38<07:48, 35.98it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11465/28299 [04:38<07:58, 35.21it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11469/28299 [04:38<07:50, 35.79it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11473/28299 [04:38<07:40, 36.57it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11477/28299 [04:38<07:33, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11481/28299 [04:38<07:25, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11485/28299 [04:38<07:20, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11489/28299 [04:39<07:39, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11493/28299 [04:39<07:34, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11497/28299 [04:39<07:31, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11501/28299 [04:39<08:34, 32.62it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11506/28299 [04:39<07:59, 35.05it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11511/28299 [04:39<07:33, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11515/28299 [04:39<07:44, 36.16it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11520/28299 [04:39<07:23, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11524/28299 [04:39<07:19, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11528/28299 [04:40<07:25, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11532/28299 [04:40<07:28, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11536/28299 [04:40<07:27, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11540/28299 [04:40<07:39, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11544/28299 [04:40<07:35, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11548/28299 [04:40<07:43, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11552/28299 [04:40<07:45, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11556/28299 [04:40<08:01, 34.76it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11560/28299 [04:40<07:48, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11564/28299 [04:41<07:36, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11568/28299 [04:41<07:27, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11572/28299 [04:41<07:38, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11576/28299 [04:41<08:25, 33.11it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11580/28299 [04:41<08:15, 33.71it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11584/28299 [04:41<08:03, 34.59it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11588/28299 [04:41<08:01, 34.69it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11592/28299 [04:41<07:56, 35.03it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11596/28299 [04:41<07:51, 35.42it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11600/28299 [04:42<07:54, 35.19it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11604/28299 [04:42<08:01, 34.69it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11608/28299 [04:42<07:51, 35.37it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11612/28299 [04:42<07:46, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11616/28299 [04:42<07:51, 35.36it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11620/28299 [04:42<07:41, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11624/28299 [04:42<07:29, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11628/28299 [04:42<07:29, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11632/28299 [04:42<07:27, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11636/28299 [04:43<07:28, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11640/28299 [04:43<07:32, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11645/28299 [04:43<07:14, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11649/28299 [04:43<07:10, 38.72it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11653/28299 [04:43<07:17, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11657/28299 [04:43<07:28, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11661/28299 [04:43<07:39, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11665/28299 [04:43<07:42, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11669/28299 [04:43<07:41, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████      | 11673/28299 [04:44<07:47, 35.60it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11677/28299 [04:44<07:59, 34.67it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11681/28299 [04:44<07:53, 35.07it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11685/28299 [04:44<07:38, 36.27it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11689/28299 [04:44<07:27, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11693/28299 [04:44<07:46, 35.58it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11697/28299 [04:44<07:33, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11701/28299 [04:44<07:26, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11705/28299 [04:44<07:30, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11709/28299 [04:45<07:30, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11713/28299 [04:45<07:27, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11717/28299 [04:45<07:40, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11721/28299 [04:45<08:31, 32.39it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11725/28299 [04:45<08:05, 34.16it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11729/28299 [04:45<08:12, 33.64it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11733/28299 [04:45<07:56, 34.74it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11737/28299 [04:45<07:44, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  41%|████▏     | 11741/28299 [04:46<07:35, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11745/28299 [04:46<07:37, 36.17it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11749/28299 [04:46<07:40, 35.92it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11753/28299 [04:46<07:43, 35.71it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11757/28299 [04:46<07:38, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11761/28299 [04:46<07:32, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11765/28299 [04:46<07:33, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11769/28299 [04:46<07:27, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11773/28299 [04:46<07:21, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11777/28299 [04:46<07:18, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11781/28299 [04:47<07:14, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11785/28299 [04:47<07:15, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11790/28299 [04:47<07:11, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11794/28299 [04:47<07:28, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11798/28299 [04:47<07:19, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11802/28299 [04:47<07:15, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11806/28299 [04:47<07:29, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11810/28299 [04:47<07:26, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11814/28299 [04:47<07:19, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11818/28299 [04:48<07:12, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11822/28299 [04:48<07:28, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11826/28299 [04:48<07:23, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11830/28299 [04:48<07:28, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11834/28299 [04:48<07:20, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11838/28299 [04:48<07:18, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11842/28299 [04:48<07:14, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11846/28299 [04:48<07:14, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11851/28299 [04:48<07:00, 39.13it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11855/28299 [04:49<07:02, 38.90it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11860/28299 [04:49<06:54, 39.69it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11864/28299 [04:49<06:59, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11868/28299 [04:49<07:09, 38.23it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11873/28299 [04:49<06:57, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11877/28299 [04:49<07:05, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11881/28299 [04:49<07:19, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11886/28299 [04:49<07:07, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11890/28299 [04:49<07:03, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11894/28299 [04:50<07:11, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11899/28299 [04:50<07:15, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11904/28299 [04:50<07:02, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11909/28299 [04:50<06:57, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11914/28299 [04:50<06:52, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11919/28299 [04:50<06:53, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11923/28299 [04:50<06:53, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11927/28299 [04:50<06:52, 39.66it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11932/28299 [04:51<06:48, 40.04it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11937/28299 [04:51<06:55, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11941/28299 [04:51<07:02, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11946/28299 [04:51<06:52, 39.67it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11951/28299 [04:51<06:45, 40.31it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11956/28299 [04:51<07:01, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11960/28299 [04:52<12:39, 21.52it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11964/28299 [04:52<11:14, 24.23it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11968/28299 [04:52<10:01, 27.14it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11973/28299 [04:52<08:54, 30.54it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11978/28299 [04:52<08:10, 33.30it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11982/28299 [04:52<07:56, 34.27it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11986/28299 [04:52<07:46, 34.99it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11990/28299 [04:52<07:40, 35.40it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11994/28299 [04:52<07:30, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 11998/28299 [04:53<07:21, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 12002/28299 [04:53<07:15, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 12006/28299 [04:53<07:11, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 12010/28299 [04:53<07:08, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 12014/28299 [04:53<07:09, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 12018/28299 [04:53<07:08, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 12022/28299 [04:53<07:09, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  42%|████▏     | 12026/28299 [04:53<07:26, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12030/28299 [04:53<07:31, 36.01it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12034/28299 [04:54<07:25, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12038/28299 [04:54<07:27, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12042/28299 [04:54<07:55, 34.16it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12046/28299 [04:54<08:13, 32.95it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12050/28299 [04:54<08:09, 33.18it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12054/28299 [04:54<08:09, 33.16it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12058/28299 [04:54<08:11, 33.02it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12062/28299 [04:54<08:00, 33.76it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12066/28299 [04:54<07:53, 34.30it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12070/28299 [04:55<07:41, 35.19it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12075/28299 [04:55<07:16, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12079/28299 [04:55<07:10, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12083/28299 [04:55<07:08, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12087/28299 [04:55<07:14, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12091/28299 [04:55<07:21, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12095/28299 [04:55<07:22, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12099/28299 [04:55<07:20, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12103/28299 [04:55<07:25, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12107/28299 [04:56<07:16, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12111/28299 [04:56<07:15, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12115/28299 [04:56<07:18, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12119/28299 [04:56<08:15, 32.64it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12123/28299 [04:56<08:13, 32.76it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12127/28299 [04:56<07:58, 33.79it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12131/28299 [04:56<07:47, 34.55it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12135/28299 [04:56<07:57, 33.82it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12139/28299 [04:57<08:00, 33.66it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12143/28299 [04:57<07:42, 34.93it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12147/28299 [04:57<07:32, 35.71it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12151/28299 [04:57<07:20, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12155/28299 [04:57<07:12, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12159/28299 [04:57<07:07, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12163/28299 [04:57<07:03, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12167/28299 [04:57<07:01, 38.23it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12171/28299 [04:57<07:19, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12175/28299 [04:57<07:16, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12179/28299 [04:58<07:36, 35.34it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12183/28299 [04:58<07:26, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12187/28299 [04:58<07:14, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12192/28299 [04:58<07:03, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12197/28299 [04:58<06:59, 38.37it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12201/28299 [04:58<07:05, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12206/28299 [04:58<06:55, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12210/28299 [04:58<06:57, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12214/28299 [04:59<06:59, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12218/28299 [04:59<07:09, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12222/28299 [04:59<07:21, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12226/28299 [04:59<07:17, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12230/28299 [04:59<07:12, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12235/28299 [04:59<06:57, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12240/28299 [04:59<06:44, 39.67it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12244/28299 [04:59<06:46, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12249/28299 [04:59<06:37, 40.39it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12254/28299 [05:00<06:40, 40.10it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12259/28299 [05:00<07:23, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12263/28299 [05:00<07:20, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12267/28299 [05:00<07:16, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12271/28299 [05:00<07:19, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12275/28299 [05:00<07:13, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12279/28299 [05:00<07:07, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12284/28299 [05:00<06:52, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12289/28299 [05:00<06:44, 39.58it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12293/28299 [05:01<06:48, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12297/28299 [05:01<06:46, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12301/28299 [05:01<06:44, 39.50it/s]\u001b[A\n",
            "Epoch 1/5:  43%|████▎     | 12306/28299 [05:01<06:38, 40.09it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12311/28299 [05:01<06:33, 40.68it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12316/28299 [05:01<06:34, 40.52it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12321/28299 [05:01<06:31, 40.83it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12326/28299 [05:01<06:40, 39.88it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12330/28299 [05:01<06:41, 39.82it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12335/28299 [05:02<06:37, 40.11it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12340/28299 [05:02<06:36, 40.24it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12345/28299 [05:02<06:47, 39.11it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12350/28299 [05:02<06:39, 39.91it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12355/28299 [05:02<06:40, 39.85it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12359/28299 [05:02<06:58, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12364/28299 [05:02<06:55, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12369/28299 [05:02<06:45, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12373/28299 [05:03<06:55, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▎     | 12377/28299 [05:03<07:04, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12381/28299 [05:03<06:59, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12386/28299 [05:03<06:49, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12390/28299 [05:03<06:48, 38.93it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12394/28299 [05:03<06:56, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12398/28299 [05:03<07:37, 34.73it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12402/28299 [05:03<07:37, 34.73it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12407/28299 [05:04<07:17, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12411/28299 [05:04<07:13, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12415/28299 [05:04<07:08, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12419/28299 [05:04<07:07, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12423/28299 [05:04<07:12, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12427/28299 [05:04<07:03, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12431/28299 [05:04<06:59, 37.79it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12435/28299 [05:04<07:07, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12439/28299 [05:04<07:22, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12443/28299 [05:05<07:09, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12447/28299 [05:05<07:02, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12452/28299 [05:05<07:02, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12456/28299 [05:05<07:05, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12460/28299 [05:05<07:08, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12464/28299 [05:05<07:04, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12469/28299 [05:05<06:57, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12474/28299 [05:05<06:42, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12478/28299 [05:05<07:03, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12482/28299 [05:06<07:40, 34.34it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12486/28299 [05:06<07:28, 35.23it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12490/28299 [05:06<07:17, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12494/28299 [05:06<07:12, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12499/28299 [05:06<06:54, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12503/28299 [05:06<06:56, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12507/28299 [05:06<07:01, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12512/28299 [05:06<06:45, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12516/28299 [05:06<06:54, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12520/28299 [05:07<06:59, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12524/28299 [05:07<07:05, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12528/28299 [05:07<07:06, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12532/28299 [05:07<07:05, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12536/28299 [05:07<07:05, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12540/28299 [05:07<06:58, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12544/28299 [05:07<07:24, 35.43it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12548/28299 [05:07<07:10, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12552/28299 [05:07<07:08, 36.79it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12557/28299 [05:08<06:55, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12561/28299 [05:08<07:00, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12565/28299 [05:08<06:54, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12569/28299 [05:08<07:19, 35.81it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12573/28299 [05:08<07:06, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12578/28299 [05:08<06:53, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12582/28299 [05:08<06:54, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12586/28299 [05:08<06:53, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  44%|████▍     | 12590/28299 [05:08<07:03, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12594/28299 [05:09<06:54, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12598/28299 [05:09<06:50, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12602/28299 [05:09<07:12, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12606/28299 [05:09<07:00, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12611/28299 [05:09<06:48, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12615/28299 [05:09<07:05, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12620/28299 [05:09<06:52, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12624/28299 [05:09<06:46, 38.56it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12629/28299 [05:09<06:40, 39.10it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12633/28299 [05:10<06:44, 38.76it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12637/28299 [05:10<06:51, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12641/28299 [05:10<06:48, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12645/28299 [05:10<06:54, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12649/28299 [05:10<06:52, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12653/28299 [05:10<06:46, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12657/28299 [05:10<06:44, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12662/28299 [05:10<06:36, 39.44it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12667/28299 [05:10<06:29, 40.11it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12672/28299 [05:11<06:59, 37.27it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12676/28299 [05:11<06:56, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12680/28299 [05:11<06:53, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12684/28299 [05:11<07:01, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12688/28299 [05:11<06:54, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12693/28299 [05:11<06:44, 38.59it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12697/28299 [05:11<06:53, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12701/28299 [05:11<07:07, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12705/28299 [05:11<07:10, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12709/28299 [05:12<07:06, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12713/28299 [05:12<07:04, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12717/28299 [05:12<07:00, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12721/28299 [05:12<06:59, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12725/28299 [05:12<06:50, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12729/28299 [05:12<07:07, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▍     | 12733/28299 [05:12<07:30, 34.53it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12737/28299 [05:12<07:17, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12741/28299 [05:12<07:06, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12745/28299 [05:13<07:02, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12749/28299 [05:13<07:15, 35.69it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12754/28299 [05:13<06:55, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12758/28299 [05:13<06:55, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12762/28299 [05:13<06:57, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12766/28299 [05:13<07:01, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12771/28299 [05:13<06:48, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12776/28299 [05:13<06:38, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12780/28299 [05:13<06:40, 38.72it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12784/28299 [05:14<06:46, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12788/28299 [05:14<07:13, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12793/28299 [05:14<06:54, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12797/28299 [05:14<06:52, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12802/28299 [05:14<06:44, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12807/28299 [05:14<06:36, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12811/28299 [05:14<06:34, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12815/28299 [05:14<06:33, 39.36it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12820/28299 [05:15<06:26, 40.01it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12824/28299 [05:15<06:37, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12829/28299 [05:15<06:30, 39.61it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12833/28299 [05:15<06:39, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12837/28299 [05:15<06:46, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12841/28299 [05:15<06:42, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12846/28299 [05:15<06:33, 39.26it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12851/28299 [05:15<06:29, 39.61it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12855/28299 [05:15<06:41, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12860/28299 [05:16<06:34, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12864/28299 [05:16<06:37, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12868/28299 [05:16<06:47, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12872/28299 [05:16<06:54, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  45%|████▌     | 12876/28299 [05:16<06:50, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12880/28299 [05:16<06:47, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12884/28299 [05:16<06:41, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12888/28299 [05:17<12:50, 20.00it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12893/28299 [05:17<10:32, 24.36it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12897/28299 [05:17<09:33, 26.87it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12901/28299 [05:17<08:39, 29.66it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12906/28299 [05:17<07:52, 32.57it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12910/28299 [05:17<07:31, 34.06it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12914/28299 [05:17<07:21, 34.84it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12919/28299 [05:17<07:00, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12923/28299 [05:18<06:59, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12928/28299 [05:18<06:48, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12932/28299 [05:18<06:49, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12936/28299 [05:18<06:46, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12940/28299 [05:18<06:57, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12944/28299 [05:18<06:57, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12948/28299 [05:18<06:51, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12953/28299 [05:18<06:40, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12957/28299 [05:18<06:39, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12961/28299 [05:19<06:40, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12965/28299 [05:19<06:41, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12969/28299 [05:19<07:12, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12973/28299 [05:19<07:14, 35.28it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12977/28299 [05:19<07:10, 35.59it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12981/28299 [05:19<07:05, 35.96it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12985/28299 [05:19<07:03, 36.16it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12989/28299 [05:19<07:01, 36.29it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12993/28299 [05:19<06:59, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 12997/28299 [05:20<07:01, 36.31it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13001/28299 [05:20<07:04, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13005/28299 [05:20<07:11, 35.48it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13009/28299 [05:20<07:04, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13013/28299 [05:20<07:13, 35.24it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13018/28299 [05:20<06:51, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13022/28299 [05:20<06:51, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13026/28299 [05:20<06:46, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13030/28299 [05:20<06:47, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13034/28299 [05:21<06:44, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13039/28299 [05:21<06:35, 38.60it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13044/28299 [05:21<06:30, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13049/28299 [05:21<06:23, 39.78it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13054/28299 [05:21<06:21, 39.99it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13058/28299 [05:21<06:28, 39.26it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13062/28299 [05:21<06:32, 38.85it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13066/28299 [05:21<06:33, 38.69it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13070/28299 [05:21<06:51, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13074/28299 [05:22<06:48, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13078/28299 [05:22<06:45, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13082/28299 [05:22<06:56, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▌     | 13086/28299 [05:22<07:02, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13090/28299 [05:22<06:58, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13094/28299 [05:22<07:09, 35.44it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13098/28299 [05:22<07:05, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13102/28299 [05:22<06:59, 36.26it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13106/28299 [05:22<07:07, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13110/28299 [05:23<06:57, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13114/28299 [05:23<06:57, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13118/28299 [05:23<06:51, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13123/28299 [05:23<06:34, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13127/28299 [05:23<06:30, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13132/28299 [05:23<06:22, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13137/28299 [05:23<06:18, 40.08it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13142/28299 [05:23<06:18, 40.03it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13146/28299 [05:23<06:25, 39.34it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13150/28299 [05:24<06:25, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13154/28299 [05:24<06:28, 39.01it/s]\u001b[A\n",
            "Epoch 1/5:  46%|████▋     | 13158/28299 [05:24<06:28, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13162/28299 [05:24<06:28, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13167/28299 [05:24<06:23, 39.50it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13172/28299 [05:24<06:16, 40.22it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13177/28299 [05:24<06:32, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13181/28299 [05:24<06:36, 38.14it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13185/28299 [05:24<06:36, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13189/28299 [05:25<06:37, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13193/28299 [05:25<06:44, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13197/28299 [05:25<06:42, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13201/28299 [05:25<06:46, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13205/28299 [05:25<06:50, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13209/28299 [05:25<06:47, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13213/28299 [05:25<06:41, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13217/28299 [05:25<06:34, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13222/28299 [05:25<06:26, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13227/28299 [05:26<06:20, 39.56it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13231/28299 [05:26<06:20, 39.61it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13235/28299 [05:26<06:19, 39.70it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13239/28299 [05:26<06:21, 39.45it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13243/28299 [05:26<06:36, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13248/28299 [05:26<06:26, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13252/28299 [05:26<06:24, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13256/28299 [05:26<06:24, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13260/28299 [05:26<06:29, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13264/28299 [05:27<06:35, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13268/28299 [05:27<06:34, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13272/28299 [05:27<06:37, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13276/28299 [05:27<06:38, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13280/28299 [05:27<06:38, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13284/28299 [05:27<06:33, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13289/28299 [05:27<06:23, 39.10it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13293/28299 [05:27<06:39, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13297/28299 [05:27<06:38, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13301/28299 [05:28<06:41, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13305/28299 [05:28<06:34, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13309/28299 [05:28<06:33, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13314/28299 [05:28<06:35, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13319/28299 [05:28<06:24, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13324/28299 [05:28<06:19, 39.43it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13329/28299 [05:28<06:14, 39.98it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13334/28299 [05:28<06:10, 40.43it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13339/28299 [05:28<06:15, 39.87it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13343/28299 [05:29<06:41, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13347/28299 [05:29<06:39, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13351/28299 [05:29<06:43, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13355/28299 [05:29<06:48, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13359/28299 [05:29<06:56, 35.88it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13363/28299 [05:29<06:48, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13367/28299 [05:29<06:55, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13371/28299 [05:29<06:53, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13375/28299 [05:29<06:49, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13379/28299 [05:30<06:44, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13383/28299 [05:30<06:50, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13387/28299 [05:30<06:44, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13391/28299 [05:30<06:56, 35.76it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13396/28299 [05:30<06:44, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13400/28299 [05:30<06:35, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13404/28299 [05:30<06:34, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13408/28299 [05:30<06:42, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13412/28299 [05:30<06:41, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13416/28299 [05:31<06:38, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13420/28299 [05:31<06:35, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13424/28299 [05:31<06:29, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13429/28299 [05:31<06:21, 39.01it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13434/28299 [05:31<06:15, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  47%|████▋     | 13438/28299 [05:31<06:22, 38.83it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13443/28299 [05:31<06:14, 39.69it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13448/28299 [05:31<06:11, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13452/28299 [05:32<06:22, 38.83it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13456/28299 [05:32<06:26, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13460/28299 [05:32<06:29, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13464/28299 [05:32<06:26, 38.37it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13469/28299 [05:32<06:14, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13474/28299 [05:32<06:09, 40.09it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13478/28299 [05:32<06:34, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13482/28299 [05:32<06:31, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13486/28299 [05:32<06:27, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13491/28299 [05:33<06:23, 38.60it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13495/28299 [05:33<06:20, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13499/28299 [05:33<06:25, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13503/28299 [05:33<06:24, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13507/28299 [05:33<06:38, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13511/28299 [05:33<06:38, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13515/28299 [05:33<06:31, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13519/28299 [05:33<06:36, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13523/28299 [05:33<06:41, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13527/28299 [05:33<06:36, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13531/28299 [05:34<06:38, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13535/28299 [05:34<06:35, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13539/28299 [05:34<06:32, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13543/28299 [05:34<06:28, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13547/28299 [05:34<06:28, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13551/28299 [05:34<06:29, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13555/28299 [05:34<06:43, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13559/28299 [05:34<06:53, 35.67it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13563/28299 [05:34<07:06, 34.54it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13567/28299 [05:35<07:04, 34.70it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13571/28299 [05:35<06:50, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13576/28299 [05:35<06:35, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13581/28299 [05:35<06:21, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13585/28299 [05:35<06:29, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13589/28299 [05:35<06:27, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13593/28299 [05:35<06:27, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13597/28299 [05:35<06:27, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13601/28299 [05:35<06:22, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13605/28299 [05:36<06:22, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13609/28299 [05:36<06:21, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13613/28299 [05:36<06:18, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13617/28299 [05:36<06:18, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13621/28299 [05:36<06:28, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13626/28299 [05:36<06:18, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13631/28299 [05:36<06:09, 39.67it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13635/28299 [05:36<06:12, 39.35it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13639/28299 [05:36<06:20, 38.55it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13643/28299 [05:37<06:21, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13647/28299 [05:37<06:19, 38.59it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13651/28299 [05:37<06:27, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13655/28299 [05:37<06:27, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13659/28299 [05:37<06:22, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13663/28299 [05:37<06:31, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13667/28299 [05:37<06:37, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13672/28299 [05:37<06:19, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13676/28299 [05:37<06:38, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13680/28299 [05:38<06:54, 35.30it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13684/28299 [05:38<06:41, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13688/28299 [05:38<06:43, 36.23it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13692/28299 [05:38<06:37, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13696/28299 [05:38<06:31, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13700/28299 [05:38<06:28, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13705/28299 [05:38<06:15, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13709/28299 [05:38<06:25, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13713/28299 [05:38<06:34, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13718/28299 [05:39<06:20, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  48%|████▊     | 13723/28299 [05:39<06:13, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13727/28299 [05:39<06:16, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13731/28299 [05:39<06:15, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13735/28299 [05:39<06:16, 38.69it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13739/28299 [05:39<06:16, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13743/28299 [05:39<06:19, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13747/28299 [05:39<06:22, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13751/28299 [05:39<06:23, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13755/28299 [05:40<06:26, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13759/28299 [05:40<06:20, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13763/28299 [05:40<06:16, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13767/28299 [05:40<06:24, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13771/28299 [05:40<06:18, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13775/28299 [05:40<06:17, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13779/28299 [05:40<06:14, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13784/28299 [05:40<06:06, 39.65it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13789/28299 [05:40<06:03, 39.92it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▊     | 13793/28299 [05:41<06:08, 39.35it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13797/28299 [05:41<06:10, 39.16it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13801/28299 [05:41<06:17, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13805/28299 [05:41<06:17, 38.35it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13809/28299 [05:41<06:20, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13813/28299 [05:41<12:23, 19.47it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13817/28299 [05:41<10:38, 22.68it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13821/28299 [05:42<09:24, 25.64it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13825/28299 [05:42<08:26, 28.57it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13829/28299 [05:42<07:56, 30.40it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13833/28299 [05:42<07:24, 32.56it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13837/28299 [05:42<07:00, 34.37it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13841/28299 [05:42<06:50, 35.25it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13845/28299 [05:42<06:45, 35.62it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13849/28299 [05:42<06:47, 35.43it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13854/28299 [05:42<06:27, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13859/28299 [05:43<06:13, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13864/28299 [05:43<06:06, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13869/28299 [05:43<06:03, 39.74it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13873/28299 [05:43<06:05, 39.47it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13877/28299 [05:43<06:11, 38.85it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13882/28299 [05:43<06:06, 39.31it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13887/28299 [05:43<06:01, 39.84it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13891/28299 [05:43<06:09, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13895/28299 [05:43<06:13, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13899/28299 [05:44<06:11, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13903/28299 [05:44<06:10, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13907/28299 [05:44<06:24, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13912/28299 [05:44<06:13, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13916/28299 [05:44<06:15, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13920/28299 [05:44<06:14, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13924/28299 [05:44<06:14, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13929/28299 [05:44<06:06, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13933/28299 [05:44<06:06, 39.18it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13937/28299 [05:45<06:04, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13941/28299 [05:45<06:11, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13945/28299 [05:45<06:13, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13949/28299 [05:45<06:11, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13954/28299 [05:45<06:04, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13958/28299 [05:45<06:11, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13963/28299 [05:45<06:02, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13968/28299 [05:45<05:57, 40.06it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13973/28299 [05:45<05:57, 40.13it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13978/28299 [05:46<05:55, 40.25it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13983/28299 [05:46<05:59, 39.84it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13988/28299 [05:46<05:53, 40.48it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13993/28299 [05:46<05:51, 40.74it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 13998/28299 [05:46<05:51, 40.65it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 14003/28299 [05:46<05:54, 40.29it/s]\u001b[A\n",
            "Epoch 1/5:  49%|████▉     | 14008/28299 [05:46<05:52, 40.50it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14013/28299 [05:46<06:09, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14018/28299 [05:47<06:04, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14022/28299 [05:47<06:04, 39.18it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14026/28299 [05:47<06:05, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14030/28299 [05:47<06:06, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14034/28299 [05:47<06:09, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14038/28299 [05:47<06:18, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14042/28299 [05:47<06:22, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14046/28299 [05:47<06:45, 35.18it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14050/28299 [05:48<06:52, 34.57it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14054/28299 [05:48<06:44, 35.20it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14059/28299 [05:48<06:26, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14064/28299 [05:48<06:16, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14068/28299 [05:48<06:14, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14072/28299 [05:48<06:28, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14076/28299 [05:48<06:24, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14080/28299 [05:48<06:24, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14084/28299 [05:48<06:22, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14088/28299 [05:49<06:23, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14092/28299 [05:49<06:23, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14096/28299 [05:49<06:15, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14100/28299 [05:49<06:18, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14104/28299 [05:49<06:23, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14108/28299 [05:49<06:26, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14112/28299 [05:49<06:25, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14116/28299 [05:49<06:28, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14120/28299 [05:49<06:26, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14124/28299 [05:49<06:19, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14128/28299 [05:50<06:16, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14132/28299 [05:50<06:13, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14136/28299 [05:50<06:15, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14140/28299 [05:50<06:14, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14144/28299 [05:50<06:09, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  50%|████▉     | 14148/28299 [05:50<06:15, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14153/28299 [05:50<06:05, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14157/28299 [05:50<06:04, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14161/28299 [05:50<06:05, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14165/28299 [05:51<06:04, 38.73it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14170/28299 [05:51<05:57, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14175/28299 [05:51<05:52, 40.03it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14180/28299 [05:51<05:46, 40.76it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14185/28299 [05:51<05:43, 41.06it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14190/28299 [05:51<05:42, 41.19it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14195/28299 [05:51<05:43, 41.06it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14200/28299 [05:51<05:52, 39.98it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14205/28299 [05:52<06:03, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14210/28299 [05:52<05:58, 39.31it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14214/28299 [05:52<05:58, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14218/28299 [05:52<05:56, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14223/28299 [05:52<05:49, 40.30it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14228/28299 [05:52<05:56, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14233/28299 [05:52<05:53, 39.79it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14238/28299 [05:52<05:53, 39.75it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14242/28299 [05:52<05:56, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14246/28299 [05:53<05:56, 39.37it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14251/28299 [05:53<05:53, 39.70it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14255/28299 [05:53<05:58, 39.20it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14259/28299 [05:53<06:00, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14263/28299 [05:53<05:59, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14267/28299 [05:53<05:58, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14272/28299 [05:53<05:49, 40.16it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14277/28299 [05:53<06:02, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14281/28299 [05:53<06:14, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14285/28299 [05:54<06:21, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  50%|█████     | 14289/28299 [05:54<06:16, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14293/28299 [05:54<06:21, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14297/28299 [05:54<06:19, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14301/28299 [05:54<06:19, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14305/28299 [05:54<06:33, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14309/28299 [05:54<06:26, 36.24it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14313/28299 [05:54<06:19, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14317/28299 [05:54<06:30, 35.81it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14321/28299 [05:55<06:26, 36.17it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14325/28299 [05:55<06:28, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14329/28299 [05:55<06:22, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14333/28299 [05:55<06:17, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14338/28299 [05:55<06:03, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14342/28299 [05:55<06:08, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14346/28299 [05:55<06:02, 38.49it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14350/28299 [05:55<06:06, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14354/28299 [05:55<06:05, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14358/28299 [05:56<06:22, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14363/28299 [05:56<06:07, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14367/28299 [05:56<06:02, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14372/28299 [05:56<06:01, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14377/28299 [05:56<05:50, 39.75it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14381/28299 [05:56<05:50, 39.70it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14386/28299 [05:56<05:46, 40.11it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14391/28299 [05:56<05:52, 39.45it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14396/28299 [05:57<05:48, 39.86it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14401/28299 [05:57<05:48, 39.91it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14406/28299 [05:57<05:45, 40.21it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14411/28299 [05:57<05:51, 39.47it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14415/28299 [05:57<05:56, 38.97it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14419/28299 [05:57<06:00, 38.52it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14423/28299 [05:57<06:04, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14427/28299 [05:57<05:59, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14431/28299 [05:57<05:57, 38.83it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14435/28299 [05:58<06:12, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14439/28299 [05:58<06:29, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14444/28299 [05:58<06:14, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14449/28299 [05:58<06:03, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14453/28299 [05:58<06:21, 36.28it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14457/28299 [05:58<06:37, 34.79it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14461/28299 [05:58<06:29, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14465/28299 [05:58<06:40, 34.52it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14469/28299 [05:59<06:47, 33.95it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14473/28299 [05:59<06:39, 34.59it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14477/28299 [05:59<06:31, 35.27it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14481/28299 [05:59<06:23, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14485/28299 [05:59<06:30, 35.36it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14489/28299 [05:59<06:36, 34.81it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14493/28299 [05:59<06:41, 34.40it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14497/28299 [05:59<06:27, 35.59it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████     | 14501/28299 [05:59<06:29, 35.38it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14505/28299 [06:00<06:47, 33.85it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14509/28299 [06:00<06:34, 34.93it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14513/28299 [06:00<06:24, 35.87it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14517/28299 [06:00<06:17, 36.54it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14522/28299 [06:00<06:04, 37.84it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14526/28299 [06:00<06:03, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14530/28299 [06:00<06:07, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14534/28299 [06:00<06:00, 38.14it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14538/28299 [06:00<06:20, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14542/28299 [06:01<06:14, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14546/28299 [06:01<06:18, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14550/28299 [06:01<06:13, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14554/28299 [06:01<06:11, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14558/28299 [06:01<06:13, 36.79it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14562/28299 [06:01<06:21, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14566/28299 [06:01<06:34, 34.82it/s]\u001b[A\n",
            "Epoch 1/5:  51%|█████▏    | 14570/28299 [06:01<06:31, 35.09it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14574/28299 [06:01<06:17, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14578/28299 [06:02<06:07, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14582/28299 [06:02<06:05, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14586/28299 [06:02<05:58, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14590/28299 [06:02<05:57, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14594/28299 [06:02<05:52, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14599/28299 [06:02<05:45, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14604/28299 [06:02<05:41, 40.13it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14609/28299 [06:02<05:46, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14613/28299 [06:02<05:53, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14617/28299 [06:03<05:58, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14621/28299 [06:03<06:27, 35.30it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14625/28299 [06:03<06:17, 36.25it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14629/28299 [06:03<06:19, 36.01it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14633/28299 [06:03<06:12, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14637/28299 [06:03<06:06, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14641/28299 [06:03<06:08, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14645/28299 [06:03<06:03, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14649/28299 [06:03<06:14, 36.42it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14653/28299 [06:04<06:24, 35.50it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14657/28299 [06:04<06:20, 35.88it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14661/28299 [06:04<06:15, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14665/28299 [06:04<06:19, 35.96it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14669/28299 [06:04<06:17, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14673/28299 [06:04<06:12, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14677/28299 [06:04<06:22, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14681/28299 [06:04<06:14, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14685/28299 [06:04<06:11, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14689/28299 [06:05<06:10, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14693/28299 [06:05<06:34, 34.52it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14697/28299 [06:05<06:23, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14701/28299 [06:05<06:18, 35.88it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14705/28299 [06:05<06:12, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14709/28299 [06:05<06:19, 35.78it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14713/28299 [06:05<06:30, 34.77it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14717/28299 [06:05<06:24, 35.30it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14721/28299 [06:05<06:31, 34.67it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14725/28299 [06:06<06:22, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14729/28299 [06:06<06:16, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14733/28299 [06:06<06:09, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14737/28299 [06:06<06:28, 34.89it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14741/28299 [06:06<11:44, 19.24it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14745/28299 [06:06<10:33, 21.41it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14749/28299 [06:07<09:25, 23.97it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14753/28299 [06:07<08:22, 26.98it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14757/28299 [06:07<07:54, 28.52it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14761/28299 [06:07<07:19, 30.84it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14765/28299 [06:07<06:50, 32.94it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14769/28299 [06:07<06:44, 33.44it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14773/28299 [06:07<06:33, 34.40it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14777/28299 [06:07<06:20, 35.58it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14781/28299 [06:07<06:11, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14785/28299 [06:08<06:18, 35.71it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14789/28299 [06:08<06:12, 36.31it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14793/28299 [06:08<06:20, 35.50it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14797/28299 [06:08<06:22, 35.29it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14801/28299 [06:08<06:13, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14805/28299 [06:08<06:10, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14809/28299 [06:08<06:16, 35.87it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14813/28299 [06:08<06:30, 34.51it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14817/28299 [06:08<06:19, 35.49it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14821/28299 [06:09<06:12, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14825/28299 [06:09<06:08, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14829/28299 [06:09<06:05, 36.90it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14833/28299 [06:09<06:02, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14837/28299 [06:09<06:12, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14841/28299 [06:09<06:07, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14845/28299 [06:09<06:00, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14849/28299 [06:09<06:00, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  52%|█████▏    | 14853/28299 [06:09<05:58, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14857/28299 [06:10<05:58, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14861/28299 [06:10<06:00, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14865/28299 [06:10<05:53, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14869/28299 [06:10<05:52, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14874/28299 [06:10<05:43, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14879/28299 [06:10<05:37, 39.79it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14884/28299 [06:10<05:34, 40.15it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14889/28299 [06:10<05:34, 40.10it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14894/28299 [06:10<05:43, 39.02it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14898/28299 [06:11<05:43, 39.01it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14902/28299 [06:11<05:48, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14906/28299 [06:11<05:54, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14910/28299 [06:11<06:00, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14914/28299 [06:11<06:12, 35.95it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14918/28299 [06:11<06:08, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14922/28299 [06:11<06:10, 36.08it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14926/28299 [06:11<06:14, 35.73it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14930/28299 [06:11<06:27, 34.52it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14934/28299 [06:12<06:20, 35.12it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14938/28299 [06:12<06:11, 35.94it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14942/28299 [06:12<06:05, 36.51it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14946/28299 [06:12<06:18, 35.26it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14950/28299 [06:12<06:12, 35.84it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14954/28299 [06:12<06:05, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14958/28299 [06:12<06:02, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14962/28299 [06:12<06:16, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14966/28299 [06:12<06:19, 35.16it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14970/28299 [06:13<06:20, 35.04it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14974/28299 [06:13<06:17, 35.33it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14978/28299 [06:13<06:16, 35.42it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14982/28299 [06:13<06:20, 34.98it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14986/28299 [06:13<06:11, 35.88it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14990/28299 [06:13<06:04, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14994/28299 [06:13<06:00, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 14998/28299 [06:13<06:02, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15002/28299 [06:13<06:13, 35.65it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15006/28299 [06:14<06:05, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15010/28299 [06:14<06:12, 35.67it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15014/28299 [06:14<06:02, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15019/28299 [06:14<05:53, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15023/28299 [06:14<05:50, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15027/28299 [06:14<05:47, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15031/28299 [06:14<05:45, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15036/28299 [06:14<05:37, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15041/28299 [06:14<05:31, 40.00it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15046/28299 [06:15<05:28, 40.38it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15051/28299 [06:15<05:24, 40.82it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15056/28299 [06:15<05:36, 39.36it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15060/28299 [06:15<05:41, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15065/28299 [06:15<05:35, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15069/28299 [06:15<05:45, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15074/28299 [06:15<05:35, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15078/28299 [06:15<05:39, 38.90it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15082/28299 [06:16<05:42, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15086/28299 [06:16<05:48, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15091/28299 [06:16<05:43, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15095/28299 [06:16<05:49, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15100/28299 [06:16<05:44, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15104/28299 [06:16<05:43, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15109/28299 [06:16<05:33, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15114/28299 [06:16<05:29, 40.07it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15119/28299 [06:16<05:39, 38.80it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15123/28299 [06:17<06:01, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15127/28299 [06:17<05:58, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15131/28299 [06:17<06:04, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15135/28299 [06:17<06:23, 34.35it/s]\u001b[A\n",
            "Epoch 1/5:  53%|█████▎    | 15139/28299 [06:17<06:24, 34.26it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15143/28299 [06:17<06:20, 34.54it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15147/28299 [06:17<06:08, 35.73it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15151/28299 [06:17<06:00, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15155/28299 [06:18<05:54, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15159/28299 [06:18<05:52, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15163/28299 [06:18<05:50, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15167/28299 [06:18<05:46, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15171/28299 [06:18<05:46, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15175/28299 [06:18<05:43, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15180/28299 [06:18<05:34, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15184/28299 [06:18<05:40, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15189/28299 [06:18<05:41, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15193/28299 [06:18<05:44, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15197/28299 [06:19<05:57, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15201/28299 [06:19<05:57, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15205/28299 [06:19<05:53, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▎    | 15209/28299 [06:19<05:48, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15213/28299 [06:19<05:50, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15217/28299 [06:19<05:49, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15221/28299 [06:19<05:51, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15226/28299 [06:19<05:41, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15231/28299 [06:19<05:31, 39.47it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15235/28299 [06:20<05:31, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15239/28299 [06:20<05:41, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15244/28299 [06:20<05:35, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15248/28299 [06:20<05:34, 38.98it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15252/28299 [06:20<05:38, 38.56it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15256/28299 [06:20<05:56, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15260/28299 [06:20<05:58, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15265/28299 [06:20<05:54, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15269/28299 [06:21<05:50, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15273/28299 [06:21<05:52, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15277/28299 [06:21<05:47, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15281/28299 [06:21<05:54, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15285/28299 [06:21<05:49, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15289/28299 [06:21<05:45, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15294/28299 [06:21<05:34, 38.90it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15299/28299 [06:21<05:29, 39.50it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15303/28299 [06:21<05:28, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15307/28299 [06:22<05:47, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15311/28299 [06:22<05:47, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15316/28299 [06:22<05:37, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15320/28299 [06:22<05:40, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15324/28299 [06:22<05:36, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15328/28299 [06:22<05:35, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15332/28299 [06:22<05:50, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15336/28299 [06:22<05:48, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15341/28299 [06:22<05:37, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15345/28299 [06:23<05:37, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15349/28299 [06:23<05:35, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15353/28299 [06:23<05:50, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15357/28299 [06:23<05:46, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15361/28299 [06:23<05:40, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15365/28299 [06:23<05:42, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15369/28299 [06:23<05:43, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15373/28299 [06:23<05:48, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15377/28299 [06:23<05:43, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15381/28299 [06:23<05:38, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15385/28299 [06:24<05:39, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15389/28299 [06:24<05:35, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15393/28299 [06:24<05:32, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15397/28299 [06:24<05:32, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15401/28299 [06:24<05:33, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15405/28299 [06:24<05:35, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15409/28299 [06:24<05:46, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15414/28299 [06:24<05:34, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  54%|█████▍    | 15419/28299 [06:24<05:28, 39.26it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15424/28299 [06:25<05:26, 39.43it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15428/28299 [06:25<05:41, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15432/28299 [06:25<05:36, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15436/28299 [06:25<05:36, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15440/28299 [06:25<05:37, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15444/28299 [06:25<05:43, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15448/28299 [06:25<05:55, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15452/28299 [06:25<05:45, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15456/28299 [06:25<05:39, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15461/28299 [06:26<05:29, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15466/28299 [06:26<05:22, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15470/28299 [06:26<05:26, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15475/28299 [06:26<05:17, 40.37it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15480/28299 [06:26<05:15, 40.67it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15485/28299 [06:26<05:25, 39.34it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15489/28299 [06:26<05:25, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15493/28299 [06:26<05:53, 36.27it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15497/28299 [06:26<05:51, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15501/28299 [06:27<05:52, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15506/28299 [06:27<05:36, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15510/28299 [06:27<05:37, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15514/28299 [06:27<05:38, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15518/28299 [06:27<05:36, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15522/28299 [06:27<05:51, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15526/28299 [06:27<05:48, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15530/28299 [06:27<05:46, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15534/28299 [06:27<05:44, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15538/28299 [06:28<05:45, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15542/28299 [06:28<05:43, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15546/28299 [06:28<05:47, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15550/28299 [06:28<05:59, 35.51it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15554/28299 [06:28<05:53, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15558/28299 [06:28<05:50, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▍    | 15562/28299 [06:28<05:52, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15566/28299 [06:28<05:46, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15570/28299 [06:28<05:43, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15574/28299 [06:29<05:42, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15578/28299 [06:29<06:23, 33.21it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15582/28299 [06:29<06:06, 34.65it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15586/28299 [06:29<06:00, 35.26it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15590/28299 [06:29<05:57, 35.53it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15594/28299 [06:29<05:50, 36.23it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15598/28299 [06:29<05:40, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15602/28299 [06:29<05:39, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15606/28299 [06:29<05:41, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15610/28299 [06:30<05:44, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15614/28299 [06:30<05:36, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15618/28299 [06:30<05:32, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15622/28299 [06:30<05:31, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15626/28299 [06:30<05:40, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15631/28299 [06:30<05:30, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15636/28299 [06:30<05:23, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15641/28299 [06:30<05:17, 39.83it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15646/28299 [06:30<05:13, 40.32it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15651/28299 [06:31<05:18, 39.75it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15655/28299 [06:31<05:29, 38.35it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15659/28299 [06:31<05:28, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15663/28299 [06:31<05:27, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15667/28299 [06:31<10:30, 20.02it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15671/28299 [06:31<09:05, 23.14it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15675/28299 [06:32<08:06, 25.97it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15679/28299 [06:32<07:26, 28.25it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15683/28299 [06:32<06:57, 30.19it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15687/28299 [06:32<06:32, 32.12it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15691/28299 [06:32<06:11, 33.97it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15695/28299 [06:32<05:58, 35.19it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15699/28299 [06:32<06:00, 34.97it/s]\u001b[A\n",
            "Epoch 1/5:  55%|█████▌    | 15703/28299 [06:32<05:49, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15707/28299 [06:32<05:52, 35.71it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15711/28299 [06:33<05:44, 36.57it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15715/28299 [06:33<05:55, 35.38it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15719/28299 [06:33<05:47, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15723/28299 [06:33<05:38, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15727/28299 [06:33<05:41, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15731/28299 [06:33<05:38, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15735/28299 [06:33<05:43, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15739/28299 [06:33<05:40, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15744/28299 [06:33<05:29, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15749/28299 [06:34<05:20, 39.18it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15753/28299 [06:34<05:32, 37.79it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15757/28299 [06:34<05:34, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15762/28299 [06:34<05:26, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15766/28299 [06:34<05:35, 37.34it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15770/28299 [06:34<05:43, 36.51it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15774/28299 [06:34<05:48, 35.92it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15778/28299 [06:34<05:42, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15782/28299 [06:35<05:59, 34.80it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15786/28299 [06:35<05:57, 34.97it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15790/28299 [06:35<05:51, 35.60it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15794/28299 [06:35<05:54, 35.29it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15798/28299 [06:35<05:45, 36.16it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15802/28299 [06:35<05:41, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15806/28299 [06:35<05:37, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15810/28299 [06:35<05:36, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15814/28299 [06:35<05:49, 35.70it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15818/28299 [06:36<06:03, 34.33it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15822/28299 [06:36<06:09, 33.80it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15826/28299 [06:36<06:04, 34.23it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15830/28299 [06:36<06:08, 33.84it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15835/28299 [06:36<05:48, 35.72it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15839/28299 [06:36<05:42, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15844/28299 [06:36<05:28, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15848/28299 [06:36<05:24, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15852/28299 [06:36<05:24, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15856/28299 [06:37<05:37, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15860/28299 [06:37<05:32, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15864/28299 [06:37<05:27, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15869/28299 [06:37<05:17, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15874/28299 [06:37<05:11, 39.87it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15878/28299 [06:37<05:32, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15883/28299 [06:37<05:20, 38.72it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15888/28299 [06:37<05:24, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15892/28299 [06:37<05:34, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15896/28299 [06:38<05:27, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15901/28299 [06:38<05:18, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15906/28299 [06:38<05:09, 40.00it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15911/28299 [06:38<05:05, 40.59it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▌    | 15916/28299 [06:38<05:09, 39.97it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15921/28299 [06:38<05:08, 40.12it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15926/28299 [06:38<05:06, 40.39it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15931/28299 [06:38<05:14, 39.27it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15935/28299 [06:39<05:15, 39.25it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15939/28299 [06:39<05:24, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15943/28299 [06:39<05:20, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15947/28299 [06:39<05:23, 38.23it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15951/28299 [06:39<05:24, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15955/28299 [06:39<05:27, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15960/28299 [06:39<05:19, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15964/28299 [06:39<05:32, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15968/28299 [06:39<05:29, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15972/28299 [06:40<05:40, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15976/28299 [06:40<05:51, 35.03it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15980/28299 [06:40<05:51, 35.03it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15984/28299 [06:40<05:42, 35.94it/s]\u001b[A\n",
            "Epoch 1/5:  56%|█████▋    | 15988/28299 [06:40<05:35, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 15992/28299 [06:40<05:31, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 15996/28299 [06:40<05:27, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16000/28299 [06:40<05:24, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16004/28299 [06:40<05:24, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16008/28299 [06:41<05:27, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16012/28299 [06:41<05:30, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16016/28299 [06:41<05:27, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16020/28299 [06:41<05:28, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16024/28299 [06:41<05:28, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16028/28299 [06:41<05:30, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16033/28299 [06:41<05:17, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16038/28299 [06:41<05:07, 39.89it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16042/28299 [06:41<05:12, 39.20it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16046/28299 [06:42<05:14, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16050/28299 [06:42<05:14, 39.01it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16055/28299 [06:42<05:07, 39.79it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16059/28299 [06:42<05:24, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16064/28299 [06:42<05:14, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16069/28299 [06:42<05:10, 39.45it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16074/28299 [06:42<05:06, 39.93it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16079/28299 [06:42<05:02, 40.36it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16084/28299 [06:42<05:01, 40.57it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16089/28299 [06:43<05:03, 40.28it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16094/28299 [06:43<05:02, 40.34it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16099/28299 [06:43<05:02, 40.36it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16104/28299 [06:43<04:59, 40.66it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16109/28299 [06:43<05:07, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16114/28299 [06:43<05:03, 40.16it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16119/28299 [06:43<05:07, 39.65it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16123/28299 [06:43<05:12, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16127/28299 [06:44<05:14, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16131/28299 [06:44<05:18, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16135/28299 [06:44<05:18, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16139/28299 [06:44<05:18, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16143/28299 [06:44<05:15, 38.52it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16147/28299 [06:44<05:14, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16151/28299 [06:44<05:15, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16155/28299 [06:44<05:15, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16159/28299 [06:44<05:18, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16163/28299 [06:45<05:18, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16167/28299 [06:45<05:28, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16171/28299 [06:45<05:23, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16175/28299 [06:45<05:23, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16179/28299 [06:45<05:24, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16183/28299 [06:45<05:21, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16187/28299 [06:45<05:18, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16191/28299 [06:45<05:18, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16195/28299 [06:45<05:18, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16199/28299 [06:45<05:40, 35.50it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16203/28299 [06:46<05:41, 35.43it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16207/28299 [06:46<05:36, 35.96it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16211/28299 [06:46<05:30, 36.54it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16215/28299 [06:46<05:30, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16219/28299 [06:46<05:28, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16223/28299 [06:46<05:27, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16227/28299 [06:46<05:49, 34.53it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16231/28299 [06:46<05:39, 35.53it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16235/28299 [06:46<05:32, 36.25it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16239/28299 [06:47<05:31, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16243/28299 [06:47<05:34, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16247/28299 [06:47<05:33, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16251/28299 [06:47<05:29, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16255/28299 [06:47<05:27, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16259/28299 [06:47<05:20, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16263/28299 [06:47<05:38, 35.60it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16267/28299 [06:47<05:35, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  57%|█████▋    | 16271/28299 [06:47<05:39, 35.44it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16275/28299 [06:48<05:36, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16279/28299 [06:48<05:38, 35.48it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16283/28299 [06:48<05:31, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16288/28299 [06:48<05:16, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16293/28299 [06:48<05:09, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16297/28299 [06:48<05:09, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16301/28299 [06:48<05:08, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16305/28299 [06:48<05:09, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16309/28299 [06:48<05:17, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16313/28299 [06:49<05:19, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16318/28299 [06:49<05:08, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16322/28299 [06:49<05:19, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16326/28299 [06:49<05:18, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16330/28299 [06:49<05:20, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16334/28299 [06:49<05:25, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16338/28299 [06:49<05:25, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16342/28299 [06:49<05:26, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16346/28299 [06:49<05:22, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16350/28299 [06:50<05:21, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16354/28299 [06:50<05:15, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16358/28299 [06:50<05:16, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16362/28299 [06:50<05:30, 36.10it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16366/28299 [06:50<05:27, 36.41it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16370/28299 [06:50<05:23, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16374/28299 [06:50<05:20, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16378/28299 [06:50<05:24, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16382/28299 [06:50<05:34, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16386/28299 [06:51<05:34, 35.60it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16390/28299 [06:51<05:30, 36.08it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16394/28299 [06:51<05:40, 35.00it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16398/28299 [06:51<05:32, 35.82it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16402/28299 [06:51<05:23, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16406/28299 [06:51<05:20, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16410/28299 [06:51<05:24, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16414/28299 [06:51<05:24, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16418/28299 [06:51<05:27, 36.28it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16422/28299 [06:52<05:23, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16426/28299 [06:52<05:28, 36.10it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16430/28299 [06:52<05:35, 35.43it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16434/28299 [06:52<05:28, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16438/28299 [06:52<05:31, 35.77it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16442/28299 [06:52<05:27, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16446/28299 [06:52<05:23, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16450/28299 [06:52<05:21, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16454/28299 [06:52<05:17, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16458/28299 [06:53<05:15, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16462/28299 [06:53<05:13, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16466/28299 [06:53<05:13, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16470/28299 [06:53<05:13, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16474/28299 [06:53<05:11, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16478/28299 [06:53<05:12, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16482/28299 [06:53<05:09, 38.14it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16486/28299 [06:53<05:15, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16490/28299 [06:53<05:10, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16494/28299 [06:53<05:08, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16498/28299 [06:54<05:08, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16502/28299 [06:54<05:12, 37.81it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16506/28299 [06:54<05:32, 35.51it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16510/28299 [06:54<05:25, 36.16it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16514/28299 [06:54<05:45, 34.16it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16519/28299 [06:54<05:24, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16523/28299 [06:54<05:18, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16528/28299 [06:54<05:07, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16532/28299 [06:55<05:07, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16536/28299 [06:55<05:06, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16540/28299 [06:55<05:08, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16544/28299 [06:55<05:09, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16548/28299 [06:55<05:28, 35.73it/s]\u001b[A\n",
            "Epoch 1/5:  58%|█████▊    | 16553/28299 [06:55<05:15, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16558/28299 [06:55<05:05, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16562/28299 [06:55<05:10, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16566/28299 [06:55<05:06, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16571/28299 [06:56<05:00, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16576/28299 [06:56<04:57, 39.45it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16580/28299 [06:56<05:06, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16584/28299 [06:56<05:04, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16589/28299 [06:56<04:55, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16593/28299 [06:56<04:55, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16597/28299 [06:57<09:22, 20.82it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16601/28299 [06:57<08:04, 24.13it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16606/28299 [06:57<06:58, 27.94it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16611/28299 [06:57<06:13, 31.31it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16615/28299 [06:57<05:51, 33.23it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16619/28299 [06:57<05:41, 34.21it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▊    | 16623/28299 [06:57<05:43, 34.03it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16628/28299 [06:57<05:23, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16633/28299 [06:57<05:07, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16637/28299 [06:58<05:04, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16641/28299 [06:58<05:00, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16645/28299 [06:58<04:59, 38.85it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16649/28299 [06:58<05:02, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16653/28299 [06:58<05:03, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16657/28299 [06:58<05:03, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16661/28299 [06:58<05:04, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16665/28299 [06:58<05:04, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16669/28299 [06:58<05:04, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16673/28299 [06:58<05:00, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16677/28299 [06:59<05:01, 38.56it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16681/28299 [06:59<05:08, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16685/28299 [06:59<05:22, 35.98it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16689/28299 [06:59<05:14, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16693/28299 [06:59<05:10, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16697/28299 [06:59<05:12, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16701/28299 [06:59<05:15, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16705/28299 [06:59<05:13, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16709/28299 [06:59<05:21, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16713/28299 [07:00<05:29, 35.14it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16717/28299 [07:00<05:21, 36.08it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16721/28299 [07:00<05:17, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16725/28299 [07:00<05:12, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16729/28299 [07:00<05:20, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16733/28299 [07:00<05:27, 35.32it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16737/28299 [07:00<05:21, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16741/28299 [07:00<05:19, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16745/28299 [07:00<05:15, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16749/28299 [07:01<05:38, 34.15it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16753/28299 [07:01<05:53, 32.68it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16757/28299 [07:01<05:41, 33.81it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16761/28299 [07:01<05:34, 34.52it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16765/28299 [07:01<05:30, 34.85it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16769/28299 [07:01<05:37, 34.18it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16773/28299 [07:01<05:30, 34.92it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16777/28299 [07:01<05:38, 34.06it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16781/28299 [07:02<05:41, 33.74it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16785/28299 [07:02<05:31, 34.74it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16789/28299 [07:02<05:25, 35.38it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16793/28299 [07:02<05:23, 35.56it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16797/28299 [07:02<05:31, 34.75it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16801/28299 [07:02<05:18, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16805/28299 [07:02<05:10, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16809/28299 [07:02<05:06, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16813/28299 [07:02<05:05, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16817/28299 [07:03<05:16, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16821/28299 [07:03<05:15, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16825/28299 [07:03<05:15, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16829/28299 [07:03<05:13, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  59%|█████▉    | 16833/28299 [07:03<05:11, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16838/28299 [07:03<04:58, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16842/28299 [07:03<04:55, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16846/28299 [07:03<04:53, 39.07it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16850/28299 [07:03<04:51, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16854/28299 [07:03<04:56, 38.59it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16859/28299 [07:04<04:50, 39.44it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16863/28299 [07:04<05:02, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16867/28299 [07:04<04:58, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16871/28299 [07:04<04:55, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16876/28299 [07:04<04:50, 39.35it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16880/28299 [07:04<04:52, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16884/28299 [07:04<04:54, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16888/28299 [07:04<04:55, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16893/28299 [07:04<04:49, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16897/28299 [07:05<05:00, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16901/28299 [07:05<05:00, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16905/28299 [07:05<05:01, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16909/28299 [07:05<05:12, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16913/28299 [07:05<05:06, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16917/28299 [07:05<05:04, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16921/28299 [07:05<05:03, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16925/28299 [07:05<05:03, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16929/28299 [07:05<05:15, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16933/28299 [07:06<05:07, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16937/28299 [07:06<05:02, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16941/28299 [07:06<04:58, 38.10it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16945/28299 [07:06<04:54, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16950/28299 [07:06<04:47, 39.49it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16955/28299 [07:06<04:44, 39.87it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16959/28299 [07:06<04:44, 39.86it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16964/28299 [07:06<04:40, 40.34it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16969/28299 [07:06<04:36, 40.94it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16974/28299 [07:07<04:38, 40.63it/s]\u001b[A\n",
            "Epoch 1/5:  60%|█████▉    | 16979/28299 [07:07<04:36, 40.96it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 16984/28299 [07:07<04:36, 40.94it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 16989/28299 [07:07<04:41, 40.24it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 16994/28299 [07:07<04:39, 40.45it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 16999/28299 [07:07<05:00, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17003/28299 [07:07<05:00, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17007/28299 [07:07<05:03, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17011/28299 [07:08<05:04, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17015/28299 [07:08<05:15, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17019/28299 [07:08<05:10, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17023/28299 [07:08<05:11, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17027/28299 [07:08<05:07, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17031/28299 [07:08<05:07, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17035/28299 [07:08<05:04, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17039/28299 [07:08<04:59, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17043/28299 [07:08<05:00, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17047/28299 [07:09<05:41, 32.95it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17051/28299 [07:09<05:29, 34.11it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17055/28299 [07:09<05:26, 34.48it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17060/28299 [07:09<05:09, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17064/28299 [07:09<05:15, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17068/28299 [07:09<05:07, 36.54it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17072/28299 [07:09<05:03, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17076/28299 [07:09<05:08, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17081/28299 [07:09<04:55, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17086/28299 [07:10<04:52, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17090/28299 [07:10<04:55, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17094/28299 [07:10<04:51, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17098/28299 [07:10<04:48, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17102/28299 [07:10<04:51, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17106/28299 [07:10<04:51, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17110/28299 [07:10<04:51, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17114/28299 [07:10<04:49, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  60%|██████    | 17119/28299 [07:10<04:42, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17123/28299 [07:11<04:42, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17127/28299 [07:11<04:48, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17131/28299 [07:11<04:55, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17135/28299 [07:11<04:53, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17140/28299 [07:11<04:46, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17145/28299 [07:11<04:45, 39.06it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17150/28299 [07:11<04:41, 39.65it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17154/28299 [07:11<04:41, 39.55it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17159/28299 [07:11<04:40, 39.71it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17163/28299 [07:12<04:41, 39.59it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17168/28299 [07:12<04:37, 40.05it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17172/28299 [07:12<04:40, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17176/28299 [07:12<04:41, 39.50it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17181/28299 [07:12<04:35, 40.37it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17186/28299 [07:12<04:36, 40.23it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17191/28299 [07:12<04:41, 39.48it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17195/28299 [07:12<04:42, 39.35it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17199/28299 [07:13<04:57, 37.27it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17203/28299 [07:13<04:57, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17207/28299 [07:13<05:04, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17212/28299 [07:13<04:52, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17216/28299 [07:13<04:52, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17220/28299 [07:13<04:58, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17224/28299 [07:13<04:57, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17228/28299 [07:13<04:57, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17232/28299 [07:13<04:54, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17236/28299 [07:13<04:49, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17240/28299 [07:14<04:48, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17244/28299 [07:14<04:50, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17248/28299 [07:14<04:57, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17252/28299 [07:14<04:53, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17256/28299 [07:14<04:50, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17260/28299 [07:14<04:58, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17264/28299 [07:14<05:00, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17268/28299 [07:14<04:57, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17272/28299 [07:14<05:18, 34.67it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17276/28299 [07:15<05:09, 35.56it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17280/28299 [07:15<05:03, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17284/28299 [07:15<04:55, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17288/28299 [07:15<04:52, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17292/28299 [07:15<04:49, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17296/28299 [07:15<04:50, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17301/28299 [07:15<04:40, 39.25it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17305/28299 [07:15<04:52, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17309/28299 [07:15<04:54, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17313/28299 [07:16<04:51, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17317/28299 [07:16<04:50, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17322/28299 [07:16<04:44, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17327/28299 [07:16<04:37, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████    | 17331/28299 [07:16<04:49, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17335/28299 [07:16<04:47, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17339/28299 [07:16<04:46, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17343/28299 [07:16<05:03, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17347/28299 [07:16<05:02, 36.23it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17352/28299 [07:17<04:50, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17356/28299 [07:17<04:57, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17360/28299 [07:17<04:54, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17365/28299 [07:17<04:44, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17370/28299 [07:17<04:37, 39.42it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17374/28299 [07:17<04:38, 39.24it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17379/28299 [07:17<04:35, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17383/28299 [07:17<04:44, 38.35it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17388/28299 [07:18<04:39, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17392/28299 [07:18<04:46, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17396/28299 [07:18<04:44, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  61%|██████▏   | 17400/28299 [07:18<04:45, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17404/28299 [07:18<04:49, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17408/28299 [07:18<04:50, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17412/28299 [07:18<04:49, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17416/28299 [07:18<04:47, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17421/28299 [07:18<04:40, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17425/28299 [07:18<04:38, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17429/28299 [07:19<04:39, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17433/28299 [07:19<04:40, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17437/28299 [07:19<04:38, 39.01it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17441/28299 [07:19<04:46, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17446/28299 [07:19<04:39, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17450/28299 [07:19<04:39, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17455/28299 [07:19<04:34, 39.47it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17460/28299 [07:19<04:31, 39.91it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17464/28299 [07:19<04:34, 39.44it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17468/28299 [07:20<04:53, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17472/28299 [07:20<04:47, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17476/28299 [07:20<04:53, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17481/28299 [07:20<04:43, 38.11it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17485/28299 [07:20<04:43, 38.11it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17489/28299 [07:20<04:45, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17494/28299 [07:20<04:38, 38.83it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17498/28299 [07:20<04:40, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17502/28299 [07:21<05:12, 34.56it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17506/28299 [07:21<05:11, 34.64it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17510/28299 [07:21<05:00, 35.95it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17514/28299 [07:21<04:57, 36.26it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17518/28299 [07:21<04:51, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17522/28299 [07:21<09:04, 19.79it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17526/28299 [07:21<07:43, 23.22it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17531/28299 [07:22<06:36, 27.19it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17535/28299 [07:22<06:00, 29.89it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17539/28299 [07:22<05:37, 31.91it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17543/28299 [07:22<05:17, 33.86it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17548/28299 [07:22<04:58, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17552/28299 [07:22<04:56, 36.27it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17556/28299 [07:22<04:52, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17561/28299 [07:22<04:42, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17565/28299 [07:22<04:39, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17570/28299 [07:23<04:34, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17574/28299 [07:23<04:46, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17578/28299 [07:23<04:46, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17582/28299 [07:23<04:44, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17586/28299 [07:23<04:43, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17590/28299 [07:23<04:44, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17594/28299 [07:23<04:48, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17599/28299 [07:23<04:39, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17603/28299 [07:23<04:39, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17607/28299 [07:24<04:41, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17611/28299 [07:24<04:51, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17616/28299 [07:24<04:39, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17620/28299 [07:24<04:37, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17624/28299 [07:24<04:39, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17628/28299 [07:24<04:39, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17632/28299 [07:24<04:38, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17636/28299 [07:24<04:41, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17640/28299 [07:24<04:45, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17644/28299 [07:25<04:45, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17648/28299 [07:25<04:48, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17652/28299 [07:25<04:55, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17656/28299 [07:25<04:55, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17660/28299 [07:25<05:10, 34.23it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17664/28299 [07:25<05:04, 34.98it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17668/28299 [07:25<05:08, 34.42it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17672/28299 [07:25<05:07, 34.61it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17676/28299 [07:25<04:59, 35.46it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17680/28299 [07:26<04:54, 36.08it/s]\u001b[A\n",
            "Epoch 1/5:  62%|██████▏   | 17684/28299 [07:26<04:47, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17688/28299 [07:26<04:42, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17692/28299 [07:26<04:46, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17697/28299 [07:26<04:34, 38.57it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17702/28299 [07:26<04:30, 39.25it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17706/28299 [07:26<04:29, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17710/28299 [07:26<04:33, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17715/28299 [07:26<04:29, 39.32it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17719/28299 [07:27<04:33, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17723/28299 [07:27<04:30, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17727/28299 [07:27<04:29, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17731/28299 [07:27<04:31, 38.93it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17736/28299 [07:27<04:28, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17740/28299 [07:27<04:31, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17745/28299 [07:27<04:25, 39.75it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17749/28299 [07:27<04:26, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17753/28299 [07:27<04:26, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17757/28299 [07:28<04:28, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17762/28299 [07:28<04:28, 39.27it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17767/28299 [07:28<04:35, 38.23it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17771/28299 [07:28<04:50, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17775/28299 [07:28<04:49, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17780/28299 [07:28<04:40, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17784/28299 [07:28<04:40, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17788/28299 [07:28<04:37, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17792/28299 [07:28<04:37, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17797/28299 [07:29<04:27, 39.26it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17801/28299 [07:29<04:27, 39.27it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17805/28299 [07:29<04:27, 39.24it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17810/28299 [07:29<04:19, 40.37it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17815/28299 [07:29<04:20, 40.32it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17820/28299 [07:29<04:31, 38.59it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17824/28299 [07:29<04:35, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17828/28299 [07:29<04:37, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17833/28299 [07:30<04:30, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17838/28299 [07:30<04:24, 39.52it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17842/28299 [07:30<04:28, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17846/28299 [07:30<04:27, 39.10it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17851/28299 [07:30<04:22, 39.74it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17855/28299 [07:30<04:22, 39.78it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17859/28299 [07:30<04:22, 39.71it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17864/28299 [07:30<04:18, 40.31it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17869/28299 [07:30<04:21, 39.94it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17873/28299 [07:31<04:32, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17877/28299 [07:31<04:31, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17881/28299 [07:31<04:32, 38.29it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17885/28299 [07:31<04:35, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17889/28299 [07:31<04:33, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17893/28299 [07:31<04:39, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17897/28299 [07:31<04:44, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17901/28299 [07:31<04:44, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17905/28299 [07:31<04:43, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17909/28299 [07:32<04:43, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17913/28299 [07:32<04:46, 36.27it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17917/28299 [07:32<04:46, 36.25it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17921/28299 [07:32<04:43, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17925/28299 [07:32<04:41, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17929/28299 [07:32<04:37, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17933/28299 [07:32<04:38, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17937/28299 [07:32<04:38, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17941/28299 [07:32<04:45, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17945/28299 [07:33<04:41, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17949/28299 [07:33<04:49, 35.78it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17953/28299 [07:33<04:44, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17957/28299 [07:33<04:39, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17961/28299 [07:33<04:41, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17965/28299 [07:33<04:43, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  63%|██████▎   | 17969/28299 [07:33<04:40, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 17973/28299 [07:33<04:36, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 17977/28299 [07:33<04:35, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 17981/28299 [07:33<04:40, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 17985/28299 [07:34<04:37, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 17989/28299 [07:34<04:31, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 17994/28299 [07:34<04:23, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 17998/28299 [07:34<04:46, 36.01it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18002/28299 [07:34<04:38, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18006/28299 [07:34<04:34, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18011/28299 [07:34<04:26, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18016/28299 [07:34<04:20, 39.48it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18021/28299 [07:35<04:17, 39.92it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18025/28299 [07:35<04:26, 38.55it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18029/28299 [07:35<04:35, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18034/28299 [07:35<04:27, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▎   | 18039/28299 [07:35<04:20, 39.32it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18043/28299 [07:35<04:36, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18047/28299 [07:35<04:32, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18052/28299 [07:35<04:26, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18056/28299 [07:35<04:25, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18061/28299 [07:36<04:18, 39.58it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18065/28299 [07:36<04:20, 39.32it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18069/28299 [07:36<04:24, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18073/28299 [07:36<04:26, 38.37it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18077/28299 [07:36<04:33, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18081/28299 [07:36<04:34, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18085/28299 [07:36<04:43, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18089/28299 [07:36<04:40, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18093/28299 [07:36<04:40, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18097/28299 [07:37<04:40, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18101/28299 [07:37<04:40, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18105/28299 [07:37<04:37, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18109/28299 [07:37<04:38, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18113/28299 [07:37<04:36, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18117/28299 [07:37<04:46, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18121/28299 [07:37<04:43, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18125/28299 [07:37<04:46, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18129/28299 [07:37<04:44, 35.69it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18133/28299 [07:38<04:52, 34.78it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18137/28299 [07:38<04:41, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18142/28299 [07:38<04:30, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18147/28299 [07:38<04:21, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18152/28299 [07:38<04:18, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18156/28299 [07:38<04:24, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18160/28299 [07:38<04:25, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18164/28299 [07:38<04:30, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18168/28299 [07:38<04:30, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18172/28299 [07:39<04:35, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18176/28299 [07:39<04:36, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18180/28299 [07:39<04:34, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18185/28299 [07:39<04:20, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18190/28299 [07:39<04:15, 39.53it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18194/28299 [07:39<04:21, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18198/28299 [07:39<04:27, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18202/28299 [07:39<04:27, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18206/28299 [07:39<04:27, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18210/28299 [07:40<04:26, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18214/28299 [07:40<04:32, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18218/28299 [07:40<04:28, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18222/28299 [07:40<04:25, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18227/28299 [07:40<04:18, 39.02it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18231/28299 [07:40<04:45, 35.22it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18235/28299 [07:40<04:40, 35.84it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18240/28299 [07:40<04:38, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18244/28299 [07:41<04:45, 35.24it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18248/28299 [07:41<04:42, 35.53it/s]\u001b[A\n",
            "Epoch 1/5:  64%|██████▍   | 18252/28299 [07:41<04:34, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18257/28299 [07:41<04:26, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18261/28299 [07:41<04:28, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18266/28299 [07:41<04:18, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18270/28299 [07:41<04:28, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18274/28299 [07:41<04:27, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18278/28299 [07:41<04:47, 34.90it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18282/28299 [07:42<04:43, 35.32it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18287/28299 [07:42<04:30, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18291/28299 [07:42<04:29, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18295/28299 [07:42<04:29, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18299/28299 [07:42<04:25, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18303/28299 [07:42<04:28, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18308/28299 [07:42<04:19, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18312/28299 [07:42<04:26, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18317/28299 [07:42<04:17, 38.73it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18321/28299 [07:43<04:18, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18325/28299 [07:43<04:26, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18329/28299 [07:43<04:27, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18333/28299 [07:43<04:28, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18337/28299 [07:43<04:30, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18341/28299 [07:43<04:30, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18345/28299 [07:43<04:27, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18349/28299 [07:43<04:27, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18353/28299 [07:43<04:26, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18357/28299 [07:44<04:41, 35.36it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18361/28299 [07:44<04:36, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18365/28299 [07:44<04:37, 35.83it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18369/28299 [07:44<04:30, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18373/28299 [07:44<04:28, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18377/28299 [07:44<04:27, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18381/28299 [07:44<04:25, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18385/28299 [07:44<04:34, 36.17it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18389/28299 [07:44<04:28, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▍   | 18393/28299 [07:45<04:28, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18397/28299 [07:45<04:44, 34.81it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18402/28299 [07:45<04:29, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18406/28299 [07:45<04:25, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18411/28299 [07:45<04:18, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18415/28299 [07:45<04:25, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18420/28299 [07:45<04:17, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18425/28299 [07:45<04:12, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18430/28299 [07:45<04:08, 39.73it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18435/28299 [07:46<04:05, 40.11it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18440/28299 [07:46<04:08, 39.72it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18444/28299 [07:46<04:07, 39.76it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18448/28299 [07:46<07:44, 21.22it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18452/28299 [07:46<06:47, 24.15it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18456/28299 [07:46<06:06, 26.84it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18460/28299 [07:47<05:32, 29.55it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18464/28299 [07:47<05:08, 31.84it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18469/28299 [07:47<04:45, 34.47it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18473/28299 [07:47<04:44, 34.57it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18477/28299 [07:47<04:35, 35.67it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18481/28299 [07:47<04:28, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18486/28299 [07:47<04:19, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18490/28299 [07:47<04:16, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18494/28299 [07:47<04:21, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18498/28299 [07:48<04:34, 35.66it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18502/28299 [07:48<04:29, 36.41it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18507/28299 [07:48<04:19, 37.79it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18512/28299 [07:48<04:10, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18517/28299 [07:48<04:06, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18521/28299 [07:48<04:08, 39.35it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18525/28299 [07:48<04:10, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18529/28299 [07:48<04:11, 38.90it/s]\u001b[A\n",
            "Epoch 1/5:  65%|██████▌   | 18533/28299 [07:49<04:28, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18537/28299 [07:49<04:28, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18541/28299 [07:49<04:26, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18545/28299 [07:49<04:31, 35.95it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18549/28299 [07:49<04:28, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18553/28299 [07:49<04:25, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18557/28299 [07:49<04:21, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18561/28299 [07:49<04:30, 35.98it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18565/28299 [07:49<04:22, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18570/28299 [07:49<04:14, 38.29it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18574/28299 [07:50<04:15, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18578/28299 [07:50<04:15, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18582/28299 [07:50<04:13, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18586/28299 [07:50<04:10, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18590/28299 [07:50<04:17, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18594/28299 [07:50<04:15, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18598/28299 [07:50<04:15, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18602/28299 [07:50<04:14, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18606/28299 [07:50<04:25, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18610/28299 [07:51<04:23, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18614/28299 [07:51<04:24, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18618/28299 [07:51<04:35, 35.15it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18622/28299 [07:51<04:28, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18626/28299 [07:51<04:25, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18630/28299 [07:51<04:23, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18634/28299 [07:51<04:21, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18638/28299 [07:51<04:22, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18642/28299 [07:51<04:21, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18646/28299 [07:52<04:26, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18650/28299 [07:52<04:30, 35.62it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18654/28299 [07:52<04:25, 36.29it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18658/28299 [07:52<04:26, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18662/28299 [07:52<04:22, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18666/28299 [07:52<04:27, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18670/28299 [07:52<04:24, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18675/28299 [07:52<04:13, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18679/28299 [07:52<04:11, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18683/28299 [07:53<04:12, 38.11it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18687/28299 [07:53<04:18, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18691/28299 [07:53<04:19, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18695/28299 [07:53<04:18, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18699/28299 [07:53<04:18, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18703/28299 [07:53<04:19, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18707/28299 [07:53<04:22, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18711/28299 [07:53<04:21, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18715/28299 [07:53<04:23, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18719/28299 [07:54<04:24, 36.23it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18723/28299 [07:54<04:28, 35.61it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18727/28299 [07:54<04:23, 36.28it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18731/28299 [07:54<04:20, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18735/28299 [07:54<04:16, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18739/28299 [07:54<04:13, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18743/28299 [07:54<04:16, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▌   | 18748/28299 [07:54<04:07, 38.52it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18752/28299 [07:54<04:05, 38.91it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18756/28299 [07:55<04:04, 39.00it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18760/28299 [07:55<04:13, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18764/28299 [07:55<04:24, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18768/28299 [07:55<04:21, 36.45it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18772/28299 [07:55<04:16, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18776/28299 [07:55<04:11, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18780/28299 [07:55<04:11, 37.79it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18784/28299 [07:55<04:17, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18789/28299 [07:55<04:08, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18794/28299 [07:56<04:02, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18798/28299 [07:56<04:03, 38.97it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18802/28299 [07:56<04:03, 38.98it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18806/28299 [07:56<04:02, 39.09it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18810/28299 [07:56<04:02, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  66%|██████▋   | 18815/28299 [07:56<03:56, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18820/28299 [07:56<03:55, 40.23it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18825/28299 [07:56<03:53, 40.62it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18830/28299 [07:56<03:53, 40.47it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18835/28299 [07:57<03:55, 40.13it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18840/28299 [07:57<04:02, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18844/28299 [07:57<04:03, 38.76it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18849/28299 [07:57<04:01, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18853/28299 [07:57<04:02, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18857/28299 [07:57<04:04, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18861/28299 [07:57<04:06, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18865/28299 [07:57<04:06, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18869/28299 [07:57<04:14, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18873/28299 [07:58<04:12, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18877/28299 [07:58<04:16, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18881/28299 [07:58<04:17, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18885/28299 [07:58<04:17, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18889/28299 [07:58<04:14, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18893/28299 [07:58<04:11, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18897/28299 [07:58<04:09, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18902/28299 [07:58<04:03, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18906/28299 [07:58<04:03, 38.55it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18911/28299 [07:59<03:59, 39.24it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18915/28299 [07:59<03:58, 39.27it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18920/28299 [07:59<03:54, 39.94it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18924/28299 [07:59<03:55, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18928/28299 [07:59<04:00, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18932/28299 [07:59<04:03, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18936/28299 [07:59<04:01, 38.80it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18941/28299 [07:59<03:54, 39.92it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18946/28299 [07:59<03:56, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18950/28299 [08:00<03:59, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18954/28299 [08:00<03:58, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18958/28299 [08:00<03:57, 39.31it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18962/28299 [08:00<04:04, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18966/28299 [08:00<04:08, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18970/28299 [08:00<04:10, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18974/28299 [08:00<04:12, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18978/28299 [08:00<04:10, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18982/28299 [08:00<04:21, 35.65it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18986/28299 [08:01<04:37, 33.54it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18990/28299 [08:01<04:37, 33.59it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18994/28299 [08:01<04:41, 33.01it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 18998/28299 [08:01<04:33, 33.95it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19002/28299 [08:01<04:25, 35.08it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19006/28299 [08:01<04:32, 34.10it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19010/28299 [08:01<04:28, 34.60it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19014/28299 [08:01<04:18, 35.89it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19018/28299 [08:01<04:26, 34.81it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19022/28299 [08:02<04:25, 34.88it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19026/28299 [08:02<04:21, 35.46it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19030/28299 [08:02<04:17, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19034/28299 [08:02<04:10, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19038/28299 [08:02<04:06, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19043/28299 [08:02<03:56, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19047/28299 [08:02<04:03, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19051/28299 [08:02<04:05, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19056/28299 [08:02<03:57, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19061/28299 [08:03<03:54, 39.45it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19065/28299 [08:03<03:54, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19070/28299 [08:03<03:51, 39.83it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19075/28299 [08:03<03:48, 40.32it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19080/28299 [08:03<03:46, 40.71it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19085/28299 [08:03<03:51, 39.86it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19089/28299 [08:03<03:54, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19093/28299 [08:03<03:57, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19097/28299 [08:04<04:01, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  67%|██████▋   | 19101/28299 [08:04<04:03, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19105/28299 [08:04<04:08, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19109/28299 [08:04<04:06, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19113/28299 [08:04<04:22, 35.04it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19117/28299 [08:04<04:25, 34.55it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19121/28299 [08:04<04:21, 35.08it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19125/28299 [08:04<04:15, 35.92it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19129/28299 [08:04<04:15, 35.90it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19133/28299 [08:05<04:09, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19137/28299 [08:05<04:11, 36.42it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19141/28299 [08:05<04:24, 34.56it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19145/28299 [08:05<04:22, 34.86it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19149/28299 [08:05<04:17, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19153/28299 [08:05<04:12, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19157/28299 [08:05<04:09, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19162/28299 [08:05<03:59, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19166/28299 [08:05<03:59, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19171/28299 [08:06<03:53, 39.11it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19175/28299 [08:06<03:53, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19179/28299 [08:06<03:52, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19183/28299 [08:06<03:58, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19187/28299 [08:06<04:20, 34.99it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19191/28299 [08:06<04:19, 35.05it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19195/28299 [08:06<04:13, 35.90it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19199/28299 [08:06<04:09, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19203/28299 [08:06<04:07, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19207/28299 [08:07<04:20, 34.84it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19211/28299 [08:07<04:15, 35.61it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19215/28299 [08:07<04:09, 36.45it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19219/28299 [08:07<04:07, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19223/28299 [08:07<04:26, 34.11it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19227/28299 [08:07<04:20, 34.84it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19231/28299 [08:07<04:14, 35.64it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19235/28299 [08:07<04:10, 36.17it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19239/28299 [08:07<04:08, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19243/28299 [08:08<04:04, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19247/28299 [08:08<04:02, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19251/28299 [08:08<04:05, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19255/28299 [08:08<04:06, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19259/28299 [08:08<04:03, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19264/28299 [08:08<03:56, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19269/28299 [08:08<03:50, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19273/28299 [08:08<03:58, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19277/28299 [08:08<03:58, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19281/28299 [08:09<03:58, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19285/28299 [08:09<03:57, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19289/28299 [08:09<04:02, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19293/28299 [08:09<04:01, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19297/28299 [08:09<04:03, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19301/28299 [08:09<03:58, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19305/28299 [08:09<04:00, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19309/28299 [08:09<04:02, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19313/28299 [08:09<03:58, 37.60it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19317/28299 [08:10<04:11, 35.76it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19321/28299 [08:10<04:15, 35.20it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19325/28299 [08:10<04:12, 35.50it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19330/28299 [08:10<04:02, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19334/28299 [08:10<04:04, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19338/28299 [08:10<04:22, 34.18it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19342/28299 [08:10<04:12, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19347/28299 [08:10<04:04, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19351/28299 [08:10<04:08, 35.94it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19356/28299 [08:11<04:01, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19360/28299 [08:11<03:57, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19365/28299 [08:11<03:52, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19370/28299 [08:11<03:49, 38.97it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19374/28299 [08:11<03:50, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19378/28299 [08:12<07:24, 20.07it/s]\u001b[A\n",
            "Epoch 1/5:  68%|██████▊   | 19382/28299 [08:12<06:32, 22.70it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19386/28299 [08:12<06:11, 24.00it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19390/28299 [08:12<05:32, 26.81it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19394/28299 [08:12<05:03, 29.39it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19398/28299 [08:12<04:39, 31.87it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19402/28299 [08:12<04:28, 33.09it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19406/28299 [08:12<04:18, 34.41it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19410/28299 [08:12<04:08, 35.72it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19414/28299 [08:12<04:01, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19418/28299 [08:13<04:03, 36.51it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19422/28299 [08:13<04:05, 36.23it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19426/28299 [08:13<04:00, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19430/28299 [08:13<04:07, 35.81it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19434/28299 [08:13<04:11, 35.23it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19438/28299 [08:13<04:02, 36.51it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19442/28299 [08:13<04:00, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19446/28299 [08:13<04:00, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19451/28299 [08:14<04:03, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▊   | 19455/28299 [08:14<04:09, 35.49it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19459/28299 [08:14<04:11, 35.09it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19464/28299 [08:14<04:00, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19468/28299 [08:14<03:54, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19472/28299 [08:14<03:55, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19477/28299 [08:14<03:48, 38.60it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19482/28299 [08:14<03:43, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19487/28299 [08:14<03:40, 39.97it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19491/28299 [08:15<03:42, 39.60it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19495/28299 [08:15<03:47, 38.73it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19499/28299 [08:15<03:48, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19503/28299 [08:15<03:46, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19508/28299 [08:15<03:39, 40.00it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19513/28299 [08:15<03:38, 40.17it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19518/28299 [08:15<03:39, 39.94it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19522/28299 [08:15<03:47, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19527/28299 [08:15<03:42, 39.43it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19532/28299 [08:16<03:40, 39.75it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19536/28299 [08:16<03:42, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19540/28299 [08:16<03:42, 39.44it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19545/28299 [08:16<03:39, 39.81it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19550/28299 [08:16<03:35, 40.64it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19555/28299 [08:16<03:42, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19559/28299 [08:16<03:42, 39.30it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19564/28299 [08:16<03:41, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19568/28299 [08:17<03:41, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19572/28299 [08:17<03:40, 39.55it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19576/28299 [08:17<03:44, 38.91it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19580/28299 [08:17<03:42, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19584/28299 [08:17<03:54, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19588/28299 [08:17<03:58, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19592/28299 [08:17<03:53, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19597/28299 [08:17<03:46, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19601/28299 [08:17<03:51, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19606/28299 [08:18<03:45, 38.49it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19610/28299 [08:18<03:47, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19614/28299 [08:18<03:47, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19618/28299 [08:18<03:47, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19622/28299 [08:18<04:10, 34.60it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19626/28299 [08:18<04:11, 34.51it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19630/28299 [08:18<04:03, 35.65it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19635/28299 [08:18<03:52, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19639/28299 [08:18<03:57, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19643/28299 [08:19<03:54, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19647/28299 [08:19<04:03, 35.48it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19651/28299 [08:19<03:59, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19655/28299 [08:19<03:52, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19660/28299 [08:19<03:45, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  69%|██████▉   | 19664/28299 [08:19<03:48, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19668/28299 [08:19<03:53, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19672/28299 [08:19<03:55, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19676/28299 [08:19<03:53, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19681/28299 [08:20<03:45, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19686/28299 [08:20<03:41, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19690/28299 [08:20<03:41, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19694/28299 [08:20<03:48, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19699/28299 [08:20<03:41, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19704/28299 [08:20<03:38, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19708/28299 [08:20<03:41, 38.85it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19712/28299 [08:20<03:51, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19716/28299 [08:20<03:58, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19720/28299 [08:21<03:56, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19724/28299 [08:21<03:54, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19728/28299 [08:21<03:48, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19732/28299 [08:21<03:44, 38.10it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19736/28299 [08:21<03:45, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19740/28299 [08:21<03:44, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19744/28299 [08:21<03:45, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19748/28299 [08:21<03:53, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19752/28299 [08:21<03:57, 35.94it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19756/28299 [08:22<04:13, 33.66it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19760/28299 [08:22<04:08, 34.37it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19765/28299 [08:22<03:54, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19769/28299 [08:22<03:53, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19773/28299 [08:22<03:55, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19777/28299 [08:22<03:57, 35.92it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19781/28299 [08:22<03:58, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19785/28299 [08:22<03:50, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19789/28299 [08:22<03:52, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19793/28299 [08:23<03:47, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19797/28299 [08:23<03:43, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19801/28299 [08:23<04:00, 35.27it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19805/28299 [08:23<03:57, 35.73it/s]\u001b[A\n",
            "Epoch 1/5:  70%|██████▉   | 19809/28299 [08:23<03:53, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19813/28299 [08:23<03:55, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19817/28299 [08:23<03:59, 35.35it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19821/28299 [08:23<03:57, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19825/28299 [08:23<03:53, 36.29it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19829/28299 [08:24<03:49, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19833/28299 [08:24<03:47, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19837/28299 [08:24<04:02, 34.85it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19841/28299 [08:24<04:01, 34.96it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19845/28299 [08:24<04:09, 33.94it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19849/28299 [08:24<04:03, 34.74it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19853/28299 [08:24<03:58, 35.43it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19857/28299 [08:24<03:56, 35.65it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19861/28299 [08:24<03:52, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19866/28299 [08:25<03:43, 37.81it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19871/28299 [08:25<03:36, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19876/28299 [08:25<03:31, 39.79it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19880/28299 [08:25<03:32, 39.54it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19884/28299 [08:25<03:32, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19888/28299 [08:25<03:33, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19892/28299 [08:25<03:34, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19896/28299 [08:25<03:37, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19900/28299 [08:25<03:37, 38.57it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19904/28299 [08:26<03:44, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19908/28299 [08:26<03:44, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19912/28299 [08:26<03:45, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19916/28299 [08:26<03:41, 37.79it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19920/28299 [08:26<03:38, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19924/28299 [08:26<03:41, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19928/28299 [08:26<03:40, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19932/28299 [08:26<03:41, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19936/28299 [08:26<03:41, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19940/28299 [08:27<03:39, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19945/28299 [08:27<03:33, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  70%|███████   | 19949/28299 [08:27<03:33, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19953/28299 [08:27<03:34, 39.00it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19958/28299 [08:27<03:33, 39.13it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19962/28299 [08:27<03:34, 38.85it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19966/28299 [08:27<03:40, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19970/28299 [08:27<03:41, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19974/28299 [08:27<03:40, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19978/28299 [08:28<03:42, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19982/28299 [08:28<03:45, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19986/28299 [08:28<03:49, 36.28it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19990/28299 [08:28<03:44, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 19995/28299 [08:28<03:33, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20000/28299 [08:28<03:29, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20005/28299 [08:28<03:27, 39.97it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20009/28299 [08:28<03:32, 38.97it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20013/28299 [08:28<03:48, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20017/28299 [08:29<04:00, 34.49it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20022/28299 [08:29<03:47, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20027/28299 [08:29<03:37, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20031/28299 [08:29<03:35, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20035/28299 [08:29<03:34, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20039/28299 [08:29<03:33, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20043/28299 [08:29<03:31, 39.02it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20047/28299 [08:29<03:34, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20052/28299 [08:29<03:29, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20057/28299 [08:30<03:27, 39.76it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20061/28299 [08:30<03:33, 38.57it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20065/28299 [08:30<03:31, 38.86it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20070/28299 [08:30<03:27, 39.71it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20075/28299 [08:30<03:23, 40.36it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20080/28299 [08:30<03:22, 40.58it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20085/28299 [08:30<03:21, 40.80it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20090/28299 [08:30<03:24, 40.06it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20095/28299 [08:31<03:25, 40.00it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20100/28299 [08:31<03:25, 39.93it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20105/28299 [08:31<03:23, 40.31it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20110/28299 [08:31<03:23, 40.31it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20115/28299 [08:31<03:23, 40.29it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20120/28299 [08:31<03:22, 40.31it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20125/28299 [08:31<03:27, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20129/28299 [08:31<03:30, 38.72it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20133/28299 [08:32<03:38, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20137/28299 [08:32<03:38, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20141/28299 [08:32<03:36, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20145/28299 [08:32<03:32, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20150/28299 [08:32<03:28, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20155/28299 [08:32<03:27, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████   | 20159/28299 [08:32<03:30, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20164/28299 [08:32<03:23, 39.94it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20168/28299 [08:32<03:23, 39.86it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20172/28299 [08:32<03:25, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20176/28299 [08:33<03:32, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20180/28299 [08:33<03:29, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20185/28299 [08:33<03:25, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20190/28299 [08:33<03:25, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20194/28299 [08:33<03:29, 38.69it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20199/28299 [08:33<03:25, 39.33it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20204/28299 [08:33<03:23, 39.81it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20208/28299 [08:33<03:31, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20212/28299 [08:34<03:28, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20216/28299 [08:34<03:31, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20220/28299 [08:34<03:33, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20224/28299 [08:34<03:32, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20228/28299 [08:34<03:35, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  71%|███████▏  | 20232/28299 [08:34<03:34, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20236/28299 [08:34<03:38, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20240/28299 [08:34<03:36, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20244/28299 [08:34<03:35, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20248/28299 [08:34<03:34, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20252/28299 [08:35<03:41, 36.31it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20256/28299 [08:35<03:42, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20260/28299 [08:35<04:00, 33.42it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20264/28299 [08:35<03:52, 34.51it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20268/28299 [08:35<03:48, 35.16it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20272/28299 [08:35<03:45, 35.52it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20276/28299 [08:35<03:46, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20280/28299 [08:35<03:51, 34.62it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20284/28299 [08:36<03:48, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20288/28299 [08:36<03:42, 35.94it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20292/28299 [08:36<03:37, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20296/28299 [08:36<03:33, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20300/28299 [08:36<03:31, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20304/28299 [08:36<06:41, 19.92it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20308/28299 [08:36<05:45, 23.13it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20312/28299 [08:37<05:01, 26.45it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20316/28299 [08:37<04:39, 28.59it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20320/28299 [08:37<04:21, 30.51it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20324/28299 [08:37<04:03, 32.75it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20329/28299 [08:37<03:46, 35.21it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20333/28299 [08:37<03:44, 35.50it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20337/28299 [08:37<03:50, 34.50it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20341/28299 [08:37<03:47, 34.93it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20345/28299 [08:37<03:40, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20350/28299 [08:38<03:32, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20354/28299 [08:38<03:28, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20359/28299 [08:38<03:28, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20363/28299 [08:38<03:26, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20367/28299 [08:38<03:32, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20371/28299 [08:38<03:28, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20375/28299 [08:38<03:26, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20380/28299 [08:38<03:22, 39.15it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20384/28299 [08:38<03:22, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20388/28299 [08:39<03:24, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20392/28299 [08:39<03:32, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20396/28299 [08:39<03:29, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20400/28299 [08:39<03:29, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20404/28299 [08:39<03:29, 37.60it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20408/28299 [08:39<03:46, 34.89it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20412/28299 [08:39<03:44, 35.11it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20416/28299 [08:39<03:41, 35.64it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20420/28299 [08:39<03:35, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20424/28299 [08:40<03:35, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20428/28299 [08:40<03:40, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20432/28299 [08:40<03:40, 35.66it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20436/28299 [08:40<03:37, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20440/28299 [08:40<03:34, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20445/28299 [08:40<03:27, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20450/28299 [08:40<03:20, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20454/28299 [08:40<03:23, 38.55it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20459/28299 [08:41<03:19, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20463/28299 [08:41<03:24, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20467/28299 [08:41<03:37, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20471/28299 [08:41<03:31, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20475/28299 [08:41<03:45, 34.64it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20480/28299 [08:41<03:33, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20485/28299 [08:41<03:24, 38.29it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20489/28299 [08:41<03:22, 38.59it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20493/28299 [08:41<03:20, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20498/28299 [08:42<03:17, 39.58it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20503/28299 [08:42<03:14, 40.04it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20508/28299 [08:42<03:16, 39.57it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20512/28299 [08:42<03:17, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  72%|███████▏  | 20516/28299 [08:42<03:20, 38.80it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20520/28299 [08:42<03:21, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20524/28299 [08:42<03:27, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20529/28299 [08:42<03:23, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20533/28299 [08:42<03:23, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20537/28299 [08:43<03:22, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20541/28299 [08:43<03:20, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20545/28299 [08:43<03:29, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20549/28299 [08:43<03:47, 34.03it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20553/28299 [08:43<03:46, 34.13it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20557/28299 [08:43<03:43, 34.69it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20562/28299 [08:43<03:30, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20566/28299 [08:43<03:37, 35.49it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20571/28299 [08:44<03:28, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20575/28299 [08:44<03:27, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20579/28299 [08:44<03:26, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20583/28299 [08:44<03:27, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20587/28299 [08:44<03:28, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20591/28299 [08:44<03:24, 37.60it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20595/28299 [08:44<03:22, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20599/28299 [08:44<03:21, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20603/28299 [08:44<03:21, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20607/28299 [08:44<03:28, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20611/28299 [08:45<03:34, 35.84it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20616/28299 [08:45<03:25, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20620/28299 [08:45<03:22, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20624/28299 [08:45<03:29, 36.55it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20628/28299 [08:45<03:32, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20632/28299 [08:45<03:28, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20636/28299 [08:45<03:26, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20640/28299 [08:45<03:28, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20644/28299 [08:45<03:34, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20649/28299 [08:46<03:23, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20653/28299 [08:46<03:22, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20657/28299 [08:46<03:23, 37.60it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20661/28299 [08:46<03:24, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20665/28299 [08:46<03:26, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20669/28299 [08:46<03:41, 34.50it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20673/28299 [08:46<03:37, 35.10it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20677/28299 [08:46<03:41, 34.38it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20681/28299 [08:47<03:35, 35.33it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20685/28299 [08:47<03:37, 35.01it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20689/28299 [08:47<03:40, 34.55it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20693/28299 [08:47<03:39, 34.66it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20698/28299 [08:47<03:27, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20703/28299 [08:47<03:20, 37.84it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20707/28299 [08:47<03:30, 36.09it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20711/28299 [08:47<03:41, 34.27it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20715/28299 [08:47<03:38, 34.69it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20719/28299 [08:48<03:32, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20723/28299 [08:48<03:30, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20727/28299 [08:48<03:25, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20731/28299 [08:48<03:20, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20735/28299 [08:48<03:23, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20739/28299 [08:48<03:25, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20743/28299 [08:48<03:25, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20747/28299 [08:48<03:24, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20751/28299 [08:48<03:24, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20755/28299 [08:49<03:22, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20759/28299 [08:49<03:20, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20763/28299 [08:49<03:23, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20767/28299 [08:49<03:34, 35.04it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20771/28299 [08:49<03:30, 35.80it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20775/28299 [08:49<03:28, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20779/28299 [08:49<03:35, 34.84it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20783/28299 [08:49<03:31, 35.61it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20788/28299 [08:49<03:28, 36.10it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20792/28299 [08:50<03:29, 35.89it/s]\u001b[A\n",
            "Epoch 1/5:  73%|███████▎  | 20796/28299 [08:50<03:23, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20801/28299 [08:50<03:17, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20806/28299 [08:50<03:19, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20810/28299 [08:50<03:23, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20814/28299 [08:50<03:21, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20818/28299 [08:50<03:40, 33.97it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20822/28299 [08:50<03:35, 34.73it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20826/28299 [08:51<03:33, 34.96it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20830/28299 [08:51<03:28, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20834/28299 [08:51<03:23, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20838/28299 [08:51<03:23, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20842/28299 [08:51<03:19, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20846/28299 [08:51<03:17, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20850/28299 [08:51<03:21, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20854/28299 [08:51<03:19, 37.34it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20858/28299 [08:51<03:20, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20862/28299 [08:51<03:20, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20866/28299 [08:52<03:18, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▎  | 20870/28299 [08:52<03:15, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20874/28299 [08:52<03:13, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20879/28299 [08:52<03:10, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20884/28299 [08:52<03:07, 39.52it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20888/28299 [08:52<03:07, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20893/28299 [08:52<03:08, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20897/28299 [08:52<03:17, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20901/28299 [08:52<03:14, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20905/28299 [08:53<03:17, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20909/28299 [08:53<03:18, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20913/28299 [08:53<03:24, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20917/28299 [08:53<03:20, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20921/28299 [08:53<03:20, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20925/28299 [08:53<03:16, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20929/28299 [08:53<03:15, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20933/28299 [08:53<03:18, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20937/28299 [08:53<03:18, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20941/28299 [08:54<03:25, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20945/28299 [08:54<03:21, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20949/28299 [08:54<03:20, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20954/28299 [08:54<03:11, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20958/28299 [08:54<03:09, 38.77it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20963/28299 [08:54<03:05, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20967/28299 [08:54<03:22, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20971/28299 [08:54<03:29, 34.94it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20975/28299 [08:55<03:28, 35.16it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20979/28299 [08:55<03:28, 35.18it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20983/28299 [08:55<03:24, 35.78it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20987/28299 [08:55<03:31, 34.59it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20991/28299 [08:55<03:33, 34.26it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20995/28299 [08:55<03:33, 34.25it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 20999/28299 [08:55<03:29, 34.81it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21004/28299 [08:55<03:18, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21008/28299 [08:55<03:17, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21012/28299 [08:56<03:14, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21016/28299 [08:56<03:14, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21020/28299 [08:56<03:16, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21024/28299 [08:56<03:16, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21028/28299 [08:56<03:16, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21033/28299 [08:56<03:09, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21037/28299 [08:56<03:12, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21041/28299 [08:56<03:14, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21045/28299 [08:56<03:16, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21049/28299 [08:57<03:27, 35.02it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21053/28299 [08:57<03:32, 34.03it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21057/28299 [08:57<03:26, 35.14it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21061/28299 [08:57<03:22, 35.77it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21065/28299 [08:57<03:18, 36.51it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21069/28299 [08:57<03:15, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21073/28299 [08:57<03:14, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21077/28299 [08:57<03:13, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  74%|███████▍  | 21081/28299 [08:57<03:15, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21085/28299 [08:58<03:14, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21089/28299 [08:58<03:16, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21093/28299 [08:58<03:18, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21097/28299 [08:58<03:31, 34.03it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21101/28299 [08:58<03:25, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21105/28299 [08:58<03:22, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21109/28299 [08:58<03:19, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21113/28299 [08:58<03:14, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21117/28299 [08:58<03:23, 35.27it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21121/28299 [08:59<03:21, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21125/28299 [08:59<03:18, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21129/28299 [08:59<03:15, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21133/28299 [08:59<03:12, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21137/28299 [08:59<03:16, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21141/28299 [08:59<03:13, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21145/28299 [08:59<03:26, 34.67it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21149/28299 [08:59<03:23, 35.16it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21153/28299 [08:59<03:19, 35.82it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21157/28299 [09:00<03:15, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21161/28299 [09:00<03:10, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21165/28299 [09:00<03:12, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21169/28299 [09:00<03:11, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21173/28299 [09:00<03:08, 37.81it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21177/28299 [09:00<03:06, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21181/28299 [09:00<03:07, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21185/28299 [09:00<03:10, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21189/28299 [09:00<03:07, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21193/28299 [09:00<03:12, 36.90it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21197/28299 [09:01<03:07, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21201/28299 [09:01<03:11, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21205/28299 [09:01<03:11, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21209/28299 [09:01<03:10, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21214/28299 [09:01<03:05, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21219/28299 [09:01<03:00, 39.25it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▍  | 21224/28299 [09:01<02:58, 39.66it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21228/28299 [09:01<03:07, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21232/28299 [09:02<05:43, 20.57it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21236/28299 [09:02<04:57, 23.72it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21240/28299 [09:02<04:23, 26.78it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21245/28299 [09:02<03:53, 30.18it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21249/28299 [09:02<03:50, 30.60it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21254/28299 [09:02<03:31, 33.33it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21258/28299 [09:03<03:22, 34.74it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21262/28299 [09:03<03:16, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21266/28299 [09:03<03:15, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21270/28299 [09:03<03:11, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21274/28299 [09:03<03:11, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21278/28299 [09:03<03:09, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21282/28299 [09:03<03:11, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21286/28299 [09:03<03:07, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21290/28299 [09:03<03:04, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21294/28299 [09:03<03:02, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21298/28299 [09:04<03:03, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21302/28299 [09:04<03:01, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21306/28299 [09:04<03:02, 38.29it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21310/28299 [09:04<03:05, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21315/28299 [09:04<02:59, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21319/28299 [09:04<03:14, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21324/28299 [09:04<03:05, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21329/28299 [09:04<03:00, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21334/28299 [09:05<02:57, 39.34it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21339/28299 [09:05<02:54, 39.87it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21343/28299 [09:05<02:56, 39.52it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21347/28299 [09:05<03:01, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21352/28299 [09:05<02:59, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21356/28299 [09:05<03:00, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21361/28299 [09:05<02:59, 38.75it/s]\u001b[A\n",
            "Epoch 1/5:  75%|███████▌  | 21365/28299 [09:05<03:01, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21369/28299 [09:05<03:03, 37.84it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21374/28299 [09:06<02:57, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21379/28299 [09:06<02:56, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21383/28299 [09:06<03:00, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21388/28299 [09:06<02:55, 39.30it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21392/28299 [09:06<02:55, 39.36it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21396/28299 [09:06<02:56, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21400/28299 [09:06<02:57, 38.80it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21404/28299 [09:06<02:57, 38.79it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21408/28299 [09:06<02:58, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21413/28299 [09:07<02:54, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21418/28299 [09:07<02:51, 40.11it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21423/28299 [09:07<02:51, 40.21it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21428/28299 [09:07<03:01, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21432/28299 [09:07<03:00, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21436/28299 [09:07<03:01, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21440/28299 [09:07<02:58, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21444/28299 [09:07<03:10, 36.03it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21448/28299 [09:07<03:07, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21452/28299 [09:08<03:15, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21456/28299 [09:08<03:16, 34.76it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21460/28299 [09:08<03:16, 34.74it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21464/28299 [09:08<03:20, 34.15it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21468/28299 [09:08<03:19, 34.19it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21472/28299 [09:08<03:11, 35.56it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21476/28299 [09:08<03:11, 35.58it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21480/28299 [09:08<03:07, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21484/28299 [09:09<03:07, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21488/28299 [09:09<03:14, 35.01it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21492/28299 [09:09<03:10, 35.73it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21496/28299 [09:09<03:07, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21500/28299 [09:09<03:04, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21504/28299 [09:09<03:00, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21508/28299 [09:09<02:58, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21512/28299 [09:09<02:59, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21516/28299 [09:09<03:06, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21520/28299 [09:09<03:04, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21524/28299 [09:10<03:03, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21528/28299 [09:10<03:05, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21533/28299 [09:10<02:59, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21537/28299 [09:10<03:07, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21541/28299 [09:10<03:08, 35.90it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21545/28299 [09:10<03:04, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21549/28299 [09:10<03:01, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21553/28299 [09:10<03:09, 35.59it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21557/28299 [09:11<03:09, 35.64it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21561/28299 [09:11<03:08, 35.67it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21565/28299 [09:11<03:06, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21569/28299 [09:11<03:03, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21573/28299 [09:11<03:01, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▌  | 21577/28299 [09:11<03:06, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21581/28299 [09:11<03:01, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21585/28299 [09:11<03:05, 36.24it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21589/28299 [09:11<03:19, 33.64it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21593/28299 [09:12<03:11, 34.99it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21597/28299 [09:12<03:05, 36.10it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21601/28299 [09:12<03:00, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21605/28299 [09:12<02:58, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21610/28299 [09:12<02:53, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21614/28299 [09:12<02:57, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21618/28299 [09:12<03:01, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21622/28299 [09:12<02:59, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21626/28299 [09:12<02:57, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21630/28299 [09:12<02:57, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21634/28299 [09:13<03:00, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21638/28299 [09:13<02:58, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21642/28299 [09:13<02:56, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  76%|███████▋  | 21646/28299 [09:13<03:04, 36.09it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21650/28299 [09:13<03:10, 34.90it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21654/28299 [09:13<03:09, 35.01it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21659/28299 [09:13<03:00, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21663/28299 [09:13<02:56, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21668/28299 [09:14<02:51, 38.73it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21672/28299 [09:14<02:53, 38.23it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21676/28299 [09:14<02:53, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21680/28299 [09:14<02:54, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21684/28299 [09:14<02:53, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21688/28299 [09:14<02:59, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21692/28299 [09:14<03:07, 35.21it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21696/28299 [09:14<03:05, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21700/28299 [09:14<03:01, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21704/28299 [09:14<02:59, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21708/28299 [09:15<02:59, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21712/28299 [09:15<03:01, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21716/28299 [09:15<02:57, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21720/28299 [09:15<02:57, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21724/28299 [09:15<02:53, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21728/28299 [09:15<02:54, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21732/28299 [09:15<02:54, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21736/28299 [09:15<03:00, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21740/28299 [09:15<02:55, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21744/28299 [09:16<02:52, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21748/28299 [09:16<03:01, 36.06it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21752/28299 [09:16<03:13, 33.81it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21756/28299 [09:16<03:16, 33.27it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21760/28299 [09:16<03:17, 33.14it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21764/28299 [09:16<03:08, 34.68it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21769/28299 [09:16<02:58, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21773/28299 [09:16<02:56, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21778/28299 [09:17<02:49, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21782/28299 [09:17<02:51, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21786/28299 [09:17<02:49, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21791/28299 [09:17<02:46, 39.13it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21796/28299 [09:17<02:43, 39.88it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21800/28299 [09:17<02:43, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21804/28299 [09:17<02:46, 38.90it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21808/28299 [09:17<02:47, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21812/28299 [09:17<02:48, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21816/28299 [09:18<02:54, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21820/28299 [09:18<02:54, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21824/28299 [09:18<02:55, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21828/28299 [09:18<03:08, 34.30it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21832/28299 [09:18<03:01, 35.62it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21837/28299 [09:18<02:53, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21841/28299 [09:18<02:49, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21846/28299 [09:18<02:45, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21850/28299 [09:18<02:47, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21854/28299 [09:19<02:53, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21858/28299 [09:19<03:02, 35.35it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21862/28299 [09:19<03:00, 35.69it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21866/28299 [09:19<03:01, 35.42it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21870/28299 [09:19<02:58, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21874/28299 [09:19<02:56, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21878/28299 [09:19<02:57, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21882/28299 [09:19<03:00, 35.53it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21886/28299 [09:19<02:57, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21890/28299 [09:20<02:54, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21894/28299 [09:20<02:53, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21898/28299 [09:20<02:57, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21902/28299 [09:20<02:57, 36.03it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21907/28299 [09:20<02:48, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21912/28299 [09:20<02:44, 38.88it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21916/28299 [09:20<02:49, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21920/28299 [09:20<02:47, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21924/28299 [09:20<02:56, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  77%|███████▋  | 21928/28299 [09:21<02:57, 35.81it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21932/28299 [09:21<02:55, 36.24it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21936/28299 [09:21<02:52, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21940/28299 [09:21<02:59, 35.52it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21944/28299 [09:21<02:57, 35.83it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21948/28299 [09:21<02:57, 35.77it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21952/28299 [09:21<02:52, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21957/28299 [09:21<02:45, 38.35it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21962/28299 [09:21<02:41, 39.34it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21966/28299 [09:22<02:42, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21970/28299 [09:22<02:50, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21974/28299 [09:22<02:53, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21978/28299 [09:22<02:50, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21982/28299 [09:22<02:48, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21986/28299 [09:22<02:48, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21990/28299 [09:22<02:56, 35.78it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21995/28299 [09:22<02:47, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 21999/28299 [09:22<02:45, 38.14it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22003/28299 [09:23<02:44, 38.17it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22007/28299 [09:23<02:51, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22011/28299 [09:23<02:52, 36.51it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22015/28299 [09:23<02:50, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22020/28299 [09:23<02:43, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22025/28299 [09:23<02:39, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22029/28299 [09:23<02:42, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22033/28299 [09:23<02:41, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22038/28299 [09:23<02:37, 39.63it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22042/28299 [09:24<02:39, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22046/28299 [09:24<02:41, 38.70it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22050/28299 [09:24<02:43, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22055/28299 [09:24<02:40, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22060/28299 [09:24<02:42, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22064/28299 [09:24<02:50, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22068/28299 [09:24<02:48, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22072/28299 [09:24<02:45, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22076/28299 [09:25<02:52, 36.17it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22081/28299 [09:25<02:45, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22085/28299 [09:25<02:45, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22089/28299 [09:25<02:48, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22093/28299 [09:25<02:55, 35.33it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22097/28299 [09:25<02:52, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22101/28299 [09:25<02:47, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22105/28299 [09:25<02:51, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22110/28299 [09:25<02:45, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22114/28299 [09:26<02:48, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22118/28299 [09:26<02:53, 35.70it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22122/28299 [09:26<02:47, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22126/28299 [09:26<02:44, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22130/28299 [09:26<02:42, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22135/28299 [09:26<02:37, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22140/28299 [09:26<02:35, 39.66it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22144/28299 [09:26<02:37, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22148/28299 [09:26<02:37, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22152/28299 [09:27<02:37, 39.13it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22156/28299 [09:27<05:08, 19.91it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22160/28299 [09:27<04:30, 22.73it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22164/28299 [09:27<03:58, 25.75it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22168/28299 [09:27<03:35, 28.46it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22172/28299 [09:27<03:22, 30.25it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22176/28299 [09:28<03:10, 32.09it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22180/28299 [09:28<03:05, 33.02it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22184/28299 [09:28<03:01, 33.76it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22189/28299 [09:28<02:53, 35.16it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22193/28299 [09:28<02:49, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22197/28299 [09:28<02:48, 36.31it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22201/28299 [09:28<02:46, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22205/28299 [09:28<02:48, 36.25it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22209/28299 [09:28<02:46, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  78%|███████▊  | 22214/28299 [09:29<02:40, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22218/28299 [09:29<02:40, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22222/28299 [09:29<02:45, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22226/28299 [09:29<02:44, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22230/28299 [09:29<02:44, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22234/28299 [09:29<02:43, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22238/28299 [09:29<02:43, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22242/28299 [09:29<02:42, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22246/28299 [09:29<02:41, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22250/28299 [09:29<02:41, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22254/28299 [09:30<02:42, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22258/28299 [09:30<02:43, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22262/28299 [09:30<02:44, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22266/28299 [09:30<02:43, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22270/28299 [09:30<02:45, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22274/28299 [09:30<02:41, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22279/28299 [09:30<02:33, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▊  | 22283/28299 [09:30<02:36, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22288/28299 [09:30<02:34, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22292/28299 [09:31<02:32, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22296/28299 [09:31<02:32, 39.24it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22300/28299 [09:31<02:41, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22304/28299 [09:31<02:43, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22308/28299 [09:31<02:39, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22312/28299 [09:31<02:41, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22316/28299 [09:31<02:40, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22320/28299 [09:31<02:43, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22324/28299 [09:31<02:40, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22328/28299 [09:32<02:39, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22332/28299 [09:32<02:37, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22336/28299 [09:32<02:35, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22341/28299 [09:32<02:32, 38.96it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22346/28299 [09:32<02:30, 39.54it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22350/28299 [09:32<02:30, 39.48it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22354/28299 [09:32<02:31, 39.18it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22358/28299 [09:32<02:35, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22362/28299 [09:32<02:33, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22366/28299 [09:33<02:33, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22370/28299 [09:33<02:33, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22374/28299 [09:33<02:40, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22378/28299 [09:33<02:37, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22382/28299 [09:33<02:36, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22386/28299 [09:33<02:34, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22390/28299 [09:33<02:35, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22394/28299 [09:33<02:35, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22398/28299 [09:33<02:42, 36.42it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22402/28299 [09:34<02:39, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22406/28299 [09:34<02:39, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22410/28299 [09:34<02:39, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22414/28299 [09:34<02:46, 35.28it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22418/28299 [09:34<02:47, 35.14it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22422/28299 [09:34<02:47, 35.02it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22426/28299 [09:34<02:53, 33.84it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22430/28299 [09:34<02:48, 34.83it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22434/28299 [09:34<02:44, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22438/28299 [09:35<02:41, 36.23it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22442/28299 [09:35<02:45, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22446/28299 [09:35<02:43, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22450/28299 [09:35<02:40, 36.41it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22454/28299 [09:35<02:40, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22458/28299 [09:35<02:41, 36.23it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22462/28299 [09:35<02:41, 36.08it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22466/28299 [09:35<02:42, 35.81it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22470/28299 [09:35<02:39, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22474/28299 [09:36<02:40, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22478/28299 [09:36<02:39, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22482/28299 [09:36<02:41, 36.09it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22486/28299 [09:36<02:48, 34.55it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22490/28299 [09:36<02:47, 34.67it/s]\u001b[A\n",
            "Epoch 1/5:  79%|███████▉  | 22494/28299 [09:36<02:45, 34.99it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22498/28299 [09:36<02:44, 35.30it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22502/28299 [09:36<02:48, 34.36it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22506/28299 [09:36<02:49, 34.13it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22510/28299 [09:37<02:51, 33.73it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22514/28299 [09:37<02:50, 33.96it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22518/28299 [09:37<02:45, 35.00it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22522/28299 [09:37<02:41, 35.84it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22526/28299 [09:37<02:38, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22530/28299 [09:37<02:34, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22534/28299 [09:37<02:37, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22538/28299 [09:37<02:34, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22542/28299 [09:37<02:35, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22546/28299 [09:38<02:33, 37.60it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22551/28299 [09:38<02:28, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22555/28299 [09:38<02:27, 39.06it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22559/28299 [09:38<02:29, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22563/28299 [09:38<02:40, 35.69it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22567/28299 [09:38<02:42, 35.36it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22571/28299 [09:38<02:40, 35.65it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22575/28299 [09:38<02:43, 34.96it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22580/28299 [09:38<02:35, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22584/28299 [09:39<02:35, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22588/28299 [09:39<02:34, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22592/28299 [09:39<02:30, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22596/28299 [09:39<02:43, 34.91it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22600/28299 [09:39<02:40, 35.53it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22605/28299 [09:39<02:33, 37.05it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22610/28299 [09:39<02:31, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22614/28299 [09:39<02:29, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22618/28299 [09:39<02:29, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22622/28299 [09:40<02:30, 37.84it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22626/28299 [09:40<02:33, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22630/28299 [09:40<02:29, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22634/28299 [09:40<02:34, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  80%|███████▉  | 22638/28299 [09:40<02:34, 36.67it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22642/28299 [09:40<02:30, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22647/28299 [09:40<02:26, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22652/28299 [09:40<02:23, 39.31it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22656/28299 [09:41<02:32, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22660/28299 [09:41<02:31, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22664/28299 [09:41<02:29, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22668/28299 [09:41<02:27, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22672/28299 [09:41<02:28, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22676/28299 [09:41<02:25, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22681/28299 [09:41<02:22, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22685/28299 [09:41<02:22, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22690/28299 [09:41<02:21, 39.78it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22695/28299 [09:41<02:18, 40.38it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22700/28299 [09:42<02:18, 40.42it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22705/28299 [09:42<02:24, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22710/28299 [09:42<02:21, 39.51it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22715/28299 [09:42<02:19, 40.12it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22720/28299 [09:42<02:19, 40.10it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22725/28299 [09:42<02:18, 40.13it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22730/28299 [09:42<02:21, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22734/28299 [09:43<02:31, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22738/28299 [09:43<02:32, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22742/28299 [09:43<02:30, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22746/28299 [09:43<02:38, 35.11it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22750/28299 [09:43<02:34, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22755/28299 [09:43<02:28, 37.27it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22759/28299 [09:43<02:37, 35.17it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22763/28299 [09:43<02:32, 36.26it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22767/28299 [09:43<02:34, 35.70it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22771/28299 [09:44<02:33, 36.09it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22775/28299 [09:44<02:32, 36.26it/s]\u001b[A\n",
            "Epoch 1/5:  80%|████████  | 22779/28299 [09:44<02:28, 37.25it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22784/28299 [09:44<02:24, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22788/28299 [09:44<02:27, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22792/28299 [09:44<02:39, 34.43it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22796/28299 [09:44<02:39, 34.55it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22800/28299 [09:44<02:34, 35.53it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22804/28299 [09:44<02:32, 36.11it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22808/28299 [09:45<02:29, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22813/28299 [09:45<02:23, 38.12it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22818/28299 [09:45<02:21, 38.76it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22822/28299 [09:45<02:22, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22826/28299 [09:45<02:22, 38.50it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22830/28299 [09:45<02:22, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22834/28299 [09:45<02:27, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22838/28299 [09:45<02:25, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22842/28299 [09:45<02:23, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22846/28299 [09:46<02:26, 37.27it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22850/28299 [09:46<02:29, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22854/28299 [09:46<02:28, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22858/28299 [09:46<02:31, 35.90it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22862/28299 [09:46<02:31, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22866/28299 [09:46<02:32, 35.72it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22870/28299 [09:46<02:27, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22875/28299 [09:46<02:21, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22879/28299 [09:46<02:20, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22883/28299 [09:47<02:21, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22887/28299 [09:47<02:26, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22891/28299 [09:47<02:23, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22895/28299 [09:47<02:26, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22900/28299 [09:47<02:21, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22904/28299 [09:47<02:22, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22908/28299 [09:47<02:21, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22912/28299 [09:47<02:21, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22916/28299 [09:47<02:24, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22920/28299 [09:48<02:29, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22924/28299 [09:48<02:27, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22928/28299 [09:48<02:32, 35.26it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22932/28299 [09:48<02:30, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22936/28299 [09:48<02:30, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22940/28299 [09:48<02:31, 35.45it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22944/28299 [09:48<02:26, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22948/28299 [09:48<02:26, 36.41it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22952/28299 [09:48<02:25, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22956/28299 [09:49<02:23, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22960/28299 [09:49<02:21, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22964/28299 [09:49<02:22, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22968/28299 [09:49<02:25, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22972/28299 [09:49<02:24, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22976/28299 [09:49<02:24, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22980/28299 [09:49<02:27, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22984/28299 [09:49<02:25, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████  | 22988/28299 [09:49<02:28, 35.76it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 22993/28299 [09:50<02:23, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 22997/28299 [09:50<02:26, 36.20it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23001/28299 [09:50<02:25, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23005/28299 [09:50<02:21, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23010/28299 [09:50<02:17, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23014/28299 [09:50<02:16, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23019/28299 [09:50<02:12, 39.77it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23023/28299 [09:50<02:14, 39.25it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23027/28299 [09:50<02:18, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23031/28299 [09:51<02:18, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23035/28299 [09:51<02:18, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23039/28299 [09:51<02:17, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23043/28299 [09:51<02:21, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23047/28299 [09:51<02:21, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23051/28299 [09:51<02:19, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23055/28299 [09:51<02:19, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23059/28299 [09:51<02:21, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  81%|████████▏ | 23063/28299 [09:51<02:24, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23067/28299 [09:52<02:30, 34.87it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23071/28299 [09:52<02:27, 35.51it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23075/28299 [09:52<02:24, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23079/28299 [09:52<02:27, 35.33it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23083/28299 [09:52<04:31, 19.21it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23087/28299 [09:52<03:55, 22.17it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23091/28299 [09:53<03:31, 24.67it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23095/28299 [09:53<03:08, 27.64it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23099/28299 [09:53<02:51, 30.29it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23103/28299 [09:53<02:45, 31.46it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23107/28299 [09:53<02:43, 31.79it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23112/28299 [09:53<02:30, 34.38it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23117/28299 [09:53<02:22, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23121/28299 [09:53<02:19, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23126/28299 [09:53<02:15, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23130/28299 [09:54<02:18, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23134/28299 [09:54<02:22, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23138/28299 [09:54<02:21, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23142/28299 [09:54<02:21, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23146/28299 [09:54<02:32, 33.81it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23150/28299 [09:54<02:26, 35.10it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23154/28299 [09:54<02:23, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23158/28299 [09:54<02:20, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23162/28299 [09:54<02:20, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23166/28299 [09:55<02:18, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23170/28299 [09:55<02:18, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23174/28299 [09:55<02:19, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23178/28299 [09:55<02:19, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23182/28299 [09:55<02:23, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23186/28299 [09:55<02:24, 35.42it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23190/28299 [09:55<02:25, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23194/28299 [09:55<02:25, 35.10it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23198/28299 [09:55<02:30, 33.89it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23202/28299 [09:56<02:24, 35.27it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23206/28299 [09:56<02:21, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23210/28299 [09:56<02:20, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23215/28299 [09:56<02:15, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23220/28299 [09:56<02:11, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23224/28299 [09:56<02:12, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23228/28299 [09:56<02:13, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23232/28299 [09:56<02:14, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23236/28299 [09:56<02:17, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23240/28299 [09:57<02:16, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23244/28299 [09:57<02:27, 34.28it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23248/28299 [09:57<02:26, 34.49it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23252/28299 [09:57<02:25, 34.60it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23256/28299 [09:57<02:35, 32.53it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23260/28299 [09:57<02:30, 33.47it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23264/28299 [09:57<02:33, 32.89it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23268/28299 [09:57<02:31, 33.11it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23272/28299 [09:58<02:26, 34.24it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23276/28299 [09:58<02:22, 35.15it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23280/28299 [09:58<02:21, 35.38it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23284/28299 [09:58<02:19, 35.83it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23288/28299 [09:58<02:16, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23292/28299 [09:58<02:17, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23296/28299 [09:58<02:14, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23300/28299 [09:58<02:13, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23304/28299 [09:58<02:12, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23308/28299 [09:59<02:13, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23312/28299 [09:59<02:12, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23316/28299 [09:59<02:14, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23320/28299 [09:59<02:14, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23325/28299 [09:59<02:10, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23329/28299 [09:59<02:10, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23333/28299 [09:59<02:11, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23337/28299 [09:59<02:10, 38.13it/s]\u001b[A\n",
            "Epoch 1/5:  82%|████████▏ | 23342/28299 [09:59<02:07, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23347/28299 [10:00<02:05, 39.46it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23351/28299 [10:00<02:05, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23355/28299 [10:00<02:06, 39.04it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23359/28299 [10:00<02:08, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23363/28299 [10:00<02:08, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23367/28299 [10:00<02:12, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23371/28299 [10:00<02:20, 35.08it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23375/28299 [10:00<02:19, 35.26it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23379/28299 [10:00<02:16, 36.10it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23383/28299 [10:01<02:14, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23387/28299 [10:01<02:18, 35.46it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23391/28299 [10:01<02:15, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23395/28299 [10:01<02:12, 36.98it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23399/28299 [10:01<02:09, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23403/28299 [10:01<02:07, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23408/28299 [10:01<02:05, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23413/28299 [10:01<02:02, 40.02it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23417/28299 [10:01<02:10, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23421/28299 [10:02<02:10, 37.34it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23425/28299 [10:02<02:08, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23429/28299 [10:02<02:11, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23433/28299 [10:02<02:15, 35.83it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23437/28299 [10:02<02:13, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23441/28299 [10:02<02:10, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23445/28299 [10:02<02:11, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23450/28299 [10:02<02:06, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23454/28299 [10:02<02:08, 37.74it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23458/28299 [10:03<02:08, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23462/28299 [10:03<02:07, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23466/28299 [10:03<02:24, 33.37it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23470/28299 [10:03<02:21, 34.07it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23474/28299 [10:03<02:15, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23479/28299 [10:03<02:10, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23483/28299 [10:03<02:07, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23487/28299 [10:03<02:06, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23491/28299 [10:03<02:09, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23496/28299 [10:04<02:05, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23500/28299 [10:04<02:08, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23504/28299 [10:04<02:07, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23508/28299 [10:04<02:05, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23512/28299 [10:04<02:08, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23516/28299 [10:04<02:16, 34.98it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23520/28299 [10:04<02:14, 35.61it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23524/28299 [10:04<02:18, 34.51it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23528/28299 [10:04<02:18, 34.34it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23532/28299 [10:05<02:15, 35.07it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23536/28299 [10:05<02:20, 33.89it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23540/28299 [10:05<02:15, 35.04it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23545/28299 [10:05<02:09, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23550/28299 [10:05<02:04, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23554/28299 [10:05<02:04, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23558/28299 [10:05<02:06, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23562/28299 [10:05<02:11, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23566/28299 [10:05<02:10, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23570/28299 [10:06<02:09, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23575/28299 [10:06<02:04, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23579/28299 [10:06<02:05, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23583/28299 [10:06<02:08, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23587/28299 [10:06<02:10, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23591/28299 [10:06<02:10, 36.09it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23595/28299 [10:06<02:15, 34.81it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23599/28299 [10:06<02:13, 35.10it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23603/28299 [10:07<02:13, 35.20it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23607/28299 [10:07<02:15, 34.66it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23611/28299 [10:07<02:11, 35.62it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23615/28299 [10:07<02:09, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23619/28299 [10:07<02:09, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23623/28299 [10:07<02:09, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  83%|████████▎ | 23627/28299 [10:07<02:10, 35.77it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23631/28299 [10:07<02:15, 34.46it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23635/28299 [10:07<02:12, 35.19it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23639/28299 [10:08<02:15, 34.48it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23643/28299 [10:08<02:16, 34.17it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23647/28299 [10:08<02:11, 35.38it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23651/28299 [10:08<02:11, 35.46it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23655/28299 [10:08<02:08, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23659/28299 [10:08<02:07, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23663/28299 [10:08<02:15, 34.33it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23668/28299 [10:08<02:07, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23672/28299 [10:08<02:08, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23676/28299 [10:09<02:09, 35.77it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23680/28299 [10:09<02:08, 36.08it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23684/28299 [10:09<02:05, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23688/28299 [10:09<02:03, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23692/28299 [10:09<02:03, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23696/28299 [10:09<02:01, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▎ | 23700/28299 [10:09<02:04, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23705/28299 [10:09<02:00, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23709/28299 [10:09<02:04, 36.79it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23713/28299 [10:10<02:03, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23717/28299 [10:10<02:02, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23721/28299 [10:10<02:01, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23725/28299 [10:10<02:02, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23729/28299 [10:10<02:02, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23733/28299 [10:10<02:00, 37.99it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23737/28299 [10:10<01:58, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23742/28299 [10:10<01:55, 39.50it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23746/28299 [10:10<02:00, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23751/28299 [10:11<01:57, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23755/28299 [10:11<01:58, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23759/28299 [10:11<01:59, 37.86it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23763/28299 [10:11<01:59, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23767/28299 [10:11<01:57, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23771/28299 [10:11<02:04, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23775/28299 [10:11<02:04, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23780/28299 [10:11<02:00, 37.60it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23784/28299 [10:11<02:00, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23788/28299 [10:12<02:01, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23792/28299 [10:12<02:00, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23797/28299 [10:12<01:58, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23801/28299 [10:12<02:08, 34.97it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23805/28299 [10:12<02:15, 33.20it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23809/28299 [10:12<02:09, 34.60it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23814/28299 [10:12<02:03, 36.42it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23819/28299 [10:12<02:00, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23823/28299 [10:13<02:00, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23827/28299 [10:13<01:58, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23831/28299 [10:13<01:57, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23835/28299 [10:13<01:57, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23839/28299 [10:13<01:57, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23844/28299 [10:13<01:57, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23848/28299 [10:13<01:57, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23852/28299 [10:13<02:03, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23856/28299 [10:13<02:03, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23860/28299 [10:14<02:00, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23865/28299 [10:14<01:56, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23869/28299 [10:14<01:55, 38.37it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23873/28299 [10:14<01:55, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23878/28299 [10:14<01:52, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23883/28299 [10:14<01:51, 39.76it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23887/28299 [10:14<01:51, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23891/28299 [10:14<01:57, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23895/28299 [10:14<01:55, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23899/28299 [10:15<01:55, 38.23it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23903/28299 [10:15<01:55, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23907/28299 [10:15<01:58, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  84%|████████▍ | 23911/28299 [10:15<01:56, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23915/28299 [10:15<01:58, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23919/28299 [10:15<01:57, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23923/28299 [10:15<01:56, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23928/28299 [10:15<01:53, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23932/28299 [10:15<01:58, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23936/28299 [10:16<01:57, 37.14it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23940/28299 [10:16<01:57, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23944/28299 [10:16<01:54, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23948/28299 [10:16<01:53, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23952/28299 [10:16<01:52, 38.56it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23956/28299 [10:16<01:52, 38.65it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23960/28299 [10:16<01:55, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23964/28299 [10:16<01:56, 37.34it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23968/28299 [10:16<01:56, 37.02it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23972/28299 [10:16<01:56, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23976/28299 [10:17<02:01, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23980/28299 [10:17<02:05, 34.36it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23984/28299 [10:17<02:01, 35.43it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23988/28299 [10:17<01:59, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23992/28299 [10:17<01:56, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 23996/28299 [10:17<01:58, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24000/28299 [10:17<01:55, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24004/28299 [10:17<01:54, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24008/28299 [10:17<01:54, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24012/28299 [10:18<03:39, 19.49it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24016/28299 [10:18<03:08, 22.71it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24020/28299 [10:18<02:49, 25.27it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24024/28299 [10:18<02:34, 27.75it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24028/28299 [10:18<02:26, 29.10it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24032/28299 [10:18<02:16, 31.28it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24036/28299 [10:19<02:09, 32.88it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24040/28299 [10:19<02:05, 34.06it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24044/28299 [10:19<02:06, 33.60it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24048/28299 [10:19<02:01, 34.87it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▍ | 24052/28299 [10:19<01:58, 35.93it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24056/28299 [10:19<01:55, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24060/28299 [10:19<01:54, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24064/28299 [10:19<01:53, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24068/28299 [10:19<01:53, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24072/28299 [10:20<01:52, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24077/28299 [10:20<01:48, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24081/28299 [10:20<01:49, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24086/28299 [10:20<01:46, 39.48it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24090/28299 [10:20<01:47, 39.24it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24094/28299 [10:20<01:48, 38.84it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24098/28299 [10:20<01:49, 38.26it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24102/28299 [10:20<01:49, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24106/28299 [10:20<01:48, 38.55it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24110/28299 [10:20<01:48, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24114/28299 [10:21<01:49, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24118/28299 [10:21<01:49, 38.04it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24122/28299 [10:21<01:54, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24126/28299 [10:21<01:54, 36.57it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24130/28299 [10:21<01:53, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24134/28299 [10:21<01:57, 35.32it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24138/28299 [10:21<01:57, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24142/28299 [10:21<01:53, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24146/28299 [10:21<01:51, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24150/28299 [10:22<01:57, 35.33it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24154/28299 [10:22<01:55, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24158/28299 [10:22<01:53, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24162/28299 [10:22<01:54, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24166/28299 [10:22<01:57, 35.05it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24171/28299 [10:22<01:52, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24175/28299 [10:22<01:53, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24180/28299 [10:22<01:49, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24184/28299 [10:23<01:49, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24188/28299 [10:23<01:49, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  85%|████████▌ | 24192/28299 [10:23<01:49, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24196/28299 [10:23<01:49, 37.61it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24200/28299 [10:23<01:48, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24204/28299 [10:23<01:49, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24208/28299 [10:23<01:47, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24212/28299 [10:23<01:47, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24216/28299 [10:23<01:47, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24220/28299 [10:23<01:48, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24224/28299 [10:24<01:48, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24228/28299 [10:24<01:47, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24232/28299 [10:24<01:46, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24236/28299 [10:24<01:46, 38.28it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24240/28299 [10:24<01:46, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24244/28299 [10:24<01:47, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24248/28299 [10:24<01:46, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24252/28299 [10:24<01:48, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24256/28299 [10:24<01:50, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24260/28299 [10:25<01:53, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24264/28299 [10:25<01:51, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24268/28299 [10:25<01:48, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24272/28299 [10:25<01:47, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24276/28299 [10:25<01:46, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24280/28299 [10:25<01:46, 37.84it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24284/28299 [10:25<01:45, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24289/28299 [10:25<01:42, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24293/28299 [10:25<01:50, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24297/28299 [10:26<01:51, 35.90it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24301/28299 [10:26<01:48, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24305/28299 [10:26<01:57, 34.04it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24309/28299 [10:26<01:58, 33.78it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24313/28299 [10:26<01:56, 34.15it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24318/28299 [10:26<01:49, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24322/28299 [10:26<01:47, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24326/28299 [10:26<01:46, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24330/28299 [10:26<01:46, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24334/28299 [10:27<01:51, 35.58it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24338/28299 [10:27<01:51, 35.61it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24342/28299 [10:27<01:50, 35.67it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24346/28299 [10:27<01:50, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24350/28299 [10:27<01:50, 35.71it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24354/28299 [10:27<01:48, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24358/28299 [10:27<01:46, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24362/28299 [10:27<01:47, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24367/28299 [10:27<01:45, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24371/28299 [10:28<01:49, 36.03it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24375/28299 [10:28<01:48, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24379/28299 [10:28<01:46, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24384/28299 [10:28<01:41, 38.52it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24388/28299 [10:28<01:42, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24392/28299 [10:28<01:47, 36.28it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24396/28299 [10:28<01:47, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24400/28299 [10:28<01:46, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▌ | 24404/28299 [10:28<01:44, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24408/28299 [10:29<01:43, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24412/28299 [10:29<01:42, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24416/28299 [10:29<01:43, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24420/28299 [10:29<01:45, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24424/28299 [10:29<01:45, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24428/28299 [10:29<01:44, 36.90it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24432/28299 [10:29<01:44, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24436/28299 [10:29<01:46, 36.25it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24440/28299 [10:29<01:46, 36.27it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24444/28299 [10:30<01:47, 35.84it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24449/28299 [10:30<01:43, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24453/28299 [10:30<01:44, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24457/28299 [10:30<01:42, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24461/28299 [10:30<01:44, 36.90it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24465/28299 [10:30<01:41, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24470/28299 [10:30<01:37, 39.14it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24474/28299 [10:30<01:37, 39.36it/s]\u001b[A\n",
            "Epoch 1/5:  86%|████████▋ | 24478/28299 [10:30<01:37, 39.38it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24482/28299 [10:31<01:39, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24486/28299 [10:31<01:39, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24490/28299 [10:31<01:39, 38.09it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24494/28299 [10:31<01:40, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24498/28299 [10:31<01:40, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24503/28299 [10:31<01:37, 38.91it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24508/28299 [10:31<01:35, 39.64it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24512/28299 [10:31<01:37, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24516/28299 [10:31<01:41, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24520/28299 [10:32<01:42, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24524/28299 [10:32<01:41, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24528/28299 [10:32<01:42, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24532/28299 [10:32<01:45, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24536/28299 [10:32<01:44, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24541/28299 [10:32<01:39, 37.91it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24545/28299 [10:32<01:38, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24549/28299 [10:32<01:40, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24553/28299 [10:32<01:41, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24557/28299 [10:33<01:41, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24561/28299 [10:33<01:40, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24565/28299 [10:33<01:39, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24569/28299 [10:33<01:38, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24573/28299 [10:33<01:37, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24577/28299 [10:33<01:37, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24581/28299 [10:33<01:37, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24585/28299 [10:33<01:36, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24589/28299 [10:33<01:40, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24593/28299 [10:34<01:38, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24597/28299 [10:34<01:41, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24601/28299 [10:34<01:40, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24605/28299 [10:34<01:40, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24609/28299 [10:34<01:40, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24613/28299 [10:34<01:38, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24617/28299 [10:34<01:39, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24621/28299 [10:34<01:38, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24625/28299 [10:34<01:36, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24629/28299 [10:34<01:36, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24633/28299 [10:35<01:42, 35.69it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24637/28299 [10:35<01:45, 34.55it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24641/28299 [10:35<01:45, 34.80it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24645/28299 [10:35<01:42, 35.77it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24650/28299 [10:35<01:37, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24655/28299 [10:35<01:33, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24660/28299 [10:35<01:32, 39.54it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24664/28299 [10:35<01:36, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24668/28299 [10:36<01:39, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24672/28299 [10:36<01:42, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24676/28299 [10:36<01:39, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24681/28299 [10:36<01:35, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24686/28299 [10:36<01:33, 38.80it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24690/28299 [10:36<01:38, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24695/28299 [10:36<01:34, 38.29it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24700/28299 [10:36<01:31, 39.24it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24705/28299 [10:37<01:29, 40.03it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24710/28299 [10:37<01:29, 40.15it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24715/28299 [10:37<01:31, 39.22it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24719/28299 [10:37<01:32, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24723/28299 [10:37<01:31, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24727/28299 [10:37<01:31, 39.21it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24731/28299 [10:37<01:33, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24735/28299 [10:37<01:35, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24739/28299 [10:37<01:34, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24743/28299 [10:38<01:37, 36.29it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24747/28299 [10:38<01:41, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24751/28299 [10:38<01:38, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24756/28299 [10:38<01:34, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  87%|████████▋ | 24761/28299 [10:38<01:32, 38.14it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24766/28299 [10:38<01:30, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24770/28299 [10:38<01:35, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24775/28299 [10:38<01:32, 38.10it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24779/28299 [10:38<01:32, 38.01it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24783/28299 [10:39<01:31, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24787/28299 [10:39<01:34, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24791/28299 [10:39<01:38, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24795/28299 [10:39<01:44, 33.59it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24799/28299 [10:39<01:41, 34.50it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24803/28299 [10:39<01:38, 35.32it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24807/28299 [10:39<01:37, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24811/28299 [10:39<01:36, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24815/28299 [10:39<01:35, 36.41it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24819/28299 [10:40<01:35, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24823/28299 [10:40<01:36, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24827/28299 [10:40<01:36, 36.01it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24831/28299 [10:40<01:35, 36.32it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24835/28299 [10:40<01:37, 35.59it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24839/28299 [10:40<01:35, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24843/28299 [10:40<01:34, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24847/28299 [10:40<01:32, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24851/28299 [10:40<01:30, 37.92it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24855/28299 [10:41<01:30, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24859/28299 [10:41<01:32, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24863/28299 [10:41<01:33, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24867/28299 [10:41<01:34, 36.33it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24871/28299 [10:41<01:34, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24875/28299 [10:41<01:33, 36.60it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24879/28299 [10:41<01:32, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24883/28299 [10:41<01:32, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24887/28299 [10:41<01:33, 36.52it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24891/28299 [10:42<01:35, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24896/28299 [10:42<01:31, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24900/28299 [10:42<01:29, 37.77it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24904/28299 [10:42<01:29, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24908/28299 [10:42<01:34, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24912/28299 [10:42<01:37, 34.69it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24916/28299 [10:42<01:36, 35.11it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24920/28299 [10:42<01:34, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24924/28299 [10:42<01:36, 35.02it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24928/28299 [10:43<01:34, 35.73it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24932/28299 [10:43<01:34, 35.52it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24936/28299 [10:43<01:34, 35.52it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24940/28299 [10:43<02:53, 19.40it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24944/28299 [10:43<02:28, 22.56it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24949/28299 [10:43<02:05, 26.78it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24953/28299 [10:44<01:56, 28.68it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24957/28299 [10:44<01:50, 30.21it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24961/28299 [10:44<01:43, 32.10it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24966/28299 [10:44<01:35, 34.78it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24970/28299 [10:44<01:35, 35.03it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24974/28299 [10:44<01:31, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24979/28299 [10:44<01:29, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24983/28299 [10:44<01:30, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24987/28299 [10:44<01:29, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24991/28299 [10:45<01:32, 35.76it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24995/28299 [10:45<01:30, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 24999/28299 [10:45<01:29, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25003/28299 [10:45<01:31, 35.97it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25007/28299 [10:45<01:29, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25011/28299 [10:45<01:29, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25015/28299 [10:45<01:29, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25019/28299 [10:45<01:27, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25024/28299 [10:45<01:24, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25028/28299 [10:46<01:26, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25032/28299 [10:46<01:26, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25036/28299 [10:46<01:27, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25040/28299 [10:46<01:27, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  88%|████████▊ | 25044/28299 [10:46<01:25, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25049/28299 [10:46<01:23, 38.80it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25053/28299 [10:46<01:24, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25057/28299 [10:46<01:25, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25062/28299 [10:46<01:22, 39.40it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25066/28299 [10:47<01:22, 39.27it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25070/28299 [10:47<01:23, 38.86it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25074/28299 [10:47<01:28, 36.48it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25078/28299 [10:47<01:30, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25082/28299 [10:47<01:29, 35.82it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25086/28299 [10:47<01:28, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25090/28299 [10:47<01:26, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25094/28299 [10:47<01:27, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25099/28299 [10:47<01:24, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25104/28299 [10:48<01:22, 38.60it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25108/28299 [10:48<01:27, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▊ | 25112/28299 [10:48<01:25, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25116/28299 [10:48<01:27, 36.57it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25121/28299 [10:48<01:23, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25125/28299 [10:48<01:23, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25129/28299 [10:48<01:23, 38.05it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25133/28299 [10:48<01:25, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25137/28299 [10:49<01:25, 36.79it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25141/28299 [10:49<01:26, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25145/28299 [10:49<01:27, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25149/28299 [10:49<01:26, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25153/28299 [10:49<01:24, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25157/28299 [10:49<01:25, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25161/28299 [10:49<01:25, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25165/28299 [10:49<01:25, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25169/28299 [10:49<01:24, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25173/28299 [10:49<01:25, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25177/28299 [10:50<01:26, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25181/28299 [10:50<01:25, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25185/28299 [10:50<01:28, 35.11it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25189/28299 [10:50<01:27, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25193/28299 [10:50<01:25, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25197/28299 [10:50<01:25, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25201/28299 [10:50<01:22, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25205/28299 [10:50<01:22, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25209/28299 [10:50<01:22, 37.63it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25213/28299 [10:51<01:22, 37.39it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25217/28299 [10:51<01:25, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25221/28299 [10:51<01:24, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25225/28299 [10:51<01:26, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25229/28299 [10:51<01:27, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25233/28299 [10:51<01:26, 35.31it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25237/28299 [10:51<01:27, 34.86it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25241/28299 [10:51<01:29, 34.10it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25245/28299 [10:52<01:27, 34.89it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25249/28299 [10:52<01:26, 35.41it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25253/28299 [10:52<01:24, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25258/28299 [10:52<01:20, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25263/28299 [10:52<01:18, 38.76it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25267/28299 [10:52<01:19, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25271/28299 [10:52<01:20, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25275/28299 [10:52<01:22, 36.58it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25279/28299 [10:52<01:24, 35.79it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25283/28299 [10:53<01:26, 35.05it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25287/28299 [10:53<01:24, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25291/28299 [10:53<01:24, 35.66it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25295/28299 [10:53<01:21, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25299/28299 [10:53<01:21, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25303/28299 [10:53<01:21, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25307/28299 [10:53<01:22, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25311/28299 [10:53<01:24, 35.16it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25315/28299 [10:53<01:23, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25319/28299 [10:54<01:22, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25323/28299 [10:54<01:21, 36.42it/s]\u001b[A\n",
            "Epoch 1/5:  89%|████████▉ | 25327/28299 [10:54<01:23, 35.69it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25331/28299 [10:54<01:24, 35.24it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25335/28299 [10:54<01:22, 35.79it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25339/28299 [10:54<01:21, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25343/28299 [10:54<01:20, 36.65it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25347/28299 [10:54<01:22, 35.82it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25351/28299 [10:54<01:21, 36.07it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25355/28299 [10:55<01:21, 36.03it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25359/28299 [10:55<01:20, 36.38it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25363/28299 [10:55<01:18, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25368/28299 [10:55<01:16, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25372/28299 [10:55<01:17, 37.88it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25376/28299 [10:55<01:18, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25380/28299 [10:55<01:18, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25384/28299 [10:55<01:18, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25388/28299 [10:55<01:17, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25392/28299 [10:56<01:16, 38.08it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25396/28299 [10:56<01:17, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25400/28299 [10:56<01:18, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25404/28299 [10:56<01:18, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25408/28299 [10:56<01:17, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25412/28299 [10:56<01:20, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25416/28299 [10:56<01:21, 35.47it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25420/28299 [10:56<01:19, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25424/28299 [10:56<01:18, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25428/28299 [10:56<01:18, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25432/28299 [10:57<01:17, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25436/28299 [10:57<01:19, 35.92it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25440/28299 [10:57<01:19, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25444/28299 [10:57<01:18, 36.41it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25448/28299 [10:57<01:19, 35.79it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25452/28299 [10:57<01:18, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25456/28299 [10:57<01:17, 36.92it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25460/28299 [10:57<01:15, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25464/28299 [10:57<01:15, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  90%|████████▉ | 25468/28299 [10:58<01:17, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25472/28299 [10:58<01:18, 35.95it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25476/28299 [10:58<01:16, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25480/28299 [10:58<01:15, 37.24it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25484/28299 [10:58<01:15, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25488/28299 [10:58<01:14, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25492/28299 [10:58<01:14, 37.58it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25496/28299 [10:58<01:14, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25500/28299 [10:58<01:16, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25504/28299 [10:59<01:15, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25508/28299 [10:59<01:15, 36.74it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25512/28299 [10:59<01:15, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25516/28299 [10:59<01:16, 36.51it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25520/28299 [10:59<01:16, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25524/28299 [10:59<01:15, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25528/28299 [10:59<01:17, 35.89it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25532/28299 [10:59<01:18, 35.18it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25536/28299 [10:59<01:18, 35.29it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25540/28299 [11:00<01:16, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25544/28299 [11:00<01:15, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25548/28299 [11:00<01:14, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25553/28299 [11:00<01:13, 37.15it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25557/28299 [11:00<01:13, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25562/28299 [11:00<01:11, 38.19it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25566/28299 [11:00<01:14, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25570/28299 [11:00<01:16, 35.70it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25574/28299 [11:01<01:18, 34.76it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25578/28299 [11:01<01:15, 36.10it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25582/28299 [11:01<01:14, 36.28it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25586/28299 [11:01<01:13, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25590/28299 [11:01<01:12, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25594/28299 [11:01<01:12, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25598/28299 [11:01<01:10, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25603/28299 [11:01<01:09, 38.99it/s]\u001b[A\n",
            "Epoch 1/5:  90%|█████████ | 25607/28299 [11:01<01:08, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25611/28299 [11:01<01:09, 38.42it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25615/28299 [11:02<01:11, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25619/28299 [11:02<01:11, 37.56it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25623/28299 [11:02<01:11, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25627/28299 [11:02<01:10, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25631/28299 [11:02<01:09, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25635/28299 [11:02<01:09, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25639/28299 [11:02<01:09, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25644/28299 [11:02<01:07, 39.29it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25649/28299 [11:02<01:06, 39.73it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25653/28299 [11:03<01:10, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25657/28299 [11:03<01:14, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25661/28299 [11:03<01:14, 35.54it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25665/28299 [11:03<01:12, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25670/28299 [11:03<01:08, 38.14it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25674/28299 [11:03<01:11, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25678/28299 [11:03<01:09, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25682/28299 [11:03<01:10, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25686/28299 [11:03<01:08, 38.00it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25690/28299 [11:04<01:10, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25694/28299 [11:04<01:10, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25698/28299 [11:04<01:12, 35.78it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25702/28299 [11:04<01:13, 35.44it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25706/28299 [11:04<01:11, 36.03it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25710/28299 [11:04<01:11, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25714/28299 [11:04<01:10, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25718/28299 [11:04<01:10, 36.39it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25722/28299 [11:04<01:10, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25726/28299 [11:05<01:10, 36.30it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25730/28299 [11:05<01:09, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25734/28299 [11:05<01:09, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25738/28299 [11:05<01:08, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25743/28299 [11:05<01:06, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25747/28299 [11:05<01:07, 38.07it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25751/28299 [11:05<01:06, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25755/28299 [11:05<01:09, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25759/28299 [11:05<01:07, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25763/28299 [11:06<01:11, 35.59it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25767/28299 [11:06<01:10, 36.10it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25771/28299 [11:06<01:08, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25775/28299 [11:06<01:08, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25780/28299 [11:06<01:05, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25784/28299 [11:06<01:08, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25789/28299 [11:06<01:05, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25793/28299 [11:06<01:05, 38.15it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25798/28299 [11:06<01:04, 39.02it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25802/28299 [11:07<01:05, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25806/28299 [11:07<01:06, 37.36it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25810/28299 [11:07<01:05, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25814/28299 [11:07<01:06, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25818/28299 [11:07<01:06, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████ | 25822/28299 [11:07<01:07, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25827/28299 [11:07<01:05, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25831/28299 [11:07<01:05, 37.52it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25835/28299 [11:07<01:04, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25840/28299 [11:08<01:03, 39.00it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25844/28299 [11:08<01:03, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25848/28299 [11:08<01:04, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25852/28299 [11:08<01:03, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25857/28299 [11:08<01:03, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25861/28299 [11:08<01:03, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25865/28299 [11:09<01:57, 20.68it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25869/28299 [11:09<01:44, 23.33it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25873/28299 [11:09<01:32, 26.25it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25877/28299 [11:09<01:22, 29.20it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25882/28299 [11:09<01:14, 32.45it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25886/28299 [11:09<01:11, 33.63it/s]\u001b[A\n",
            "Epoch 1/5:  91%|█████████▏| 25890/28299 [11:09<01:09, 34.76it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25895/28299 [11:09<01:05, 36.45it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25900/28299 [11:09<01:04, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25904/28299 [11:10<01:03, 37.95it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25909/28299 [11:10<01:01, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25913/28299 [11:10<01:01, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25917/28299 [11:10<01:01, 38.48it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25921/28299 [11:10<01:01, 38.81it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25926/28299 [11:10<01:00, 39.47it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25931/28299 [11:10<00:59, 39.98it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25936/28299 [11:10<00:59, 39.98it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25941/28299 [11:11<01:03, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25945/28299 [11:11<01:03, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25949/28299 [11:11<01:03, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25953/28299 [11:11<01:03, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25957/28299 [11:11<01:03, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25961/28299 [11:11<01:06, 35.36it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25965/28299 [11:11<01:04, 36.18it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25970/28299 [11:11<01:01, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25975/28299 [11:11<00:59, 38.74it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25979/28299 [11:12<00:59, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25983/28299 [11:12<01:02, 37.33it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25987/28299 [11:12<01:02, 37.21it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25991/28299 [11:12<01:02, 37.03it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25995/28299 [11:12<01:02, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 25999/28299 [11:12<01:06, 34.69it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26003/28299 [11:12<01:04, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26007/28299 [11:12<01:03, 36.29it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26012/28299 [11:12<01:01, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26016/28299 [11:13<01:01, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26020/28299 [11:13<01:00, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26025/28299 [11:13<00:59, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26029/28299 [11:13<00:58, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26033/28299 [11:13<00:58, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26037/28299 [11:13<00:59, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26041/28299 [11:13<01:03, 35.78it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26045/28299 [11:13<01:05, 34.67it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26049/28299 [11:13<01:03, 35.61it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26053/28299 [11:14<01:01, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26057/28299 [11:14<00:59, 37.44it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26061/28299 [11:14<01:03, 35.42it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26065/28299 [11:14<01:02, 36.01it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26069/28299 [11:14<01:00, 36.82it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26073/28299 [11:14<01:00, 36.59it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26077/28299 [11:14<01:00, 36.44it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26081/28299 [11:14<01:00, 36.69it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26085/28299 [11:14<01:02, 35.58it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26089/28299 [11:15<01:03, 34.58it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26093/28299 [11:15<01:02, 35.42it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26097/28299 [11:15<01:02, 35.07it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26101/28299 [11:15<01:03, 34.70it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26105/28299 [11:15<01:02, 35.15it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26109/28299 [11:15<01:01, 35.48it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26113/28299 [11:15<01:02, 34.70it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26117/28299 [11:15<01:02, 34.99it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26121/28299 [11:15<01:03, 34.52it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26125/28299 [11:16<01:00, 35.84it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26129/28299 [11:16<00:59, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26133/28299 [11:16<00:57, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26137/28299 [11:16<00:57, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26141/28299 [11:16<00:57, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26145/28299 [11:16<00:57, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26149/28299 [11:16<00:56, 38.21it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26153/28299 [11:16<00:55, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26157/28299 [11:16<00:56, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26161/28299 [11:17<00:56, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26165/28299 [11:17<00:56, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26169/28299 [11:17<00:56, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  92%|█████████▏| 26173/28299 [11:17<00:57, 36.75it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26177/28299 [11:17<00:57, 37.16it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26181/28299 [11:17<00:57, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26185/28299 [11:17<00:57, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26189/28299 [11:17<00:57, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26193/28299 [11:17<00:57, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26197/28299 [11:18<00:59, 35.60it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26201/28299 [11:18<01:00, 34.57it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26205/28299 [11:18<00:59, 35.27it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26209/28299 [11:18<00:58, 35.72it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26213/28299 [11:18<00:58, 35.40it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26217/28299 [11:18<00:58, 35.71it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26221/28299 [11:18<00:59, 35.13it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26225/28299 [11:18<00:57, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26229/28299 [11:18<00:56, 36.57it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26233/28299 [11:19<00:55, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26237/28299 [11:19<00:53, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26241/28299 [11:19<00:53, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26245/28299 [11:19<00:52, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26249/28299 [11:19<00:54, 37.34it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26253/28299 [11:19<00:55, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26258/28299 [11:19<00:53, 38.16it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26263/28299 [11:19<00:51, 39.17it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26267/28299 [11:19<00:51, 39.23it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26271/28299 [11:19<00:51, 39.19it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26275/28299 [11:20<00:52, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26279/28299 [11:20<00:52, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26283/28299 [11:20<00:51, 38.98it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26287/28299 [11:20<00:51, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26291/28299 [11:20<00:51, 39.06it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26295/28299 [11:20<00:55, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26299/28299 [11:20<00:54, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26303/28299 [11:20<00:53, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26307/28299 [11:20<00:53, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26311/28299 [11:21<00:54, 36.50it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26315/28299 [11:21<00:53, 36.86it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26319/28299 [11:21<00:56, 34.75it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26323/28299 [11:21<00:56, 35.24it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26327/28299 [11:21<00:54, 35.93it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26331/28299 [11:21<00:54, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26335/28299 [11:21<00:53, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26339/28299 [11:21<00:53, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26343/28299 [11:21<00:53, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26347/28299 [11:22<00:52, 37.20it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26351/28299 [11:22<00:52, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26355/28299 [11:22<00:52, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26359/28299 [11:22<00:53, 36.37it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26363/28299 [11:22<00:51, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26367/28299 [11:22<00:52, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26371/28299 [11:22<00:53, 35.91it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26375/28299 [11:22<00:54, 35.06it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26379/28299 [11:22<00:54, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26383/28299 [11:23<00:53, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26387/28299 [11:23<00:52, 36.47it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26391/28299 [11:23<00:51, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26395/28299 [11:23<00:51, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26399/28299 [11:23<00:51, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26403/28299 [11:23<00:50, 37.65it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26407/28299 [11:23<00:49, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26411/28299 [11:23<00:49, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26415/28299 [11:23<00:53, 34.94it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26419/28299 [11:24<00:52, 35.96it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26423/28299 [11:24<00:51, 36.68it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26427/28299 [11:24<00:53, 34.85it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26432/28299 [11:24<00:50, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26437/28299 [11:24<00:49, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26441/28299 [11:24<00:48, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26446/28299 [11:24<00:47, 39.36it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26450/28299 [11:24<00:48, 38.30it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26454/28299 [11:24<00:47, 38.58it/s]\u001b[A\n",
            "Epoch 1/5:  93%|█████████▎| 26458/28299 [11:25<00:48, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26462/28299 [11:25<00:48, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26466/28299 [11:25<00:47, 38.32it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26470/28299 [11:25<00:47, 38.47it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26474/28299 [11:25<00:47, 38.29it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26479/28299 [11:25<00:46, 39.18it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26483/28299 [11:25<00:46, 39.27it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26488/28299 [11:25<00:45, 39.62it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26493/28299 [11:25<00:44, 40.25it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26498/28299 [11:26<00:46, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26502/28299 [11:26<00:46, 38.45it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26506/28299 [11:26<00:46, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26510/28299 [11:26<00:47, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26514/28299 [11:26<00:49, 35.93it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26518/28299 [11:26<00:48, 36.61it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26522/28299 [11:26<00:48, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26526/28299 [11:26<00:48, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▎| 26530/28299 [11:26<00:48, 36.85it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26534/28299 [11:27<00:51, 34.05it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26538/28299 [11:27<00:50, 34.71it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26542/28299 [11:27<00:51, 34.01it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26546/28299 [11:27<00:50, 35.01it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26550/28299 [11:27<00:52, 33.27it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26554/28299 [11:27<00:50, 34.60it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26558/28299 [11:27<00:49, 35.37it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26562/28299 [11:27<00:49, 34.94it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26566/28299 [11:27<00:48, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26570/28299 [11:28<00:48, 35.96it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26574/28299 [11:28<00:47, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26578/28299 [11:28<00:46, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26582/28299 [11:28<00:46, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26587/28299 [11:28<00:44, 38.57it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26591/28299 [11:28<00:45, 37.68it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26596/28299 [11:28<00:44, 38.56it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26600/28299 [11:28<00:43, 38.89it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26604/28299 [11:28<00:44, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26608/28299 [11:29<00:44, 37.81it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26613/28299 [11:29<00:43, 38.73it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26617/28299 [11:29<00:43, 38.80it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26621/28299 [11:29<00:43, 38.94it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26625/28299 [11:29<00:43, 38.43it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26629/28299 [11:29<00:44, 37.89it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26633/28299 [11:29<00:44, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26637/28299 [11:29<00:45, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26641/28299 [11:30<00:48, 34.46it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26645/28299 [11:30<00:46, 35.42it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26649/28299 [11:30<00:45, 36.05it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26653/28299 [11:30<00:44, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26657/28299 [11:30<00:48, 34.16it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26661/28299 [11:30<00:50, 32.27it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26665/28299 [11:30<00:48, 33.57it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26669/28299 [11:30<00:47, 34.04it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26673/28299 [11:30<00:45, 35.50it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26677/28299 [11:31<00:44, 36.26it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26681/28299 [11:31<00:43, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26685/28299 [11:31<00:44, 36.31it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26689/28299 [11:31<00:43, 37.27it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26693/28299 [11:31<00:43, 37.11it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26697/28299 [11:31<00:42, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26701/28299 [11:31<00:42, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26706/28299 [11:31<00:40, 38.87it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26710/28299 [11:31<00:40, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26715/28299 [11:31<00:39, 39.61it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26719/28299 [11:32<00:40, 39.24it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26723/28299 [11:32<00:40, 38.62it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26727/28299 [11:32<00:41, 38.29it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26731/28299 [11:32<00:41, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26736/28299 [11:32<00:40, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  94%|█████████▍| 26740/28299 [11:32<00:39, 39.02it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26745/28299 [11:32<00:39, 39.68it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26749/28299 [11:32<00:39, 39.39it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26753/28299 [11:32<00:41, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26757/28299 [11:33<00:42, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26761/28299 [11:33<00:43, 35.51it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26765/28299 [11:33<00:42, 36.40it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26769/28299 [11:33<00:41, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26774/28299 [11:33<00:40, 37.23it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26778/28299 [11:33<00:41, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26783/28299 [11:33<00:39, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26788/28299 [11:33<00:38, 38.92it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26792/28299 [11:34<01:11, 21.07it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26796/28299 [11:34<01:03, 23.76it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26800/28299 [11:34<00:57, 26.20it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26804/28299 [11:34<00:53, 28.20it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26808/28299 [11:34<00:49, 30.13it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26812/28299 [11:34<00:45, 32.34it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26817/28299 [11:35<00:42, 35.11it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26821/28299 [11:35<00:40, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26825/28299 [11:35<00:39, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26829/28299 [11:35<00:39, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26833/28299 [11:35<00:39, 37.22it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26838/28299 [11:35<00:38, 38.44it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26843/28299 [11:35<00:37, 39.28it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26847/28299 [11:35<00:37, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26851/28299 [11:35<00:39, 36.29it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26855/28299 [11:36<00:38, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26859/28299 [11:36<00:38, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26863/28299 [11:36<00:38, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26867/28299 [11:36<00:37, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26871/28299 [11:36<00:37, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26875/28299 [11:36<00:37, 37.82it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26879/28299 [11:36<00:37, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▍| 26883/28299 [11:36<00:36, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26887/28299 [11:36<00:36, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26891/28299 [11:36<00:37, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26895/28299 [11:37<00:37, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26899/28299 [11:37<00:37, 37.34it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26903/28299 [11:37<00:37, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26907/28299 [11:37<00:37, 37.08it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26911/28299 [11:37<00:42, 32.97it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26915/28299 [11:37<00:43, 31.94it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26919/28299 [11:37<00:41, 33.06it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26923/28299 [11:37<00:39, 34.51it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26927/28299 [11:38<00:40, 34.16it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26931/28299 [11:38<00:38, 35.57it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26935/28299 [11:38<00:37, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26939/28299 [11:38<00:37, 36.09it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26943/28299 [11:38<00:36, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26947/28299 [11:38<00:38, 34.95it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26951/28299 [11:38<00:37, 35.84it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26955/28299 [11:38<00:36, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26959/28299 [11:38<00:36, 36.54it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26963/28299 [11:38<00:36, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26967/28299 [11:39<00:35, 37.43it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26971/28299 [11:39<00:36, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26975/28299 [11:39<00:35, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26979/28299 [11:39<00:35, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26984/28299 [11:39<00:34, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26988/28299 [11:39<00:33, 38.85it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26992/28299 [11:39<00:35, 36.53it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 26996/28299 [11:39<00:36, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 27000/28299 [11:39<00:35, 37.00it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 27004/28299 [11:40<00:34, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 27008/28299 [11:40<00:34, 36.97it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 27012/28299 [11:40<00:34, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 27016/28299 [11:40<00:33, 37.97it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 27020/28299 [11:40<00:33, 38.31it/s]\u001b[A\n",
            "Epoch 1/5:  95%|█████████▌| 27024/28299 [11:40<00:33, 37.59it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27028/28299 [11:40<00:34, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27032/28299 [11:40<00:34, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27037/28299 [11:40<00:33, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27041/28299 [11:41<00:33, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27045/28299 [11:41<00:33, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27049/28299 [11:41<00:32, 37.96it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27053/28299 [11:41<00:33, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27057/28299 [11:41<00:35, 35.39it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27061/28299 [11:41<00:34, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27065/28299 [11:41<00:34, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27069/28299 [11:41<00:33, 36.77it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27073/28299 [11:41<00:33, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27077/28299 [11:42<00:32, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27081/28299 [11:42<00:32, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27085/28299 [11:42<00:31, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27089/28299 [11:42<00:32, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27093/28299 [11:42<00:32, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27097/28299 [11:42<00:32, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27101/28299 [11:42<00:32, 37.35it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27105/28299 [11:42<00:31, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27109/28299 [11:42<00:31, 37.71it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27113/28299 [11:43<00:32, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27117/28299 [11:43<00:31, 36.99it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27121/28299 [11:43<00:31, 37.48it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27126/28299 [11:43<00:30, 38.69it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27131/28299 [11:43<00:29, 39.61it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27136/28299 [11:43<00:28, 40.45it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27141/28299 [11:43<00:29, 39.92it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27145/28299 [11:43<00:30, 38.38it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27149/28299 [11:43<00:31, 36.76it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27153/28299 [11:44<00:30, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27157/28299 [11:44<00:30, 37.31it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27161/28299 [11:44<00:30, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27165/28299 [11:44<00:30, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27169/28299 [11:44<00:30, 36.79it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27173/28299 [11:44<00:30, 37.26it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27177/28299 [11:44<00:29, 37.67it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27181/28299 [11:44<00:30, 37.10it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27185/28299 [11:44<00:29, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27189/28299 [11:45<00:31, 35.79it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27193/28299 [11:45<00:31, 35.17it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27197/28299 [11:45<00:32, 34.23it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27201/28299 [11:45<00:31, 34.44it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27205/28299 [11:45<00:31, 34.78it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27209/28299 [11:45<00:30, 36.12it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27213/28299 [11:45<00:30, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27217/28299 [11:45<00:29, 36.27it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27221/28299 [11:45<00:29, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27226/28299 [11:46<00:28, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27230/28299 [11:46<00:31, 33.67it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▌| 27234/28299 [11:46<00:30, 34.99it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27238/28299 [11:46<00:29, 36.19it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27242/28299 [11:46<00:28, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27246/28299 [11:46<00:28, 37.07it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27250/28299 [11:46<00:28, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27254/28299 [11:46<00:27, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27258/28299 [11:46<00:27, 38.03it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27262/28299 [11:47<00:27, 37.78it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27266/28299 [11:47<00:26, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27270/28299 [11:47<00:27, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27274/28299 [11:47<00:29, 35.13it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27278/28299 [11:47<00:28, 36.00it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27282/28299 [11:47<00:27, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27286/28299 [11:47<00:28, 35.68it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27290/28299 [11:47<00:27, 36.04it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27294/28299 [11:47<00:27, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27298/28299 [11:48<00:27, 36.24it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27302/28299 [11:48<00:26, 36.93it/s]\u001b[A\n",
            "Epoch 1/5:  96%|█████████▋| 27306/28299 [11:48<00:26, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27310/28299 [11:48<00:25, 38.06it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27314/28299 [11:48<00:26, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27318/28299 [11:48<00:26, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27323/28299 [11:48<00:25, 38.51it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27327/28299 [11:48<00:25, 38.33it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27331/28299 [11:48<00:26, 37.18it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27335/28299 [11:49<00:27, 35.67it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27339/28299 [11:49<00:27, 35.26it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27343/28299 [11:49<00:26, 35.99it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27347/28299 [11:49<00:25, 37.06it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27351/28299 [11:49<00:25, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27355/28299 [11:49<00:26, 36.14it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27359/28299 [11:49<00:25, 36.83it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27363/28299 [11:49<00:24, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27367/28299 [11:49<00:24, 37.87it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27371/28299 [11:50<00:24, 37.85it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27375/28299 [11:50<00:24, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27379/28299 [11:50<00:24, 36.94it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27383/28299 [11:50<00:24, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27387/28299 [11:50<00:25, 36.43it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27391/28299 [11:50<00:24, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27395/28299 [11:50<00:24, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27399/28299 [11:50<00:26, 34.56it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27403/28299 [11:50<00:25, 35.29it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27407/28299 [11:51<00:24, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27411/28299 [11:51<00:24, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27415/28299 [11:51<00:25, 35.15it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27419/28299 [11:51<00:24, 36.03it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27423/28299 [11:51<00:24, 35.51it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27427/28299 [11:51<00:24, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27431/28299 [11:51<00:23, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27436/28299 [11:51<00:22, 38.10it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27441/28299 [11:51<00:21, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27445/28299 [11:52<00:21, 39.30it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27449/28299 [11:52<00:21, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27453/28299 [11:52<00:22, 37.98it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27458/28299 [11:52<00:21, 39.02it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27462/28299 [11:52<00:21, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27467/28299 [11:52<00:21, 39.08it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27471/28299 [11:52<00:21, 38.40it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27475/28299 [11:52<00:21, 37.94it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27479/28299 [11:52<00:21, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27484/28299 [11:53<00:21, 38.78it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27488/28299 [11:53<00:21, 37.29it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27492/28299 [11:53<00:21, 37.53it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27496/28299 [11:53<00:22, 36.34it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27500/28299 [11:53<00:22, 36.09it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27504/28299 [11:53<00:21, 37.04it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27508/28299 [11:53<00:21, 37.51it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27512/28299 [11:53<00:21, 37.40it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27516/28299 [11:53<00:20, 37.49it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27521/28299 [11:54<00:20, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27526/28299 [11:54<00:19, 38.71it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27530/28299 [11:54<00:20, 37.93it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27534/28299 [11:54<00:20, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27538/28299 [11:54<00:20, 37.69it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27542/28299 [11:54<00:20, 37.55it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27546/28299 [11:54<00:19, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27550/28299 [11:54<00:20, 36.88it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27554/28299 [11:54<00:20, 36.35it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27558/28299 [11:55<00:20, 36.45it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27562/28299 [11:55<00:20, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27566/28299 [11:55<00:19, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27570/28299 [11:55<00:19, 36.56it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27574/28299 [11:55<00:19, 36.72it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27578/28299 [11:55<00:19, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27582/28299 [11:55<00:19, 37.38it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27586/28299 [11:55<00:19, 36.78it/s]\u001b[A\n",
            "Epoch 1/5:  97%|█████████▋| 27590/28299 [11:55<00:19, 36.63it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27594/28299 [11:56<00:20, 34.49it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27598/28299 [11:56<00:20, 34.95it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27602/28299 [11:56<00:20, 34.19it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27606/28299 [11:56<00:19, 35.17it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27610/28299 [11:56<00:18, 36.46it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27614/28299 [11:56<00:18, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27618/28299 [11:56<00:18, 36.87it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27622/28299 [11:56<00:18, 37.09it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27626/28299 [11:56<00:17, 37.41it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27630/28299 [11:57<00:18, 35.55it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27634/28299 [11:57<00:18, 35.28it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27638/28299 [11:57<00:18, 35.75it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27642/28299 [11:57<00:18, 35.49it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27646/28299 [11:57<00:17, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27650/28299 [11:57<00:17, 36.29it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27654/28299 [11:57<00:18, 35.58it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27658/28299 [11:57<00:17, 36.02it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27662/28299 [11:57<00:18, 35.13it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27666/28299 [11:58<00:17, 35.35it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27670/28299 [11:58<00:18, 34.64it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27674/28299 [11:58<00:17, 35.23it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27679/28299 [11:58<00:16, 37.32it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27684/28299 [11:58<00:16, 38.34it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27688/28299 [11:58<00:16, 37.47it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27692/28299 [11:58<00:16, 37.12it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27697/28299 [11:58<00:15, 38.02it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27701/28299 [11:58<00:15, 37.46it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27705/28299 [11:59<00:15, 37.60it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27709/28299 [11:59<00:15, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27713/28299 [11:59<00:16, 35.86it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27717/28299 [11:59<00:15, 36.71it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27721/28299 [11:59<00:29, 19.43it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27725/28299 [11:59<00:25, 22.56it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27729/28299 [12:00<00:22, 25.67it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27733/28299 [12:00<00:20, 27.99it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27737/28299 [12:00<00:19, 29.43it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27741/28299 [12:00<00:18, 30.31it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27745/28299 [12:00<00:17, 32.17it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27749/28299 [12:00<00:16, 33.54it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27753/28299 [12:00<00:15, 34.74it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27757/28299 [12:00<00:15, 35.28it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27762/28299 [12:00<00:14, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27766/28299 [12:01<00:14, 36.91it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27770/28299 [12:01<00:14, 36.64it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27774/28299 [12:01<00:14, 36.81it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27778/28299 [12:01<00:14, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27782/28299 [12:01<00:14, 36.03it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27786/28299 [12:01<00:14, 36.13it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27790/28299 [12:01<00:14, 35.63it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27794/28299 [12:01<00:14, 35.17it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27798/28299 [12:01<00:14, 35.36it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27802/28299 [12:02<00:13, 35.85it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27806/28299 [12:02<00:13, 36.73it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27810/28299 [12:02<00:13, 37.28it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27815/28299 [12:02<00:12, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27819/28299 [12:02<00:12, 37.66it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27823/28299 [12:02<00:12, 38.24it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27827/28299 [12:02<00:12, 38.22it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27831/28299 [12:02<00:12, 38.41it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27835/28299 [12:02<00:12, 37.42it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27840/28299 [12:03<00:11, 38.54it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27844/28299 [12:03<00:12, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27848/28299 [12:03<00:11, 37.72it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27853/28299 [12:03<00:11, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27858/28299 [12:03<00:11, 39.56it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27862/28299 [12:03<00:11, 39.05it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27866/28299 [12:03<00:11, 36.15it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27870/28299 [12:03<00:11, 36.89it/s]\u001b[A\n",
            "Epoch 1/5:  98%|█████████▊| 27874/28299 [12:03<00:11, 37.54it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27878/28299 [12:04<00:11, 38.20it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27882/28299 [12:04<00:10, 38.27it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27886/28299 [12:04<00:11, 37.50it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27890/28299 [12:04<00:11, 36.96it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27894/28299 [12:04<00:11, 36.70it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27898/28299 [12:04<00:10, 36.95it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27902/28299 [12:04<00:10, 37.30it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27906/28299 [12:04<00:10, 37.70it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27910/28299 [12:04<00:10, 36.62it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27914/28299 [12:05<00:10, 37.19it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27918/28299 [12:05<00:10, 36.22it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27923/28299 [12:05<00:09, 37.75it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27928/28299 [12:05<00:09, 38.67it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27932/28299 [12:05<00:09, 38.46it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27936/28299 [12:05<00:09, 38.18it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27940/28299 [12:05<00:09, 38.35it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▊| 27944/28299 [12:05<00:09, 38.36it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27949/28299 [12:05<00:08, 39.12it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27953/28299 [12:06<00:08, 38.90it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27957/28299 [12:06<00:08, 38.53it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27962/28299 [12:06<00:08, 38.61it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27966/28299 [12:06<00:08, 37.76it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27970/28299 [12:06<00:09, 36.49it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27974/28299 [12:06<00:08, 36.21it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27978/28299 [12:06<00:08, 35.98it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27982/28299 [12:06<00:08, 36.90it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27986/28299 [12:06<00:08, 36.54it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27990/28299 [12:07<00:08, 37.37it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27994/28299 [12:07<00:08, 37.64it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 27998/28299 [12:07<00:07, 37.73it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28002/28299 [12:07<00:07, 37.90it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28007/28299 [12:07<00:07, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28011/28299 [12:07<00:07, 37.62it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28015/28299 [12:07<00:07, 35.90it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28019/28299 [12:07<00:07, 36.42it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28023/28299 [12:07<00:07, 37.13it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28027/28299 [12:08<00:07, 37.17it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28031/28299 [12:08<00:07, 36.66it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28035/28299 [12:08<00:07, 35.24it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28039/28299 [12:08<00:07, 35.90it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28043/28299 [12:08<00:07, 35.22it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28047/28299 [12:08<00:06, 36.36it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28051/28299 [12:08<00:06, 37.27it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28056/28299 [12:08<00:06, 38.49it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28060/28299 [12:08<00:06, 38.64it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28064/28299 [12:09<00:06, 38.95it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28068/28299 [12:09<00:05, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28072/28299 [12:09<00:05, 38.63it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28076/28299 [12:09<00:05, 38.82it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28081/28299 [12:09<00:05, 39.41it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28085/28299 [12:09<00:05, 37.83it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28089/28299 [12:09<00:06, 34.07it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28094/28299 [12:09<00:05, 35.74it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28098/28299 [12:09<00:05, 36.84it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28102/28299 [12:10<00:05, 37.01it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28106/28299 [12:10<00:05, 36.80it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28110/28299 [12:10<00:05, 35.94it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28115/28299 [12:10<00:04, 37.57it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28120/28299 [12:10<00:04, 38.69it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28124/28299 [12:10<00:04, 38.66it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28128/28299 [12:10<00:04, 38.68it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28132/28299 [12:10<00:04, 38.39it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28136/28299 [12:10<00:04, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28140/28299 [12:11<00:04, 37.45it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28144/28299 [12:11<00:04, 37.80it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28148/28299 [12:11<00:03, 38.25it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28153/28299 [12:11<00:03, 39.03it/s]\u001b[A\n",
            "Epoch 1/5:  99%|█████████▉| 28157/28299 [12:11<00:03, 37.79it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28161/28299 [12:11<00:03, 36.55it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28165/28299 [12:11<00:03, 37.43it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28169/28299 [12:11<00:03, 37.63it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28173/28299 [12:11<00:03, 36.05it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28177/28299 [12:12<00:03, 33.23it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28181/28299 [12:12<00:03, 32.65it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28185/28299 [12:12<00:03, 33.84it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28189/28299 [12:12<00:03, 34.68it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28193/28299 [12:12<00:03, 35.22it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28197/28299 [12:12<00:02, 35.50it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28201/28299 [12:12<00:02, 35.39it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28205/28299 [12:12<00:02, 36.03it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28209/28299 [12:12<00:02, 35.63it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28213/28299 [12:13<00:02, 36.03it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28217/28299 [12:13<00:02, 35.09it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28221/28299 [12:13<00:02, 35.14it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28225/28299 [12:13<00:02, 33.34it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28229/28299 [12:13<00:02, 34.48it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28233/28299 [12:13<00:01, 35.84it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28237/28299 [12:13<00:01, 36.78it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28242/28299 [12:13<00:01, 38.09it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28246/28299 [12:14<00:01, 38.53it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28250/28299 [12:14<00:01, 38.08it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28254/28299 [12:14<00:01, 38.32it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28258/28299 [12:14<00:01, 38.23it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28263/28299 [12:14<00:00, 39.05it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28268/28299 [12:14<00:00, 39.42it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28272/28299 [12:14<00:00, 39.51it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28276/28299 [12:14<00:00, 35.84it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28281/28299 [12:14<00:00, 37.16it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28286/28299 [12:15<00:00, 38.47it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28290/28299 [12:15<00:00, 37.68it/s]\u001b[A\n",
            "Epoch 1/5: 100%|█████████▉| 28294/28299 [12:15<00:00, 35.68it/s]\u001b[A\n",
            "Epoch 1/5: 100%|██████████| 28299/28299 [12:15<00:00, 38.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 avg loss: 0.0516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 28299/28299 [11:44<00:00, 40.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 avg loss: 0.0412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 28299/28299 [11:41<00:00, 40.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 avg loss: 0.0396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 28299/28299 [11:52<00:00, 39.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 avg loss: 0.0389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 28299/28299 [11:46<00:00, 40.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 avg loss: 0.0386\n",
            "Sample 1: Q: What's the color of graph with 56 as the highest value? | GT: Blue | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 2: Q: In which year the difference between blue and green graph 1? | GT: 2018 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The difference is...\". Do not say \"In the year\n",
            "Sample 3: Q: What does the blue line represent? | GT: Not too much/not at all | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Question: What does the blue line represent? Answer:\n",
            "Sample 4: Q: What is the max value of blue line? | GT: 0.72 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Table cells in the same row are separated by '|', and each row is in\n",
            "Sample 5: Q: What's the percentage of respondents who say Job is a top priority for the president and Congress in 2016? | GT: 68 | Pred:  The chart shows the percentage of respondents who say that various issues are a top priority for the president and Congress in 2016. The chart includes the\n",
            "Sample 6: Q: Which line has the lowest value of 71%? | GT: Economy | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The line with the lowest value of 71% is\n",
            "Sample 7: Q: What is the unfavourable value in 2014? | GT: 64 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | Value |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 8: Q: What is the median value of favourable line in the graph? | GT: 40 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot determine\". The chart\n",
            "Sample 9: Q: Which answer response has the highest value on this graph? | GT: Disapprove | Pred:  Do not use abbreviations. Do not say I cannot answer the question or I don't know. Do not say based on the chart. The chart shows the\n",
            "Sample 10: Q: How many data points on the disapprove line are above 50? | GT: 2 | Pred:  Do not make up data points or values.\n",
            "\n",
            "100\n",
            "90\n",
            "80\n",
            "70\n",
            "60\n",
            "50\n",
            "40\n",
            "3\n",
            "Sample 11: Q: Which indicator remains all time lowest from Dec. 2008 to Sep. 2011? | GT: Mostly good news | Pred:  Do not make up data or statistics.\n",
            "\n",
            "The indicator that remained all time lowest from Dec. 2008 to Sep. 2011 is\n",
            "Sample 12: Q: How much value of 'Mostly bad news' increased from Jan. 2011 to Sept. 2011? | GT: 37 | Pred:  The chart shows the value of 'Mostly bad news' from Jan. 2011 to Sept. 2011. The value in\n",
            "Sample 13: Q: When does the red line reach the peak? | GT: 44538 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Question: When does the red line reach the peak?\n",
            "\n",
            "Sample 14: Q: What's the total sum of peak points of all three lines? | GT: 155 | Pred:  The chart has three lines: Line A, Line B, and Line C. Each line has a peak point, which is the highest value on that line.\n",
            "Sample 15: Q: When does the yellow line reach the peak? | GT: 44207 | Pred:  Chart cells that are blank are empty.\n",
            "[{'x': '1990', 'y': 10}, {'x': '199\n",
            "Sample 16: Q: What's the total sum of peak points of green and red lines? | GT: 87 | Pred:  Chart cells are separated by tab, and each row is a new line.\n",
            "\n",
            "Line\t2010\t2011\t2012\t\n",
            "Sample 17: Q: What's the lowest value of yellow line? | GT: 19 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. \n",
            "\n",
            "Chart:\n",
            "|   | A | B | C\n",
            "Sample 18: Q: What's the difference of value of highiest value of red and lowest value of green line? | GT: 79 | Pred:  The chart has 3 lines: red, green, and blue. The red line goes up and down, the green line goes up and down, and the\n",
            "Sample 19: Q: What is the colour of oppose in the graph? | GT: Light blue | Pred:  Do not make up information. Do not say I cannot answer that question. Do not say the chart is missing. Do not say the chart is not available.\n",
            "Sample 20: Q: How many times there is 44 value in the Favor? | GT: 3 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"From the\n",
            "Sample 21: Q: What is the percentage of people who are dissatisfied with Spain's democracy? | GT: 68 | Pred:  The chart shows the percentage of people who are dissatisfied with Spain's democracy.\n",
            "Answer: 30% of people are dissatisfied with Spain's democracy.\n",
            "Sample 22: Q: What is the ratio of people who are dissatisfied and satisfied with Spain's democracy? | GT: 2.125 | Pred:  The chart shows the results of a survey of 1000 people about their satisfaction with Spain's democracy.\n",
            "\n",
            "| Satisfaction Level | Number of People |\n",
            "|\n",
            "Sample 23: Q: Is the Pie chart divided into 3 segment? | GT: Yes | Pred:  If the information is not available in the chart, respond with \"Information not available\". \n",
            "\n",
            "Pie chart: \n",
            "- Segment A: 30%\n",
            "- Segment\n",
            "Sample 24: Q: IS the value of No more then sum of Yes and Dk? | GT: Yes | Pred:  Do not make up data. Table cells in a row are seperated by '|', and rows are seperated by '\n",
            "'.\n",
            "\n",
            "|  | Yes | No |\n",
            "Sample 25: Q: What is the percentage of Iraqi dependents citizen? | GT: 0.12 | Pred:  Chart cells that are blank are empty. Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| \n",
            "Sample 26: Q: What is the total percentage of Afghan applicants and Iraqi applicants? | GT: 0.34 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. The chart contains the following data:\n",
            "Afghanistan|Iraq|Total\n",
            "---|---\n",
            "Sample 27: Q: Is the color of 53% segment light green? | GT: No | Pred:  Do not make up data. Do not say \"Based on the chart...\". Say \"No\" if the chart does not contain enough information to answer the question\n",
            "Sample 28: Q: What's the ratio of Lean Republican segment and Republican segment? | GT: 0.7358 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 29: Q: What segment represent by dark grey color? | GT: Both | Pred:  Do not make up information. Do not say \"Based on the chart...\". The chart is: \n",
            "A pie chart with the following segments: \n",
            "- \n",
            "Sample 30: Q: What is the percentage of both and don't know? | GT: [4, 9] | Pred:  Avoid making up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Question | Both | Don't\n",
            "Sample 31: Q: What's the value of leftmost bar in the bottom? | GT: 12 | Pred:  Each cell in the chart is 1 unit by 1 unit. The chart is as follows:\n",
            "\n",
            "|   | A | B | C | D | E\n",
            "Sample 32: Q: What is the largest value of dark green bar? | GT: 0.92 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The largest value is...\". Do not say \"The value\n",
            "Sample 33: Q: Which country data analysed here? | GT: cuba | Pred:  Do not make things up. If the chart does not contain the information, reply \"Insufficient information\".\n",
            "\n",
            "Sure. Please provide the chart or relevant context for analysis\n",
            "Sample 34: Q: What is the maximum value of dark brown bar? | GT: 7 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Table cells in the same row are seperated by '|', and each row is\n",
            "Sample 35: Q: What's the percentage of very important bar for healthy eating habits? | GT: 0.72 | Pred:  Chart cells are separated by newlines, rows are separated by empty lines. Each cell contains either a number or a text. Do not make anything up.\n",
            "\n",
            "1\n",
            "Sample 36: Q: What's the average of green bar median and light blue bar median? | GT: 17 | Pred:  Chart cells are separated by tab characters, and each row is on a new line.\n",
            "Green bar median|Light blue bar median\n",
            "---|---\n",
            "10|\n",
            "Sample 37: Q: What does dark blue bar represents? | GT: Very Important | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"The chart shows...\". Do not say \"Dark blue bar represents...\".\n",
            "Sample 38: Q: What's the average value of all dark blue bars? | GT: 62.75 | Pred:  Chart cells are separated by tab characters, and each row is on a new line. Each cell contains either a number or a blank. Blank cells are represented as\n",
            "Sample 39: Q: What does the color green indicate? | GT: Support | Pred:  Table cells in the chart are separated by tabs and each row is a new line.\n",
            "\n",
            "| Color | Meaning |\n",
            "| --- | --- |\n",
            "| Red | Danger |\n",
            "\n",
            "Sample 40: Q: What is the difference between the longest and the shortest green bar? | GT: 7 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 41: Q: Which country has the highest percentage value of \"a lot\"? | GT: Kenya | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the highest percentage value of 'a lot'\n",
            "Sample 42: Q: What is the maximum value of \"a lot\" among countries? | GT: 0.69 | Pred:  Do not make up data or statistics. If the information is not available in the chart, respond with \"Insufficient data\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer:\n",
            "Sample 43: Q: How many bars are there in the graph? | GT: 2 | Pred:  The chart shows the number of bars in a graph. The graph has 10 bars. What is the total number of bars?\n",
            "\n",
            "The graph has 1\n",
            "Sample 44: Q: What is the total sum of both the bars? | GT: 7.81 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 45: Q: What's the value of United States? | GT: 0.124 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | 1st | 2nd\n",
            "Sample 46: Q: What's the average value of Canada, Belgium and France? | GT: 0.0277 | Pred:  Chart cells are separated by tabs, rows and columns are separated by newlines. \n",
            "Canada\tBelgium\tFrance\n",
            "10\t15\t20\n",
            "Sample 47: Q: What is the death rate in the age group 5-14 years old? | GT: 0.0034 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 48: Q: Find the median value of all the bars? | GT: 0.68 | Pred:  Do not make up data. Do not say things like 'the median value is' or 'the median is'. Just give the value. 100\n",
            "Sample 49: Q: Which place shows the highest death rate? | GT: Grenada | Pred:  The chart shows the number of deaths per 100,000 people in different countries.\n",
            "\n",
            "| Country | Deaths per 100,0\n",
            "Sample 50: Q: Is the value of death rate in Denmark more then Croatia? | GT: No | Pred:  If the information is not available in the chart, respond with \"Insufficient data\".\n",
            "\n",
            "Chart: {\"data\": [{\"country\": \"Denmark\", \"death_rate\n",
            "Sample 51: Q: How many categories are there in the chart? | GT: 3 | Pred:  Each row in the chart corresponds to a data point. Each column in the chart corresponds to a category. The first row of the chart is a header row that\n",
            "Sample 52: Q: What's the average of two smallest bar? | GT: 70.535 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 53: Q: How many bars are there in the graph? | GT: 2 | Pred:  The chart has the following data: \n",
            "| Month | Sales (in $1000) |\n",
            "|-------|------------------|\n",
            "| Jan   | \n",
            "Sample 54: Q: What is the total add up value of Both the bars? | GT: 59 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot tell\". Do not say \"Not enough information\". Do not\n",
            "Sample 55: Q: What denotes the light blue color bar? | GT: United States | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". Do\n",
            "Sample 56: Q: What's the average value of all bars in the chart? | GT: 126.41 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available\".\n",
            "\n",
            "Chart: {\"type\": \"bar\", \"data\n",
            "Sample 57: Q: What does the value 2122 represent? | GT: Incidence | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The value\". Do not say \"It represents\". Do not\n",
            "Sample 58: Q: What is the difference in the value between Incidence and Prevalence? | GT: 1092 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Term | Definition |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 59: Q: Which age group has the highest value? | GT: 20-24 years old | Pred:   Table cells in the chart are separated by tabs, and each row contains the following data in order: age group, number of people, percentage of total.\n",
            "Sample 60: Q: Find the average of the percentage value of bars greater than 1? | GT: 1.608 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The average is\". Do not say \"The answer is\".\n",
            "Sample 61: Q: Which state shows the highest fertility rate? | GT: Malawi | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: {\"United States\n",
            "Sample 62: Q: Is the value of Malawi greater then sum of Netherlands and Africa? | GT: Yes | Pred:  The chart has the following columns: Country, GDP (in USD), Population (in millions), Area (in km²), GDP per capita (in USD).\n",
            "Sample 63: Q: What is the value of the largest bar? | GT: 1715 | Pred:  Table cells in a row are seperated by '|', and each row by a new line. Table:\n",
            "| Bar | Value |\n",
            "| --- | --- |\n",
            "|\n",
            "Sample 64: Q: What is the difference between the largest bar and the smallest bar? | GT: 1654 | Pred:  Do not make up data. Do not refer to \"the chart\" or \"the data\". The answer must be a complete sentence.\n",
            "\n",
            "The largest bar is \n",
            "Sample 65: Q: Which country has its value 5.97%? | GT: India | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"According to the data...\". \n",
            "\n",
            "Chart content:\n",
            "| Country |\n",
            "Sample 66: Q: Find the total percentage of the three countries having values lower than India? | GT: 0.07 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 67: Q: What is the value of longest bar? | GT: 96 | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The value is...\". Do not say \"According to the\n",
            "Sample 68: Q: How many bars have value less then 1? | GT: 5 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart...\". If the chart does not contain the information\n",
            "Sample 69: Q: Which country represent by pink bar? | GT: Ethiopia | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Question: Which country represent by pink bar?\n",
            "Answer:\n",
            "Sample 70: Q: What is the difference between red and blue bar? | GT: 0.56 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The difference is...\". Do not say \"It shows that\n",
            "Sample 71: Q: How many response options are below 150 n mi? | GT: 2 | Pred:  Chart: 100 n mi 150 n mi 200 n mi 250 n mi 300 n mi\n",
            "Sample 72: Q: What is the average of '24 hours' and '48 hours'? | GT: 105.45 | Pred:  Chart: none\n",
            "Answer:\n",
            "36 hours\n",
            "\n",
            "Question: What is the average of '24 hours' and '48 hours'?, You are a\n",
            "Sample 73: Q: Which year mentioned in the heading of the chart? | GT: 1911 | Pred:  Chart cells are separated by tabs, rows are separated by new lines.\n",
            "Year\\tSales (in millions)\\tProfit (in millions)\\tRevenue (in millions\n",
            "Sample 74: Q: How many times political competition data bigger than political participation? | GT: 7.02 | Pred:  Chart cells are separated by tabs, rows and columns are separated by new lines.\n",
            "\"Political Competition Data\"\t\"Political Participation Data\"\n",
            "\"1\"\t\"\n",
            "Sample 75: Q: Find the value of green bar? | GT: 1.45 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I don't know\". Do not say \"Cannot determine\". Do not\n",
            "Sample 76: Q: How many times green bar greater than Agriculture bar? | GT: 8.53 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The bar for green is...\". Do not say \"The\n",
            "Sample 77: Q: What is the value shown for Australia? | GT: 0.4368 | Pred:  The chart has the following columns: Country, 2010, 2011, 2012, 2013\n",
            "Sample 78: Q: What is the average of bottom three bars? | GT: 38.08 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "|   | A | B\n",
            "Sample 79: Q: What is color of the Age-standardized? | GT: cyan | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"The color of the Age\n",
            "Sample 80: Q: What is the value of the 50-69 years old? | GT: 8.88 | Pred:  Table cells in a row are seperated by tabs, and different rows are new lines. Assume the first row is the header row. Each character in the text\n",
            "Sample 81: Q: The value is 40.49, find the category? | GT: Kidney cancer | Pred:  The chart has the following columns: Category, Min, Max. Here is the chart: Category | Min | Max  A | 0 | 10\n",
            "Sample 82: Q: How many times stomach cancer bigger than Kidney cancer data? | GT: 10.13 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year | Stomach\n",
            "Sample 83: Q: Which two places mentioned in the chart? | GT: [Madagascar, Central Europe] | Pred:  Do not make up information. Do not say things like 'Based on the chart...'. Just answer the question. Question: Which two places mentioned in the chart\n",
            "Sample 84: Q: How much times Madagascar greater than Central europe data? | GT: 32 | Pred:  The chart has the following columns: Country, Population, Area (km²), Population density (people/km²), GDP (USD billion), GDP per capita\n",
            "Sample 85: Q: What is the average maize yield in Syria? | GT: 3.251 | Pred:  The chart has the following columns: Country, Maize Yield (kg/ha), Wheat Yield (kg/ha), Rice Yield (kg/ha). The\n",
            "Sample 86: Q: Find the ratio of highest value and average of two lowest values? | GT: 1.841359773 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer\". Do not say \"Not enough information\". Do not\n",
            "Sample 87: Q: What is Female-to-male ratio to time devoted to unpaid care work in Italy? | GT: 3.37 | Pred:  The chart shows the following data: \n",
            "\n",
            "| Country | Female-to-male ratio to time devoted to unpaid care work |\n",
            "|---------|----------------------------------------------------------|\n",
            "| Italy\n",
            "Sample 88: Q: What is the average of the values lower than 3 and greater than 2? | GT: 2.445 | Pred:  Chart:\n",
            "| x | y |\n",
            "|---|---|\n",
            "| 1 | 2 |\n",
            "| 2 | 3 |\n",
            "| 3 | 4\n",
            "Sample 89: Q: What is the value of largest bar? | GT: 396 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Item | Value |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 90: Q: Is the add up value of Comoros,Nicargua,Australia,Belgium is gretaer then Laos? | GT: No | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "| country | 2010 | 2011 | 2012 | 20\n",
            "Sample 91: Q: Which country has longest bar? | GT: Malta | Pred:  Do not make up information. If information is not in the chart, say so.\n",
            "\n",
            "The chart does not contain information about the length of bars in any country.\n",
            "Sample 92: Q: What is the difference of Sweden and Malta? | GT: 7.49 | Pred:  The chart has the following columns: country, capital, population, area (km2), gdp (billion USD), gdp per capita (USD),\n",
            "Sample 93: Q: How many colors are used in the graph? | GT: 1 | Pred:  Table cells in a row are seperated by tabs, and different rows are new lines. Assume the first row is the header row.\n",
            "\n",
            "Table:\n",
            "|  |\n",
            "Sample 94: Q: What is the sum of largest and smallest bar? | GT: 159.85 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"From the chart...\". Do not say \"According to the\n",
            "Sample 95: Q: How many colors are represented in the bar?? | GT: 5 | Pred:  The bar chart shows the number of students in a class who like different colors. The colors are: red, blue, green, yellow, and purple. The\n",
            "Sample 96: Q: What is the difference between Industry employment percentage in Iran and Kenya?? | GT: 26.38 | Pred:  The chart shows the percentage of people employed in the industry sector in different countries.\n",
            "\n",
            "In 2010, the industry employment percentage in Iran was 2\n",
            "Sample 97: Q: Which place shows the highest cases of guinea worm? | GT: South Sudan | Pred:  Each row in the chart represents a different place. Each column in the chart represents a different category. The first column is \"Place\", and the following columns are\n",
            "Sample 98: Q: Is the sum of Senegal and Central African Republic more then Chad? | GT: No | Pred:  The chart has the following columns: country, population, area (sq. km), population density (people per sq. km). \n",
            "\n",
            "country\tpopulation\tarea (\n",
            "Sample 99: Q: How many colors are represented in the bar?? | GT: 8 | Pred:  Each cell in the chart contains a number. The numbers represent the number of items of a certain color in a group. For example, if a cell contains \n",
            "Sample 100: Q: What's the average value of first two bars in the chart?? | GT: 0.33 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 101: Q: What group has the highest death rate? | GT: 70+ years old | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The group with the highest death rate is...\". Do not\n",
            "Sample 102: Q: What is the difference between the death rates of 5-14 ears old with the death rate of 70+ years old? | GT: 272.62 | Pred:  Do not make up data or statistics. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "70+ years old:\n",
            "Sample 103: Q: Which country represented by Brown bar? | GT: Bangladesh | Pred:  Each row in the chart represents a different country. The first column is the country name, the second column is the capital city, and the third column is the\n",
            "Sample 104: Q: What is the difference of largest and smallest bar? | GT: 409.13 | Pred:  Chart cells are separated by newlines, with headers in the first row. Each cell is separated by a tab from the next. Row and column headers are not\n",
            "Sample 105: Q: Which country is indicated by the middle bar? | GT: Namibia | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The answer must be one\n",
            "Sample 106: Q: Total values of all the three bars lower than .02? | GT: No | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "|   | A | B\n",
            "Sample 107: Q: Which country has longest bar? | GT: Iraq | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"According to the data...\". The chart is: None\n",
            "Answer\n",
            "Sample 108: Q: Does the sum of smallest two bar is greater then the largest bar? | GT: No | Pred:  If the information is not available in the chart, respond with \"Cannot be determined\".\n",
            "\n",
            "Bar chart: \n",
            "|   | A | B | C | D |\n",
            "Sample 109: Q: What is the color of Mexico bar? | GT: Pink | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in the chart.\"\n",
            "\n",
            "Mexico bar: Red\n",
            "Answer:\n",
            "Red\n",
            "Sample 110: Q: What is the sum of smallest three bar? | GT: 3.7 | Pred:  Do not make up data. Do not say \"insufficient information\". Do not say \"I don't know\". Do not say \"Cannot determine\". Do not\n",
            "Sample 111: Q: What is the highest value in the bar graph? | GT: 23 | Pred:  The bar graph shows the number of books read by students in a class over the summer. The x-axis represents the number of books read, and the y-axis\n",
            "Sample 112: Q: Is Croatia global hunger index extremely alarminhg? | GT: No | Pred:  If the information is not available in the chart, say \"Information not available\".\n",
            "\n",
            "Chart title: Global Hunger Index (GHI) 2022\n",
            "\n",
            "Sample 113: Q: How many colors are used in the graph? | GT: 1 | Pred:  Each cell in the chart contains a number. The numbers represent the number of items of a certain color in a group. For example, if a cell contains \n",
            "Sample 114: Q: What is the average of smallest two bars? | GT: 13 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 115: Q: What denotes the green color bar ?? | GT: Sub-Saharan Africa | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"As shown in\n",
            "Sample 116: Q: Find out the average of the bottom three countries ?? | GT: 0.0593 | Pred:   Table cells in the chart are separated by tabs, and different rows are new lines. Table header is on the first line. The chart might not contain all\n",
            "Sample 117: Q: What country is represented by the Red bar? | GT: Libya | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 118: Q: What is the difference between the largest bar and the smallest bar? | GT: 0.092 | Pred:  The chart has the following data: \n",
            "| Bar | Value |\n",
            "|---|---|\n",
            "| Bar 1 | 10 |\n",
            "| Bar 2 |\n",
            "Sample 119: Q: Which animal is represented by longest bar? | GT: Cattle | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The chart is: \n",
            "Sample 120: Q: What is difference of value of Paddy rice and Wheat? | GT: 6.5 | Pred:  Table cells in a row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | Paddy Rice | Wheat |\n",
            "|\n",
            "Sample 121: Q: How many region are shown in the chart? | GT: 7 | Pred:  Chart: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10\n",
            "Sample 122: Q: What the difference in value between Asia and Caribbean? | GT: 1.18 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The difference is...\". Do not say \"According to the\n",
            "Sample 123: Q: What is the death rate from drug use disorders in Thailand? | GT: 0.77 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Chart title:\n",
            "Death rate from drug use disorders in Thailand (per 100,\n",
            "Sample 124: Q: Is the average value of Andean Latin America and Cambodia more than the value of Thailand? | GT: Yes | Pred:  Chart cells that are blank are empty.\n",
            "| Country | 2010 | 2011 | 2012 | 20\n",
            "Sample 125: Q: What is the number of undernourished people in Southern Asia as of 2000 ( in millions)? | GT: 264.5 | Pred:  The chart shows the number of undernourished people in various regions of the world as of 2000 (in millions). Southern Asia: \n",
            "Sample 126: Q: What is the sum of undernourished people in Low Income economies and Sub-Saharan Africa combined (in millions)? | GT: 341.9 | Pred:  The chart shows the number of undernourished people in different regions of the world.\n",
            "\n",
            "The chart shows the following data:\n",
            "- Asia: 400\n",
            "Sample 127: Q: What is the value of Pink bar? | GT: 21524 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 128: Q: Does the Saudi Arabia and Australasia has same value ? | GT: No | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "|  | 2010 | 2011 | 2012 | 20\n",
            "Sample 129: Q: What does the color orange represent? | GT: Estimated number of polio cases | Pred:  Each row in the chart represents a different category, and each column represents a different attribute. The first row is the header row, and the first column is the\n",
            "Sample 130: Q: How many bar has the same value ? | GT: 2 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| bar | value |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 131: Q: What does the lowest bar represent? | GT: Pre-demographic dividend | Pred:  Do not make up information. Do not say I cannot answer that question. Do not say based on the chart. Do not say from the chart. Do not\n",
            "Sample 132: Q: What is the difference of value  between Malaysia and Barbados? | GT: 10.18 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Country | GDP (in USD\n",
            "Sample 133: Q: How many age group are shown the graph? | GT: 6 | Pred:  Graph: A bar graph showing the number of students in different age groups. The age groups are: 10-12, 13-1\n",
            "Sample 134: Q: What is the sum of lowest bar and top most bar in the grap? | GT: 61.23 | Pred:  Do not make up data. Do not say \"insufficient information\". The chart shows the number of students in different grades at a school. \n",
            "\n",
            "Grade | Number\n",
            "Sample 135: Q: What is the % of people who are undernourished in Southern Asia as of 2000? | GT: 18.2 | Pred:  The chart shows the % of people who are undernourished in different regions of the world as of 2000.\n",
            "\n",
            "Southern Asia: 2\n",
            "Sample 136: Q: Is the sum of the % of people who are undernourished in Southern Asia and Eastern Asia more than that in Sub-Saharan Africa? | GT: Yes | Pred:  The chart has the following columns: Region, % of people undernourished. Southern Asia: 17%, Eastern Asia: 13%, Sub\n",
            "Sample 137: Q: What is the % of people who are worried about losing their job in Cyprus? | GT: 58.79 | Pred:  Avoid making up data. If the chart does not contain the information, respond with \"Data not available\".\n",
            "\n",
            "% of people worried about losing their job in Cyprus:\n",
            "Sample 138: Q: What is the difference in % between Poland and Australia for people who are worried about losing their job? | GT: 17.05 | Pred:  The chart shows the percentage of people who are worried about losing their job in different countries. Poland: 40%, Australia: 30%\n",
            "\n",
            "70\n",
            "Sample 139: Q: In which country has the smallest value? | GT: Angola | Pred:   Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Country | Population | Area (km²\n",
            "Sample 140: Q: How many bars with the equal value in the bar graph? | GT: 2 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I don't know\". Do\n",
            "Sample 141: Q: Which country recorded highest percentage in the chart ? | GT: Tanzania | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"According to the chart...\". The chart shows the percentage of people\n",
            "Sample 142: Q: How many times Tanzania data bigger than Ethiopia data ? | GT: 3.5 | Pred:  Each cell in the chart is a single number. The chart has the following columns: Country, Population, Area (km²), GDP (USD), GDP per\n",
            "Sample 143: Q: What's the value of smallest bar? | GT: 0.96 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I don't know\". Do not say \"Cannot determine\". Do not\n",
            "Sample 144: Q: Does the difference of iDA only and Upper middle income is equal to the value of smallest bar? | GT: No | Pred:  Do not make up data. If information is not available in the chart, say so.\n",
            "\n",
            "Answer: No. The difference between iDA only and Upper middle income\n",
            "Sample 145: Q: Which country has highest Pig meat yields ? | GT: United States | Pred:  Do not make up data or statistics. If the information is not available in the chart, respond with 'Data not available'.\n",
            "\n",
            "Chart: \n",
            "| Country | Pig\n",
            "Sample 146: Q: What is the difference in Green and Purple bar? | GT: 5 | Pred:  Do not make up data. Do not refer to \"the chart\" or \"the table\". The response must be in the form: Answer: X\n",
            "\n",
            "Answer\n",
            "Sample 147: Q: What's the value of largest bar? | GT: 270827 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Item | Value |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 148: Q: Does the sum of smallest two bar is equal to 3rd smallest bar? | GT: No | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| bar | value |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 149: Q: How many colors are there in the graph? | GT: 4 | Pred:  Do not make up information. Do not say things like 'Based on the chart...'. Just answer the question. Do not make up information. Do not say\n",
            "Sample 150: Q: Does the sum of smallest two bar is greater then then the value of largest bar? | GT: Yes | Pred:  If the information is not available in the chart, respond with \"Cannot be determined\".\n",
            "\n",
            "Bar chart: \n",
            "| Bar | Value |\n",
            "|-----|-------|\n",
            "|\n",
            "Sample 151: Q: What is the value of middle bar ? | GT: 81.71 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The value of middle bar is\". Do not say \"Middle\n",
            "Sample 152: Q: What is ratio between Primary school and upper secondary ? | GT: 0.3493 | Pred:  Chart cells are separated by newlines, columns are separated by tabs. Chart:\n",
            "| Year | 1990 | 1995 | \n",
            "Sample 153: Q: what is orange bar represents ? | GT: Europe | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"From the\n",
            "Sample 154: Q: what is the sum of africa and pacific ? | GT: 0.07 | Pred:  Each row in the chart represents a different country or region. The first column is the name of the country or region. The second column is the number of people\n",
            "Sample 155: Q: Which color bar resembles the name of a fruit? | GT: orange | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say \"I\n",
            "Sample 156: Q: What is the value of the Child Labor bar? | GT: 0.193 | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"According to the chart...\". The chart is: 1.\n",
            "Sample 157: Q: In chart Middle bar represents what ? | GT: Madagascar | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot determine\". Do\n",
            "Sample 158: Q: What is the average of all the numbers ? | GT: 1.55 | Pred:  Do not make up data. Do not say things like 'The average is' or 'The answer is'. Just give the final answer.\n",
            "\n",
            "Chart:\n",
            "| Number\n",
            "Sample 159: Q: Which is the highest percentage of the value? | GT: 0.405 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The highest percentage is...\". Do not say \"The value\n",
            "Sample 160: Q: What is the value of the United Kingdom? | GT: 0.354 | Pred:  Do not make up data or statistics. If the information is not present in the chart, say \"Data not available\".\n",
            "\n",
            "Chart content: The chart does not contain\n",
            "Sample 161: Q: What is the color of the shortest bar? | GT: Gray | Pred:  The chart has the following data:\n",
            "| Bar | Length (cm) | Color |\n",
            "|----|------------|-------|\n",
            "| A  | 4          |\n",
            "Sample 162: Q: Would the combined homicide rate for the 5-14 and Under 5's be bigger than All Ages? | GT: No | Pred:  The chart shows the homicide rates per 100,000 people for different age groups in the United States in 2020.\n",
            "\n",
            "Age\n",
            "Sample 163: Q: How many lines are shown in the chart? | GT: 6 | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 164: Q: When does the gap between Nigeria and India reach the largest value? | GT: 2021 | Pred:  The chart has the following columns: Year, Nigeria, India. The data in the chart is: Year, Nigeria, India 1960, \n",
            "Sample 165: Q: Which country has the highest value in 1979? | GT: Iceland | Pred:  Each row in the chart represents a country, and each column represents a year. The values in the cells are the GDP (in billions of USD) for that\n",
            "Sample 166: Q: Which country has the smallest fluctuations in the chart? | GT: South Korea | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the smallest fluctuations is...\". Do not say\n",
            "Sample 167: Q: In which year was the death rate due to unsafe water sources is lowest in the Maldives? | GT: 2000 | Pred:  The chart shows the death rate due to unsafe water sources in the Maldives from 1990 to 2010.\n",
            "Answer: 1\n",
            "Sample 168: Q: Which country saw the higher death rate due to unsafe water sources from 1990 to 2000 between Palestine and Norway? | GT: Palestine | Pred:  The chart shows the number of deaths per 100,000 people due to unsafe water sources from 1990 to 20\n",
            "Sample 169: Q: The pink line in the chart belongs to which country data? | GT: France | Pred:  Make sure to follow the instructions in bold.\n",
            "\n",
            "Question: The pink line in the chart belongs to which country data?\n",
            "Answer: The pink line in the chart belongs\n",
            "Sample 170: Q: Find out Which country data is stable for the entire 3 years? | GT: France | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The data for...\". Do not say \"From the chart\n",
            "Sample 171: Q: When did the line reach its peak? | GT: 1998 | Pred:  Table cells in the chart are separated by tabs, and each row is a new line.\n",
            "\n",
            "date|value\n",
            "---|---\n",
            "1990|10\n",
            "Sample 172: Q: During which period does the line have the greatest increase? | GT: 1998 | Pred:  Table cells in a row are seperated by tabs and a new row is represented by a new line.\n",
            "Period|Value\n",
            "---|---\n",
            "1990\n",
            "Sample 173: Q: Which two countries are being compared in the given line graph? | GT: [Africa, Northern America] | Pred:  Final answer format: The two countries are \\textbf{X} and \\textbf{Y}.\n",
            "\n",
            "QUESTION: Which two countries are being compared in the\n",
            "Sample 174: Q: Which of the following countries saw a higher demand in education over the given years, Africa or North America? | GT: Africa | Pred:  Do not make up data. Do not say \"Insufficient data\". The chart shows the demand in education in Africa and North America from 2010\n",
            "Sample 175: Q: What does Orange line represents? | GT: Urban | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"According to the chart...\". The chart is: 1.\n",
            "Sample 176: Q: What's the difference in the value of highest percentage value given in the chart and the percentage points where two lines cross? | GT: 0.3 | Pred:  Assume the chart is visible and can be interacted with.\n",
            "\n",
            "10\n",
            "Answer: 10\n",
            "\n",
            "The difference in the value of the highest percentage value given\n",
            "Sample 177: Q: In which year the share of youth not in education is maximum� in Laos? | GT: 2017 | Pred:  The chart shows the share of youth (aged 15-24) not in education in selected countries in 2005 and 20\n",
            "Sample 178: Q: In how many years the share of youth not in education is more than 20 %? | GT: 4 | Pred:  The chart shows the percentage of youth (aged 15-24) not in education in different countries in 2005 and 20\n",
            "Sample 179: Q: In which year the commercial bank branches are maximum in Senegal? | GT: 2009 | Pred:  Do not make up data. The chart shows the number of commercial bank branches in Senegal from 1990 to 2010. The\n",
            "Sample 180: Q: In how many years does the number of commercial bank branches are greater than 30 in Montenegro? | GT: 3 | Pred:  The chart shows the number of commercial bank branches in Montenegro from 2005 to 2015.\n",
            "\n",
            "The chart data:\n",
            "- 2\n",
            "Sample 181: Q: What age group does the Red bar Show in the graph? | GT: 15-17 years | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". The\n",
            "Sample 182: Q: Which among Red and Grey bar has the highest value in the year 2000? | GT: Red | Pred:  Do not make up data. Do not say anything like \"Based on the chart...\" or \"From the chart we can see...\".\n",
            "\n",
            "Red bar has the highest\n",
            "Sample 183: Q: Which year saw the maximum change in the death rate due to tuberculosis in the age group 70+ years old in Seria? | GT: 2010 | Pred:  2010 2011 2012 2013 2014 2015 2\n",
            "Sample 184: Q: Which age group saw the maximum change in the death rate due to tuberculosis over the years? | GT: Under-5s | Pred:  The chart shows the death rates (per 100,000 people) from tuberculosis in different age groups in 1980 and \n",
            "Sample 185: Q: Which year recorded the least daily hempseed production in Europe? | GT: 1990 | Pred:  The chart shows the daily production of hempseed in Europe from 2010 to 2015.\n",
            "Answer: 2015.\n",
            "Sample 186: Q: Which of the following saw the higher daily hempseed production over the years, Europe or Europe, Western? | GT: Europe | Pred:  The chart shows the daily production of hempseed in Europe and Western Europe from 1990 to 2000.\n",
            "\n",
            "Based on the chart,\n",
            "Sample 187: Q: How many years shows the Unemployment rate in the graph? | GT: 9 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "10 years\n",
            "\n",
            "8 years\n",
            "\n",
            "\n",
            "Sample 188: Q: In which year did the color green and orange bar intersect? | GT: 2005 | Pred:  The chart has the following columns: Year, Green Bar, Orange Bar. The chart data is: Year, Green Bar, Orange Bar 1990\n",
            "Sample 189: Q: Which age group recorded the highest daily rates of bipolar disorder in Argentina? | GT: 15-49 years old | Pred:  The chart has the following columns: Age group, Prevalence rate (per 100,000), Daily rate (per 10\n",
            "Sample 190: Q: How many age groups are mentioned in the given graph? | GT: 4 | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 191: Q: How many regions have more than 60 % proportions that applied for accreditation? | GT: 1 | Pred:  Chart cells are separated by tabs, rows and columns are separated by newlines. \n",
            "Chart:\n",
            "Region\\tProportion of applications for accreditation\n",
            "North\\t40\n",
            "Sample 192: Q: Which region saw the highest proportion of accreditation over the given years? | GT: Southern Asia | Pred:  Chart cells are separated by new lines, and columns are separated by tabs. Years are in the first row, and the first column contains regions. Each cell contains\n",
            "Sample 193: Q: In which year the share of people having access to clean fuel for cooking is maximum in Bosnia and Herzegovina? | GT: 2013 | Pred:  The chart shows the share of people having access to clean fuel for cooking in Bosnia and Herzegovina from 2000 to 2015\n",
            "Sample 194: Q: Which of the following countries has had higher access to clean fuels for cooking over the years, Latvia or Belize? | GT: Latvia | Pred:  The chart shows the percentage of population with access to clean fuels for cooking in selected countries from 1990 to 2015.\n",
            "\n",
            "- Latvia\n",
            "Sample 195: Q: Which year recorded the highest prevalence of Anemia in women in the Bahamas? | GT: 1990 | Pred:  The chart has the following columns: Year, Prevalence of Anemia in Women (%), Prevalence of Anemia in Men (%), Prevalence\n",
            "Sample 196: Q: Which of the following countries recorded the higher prevalence of Anemia in women over the years, Zambia or Bahamas? | GT: Zambia | Pred:  The chart shows the prevalence of anemia in women in Zambia and the Bahamas from 2000 to 2010.\n",
            "\n",
            "Zambia: \n",
            "Sample 197: Q: Which year recorded the lowest mortality rate in the Caribbean? | GT: 1990 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: Which year recorded the lowest mortality rate in the\n",
            "Sample 198: Q: In how many years has the mortality rate is greater than 10% in the Caribbean? | GT: 3 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: In how many years has the mortality rate is\n",
            "Sample 199: Q: Which year does Czechia point? | GT: 1992 | Pred:  Do not make up information. Do not say things like \"Based on the chart...\". Just answer the question. If the information is not in the chart,\n",
            "Sample 200: Q: Between which, two years does the bar shows the lowest value? | GT: [1965, 1970] | Pred:  Do not make up data. Do not say things like 'The chart shows' or 'Based on the chart'. Do not say things like 'I notice'\n",
            "Sample 201: Q: Which year recorded the maximum urban population living in slums in Kenya? | GT: 2000 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: Which year recorded the maximum urban population living in\n",
            "Sample 202: Q: Which year recorded the least urban population living in slums in Kenya? | GT: 1990 | Pred:  The chart shows the urban population living in slums in Kenya from 1990 to 2010.\n",
            "\n",
            "1990: 3\n",
            "Sample 203: Q: What does country does the orange line represent? | GT: Tajikistan | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The chart is: \n",
            "Sample 204: Q: what is the difference in Alcohol and drug use disorders in Tajikistan between 2000 and 2009? | GT: 0.005 | Pred:  The chart shows the following data: \n",
            "\n",
            "| Year | Alcohol Use Disorder | Drug Use Disorder |\n",
            "|------|---------------------|-------------------|\n",
            "| 20\n",
            "Sample 205: Q: How many drugs are shown in the graph? | GT: 4 | Pred:  The graph shows the number of drugs approved by the FDA in the United States from 2000 to 2010. 200\n",
            "Sample 206: Q: When does the gap between Opioids and Cocaine reach the peak? | GT: 2014 | Pred:  Each row in the chart represents a year, and each column represents a different metric. The first row is the header row. The first column is the year.\n",
            "Sample 207: Q: In which year the home production time by male age group 25-54 is minimum? | GT: 1930 | Pred:  The chart shows the home production time (in hours per week) by gender and age group. The age groups are: 18-24, \n",
            "Sample 208: Q: In how many years the weekly production time by age group 55-64 is greater than 25 hours? | GT: 31 | Pred:  The chart shows the weekly production time (in hours) for different age groups.\n",
            "\n",
            "| Age Group | Weekly Production Time (hours) |\n",
            "|-----------|-------------------------------\n",
            "Sample 209: Q: Which country is represented by the blue color line? | GT: Russia | Pred:  Make sure your response is as close to the chart's original wording as possible. Do not make things up.\n",
            "\n",
            "Answer: The blue color line represents Germany. Answer\n",
            "Sample 210: Q: Which country has a higher share of the population using safely managed drinking water over the years? | GT: Bosnia and Herzegovina | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just give the country with the higher share of the population using safely managed drinking water\n",
            "Sample 211: Q: Which year recorded the highest suicide rates by males in Portugal? | GT: 1996 | Pred:  The chart shows the suicide rates (per 100,000 people) by gender and year from 1990 to 20\n",
            "Sample 212: Q: Which of the following sex recorded the higher suicide rates over the years, male or female? | GT: Male | Pred:  The chart shows the suicide rates per 100,000 people for males and females in the United States from 1999 to \n",
            "Sample 213: Q: Which country is represented by the red color line? | GT: United States Virgin Islands | Pred:  Make sure to follow the formatting instructions: wrap the final answer in double curly braces {{ }}.\n",
            "\n",
            "The chart shows the population of different countries in 202\n",
            "Sample 214: Q: In how many countries the concentration of particulate matter is found to be more than 20 micrograms? | GT: 2 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 215: Q: How many countries are represented on the graph? | GT: 2 | Pred:   Question: How many countries are represented on the graph?\n",
            "Answer: 5\n",
            "\n",
            "Question: What is the total number of students in the school?\n",
            "Answer:\n",
            "Sample 216: Q: How many years are Greece's population rate below 35% | GT: 1 | Pred:   Chart cells are separated by new lines, columns are separated by tabs. Date\t2000\t2001\t2002\t\n",
            "Sample 217: Q: Which country is represented by the red line? | GT: Kenya | Pred:  Do not make up information. Question: Which country is represented by the red line? Answer: China\n",
            "\n",
            "Question: Which country is represented by the blue line?\n",
            "Sample 218: Q: Which country has an all-time lower share of children younger than 5 who are underweight for their age? | GT: Peru | Pred:  The chart has the following columns: Country, Share of children younger than 5 who are underweight for their age, Share of children younger than 5 who\n",
            "Sample 219: Q: Which country is represented by the given line graph? | GT: Niger | Pred:  Do not make up information. Do not say I cannot answer this question. Do not say based on the chart. Do not say using the information from the chart\n",
            "Sample 220: Q: In which year did the line graph saw its lowest dip? | GT: 2013 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The lowest dip occurred in...\". Do not say \"The\n",
            "Sample 221: Q: Is the starting value of the red graph the lowest value? | GT: Yes | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The answer must be either\n",
            "Sample 222: Q: Is the value of the blue graph constantly increasing? | GT: Yes | Pred:  If the information is not present in the chart, respond with \"Cannot be determined\". \n",
            "\n",
            "Chart: \n",
            "| x | y |\n",
            "|---|---|\n",
            "|\n",
            "Sample 223: Q: Which country has the highest rise in the number of poultry birds from 1961 to 1990? | GT: Cuba | Pred:  The chart shows the number of poultry birds (in millions) in different countries from 1961 to 1990. The countries are:\n",
            "Sample 224: Q: In which year, the middle line (Uruguay) is lowest? | GT: 1975 | Pred:  The chart has the following columns: Year, Argentina, Brazil, China, France, Germany, India, Indonesia, Italy, Japan, South Korea, Mexico,\n",
            "Sample 225: Q: Which area/region is represented by the upper line? | GT: Bahrain | Pred:  Do not make up information. Do not say I cannot answer this question. The chart shows the number of students in different regions of a country. The upper line\n",
            "Sample 226: Q: Which bar has the lowest value? | GT: Lesotho | Pred:  Do not use abbreviations. Do not say I cannot answer this question. Do not say the chart is missing. Do not say based on the chart. The\n",
            "Sample 227: Q: Is the National GDP value lower than 7 billion in 1955? | GT: Yes | Pred:  If the information is not available in the chart, respond with \"Information not available in chart\".\n",
            "\n",
            "Chart: \n",
            "| Year | GDP (in billion USD) |\n",
            "\n",
            "Sample 228: Q: In which year National GDP value crossed 20 billion? | GT: 1974 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "National GDP value crossed \n",
            "Sample 229: Q: Which gender is represented by the red color line? | GT: Male | Pred:  Do not make up information. Do not say things like 'Based on the chart...' or 'From the chart we can see...'. Do not say things like\n",
            "Sample 230: Q: Which year recorded the highest number of cases of killing of male Journalists? | GT: 2018 | Pred:  The chart shows the number of cases of killing of male journalists from 2016 to 2020.\n",
            "\n",
            "2016: 1\n",
            "Sample 231: Q: Which line has an all-time 'high share of the population with severe food insecurity than other lines? | GT: Low income | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with 'Data not available'. \n",
            "\n",
            "Chart: \n",
            "| Line |\n",
            "Sample 232: Q: Which line has the slightest change in the share of the population with severe food insecurity? | GT: Eastern Asia | Pred:  The chart shows the share of the population with severe food insecurity in the United States from 2007 to 2019. The x-axis\n",
            "Sample 233: Q: Is the highest value of Myanmar greater than 30000? | GT: Yes | Pred:  Chart cells are separated by tabs, and each row is on a new line. Each data point in the chart is given as \"year\\tvalue\". 1\n",
            "Sample 234: Q: Is the Myanmar graph value in 1997 is the median value of this graph? | GT: Yes | Pred:  Chart: 1997 1998 1999 2000 2001 2002\n",
            "Sample 235: Q: Which country is used in the line graph? | GT: Guatemala | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Question: Which country is used in the line graph?\n",
            "Sample 236: Q: Which year it is in peak? | GT: 2006 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot determine from the chart\".\n",
            "\n",
            "Chart: \n",
            "\n",
            "Sample 237: Q: Which region is represented by the given line graph? | GT: South Eastern Asia | Pred:  Do not make up information. Do not say I cannot answer this question. The chart is not provided.\n",
            "\n",
            "Question: Which region is represented by the given line graph\n",
            "Sample 238: Q: Which year recorded the lowest value Red List Index? | GT: 2019 | Pred:  The chart shows the Red List Index (RLI) values from 1970 to 2020. The RLI is a measure of\n",
            "Sample 239: Q: Which country is represented by the given line graph? | GT: Jamaica | Pred:  Do not make up information. Do not say I cannot answer this question. Do not say based on the chart. Do not say using the information from the chart\n",
            "Sample 240: Q: In how many years, the share of government expenditure is more than 10% in Jamaica? | GT: 4 | Pred:  Do not make up data. Do not say things like 'Based on the chart...'. Just answer the question. If the information is not available in the chart\n",
            "Sample 241: Q: What is the value of drug use in the year 1990? | GT: 1000 | Pred:  Chart cells that are blank are empty.\n",
            "| Year | 1980 | 1985 | 1990 | 19\n",
            "Sample 242: Q: What is the approximate difference of values in the year 1990? | GT: 900 | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "Year | 1980 | 1985 | 1990 | 199\n",
            "Sample 243: Q: Which country is featured in the graph? | GT: Canada | Pred:  The chart is as follows: 1. The graph shows the population of different countries in millions. 2. The x-axis represents the country names. \n",
            "Sample 244: Q: After which year does the line have the sharpest decrease? | GT: 2008 | Pred:  Do not make up data. Do not say I cannot answer. Do not say based on the chart. Do not say from the chart. After which year does\n",
            "Sample 245: Q: Which country is represented in this graph? | GT: Australia | Pred:  Graph: A bar graph showing the number of students in different countries in a school. The countries are: United States, Canada, United Kingdom, Australia, and\n",
            "Sample 246: Q: In what year did Australia reach its peak? | GT: 1980 | Pred:  The chart shows the population of Australia from 1901 to 2016.\n",
            "\n",
            "According to the chart, Australia reached its peak population in the\n",
            "Sample 247: Q: How many regions are represented? | GT: 5 | Pred:  Each row in the chart represents a region. The chart has the following columns: Region, Population, Area (km²), and Density (people/km²\n",
            "Sample 248: Q: How many regions saw increases? | GT: 5 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|c|c|} \\hline\n",
            "Sample 249: Q: In which year, the value of the red graph peaked? | GT: 2009 | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The peak value occurred in...\". Do not say \"The\n",
            "Sample 250: Q: In which year was the difference between the prevalence of obesity in adult males maximum in Sri Lanka and Czechia? | GT: 2009 | Pred:  The chart shows the prevalence of obesity in adult males in Sri Lanka and Czechia from 1990 to 2016. The difference between\n",
            "Sample 251: Q: In which year, the value of Employment in the agriculture graph peaked? | GT: 1999 | Pred:  Do not make up information. Do not say I cannot answer this question. If the chart does not contain the needed information, say so. Question: In which\n",
            "Sample 252: Q: For how many years, the value of the \"Employment in services\" graph smaller than 60%? | GT: 13 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 253: Q: Which country is represented by blue color line? | GT: Korea | Pred:  Chart cells are separated by tabs, rows are new lines. Chart:\n",
            "Country|2010|2011|2012|2\n",
            "Sample 254: Q: Which year recorded the least number of Caesarean sections in the Czech Republic? | GT: 2006 | Pred:  The chart shows the number of Caesarean sections performed in the Czech Republic from 1990 to 2010.\n",
            "\n",
            "199\n",
            "Sample 255: Q: Is the crude oil import price greater than 25$/barrel in 1984? | GT: Yes | Pred:  Assume the chart is available and can be viewed. \n",
            "\n",
            "Yes\n",
            "No\n",
            "No\n",
            "\n",
            "The chart shows that the crude oil import price in 1984\n",
            "Sample 256: Q: In how many years has the crude oil import price smaller than 15$/barrel? | GT: 1 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: In how many years has the crude oil import\n",
            "Sample 257: Q: What's the percentage of Trump voters who are against Biden? | GT: 24 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"According to the chart...\". Do not say things like \"The\n",
            "Sample 258: Q: What's the ratio of Trump voters who are against Biden and Biden voters who are for Biden? | GT: 0.340972222 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 259: Q: What's the percentage value of the topmost green bar? | GT: 60 | Pred:  The chart has the following data: \n",
            "- Green: 30%\n",
            "- Blue: 25%\n",
            "- Yellow: 20%\n",
            "- Red:\n",
            "Sample 260: Q: What's the ratio of Never/Rarely and Occasionally/Frequently in Luo? | GT: 0.085416667 | Pred:  Do not make up data. Do not say anything like \"Based on the chart...\" or \"From the chart...\". Do not say that the data is missing\n",
            "Sample 261: Q: What's the lowest value of the light blue bar? | GT: 8 | Pred:  Do not make up data. Do not say \"Insufficient data\". The chart shows the number of students in each grade level at Lincoln High School. \n",
            "\n",
            "Grade\n",
            "Sample 262: Q: What's the average of all the bars in Germany? | GT: 24.25 | Pred:  Do not make up data. If the chart does not contain the necessary information, respond with \"Cannot determine from the chart.\"\n",
            "\n",
            "Average of all the bars in Germany\n",
            "Sample 263: Q: 18, 22, _, 20, find the missed data? | GT: 40 | Pred:  18, 22, _, 20, 24, 26, 28, 30, 32\n",
            "Sample 264: Q: What's the ratio(A:B) of the largest value and the rightmost value in WHO category? | GT: 0.084027778 | Pred:  The chart has the following columns: WHO category, Lower limit of the range, Upper limit of the range, Largest value, Rightmost value.\n",
            "Answer: \n",
            "Sample 265: Q: What percent of US adults who say their state governments policies to control the spread of coronavirus are influence A Fair amount by evidence from public health experts ? | GT: 40 | Pred:  The chart shows the percent of US adults who say their state governments' policies to control the spread of coronavirus are influenced by evidence from public health experts.\n",
            "\n",
            "| Percent\n",
            "Sample 266: Q: Is the A Great deal value of the state government more than Federal government ? | GT: Yes | Pred:  Table cells in the chart are separated by tabs, and each row is a new line.\n",
            "\n",
            "Year|State Government|Federal Government\n",
            "---|---|---\n",
            "2\n",
            "Sample 267: Q: What's the highest value of gray bar? | GT: 61 | Pred:  Table cells in a row are seperated by tabs, and different rows are new lines. Table header row is optional and might be missing. Always assume first row\n",
            "Sample 268: Q: What's the median value of the green bars? | GT: 19 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 269: Q: What's the value of the green bar for 65+ age group? | GT: 58 | Pred:  The chart has the following columns: Age group, 2010, 2015, 2020, 202\n",
            "Sample 270: Q: How many values of green bar exceed 30? | GT: 3 | Pred:  Chart cells are separated by newlines, rows are separated by empty lines.\n",
            "Green bar: 10, 20, 30, 4\n",
            "Sample 271: Q: What's the leftmost value of bar in \"All adults\" category? | GT: 48 | Pred:  The chart has the following columns: Category, Bar 1, Bar 2, Bar 3, Bar 4, Bar 5, Bar 6\n",
            "Sample 272: Q: What's the median value of all the bars in rightside? | GT: 50 | Pred:  Do not make up data. Do not say \"insufficient information\" if a reasonable conclusion cannot be drawn. If the question cannot be answered from the chart,\n",
            "Sample 273: Q: What is youtube Trust data? | GT: 17 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Data | Value |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 274: Q: What is the average of all the Trust Data? | GT: 248.83 | Pred:  Table cells in the chart are separated by '|', and rows in the chart are separated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | 1st | 2nd\n",
            "Sample 275: Q: How many consumers feel A lot confident about what they are buying? | GT: 37 | Pred:  Chart cells that are blank are empty. Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| \n",
            "Sample 276: Q: What�s the difference between the maximum and the minimum value in the last bar? | GT: 49 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 277: Q: What color represent Confidence in the bar? | GT: Green | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 278: Q: Which region has the highest value that has No confidence in Mohammad bin Salman? | GT: Israel | Pred:  The chart has the following columns: Region, Value, Confidence.\n",
            "Answer: There is no region listed with \"No confidence\" in Mohammad bin Salman. Therefore,\n",
            "Sample 279: Q: which color shows As in the bar? | GT: gray | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say \"I\n",
            "Sample 280: Q: What is the total of Jordan in More, As, and less? | GT: 99 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I don't know\". Do not say \"Cannot determine\". Do not\n",
            "Sample 281: Q: 46, 43, 41 which data is missed? | GT: 47 | Pred:  46, 43, 41, ?, 37, 35, 33, 31, 29\n",
            "Sample 282: Q: Is the sum of the highest value of navy blue bar and median of light blue bar greater than 100? | GT: No | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "|   | Jan | Feb | Mar | Apr | May | Jun | Jul | Aug | Sep | Oct | Nov\n",
            "Sample 283: Q: What's the percentage of men who have \"Should NOT be made legal\" opinions? | GT: 30 | Pred:  The chart has the following columns: \"Opinion\", \"Women (%)\", \"Men (%)\". The row with \"Should NOT be made legal\" has \"Women\n",
            "Sample 284: Q: Count the number of yellow bars with 30 values? | GT: 3 | Pred:  Do not make up data. Do not say things like 'I don't know' or 'Unable to determine'. If the chart is not provided, respond with\n",
            "Sample 285: Q: What percent of the Labour group shows the economic situation is Bad in Uk? | GT: 60 | Pred:  Do not make up data. Do not say things like \"based on the chart\" or \"from the chart\". Do not say things like \"the percentage is\n",
            "Sample 286: Q: What is the total of Bad and Good in the Remain? | GT: 100 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 287: Q: How many of them say in West Germany that religion is very important in their lives? | GT: 27 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the distribution of responses to the question \"How important is religion in\n",
            "Sample 288: Q: What is the Ration of Somewhat in West Germany and East Germany? | GT: 1.393055556 | Pred:  The chart has the following columns: Country, 1981, 1982, 1983, 1984\n",
            "Sample 289: Q: What's the value of the blue bar in France? | GT: 76 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | 1st | 2nd\n",
            "Sample 290: Q: Is the median of green bars greater than the median of the blue bar? | GT: No | Pred:  The chart shows the number of books read by students in a class in a month. \n",
            "\n",
            "| Color | Number of books |\n",
            "|-------|----------------|\n",
            "| Green\n",
            "Sample 291: Q: What's the maximum value in the brightest yellow bar? | GT: 53 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot tell\". The chart shows the number of students in each grade\n",
            "Sample 292: Q: What's the difference in the value of the total number of persons who want to improve the way government works and who have not? | GT: 33 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot tell\". Do not say \"Not enough information\". Do not\n",
            "Sample 293: Q: How many people in total think Chinese growth is a good thing for the US? | GT: 50 | Pred:  The chart shows the percentage of people in various countries who think Chinese growth is a good thing for the US.\n",
            "\n",
            "- United States: 30%\n",
            "- China\n",
            "Sample 294: Q: What's the average percentage for people between 18-49 who think Chinese growth is a good thing for the US? | GT: 53.5 | Pred:  The chart shows the percentage of people between 18-49 who think Chinese growth is a good thing for the US in 2010,\n",
            "Sample 295: Q: How many rows of data are there | GT: 7 | Pred:  Rows: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n",
            "Sample 296: Q: For all Dem/Lean Dem, what is the difference in opinions between supporting 50s and the oldest age studied as the best age to be a president | GT: 44 | Pred:  The chart shows the percentage of people in each age group who support the idea that the best age to be president is in their 50s. The chart\n",
            "Sample 297: Q: What's the percentage of white who oppose the death penalty for persons convicted of murder? | GT: 34 | Pred:  Chart cells that are blank are empty. Table cells in one row are seperated by '|', and each row is in one line. Table is separated by '\n",
            "Sample 298: Q: What's the ratio of medians of Oppose and Favor bars? | GT: 0.554166667 | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "|  | Oppose | Favor | Total |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "|\n",
            "Sample 299: Q: What's the percentage value of the blue bar in Greece? | GT: 87 | Pred:  The chart shows the percentage of the population in each country that is under the age of 25. Greece has a blue bar with a value of 1\n",
            "Sample 300: Q: Is the median of the green bar greater than the largest value of the gray bar? | GT: Yes | Pred:  The chart has two bars: a green bar and a gray bar. The green bar has a value of 30, and the gray bar has a value\n",
            "Sample 301: Q: What's the percentage of adults who are not concerned about identity theft? | GT: 16 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 302: Q: What's the sum of all the gray bars whose value exceeds 15? | GT: 72 | Pred:  Do not make up data. Do not say things like 'The chart shows' or 'Based on the chart'. Do not say things like 'I don't\n",
            "Sample 303: Q: Which color represents Republican? | GT: Red | Pred:  Do not make up information.\n",
            "\n",
            "Answer: Red. \n",
            "\n",
            "Question: Which color represents Republican?\n",
            "Answer: Red. \n",
            "\n",
            "Question: Which color represents Republican?\n",
            "Answer:\n",
            "Sample 304: Q: What is the total of Republicans and Democrats in 2010? | GT: 87 | Pred:  Chart cells that are blank are empty.\n",
            "Chart:\n",
            "| Year | Republicans | Democrats | Total |\n",
            "|------|-------------|-----------|-------|\n",
            "| 20\n",
            "Sample 305: Q: What's the lowest value of Mostly good bars? | GT: 21 | Pred:  Avoid making up information. If information is not available in the chart, respond with \"Insufficient information\".\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Insufficient informationHuman\n",
            "Sample 306: Q: What's the median of all the right-side bars? | GT: 35 | Pred:  Do not make up data. Do not say \"insufficient information\" if an answer can be derived from the chart. If the question is unanswerable,\n",
            "Sample 307: Q: What's the NET value of the All Teens bar? | GT: 57 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Chart: 1. All Teens bar: 1\n",
            "Sample 308: Q: How many bars have a Very worried value is greater than its Somewhat Worried value? | GT: 1 | Pred:  The chart has the following columns: Bars, Very Worried, Somewhat Worried, Mildly Worried, Not Worried. Bars: A, B\n",
            "Sample 309: Q: How much does Italy's government's responsibility had the highest percentage? | GT: 0.74 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Chart title: Italy's government's responsibility for the cost of healthcare\n",
            "Italy's government's\n",
            "Sample 310: Q: What is the difference between the government's responsibility of Sweden to the UK? | GT: 0.04 | Pred:  Do not make up information. Do not say things like \"based on the chart\" or \"as shown in the chart\". Do not say things like \"the\n",
            "Sample 311: Q: What's the value of the 1st Longest bar in the graph? | GT: 25 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 312: Q: What's the total sum of immigrants of South and West? | GT: 8 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 313: Q: What does the Dark blue bar represent? | GT: A great deal | Pred:  Do not use abbreviations. Do not say I don't know. Do not say based on the chart. Do not say from the chart. Do not say\n",
            "Sample 314: Q: Is the sum of all values of \"None at all\" is greater than the largest value of the dark blue bar? | GT: No | Pred:  Do not make up data. Do not say anything like \"Based on the chart...\" or \"From the chart...\".\n",
            "\n",
            "No\n",
            "\n",
            "Question: Is the sum of\n",
            "Sample 315: Q: Which county plays the least important role in the world than it did 10 years ago? | GT: UK | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 316: Q: What is the sum of the least and highest value in the graph? | GT: 0.91 | Pred:  Do not make up data. Do not say things like 'The chart shows...' or 'Based on the chart...'. Do not say things like 'I cannot\n",
            "Sample 317: Q: How many colors are shown in the graph? | GT: 4 | Pred:   Question: How many colors are shown in the graph?\n",
            "Answer: 4\n",
            "\n",
            "Question: How many colors are shown in the graph?\n",
            "Answer: 4\n",
            "Sample 318: Q: Is the Very value in All voters more than Somewhat in All voters? | GT: No | Pred:  Chart cells that are blank are empty. Table cells in one row are seperated by '|', and rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "|  |\n",
            "Sample 319: Q: What's the color of the Rightmost bar? | GT: Green | Pred:  Each row in the table represents a bar in a bar chart. The first column is the category, the second column is the value, and the third column is\n",
            "Sample 320: Q: Is the add-up the value of all Green segments is greater than the sum of all Dark blue segments? | GT: Yes | Pred:  Table cells in a row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Segment | Value |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 321: Q: Is the color of the middle bars gray? | GT: Yes | Pred:  Table cells in a row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Bar | Color |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 322: Q: Is the median of green bars greater than the largest value of the gray bar? | GT: No | Pred:  The chart shows the number of students in different grade levels in a school. \n",
            "\n",
            "| Grade | Number of Students |\n",
            "|-------|--------------------|\n",
            "| 9th\n",
            "Sample 323: Q: What percent of White believes that race or ethnicity should be a major factor in college admission decisions? | GT: 4 | Pred:  The chart shows the percentage of respondents who believe that race or ethnicity should be a major factor in college admission decisions. \n",
            "\n",
            "| Group | Percentage |\n",
            "|------|\n",
            "Sample 324: Q: How many shades of Green does a bar show? | GT: 2 | Pred:  Each cell in the chart contains a number. The first row contains the names of categories. The first column contains the names of subcategories. Each cell's value\n",
            "Sample 325: Q: In the chart, Too little 69 percentage refers to? | GT: Protect water quality of lakes, rivers, streams | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 326: Q: As per the study, if you ask 500 people,� how many will say Protect air quality- too little and Too much? | GT: 360 | Pred:  Do not make up data. Do not say \"Insufficient data to determine\". Do not say \"I can't answer that\". Do not say \"Not enough\n",
            "Sample 327: Q: What's the value of the rightmost bar in the middle? | GT: 50 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "|  | A | B | C | D\n",
            "Sample 328: Q: What's the ratio of two bars in the middle (A: B)? | GT: 0.042361111 | Pred:  Chart cells are separated by tabs, rows are new lines.\n",
            "\n",
            "Bar A\tBar B\n",
            "10\t15\n",
            "Answer:\n",
            "2:3Human:\n",
            "Sample 329: Q: What is the average between men and women? | GT: 67.5 | Pred:  Chart cells that are blank are empty. Table cells in the first row are headers, the first column are headers for the columns. Table:\n",
            "|  | \n",
            "Sample 330: Q: What is the average of everyone who is winning more than they are losing? | GT: 30.4 | Pred:  Chart: None\n",
            "Answer: Cannot determine from the given information. The chart is missing, and there is no data provided to calculate the average of people who are\n",
            "Sample 331: Q: How many % of respondents from Mexico have confidence in President Trump? | GT: 5 | Pred:  Chart cells that are blank are empty. The chart has the following rows and columns: Index, Mexico, United States, Canada, United Kingdom, Germany, France\n",
            "Sample 332: Q: What is the ratio of people who have confidence in President Trump and those who don't in Venezuela? | GT: 0.884722222 | Pred:  Chart cells that are blank are empty. The chart is as follows:  +----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------+\n",
            "Sample 333: Q: What percent of High school or less says the country Has been about right when it comes to giving women equal rights with men? | GT: 46 | Pred:  Chart cells that are blank are empty. Table cells in the chart are separated by '|', and rows in the chart are separated by '\n",
            "'.\n",
            "\n",
            "Chart:\n",
            "| \n",
            "Sample 334: Q: Is the sum of Bachelors more than the sum of Women? | GT: Yes | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Category | 2010 | \n",
            "Sample 335: Q: Who says Good more to the question? | GT: General public | Pred:  If the information is not in the chart, say \"Not in chart\".\n",
            "\n",
            "Chart:\n",
            "| Question | Answer |\n",
            "| --- | --- |\n",
            "| What is the capital\n",
            "Sample 336: Q: How many times good is more than bad in General Public? | GT: 2.62 | Pred:  Table cells in the chart are separated by '|', and rows in the chart are separated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Question | Answer |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 337: Q: In which country, 16% of human rights organizations are primarily dedicated to promoting the interest of foreign groups? | GT: Kenya | Pred:  Each row in the chart represents a country. Each column in the chart represents a different attribute of the country. The first column is the country name. The remaining\n",
            "Sample 338: Q: Take the median of orange bars, multiply it by 3, is the result greater than the smallest value of the green bar? | GT: No | Pred:  The chart has the following data:\n",
            "|   | A | B | C | D | E | F |\n",
            "|---|---|---|---|---\n",
            "Sample 339: Q: How many colors are in the bar?? | GT: 3 | Pred:  Each cell in the table contains a number. The numbers represent the number of items of a certain color in a bar. For example, if a cell has the\n",
            "Sample 340: Q: What is the total distribution of adversary and serious problems?? | GT: 65 | Pred:  Each cell in the chart is a single number. The chart has the following columns: \"Adversary\", \"Serious Problems\", \"Total\". The rows\n",
            "Sample 341: Q: What's the value of the top rightmost bar? | GT: 7 | Pred:  Do not make up data. Do not say \"insufficient information\". \n",
            "\n",
            "Bar chart: \n",
            "|  | A | B | C | D | E |\n",
            "\n",
            "Sample 342: Q: What's the ratio of the smallest Gen X bar and second smallest Silent/Greatest bar? | GT: 1.00625 | Pred:  Assume all values are in millions. \n",
            "\n",
            "Gen X Bar: 12, 14, 16, 18, 20  \n",
            "\n",
            "Sample 343: Q: What's the percentage of U.S. adults who oppose more fracking? | GT: 53 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "The chart shows the percentage\n",
            "Sample 344: Q: Take the sum of the two smallest green bars, is it greater than the smallest blue bar? | GT: No | Pred:  Do not make up data. Do not say \"Insufficient data\". The following chart is provided: \n",
            "|   | A | B | C | D |\n",
            "Sample 345: Q: What's the value of the rightmost first bar from the bottom? | GT: 8 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "|  | A | B | C | D\n",
            "Sample 346: Q: What's the average of all the uppermost bars (round to one decimal place)? | GT: 32.7 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The average is\". Do not say \"It is\". Do\n",
            "Sample 347: Q: What input situation is represented by the biggest bar | GT: Click on links to news stories | Pred:  Do not make up data. Do not say things like 'based on the chart' or 'from the chart'. Do not say things like 'the biggest bar\n",
            "Sample 348: Q: What is the sum of the median often opinion and the biggest net opinion | GT: 88 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot determine\". Do not\n",
            "Sample 349: Q: What represents the two bars in the chart?? | GT: [Oppose, Favor] | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The two bars represent...\". Do not say \"The two\n",
            "Sample 350: Q: What is the ratio between oppose and favor distribution for a ban on high-capacity ammunition clips?? | GT: 1.993055556 | Pred:  Do not make up data. Do not say things like 'based on the chart' or 'as shown in the chart'. Do not say things like 'the\n",
            "Sample 351: Q: What is the value of Very opinion in Aug 2016? | GT: 49 | Pred:  Avoid making up data or inferences. If information is not available in the chart, respond with \"Insufficient data\".\n",
            "\n",
            "Chart cells that contain data are filled with\n",
            "Sample 352: Q: What's the ratio of the largest bar and the sum of the two smallest bars? | GT: 2.588888889 | Pred:  The chart has the following data: \n",
            "Bar 1: 20\n",
            "Bar 2: 30\n",
            "Bar 3: 40\n",
            "\n",
            "Sample 353: Q: What's the value of the largest bar in Total? | GT: 53 | Pred:  Table cells in a row are seperated by tabs, and different rows are new lines. Assume the header row is not part of the data. Table:\n",
            "|\n",
            "Sample 354: Q: How many bars have a value below 40? | GT: 6 | Pred:  The chart shows the number of bars with a value below 40.\n",
            "\n",
            "| Bars | Value |\n",
            "|------|-------|\n",
            "| 1    | 3\n",
            "Sample 355: Q: What's the percentage of the total population that favors weakening the EU? | GT: 65 | Pred:  Do not make up data. If the chart does not contain the necessary information, respond with \"Cannot be determined\".% of total population that favors weakening the EU\n",
            "Sample 356: Q: What are the top three groups that favor weakening the EU? | GT: [50+, Men, Secondary education or less] | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot answer that question\n",
            "Sample 357: Q: What's the percentage of Black saying it is very important that their children earn a college degree? | GT: 17 | Pred:  Do not make up data. Do not say anything like \"according to the chart\" or \"as shown in the chart\". Do not say that the data is\n",
            "Sample 358: Q: Take \"Extremely important\" bar median and \"Very important\" bar median, divide larger value by smaller value, what's the result(only integer value)? | GT: 1 | Pred:  The chart is as follows: \n",
            "Bar 1: Extremely important - 10, Very important - 8  \n",
            "Bar 2: Extremely important - \n",
            "Sample 359: Q: How many colors are represented in the bar?? | GT: 3 | Pred:  The bar chart shows the number of students in a class who like different colors. The colors are: red, blue, green, yellow, and purple. The\n",
            "Sample 360: Q: What's the average of the two smallest green bar?? | GT: 0.5 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"From the chart...\". Do not say \"According to the\n",
            "Sample 361: Q: How many categories are there in the chart?? | GT: 8 | Pred:  Each row in the chart represents a different category. Count the number of rows in the chart to determine the number of categories.\n",
            "\n",
            "Table cells in each row are separated\n",
            "Sample 362: Q: What's the average of the two smallest bar?? | GT: 38.5 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The average is\". Do not say \"The two smallest bars\n",
            "Sample 363: Q: Which two country is compared here? | GT: [Czech Republic, New Zealand] | Pred:  Do not make things up. Do not say that the information is not available. Do not say that the question can't be answered. Do not say \"I\n",
            "Sample 364: Q: How many times  New Zealand greater than Czech Republic? | GT: 3.0659 | Pred:  Assume all values are in millions. \n",
            "\n",
            "Czech Republic: 10.3  \n",
            "New Zealand: 4.7  \n",
            "Answer:\n",
            "New Zealand is not\n",
            "Sample 365: Q: Which country is represented by longest bar? | GT: Japan | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The chart is: \n",
            "Sample 366: Q: What's the total add up value of japan and Colombia? | GT: 51.7 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 367: Q: Which country has the largest bar? | GT: Denmark | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot determine\". Do\n",
            "Sample 368: Q: How many countries have over 4 broad money? | GT: 2 | Pred:  Each row in the chart represents a country, and each column represents a different metric. The first column is the country name. The rest of the columns are metrics\n",
            "Sample 369: Q: What is the value Exports in Hungary? | GT: 4.5 | Pred:  The chart has the following columns: Country, Exports, Imports, Trade Balance. The row for Hungary has the following values: Country: Hungary, Exports\n",
            "Sample 370: Q: Is the average value of these two bars greater than 3? | GT: No | Pred:  Do not make up data. Do not say \"insufficient information\". The chart shows the number of students in each grade at Lincoln High School. \n",
            "\n",
            "Grade |\n",
            "Sample 371: Q: How many colors are represented in the bar? | GT: 2 | Pred:  The bar chart shows the number of students in a class who like different colors. The colors are: red, blue, green, yellow, and purple. The\n",
            "Sample 372: Q: What's the average of two smallest bar? | GT: 40.9 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Month | Jan | Feb | Mar | Apr\n",
            "Sample 373: Q: Which country represented by Blue bar? | GT: Romania | Pred:  Do not make up information. Do not say things like 'Based on the chart...'. Just answer the question. Do not make up information. Do not say\n",
            "Sample 374: Q: What is the average of all the three bars? | GT: 8.3 | Pred:  Bars: 2, 4, 6\n",
            "\n",
            "The average of all the three bars is 4. 4Human: What is the average of\n",
            "Sample 375: Q: What's the color of smallest bar? | GT: Red | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say \"I\n",
            "Sample 376: Q: What is the average value of both the bars? | GT: 6.3 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot tell\". Do not say \"Not enough information\". Do not\n",
            "Sample 377: Q: What is the color of the highest bar? | GT: green | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: What is the color of the highest bar?\n",
            "Sample 378: Q: What is the difference in Inward FDI stocks between Spain and Poland? | GT: 0.42 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the following data: Spain: 120 billion, Poland\n",
            "Sample 379: Q: What's the value of blue bar? | GT: 29 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Table cells in the same row are separated by '|', and each row is in\n",
            "Sample 380: Q: What's the add up value of Australia and France? | GT: 40.6 | Pred:  Do not make up data. Do not say \"insufficient information\". Do not say \"I can't answer that\". Do not say \"not enough information\".\n",
            "Sample 381: Q: How many color bars are there in the Graph? | GT: 3 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 382: Q: Is the difference of value of Austria and Ireland bar is greater then the value of United States bar? | GT: No | Pred:  The chart has the following columns: country, 2010, 2011, 2012, 2013\n",
            "Sample 383: Q: What color represent Norway? | GT: purple | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in the chart\".\n",
            "\n",
            "Chart: \n",
            "| Country | Color |\n",
            "|\n",
            "Sample 384: Q: How many countries have long term interest rates over 5 percent? | GT: 3 | Pred:  The chart has the following columns: Country, Long Term Interest Rate (%), Short Term Interest Rate (%), Inflation Rate (%), GDP Growth Rate (%), Un\n",
            "Sample 385: Q: Which country is represented by RED bar? | GT: Austria | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The answer must be one\n",
            "Sample 386: Q: Does the difference in the value of largest two bars is half the value of smallest bar? | GT: No | Pred:  If the information is not available in the chart, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: \n",
            "|   | Jan | Feb | Mar | Apr | May\n",
            "Sample 387: Q: What is the color of the lowest value in the graph? | GT: Blue | Pred:  Do not make up information. Do not say I cannot answer that question. Do not say the chart is missing. The chart is available. Question: What is\n",
            "Sample 388: Q: What is the difference in the value of China and Tanzania? | GT: 0.4 | Pred:  The chart has the following columns: Country, GDP (in USD), Population (in millions), GDP per capita (in USD). China has a GDP of \n",
            "Sample 389: Q: How many color are shown in the chart? | GT: 4 | Pred:  Chart: 1 2 3 4 5 6 7 8 9 10 11 12 13\n",
            "Sample 390: Q: Is the difference value of DAC Countries is more then Sweden? | GT: Yes | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "?  \n",
            "?  \n",
            "?  \n",
            "?\n",
            "Sample 391: Q: What does the red bar represent? | GT: Russia | Pred:  Do not make up information. Do not say I cannot answer the question or I don't know. If the chart is not provided, say \"Chart not provided\n",
            "Sample 392: Q: What's the difference between two bars? | GT: 0.044 | Pred:  The chart has the following columns: Date, Open, High, Low, Close, Volume. \n",
            "Date: 2023-04-0\n",
            "Sample 393: Q: Which country has the highest value of Reading performance? | GT: Finland | Pred:  The chart shows the average reading performance of students in different countries in the PISA 2018 assessment.\n",
            "Answer: The country with the highest value of\n",
            "Sample 394: Q: Is the median value of all bars greater than 500? | GT: No | Pred:  The chart shows the following data: \n",
            "Bar 1: 300\n",
            "Bar 2: 400\n",
            "Bar 3: 5\n",
            "Sample 395: Q: What is the Real GDP long-term forecast for Poland? | GT: 1.26M | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Real GDP long-term forecast for Poland\n",
            "Sample 396: Q: Is the average of the two bar values as shown in the graph greater than 1? | GT: No | Pred:  Do not make up data. Do not say \"Insufficient data\". The following chart shows the bar values: 1.2, 1.4,\n",
            "Sample 397: Q: Is there any value 50.2 in this graph? | GT: Yes | Pred:  If the value is not present, answer with 'No'.\n",
            "Graph: {\"data\": [{\"x\": \"A\", \"y\": 10}, {\"x\n",
            "Sample 398: Q: Is the median value of all the bars greater than 50.2? | GT: No | Pred:  The chart shows the following data: \n",
            "Bar 1: 49.8  \n",
            "Bar 2: 50.1  \n",
            "Bar 3:\n",
            "Sample 399: Q: Which country has the highest interest rate? | GT: Korea | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the highest interest rate is...\". The answer\n",
            "Sample 400: Q: How many countries fall below 6%? | GT: 2 | Pred:  The chart has the following columns: Country, GDP per capita (PPP), GDP per capita (nominal), GDP per capita (PPP) rank, GDP per\n",
            "Sample 401: Q: Which is the top place in the chart? | GT: School | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"The top place is...\"\n",
            "Sample 402: Q: How many places in the chart have over 50% value? | GT: 3 | Pred:  Chart cells are separated by a new line, columns are separated by a tab. Cell (row, col) has value chart[row][col]. Row 0\n",
            "Sample 403: Q: What does the yellow bar represent? | GT: Distrust | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The yellow bar represents...\". Do not say \"The yellow\n",
            "Sample 404: Q: What is the difference between maximum and minimum values of trust and distrust respectively? | GT: 41 | Pred:  Do not make up data. Do not say things like \"based on the chart\" or \"as shown in the chart\". Do not say things like \"the\n",
            "Sample 405: Q: What % of UK residents believe in the use of force to defend Allies in case they are attacked by Russia? | GT: 0.49 | Pred:  Do not make up data. Do not say things like \"based on the chart\" or \"as shown in the chart\". Do not say \"I cannot answer\n",
            "Sample 406: Q: In how many countries do more than 45% of the respondents believe that their country should defend allies in case they are attacked by Russia? | GT: 6 | Pred:  The chart shows the percentage of respondents in various countries who believe that their country should defend allies in case they are attacked by Russia.\n",
            "Answer: 3 countries.\n",
            "Sample 407: Q: How many support Euro in Spain? | GT: 0.71 | Pred:  Each row in the chart represents a different country. The chart has the following columns: Country, Population, GDP (in USD), GDP per capita (in USD\n",
            "Sample 408: Q: What is the difference in the support of Euro between Spain and Italy? | GT: 0.15 | Pred:  The chart has the following columns: Country, 2010, 2011, 2012, 2013\n",
            "Sample 409: Q: What is Republican data in Feb 2015 for mostly good? | GT: [12,63,23] | Pred:  Avoid making things up. If information is not available in the chart, say so.\n",
            "\n",
            "Table cells in the chart are separated by tabs, and each row in the\n",
            "Sample 410: Q: What is the ratio between  Mostly good and Mostly bad in Democrat Feb 2015? | GT: 3.22222 | Pred:  Avoid making things up. If something isn't in the table, say so.\n",
            "\n",
            "Table cells in a single row are seperated by '|', and different rows are\n",
            "Sample 411: Q: What is total personal remittances paid by India (in million dollar)? | GT: 350.83 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 412: Q: Is the sum of two smallest bar greater than largest bar? | GT: No | Pred:  If the information is not present in the chart, respond with \"Cannot be determined\".\n",
            "\n",
            "bar: 3, 5, 7, 9, \n",
            "Sample 413: Q: Which country is represented by brown color bar? | GT: Cameroon | Pred:  The chart has the following data:\n",
            "| Country | Color |\n",
            "| --- | --- |\n",
            "| Australia | Blue |\n",
            "| Brazil | Brown |\n",
            "| Canada | Green |\n",
            "\n",
            "Sample 414: Q: What is the average of coffee yields by Congo and Cameroon? | GT: 0.51 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Chart title: Coffee Yield by Country (in metric tons) \n",
            "Congo|Cameroon\n",
            "Sample 415: Q: What is the projected number of children per women in the Fast Track scenario? | GT: 1.92 | Pred:  The chart is as follows:  | Scenario | 1990 | 2000 | 2010 | 202\n",
            "Sample 416: Q: What is the sum in the the projected number of children per women in all scenarios? | GT: 6.33 | Pred:  The chart shows the projected number of children per woman in various scenarios for different years.\n",
            "\n",
            "| Year | Scenario 1 | Scenario 2 | Scenario 3 |\n",
            "Sample 417: Q: What country has the highest share that disagree that vaccines are important? | GT: Namibia | Pred:  Each row in the chart represents a country. Each column in the chart represents a different year. Each cell in the chart contains a percentage of people in that country\n",
            "Sample 418: Q: What is the average among the two contries in the share that disagree that vaccines are important? | GT: 1.105 | Pred:  The chart has the following columns: Country, Share that agree vaccines are important, Share that disagree vaccines are important. \n",
            "\n",
            "Country | Share that agree vaccines are important\n",
            "Sample 419: Q: What country have the loewst suicide rate? | GT: Niger | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: 1.\n",
            "Sample 420: Q: Is the suicide rate in Ukraine higer then the sum of the other four countries? | GT: No | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "Country | Suicide rate (per \n",
            "Sample 421: Q: Which country has the largest bar? | GT: Nepal | Pred:  The chart shows the number of bars per 100,000 people in different countries.\n",
            "\n",
            "| Country | Bars per 100,0\n",
            "Sample 422: Q: Is the sum of Australasia and Switzerland larger than Nepal? | GT: No | Pred:  If the information is not available in the chart, respond with \"Insufficient information\".\n",
            "\n",
            "Chart cells are separated by tab, with row and column headers at the top\n",
            "Sample 423: Q: How many color bar are shown the graph? | GT: 5 | Pred:   Question: How many color bars are shown in the graph?  Chart: 100% 90% 80% 70\n",
            "Sample 424: Q: What is the total value of two least bar? | GT: 20.34 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Item | Price |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 425: Q: Which price is represented by brown color bar? | GT: Northwest Europe marker price | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 426: Q: What is the average price of Japan coking coal import cif and Japan steam spot cif? | GT: 177.625 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average price of Japan coking coal\n",
            "Sample 427: Q: What is red line represents? | GT: Germany | Pred:  Table cells in a row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Type of line | Description |\n",
            "| --- |\n",
            "Sample 428: Q: Which country data shows a down trend? | GT: United States | Pred:  Do not make up data or statistics.\n",
            "\n",
            "The chart shows the number of people in the United States, Canada, and the United Kingdom who own a smartphone. The\n",
            "Sample 429: Q: In which year the percentage of daily smokers peaked in Luxembourg? | GT: 2019 | Pred:  The chart shows the percentage of daily smokers in Luxembourg from 1980 to 2010.\n",
            "Answer: 1980. The\n",
            "Sample 430: Q: In which year, the percentage of daily smokers in Luxembourg is greater than Ireland? | GT: 2019 | Pred:  The chart shows the percentage of daily smokers in various countries in 2000 and 2010.\n",
            "Answer: 2010.\n",
            "Sample 431: Q: Which country is represented by blue color line? | GT: Belgium | Pred:  Chart cells are separated by tabs, rows are new lines. Chart:\n",
            "Country|2010|2011|2012|2\n",
            "Sample 432: Q: How many countries have more than 40k enterprises over the given years? | GT: 2 | Pred:  The chart shows the number of enterprises (in thousands) in different countries over the years 2010 to 2015.\n",
            "\n",
            "Answer: \n",
            "Sample 433: Q: How many countries are shown in the chart? | GT: 2 | Pred:  Chart: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10\n",
            "Sample 434: Q: When does the gap between two countries become biggest? | GT: 2012 | Pred:  Do not make up data. Do not say things like 'Based on the chart...'. Just answer the question.\n",
            "\n",
            "The gap between two countries becomes biggest when the\n",
            "Sample 435: Q: Which two countries are being compared in the given graph? | GT: [Argentina, Indonesia] | Pred:  The chart is as follows:  \\begin{center} \\begin{tabular}{|c|c|c|c|c|} \\h\n",
            "Sample 436: Q: Which year recorded the highest fertility rate in Indonesia? | GT: 1976 | Pred:  Make up a chart if the actual chart is not provided.\n",
            "\n",
            "Year | Fertility Rate (children per woman)\n",
            "--- | ---\n",
            "1960 | 6\n",
            "Sample 437: Q: Which country is represented by blue color line? | GT: Estonia | Pred:  The chart is as follows:  | Country | 2010 | 2011 | 2012 | 201\n",
            "Sample 438: Q: Which country has highest government production costs over the given years? | GT: France | Pred:  Chart cells are separated by new lines, columns are separated by tabs. The first row of the chart is the header row.\n",
            "Year\\tCountry\\tProduction Cost (\n",
            "Sample 439: Q: Which country is in middle of Canad and Slovenia? | GT: United States | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 440: Q: Is the median value of Slovenia data points greater than 40? | GT: Yes | Pred:  Assume missing values are not present in the dataset. Do not make up data or conclusions. If the chart does not contain sufficient information to answer the question, respond\n",
            "Sample 441: Q: Which country has the lowest household net worth over the years? | GT: Estonia | Pred:  The chart shows the average household net worth in the United States, United Kingdom, Germany, and Japan from 2000 to 2010\n",
            "Sample 442: Q: In which year the value of red line is smaller than blue line? | GT: 2009 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 443: Q: Is Austria represented by purple dotted line? | GT: Yes | Pred:  Make sure to identify if the answer is supported or not. Answer according to the chart. If the chart does not contain enough information, answer \"Not supported\".\n",
            "\n",
            "\n",
            "Sample 444: Q: Which country recorded smallest labour productivity value over the years? | GT: Slovenia | Pred:  Make up a chart if the given information is insufficient.\n",
            "\n",
            "Chart:\n",
            "| Year | Country A | Country B | Country C | Country D |\n",
            "|------|-----------\n",
            "Sample 445: Q: In which country has the highest peak in this bar graph? | GT: Switzerland | Pred:  Do not make up information. Do not say I cannot answer this question. The chart is not provided.\n",
            "\n",
            "\\boxed{Unknown} The chart is not provided,\n",
            "Sample 446: Q: What is the difference between the highest value and lowest value of switzerland? | GT: 4 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart does not exist.\n",
            "\n",
            "The difference between the highest value and lowest value of\n",
            "Sample 447: Q: What country have the lowest value in national insurance market share? | GT: Iceland | Pred:  The chart shows the national insurance market share for different countries. The country with the lowest value in national insurance market share is France. France. France. France.\n",
            "Sample 448: Q: Between what years Netherlands had the highest change in the value of national insurance market share? | GT: 2015 | Pred:  The chart shows the value of the national insurance market share in the Netherlands from 2000 to 2010. The data points are as\n",
            "Sample 449: Q: Which country is represented by the given line graph? | GT: Canada | Pred:  Do not make things up. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 450: Q: Which year recorded the lowest net childcare costs in Canada? | GT: 2019 | Pred:  2010 2011 2012 2013 2014 2015 2\n",
            "Sample 451: Q: In what year Poland achieved the highest value in pension funds' assets? | GT: 2013 | Pred:  The chart shows the value of pension funds' assets in Poland from 1995 to 2005.\n",
            "\n",
            "1995: 1\n",
            "Sample 452: Q: In what year Belgium passed Poland in the value of pension funds' assets? | GT: 2019 | Pred:  Chart cells that are blank are empty. The chart has the following columns: Year, Belgium, Poland. The chart has the following rows: 200\n",
            "Sample 453: Q: Which country does the blue line represent? | GT: Canada | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Question: Which country does the blue line represent? Answer\n",
            "Sample 454: Q: When does the gap between Poland and Denmark become smallest? | GT: 2017 | Pred:  The chart has the following columns: Year, Poland, Denmark. The chart data is: Year, Poland, Denmark 1980, 10\n",
            "Sample 455: Q: Which country shows highest rise in the Short term interest rates from 1995 to 2000? | GT: Brazil | Pred:   Chart: 1995-2000 Short Term Interest Rates: 1995-2000 Short Term Interest Rates\n",
            "Sample 456: Q: Which four countries data is compared in this graph? | GT: [Brazil, Slovenia, Switzerland, Japan] | Pred:  Do not make up data or information. Do not say things like 'Based on the chart...' or 'From the chart we can see...'. Do not say\n",
            "Sample 457: Q: Which country is represented by blue color line? | GT: New Zealand | Pred:  Do not make up information. Do not say things like 'Based on the chart...'. Just give the answer. Blue\n",
            "\n",
            "**Final Answer:** BlueHuman\n",
            "Sample 458: Q: Between which two years , the GDP of New Zealand is maximum? | GT: 2009 | Pred:  Do not make up data or statistics. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "New Zealand GDP\n",
            "Sample 459: Q: Which country is represented by blue color line? | GT: France | Pred:  Make sure to use the exact words from the question in your response. Which country is represented by blue color line?\n",
            "\n",
            "Answer: The country represented by the blue color\n",
            "Sample 460: Q: At how much points does lines representing Australia and France crosses each other? | GT: 1 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The lines cross at...\". Do not say \"The lines\n",
            "Sample 461: Q: Which country does the red line refer to? | GT: Poland | Pred:  Do not make up information. Do not say anything like \"Based on the chart...\" or \"From the chart we can see...\".\n",
            "\n",
            "United States\n",
            "Canada\n",
            "\n",
            "Sample 462: Q: When does the difference between two countries become largest? | GT: 2019 | Pred:  Do not make up data. Do not say things like \"As shown in the chart...\" or \"Based on the information in the chart...\".\n",
            "\n",
            "The difference between\n",
            "Sample 463: Q: Which country does the red line represent? | GT: Netherlands | Pred:  The chart has the following columns: Country, 2010, 2011, 2012, 2013\n",
            "Sample 464: Q: During which time did tourism receipts and spending in Netherlands decline? | GT: 2014 | Pred:  Do not make up data points or trends. If the information is not available in the chart, say so.\n",
            "\n",
            "Answer: There is no chart provided to determine the\n",
            "Sample 465: Q: Who has the most oscars out of the the actors listed | GT: Katharine Hepburn | Pred:  Do not make up data. If the data is not present in the chart, respond with \"Data not available\". \n",
            "\n",
            "| Actor | Oscars |\n",
            "|-------|\n",
            "Sample 466: Q: How many oscars do jack nicolson and meryl streep have combined? | GT: 6 | Pred:  Do not make up information. If the information is not in the chart, say \"Insufficient information\".\n",
            "\n",
            "Chart Cells:\n",
            "[0] Jack Nicholson\n",
            "[1\n",
            "Sample 467: Q: How many distribution are there in the pie chart? | GT: 8 | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". Do not\n",
            "Sample 468: Q: Take highest percentage and lowest percentage (leave 0), add it and divide it by 2, what is the result? | GT: 17.5 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"Final Answer\". Do\n",
            "Sample 469: Q: What is very important percentage? | GT: 12 | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"According to the chart...\". The chart is: 1.\n",
            "Sample 470: Q: Assume total respondent as 1000, what is the sum of person will tell 'very Important' and 'important'? | GT: 620 | Pred:  The chart is as follows: \n",
            "| Question | Very Important | Important | Not Important | Not at all Important |\n",
            "| --- | --- | --- | --- |\n",
            "Sample 471: Q: Find out , who is referred in blue? | GT: 620 | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"It is\". Do\n",
            "Sample 472: Q: What percentage we get , if we add red and grey color? | GT: 27 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available\".\n",
            "\n",
            "Chart content: None\n",
            "Final Answer: Data not\n",
            "Sample 473: Q: Which country has the highest distribution of coal export in 2018? | GT: Indonesia | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the highest distribution of coal export in 2\n",
            "Sample 474: Q: What is the sum total percentage of Canada and U.S country in 2018? | GT: 10 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "100%Question: What is\n",
            "Sample 475: Q: Pizza Hut : 765 ,  KFC : ?    ? | GT: 181 | Pred:   The chart is as follows:  Pizza Hut : 765 ,  KFC : 764 ,  McDonald's : 76\n",
            "Sample 476: Q: What is the ratio between KFC vs Taco Bell? | GT: 2.623 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Insufficient data\".\n",
            "\n",
            "Chart: None\n",
            "Answer\n",
            "Sample 477: Q: What's the percentage market share of NEXANS for offshore wind farms in Europe in 2020? | GT: 27 | Pred:  You may say \"Unknown\" if the information is not available in the chart.\n",
            "\n",
            "100%  \n",
            "90%  \n",
            "80%  \n",
            "70%\n",
            "Sample 478: Q: Are the sum of NSW Technology and TFK Group segment greater than 50%? | GT: Yes | Pred:  Assume all values are in percentage.\n",
            "\n",
            "Yes\n",
            "No\n",
            "\n",
            "Based on the provided chart, the sum of NSW Technology and TFK Group segments is 45%.\n",
            "Sample 479: Q: What color represents Asia? | GT: Gray | Pred:  Do not make up information. If the chart is not provided, say \"Chart not provided.\"\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Chart not provided.Human:\n",
            "Sample 480: Q: What's the sum of percentage value of top two markets? | GT: 71 | Pred:  Do not make up data. Do not say \"Insufficient data\". The following chart is described in text: The chart shows the market share of different countries in\n",
            "Sample 481: Q: Is the graph increasing or decreasing? | GT: Increasing | Pred:  \n",
            "\n",
            "Chart:\n",
            "| x | y |\n",
            "|---|---|\n",
            "| 0 | 3 |\n",
            "| 1 | 2 |\n",
            "| 2 | \n",
            "Sample 482: Q: In How many days, COVID rose to 1022? | GT: 7 | Pred:  Table cells in the chart are separated by tabs, and each row is a new line.\n",
            "\n",
            "date|confirmed|deaths|recovered\n",
            "---|---|\n",
            "Sample 483: Q: In which year the ratio of government expenditure to gross domestic product peak? | GT: 2020 | Pred:  Assume the chart is provided and visible.\n",
            "\n",
            "1960\n",
            "1970\n",
            "1980\n",
            "1990\n",
            "2000\n",
            "Sample 484: Q: What is the average for the last 4 years? | GT: 19.79 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: | Year | Value |\n",
            "| ---\n",
            "Sample 485: Q: Which Sales share of Crocs worldwide in 2020 is highest? | GT: Wholesale | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Sales share of Crocs worldwide in 2\n",
            "Sample 486: Q: How much percentage is the Retail sales? | GT: 24.1 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 487: Q: What's the percentage share of Ladies in Ross Stores sales in the U.S. in 2020? | GT: 23 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 488: Q: Is the sum of yellow and green segment greater than Ladies segment? | GT: No | Pred:  If the information is not available in the chart, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: \n",
            "| Segment | Value |\n",
            "|--------|-------|\n",
            "| Yellow\n",
            "Sample 489: Q: Which product has least percentage? | GT: Watches | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 490: Q: What is the difference between the two products? | GT: 64 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "| Feature | Product A | Product B |\n",
            "| --- |\n",
            "Sample 491: Q: What is the color of smallest segment? | GT: Green | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"Final Answer\". Do\n",
            "Sample 492: Q: What's the result after dividing gray segment with the smallest segment? | GT: 2.47 | Pred:  The chart is as follows: | segment | length | color |  |  |  |  |  |  |  |  |  | \n",
            "Sample 493: Q: How many troughs are there in the data line? | GT: 4 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: How many troughs are there in the data\n",
            "Sample 494: Q: Which year experienced the greatest improvement in poverty? | GT: 2005 | Pred:  The chart shows the number of people living in poverty in the United States from 1980 to 2010. \n",
            "\n",
            "Year | Number in\n",
            "Sample 495: Q: What is the percentage of sales share of Domestics merchandise of Bed Bath & Beyond worldwide in the year 2020? | GT: 34 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Percentage of sales share of Domest\n",
            "Sample 496: Q: What is the difference between Home Furnishings and Domestics merchandise as a share of Bed Bath & Beyond sales worldwide in the year 2020? | GT: 31 | Pred:  The chart shows the sales share of different merchandise categories for Bed Bath & Beyond in the year 2020. The categories are: Home Furnishings\n",
            "Sample 497: Q: What's the most popular condition in the chart? | GT: Normal, healthy | Pred:  Do not make up information. Do not say \"I cannot determine\" or \"I don't know\". Do not say \"Based on the chart, the most\n",
            "Sample 498: Q: What's the sum of conditions that have more weights than expected? | GT: 55.8 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Condition | Weight | Expected Weight |\n",
            "| ---\n",
            "Sample 499: Q: What is the sum of the middle two bars? | GT: 59 | Pred:  Do not make up data. Do not refer to \"the chart\" or \"the table\". Bars are labeled A, B, C, D, E,\n",
            "Sample 500: Q: From 2010 to 2012, which year saw the biggest change in bankruptcies? | GT: 2011 | Pred:  The chart shows the number of bankruptcies in the United States from 2010 to 2012. In 2010,\n",
            "Sample 501: Q: The bar chart covers how many years? | GT: 6 | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 502: Q: What is the median of the three least raised biotech venture capitals? | GT: 12000 | Pred:  Do not make up data. Do not say \"Insufficient data\". \n",
            "\n",
            "Chart: \n",
            "| Name | Raised (in millions) |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 503: Q: What is the value when the tallest bar is divided by the shortest bar? | GT: 14.33 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot tell\". Do not say \"Not enough information\". Do not\n",
            "Sample 504: Q: What is the difference in percentage between the most and the second most adopted eating habits? | GT: 18 | Pred:  The chart has the following columns: Eating Habit, Number of Adopters, Percentage of Adopters. The rows are: Eating Habit, Number of Adopters,\n",
            "Sample 505: Q: What is the percentage value of total government expenditure in Country Japan ? | GT: 23.6 | Pred:  The chart has the following columns: Country, Year, Total Government Expenditure (in $ billions), Total Government Revenue (in $ billions), Total Debt (\n",
            "Sample 506: Q: Is the sum value  of country Germany and Ireland more then Costa Rica ? | GT: No | Pred:  The chart has the following columns: Country, Population, Area (km²), Population density (inhabitants/km²). \n",
            "\n",
            "Country\tPopulation\t\n",
            "Sample 507: Q: Which has the lowest Radio device ownership among 15-39 year-olds in the United States in 2017? | GT: A portable AM/FM radio | Pred:  The chart shows the following data: \n",
            "- Radio ownership among 15-39 year-olds in the United States in 2017:\n",
            " \n",
            "Sample 508: Q: What is the difference between the highest and the lowest Radio device ownership among 15-39-year olds in the United States in 2017? | GT: 71 | Pred:  The chart shows the percentage of 15-39-year-olds in the United States who owned a radio in 2017, broken down by\n",
            "Sample 509: Q: How many types have been considered? | GT: 4 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Type | Description | Number of types considered |\n",
            "\n",
            "Sample 510: Q: What is the sum of Black and white? | GT: 56.01 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. \n",
            "\n",
            "Chart:\n",
            "| Color | Count |\n",
            "|-------|\n",
            "Sample 511: Q: Which has the lowest Revenue of selected home and garden products retailers in Germany in 2013? | GT: Max Bahr | Pred:  The chart shows the revenue of selected home and garden products retailers in Germany in 2013. The options are: A) Aldi, B)\n",
            "Sample 512: Q: What is the difference between the highest and the lowest in Revenue of selected home and garden products retailers in Germany in 2013? | GT: 1.3 | Pred:  The chart shows the revenue of selected home and garden products retailers in Germany in 2013. The retailers are: Bauhaus, Bauen & Wohn\n",
            "Sample 513: Q: Which channel has a share of 4.28? | GT: ABC News | Pred:  Do not make up information. If the information is not in the chart, you should say \"Information not available in the chart\".\n",
            "\n",
            "Channel Share\n",
            "A: \n",
            "Sample 514: Q: How many channels have higher than 5 million? | GT: 3 | Pred:   Chart: 1. Channel A: 3 million 2. Channel B: 4 million 3. Channel C: 6 million 4\n",
            "Sample 515: Q: What does the grey color indicate? | GT: All households | Pred:  Do not make up information. Do not say I cannot answer the question or I don't know. If the chart does not contain the information to answer the question\n",
            "Sample 516: Q: By how much Pensioners is higher than long term unemployed? | GT: 6680 | Pred:  Do not make up data. Do not say \"The chart shows\". Do not say \"Based on the chart\". Do not say \"According to the chart\".\n",
            "Sample 517: Q: What is the colour of Overall score in bar chart? | GT: gray | Pred:  Do not make up information. If information is not available in the chart, say so.\n",
            "\n",
            "Available choices:\n",
            "- Red\n",
            "- Blue\n",
            "- Green\n",
            "- Yellow\n",
            "Sample 518: Q: In which category the index score value is 1? | GT: Legislators, senior officials and managers | Pred:  The chart has the following columns: Category, Index Score Value, Index Score Value, Index Score Value, Index Score Value, Index Score Value, Index Score Value\n",
            "Sample 519: Q: By how much is 2 persons higher than that of 1 person? | GT: 34960 | Pred:  Chart: none\n",
            "Answer: The question cannot be answered with the given information. There is no chart provided to support the comparison between 2 persons and 1\n",
            "Sample 520: Q: What is the median value? | GT: 37700 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart content: \n",
            "| Year |\n",
            "Sample 521: Q: Which product has the highest value? | GT: Flash/NV | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The highest value is...\". Do not say \"The product\n",
            "Sample 522: Q: What is the sum value  of product Logic and Foundry? | GT: 27.2 | Pred:  Do not make up information. If the information is not in the chart, say \"Insufficient information\".\n",
            "\n",
            "Table cells in one row are seperated by '|',\n",
            "Sample 523: Q: What type of store sells  snowboarding boots for the highest price? | GT: Specialty shop | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Store | Price |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 524: Q: What is the average price for snowboard boots? (in dolalrs)? | GT: 158.58 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The average price is...\". Do not say \"According to\n",
            "Sample 525: Q: What years are the starting years on this graph? | GT: 2010/11 | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". The\n",
            "Sample 526: Q: What is the average of all the years? | GT: 19287.4285 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the information in the chart...\". The chart is: Year\n",
            "Sample 527: Q: Which opinion has the highest share? | GT: Nothing at all | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The highest share is...\". Do not say \"The opinion\n",
            "Sample 528: Q: What is the sum of the two medians? | GT: 47 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\". Chart: | x | y | z |\n",
            "Sample 529: Q: What has the second least reviews? | GT: YellowPages.com | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"From the\n",
            "Sample 530: Q: Which site is three times than yellowpages? | GT: Industry specific | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Site | Number of listings |\n",
            "| --- |\n",
            "Sample 531: Q: Which product have the highest value of market share? | GT: Stockings | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Product A: 30%\n",
            "Product B: \n",
            "Sample 532: Q: What is the sum of cotton socks and children socks? | GT: 32 | Pred:  Do not make up data or assumptions. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Data\n",
            "Sample 533: Q: How many number of golfers are there in 2016? | GT: 463952 | Pred:  Chart cells are separated by tabs, and each row is a new line. \n",
            "2012\t2013\t2014\t2\n",
            "Sample 534: Q: By how much percentage is 2017 higher than 2018? | GT: 7166 | Pred:  Chart: 2017 2018 2019 2020 2021 2022\n",
            "Sample 535: Q: Which repsone has the biggest slice of the graph? | GT: As much as before the lockdown | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say \"I\n",
            "Sample 536: Q: What is the color of the smallest slice? | GT: Red | Pred:  Do not make up information. Do not say I cannot answer that question. Do not say based on the chart. Do not say using the information. Do not\n",
            "Sample 537: Q: What is the patient spending for a 400 dollar insulin if the patient is in deductible phase in the US as of 2017? | GT: 408 | Pred:  If the information is not available in the chart, respond with \"Not available in chart\".\n",
            "\n",
            "Chart content: None\n",
            "Final answer: Not available in chartHuman\n",
            "Sample 538: Q: What is the value of the highest bar? | GT: 408 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot determine\". Do not\n",
            "Sample 539: Q: What is the revenue of travel agencies? | GT: 270.3 | Pred:  Table cells in the same row are seperated by '|', and each row corresponds to a different country. The table has the following columns: Country, Revenue (\n",
            "Sample 540: Q: What is the difference between the food service and accommodation? | GT: 3986.8 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Question | Answer |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 541: Q: WHat is the highest value? | GT: 37 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Name | Age | Height (cm) |\n",
            "Sample 542: Q: What is the ratio of No change to not sure? | GT: 1.6 | Pred:  The chart is as follows: \\begin{tabular}{|c|c|c|c|c|} \\hline \\textbf{Category\n",
            "Sample 543: Q: Which year has 2.03%? | GT: 2016 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The year with 2.03% is...\".\n",
            "Sample 544: Q: What is the average of all the years? | GT: 2.07 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the information in the chart...\". The chart is: Year\n",
            "Sample 545: Q: What year is represented in the graph? | GT: 2014 | Pred:  Graph: 2010 2011 2012 2013 2014 2015\n",
            "Sample 546: Q: What is the difference between Carex and Palmolive? | GT: 24.3 | Pred:  Each row in the chart represents a different entity. The first column is the entity name, the second column is its type, and the third column is a description\n",
            "Sample 547: Q: How many years have the same emission rate of 25%? | GT: 3 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 548: Q: What is the ratio of least and highest rates? | GT: 0.444444444 | Pred:  Do not make up data. Do not invent answers. Do not hallucinate. If the data is not present in the chart, you must say \"Data not\n",
            "Sample 549: Q: What is the percentage of rheumatologists in the U.S. who worked at a Hospital as of 2019? | GT: 15 | Pred:  The chart has the following columns: Specialty, Number of Practitioners, Percentage of Practitioners, Worked at a Hospital, Worked at a Clinic\n",
            "Sample 550: Q: What is the percentage of rheumatologists in the U.S. who either worked at a Hospital  or an Office-based solo practice as of 2019? | GT: 27 | Pred:  The chart is as follows:  \\begin{tabular}{ |c|c|c|c|c| } \\hline\n",
            "& 2\n",
            "Sample 551: Q: Which year has the highest value? | GT: 2013 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 552: Q: How many years have consumption higher than 3%? | GT: 5 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: How many years have consumption higher than 3\n",
            "Sample 553: Q: Which colored segment occupies more than half the pie chart? | GT: blue | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The answer must be one\n",
            "Sample 554: Q: Which sales is larger, Accessories or all other product segments combined? | GT: Accessories | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Sales (in millions): \n",
            "- Accessories\n",
            "Sample 555: Q: Which represents 1%? | GT: Both scared and optimistic | Pred:  Chart: 100% = 100, 50% = 50, 25% = 25, \n",
            "Sample 556: Q: How many people scared? | GT: 58 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Date | Location | Number of people scared |\n",
            "\n",
            "Sample 557: Q: Which period crossed 100 billions? | GT: Q3 '12 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 558: Q: What is the value of the highest point? | GT: 181.95 | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". Do not\n",
            "Sample 559: Q: Which has the percentage higher than 50%? | GT: Photos | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 560: Q: What is the ratio of Videos and Carousel? | GT: 1.545454545 | Pred:  Do not make up data. Table cells in the same row are seperated by '|', and each row corresponds to an entry in the following table. Table:\n",
            "\n",
            "Sample 561: Q: Which country has the least amount of seats? | GT: USA | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"According to the chart...\". The chart is: \n",
            "Country\t\n",
            "Sample 562: Q: What percentage of seats does PH hold? | GT: 50.9 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Question: What percentage of seats does PH hold\n",
            "Sample 563: Q: what age group contributes highest revenue? | GT: 45-64 | Pred:  Each chart has a title, x-axis, y-axis, and data. The data is given as a list of lists, where the first row is the header\n",
            "Sample 564: Q: What's the percentage of revenue contributes by people under 44? | GT: 40.3 | Pred:  Do not make up data. Do not say \"Insufficient data\". The following chart shows the revenue distribution by age group: \n",
            "- Under 44:\n",
            "Sample 565: Q: Which adults in the United States  has the least number of use of internet in 2021? | GT: 65+ years | Pred:  The chart shows the percentage of adults in the United States who used the internet in 2021, by age group. \n",
            "\n",
            "| Age Group | Percentage\n",
            "Sample 566: Q: Which age group has highest share of population in 2021? | GT: 18 to 29 years | Pred:  The chart shows the age distribution of the population in a country in 2021.\n",
            "Answer: The age group with the highest share of population in \n",
            "Sample 567: Q: Which year has the lowest company sales and revenue streams? | GT: 2020 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The year with the lowest sales and revenue streams is...\".\n",
            "Sample 568: Q: What is the difference in company sales and revenue streams between 2013 and 2020 in US dollars? | GT: 16.3 | Pred:  The chart shows the sales and revenue streams of a company from 2013 to 2020 in US dollars. In 201\n",
            "Sample 569: Q: What sex contributes to more cases? | GT: Female | Pred:  Chart: | Sex | Number of cases | | --- | --- | | Male | 120 | | Female | 80 | | Total |\n",
            "Sample 570: Q: What the difference between percentage of female and male in the chart? | GT: 2.2 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The difference is...\". Do not say \"According to the\n",
            "Sample 571: Q: Which country has the highest number of deaths caused by major droughts worldwide from 1900-2016? | GT: China (1928) | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available\n",
            "Sample 572: Q: What's the total number of  deaths caused by major droughts worldwide in Sudan at 1983? | GT: 250000 | Pred:  The chart has the following columns: Country, Year, Deaths, Type of disaster. The chart has the following rows: Sudan, 1983,\n",
            "Sample 573: Q: What did the majority of people respond with? | GT: Yes | Pred:  Each row in the chart represents a different group of people, and each column represents a different response option. The first column is the group name. The rest are\n",
            "Sample 574: Q: How many people didn't respond with yes? | GT: 38.6 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Age Group | Yes | No | Total |\n",
            "\n",
            "Sample 575: Q: What is the budgeted public sector expenditure on Transport in 2019  (in billion GBP)? | GT: 44 | Pred:  Do not make up numbers. Do not say \"The chart does not show\". The chart shows the following data: \n",
            "- Public sector expenditure on Transport in \n",
            "Sample 576: Q: What is the total budgeted public sector expenditure on Transport and Defense (in billion GBP)? | GT: 99 | Pred:  Do not make up numbers. Do not say \"Based on the chart...\". Just give the final answer. Do not make up numbers. Do not say \"\n",
            "Sample 577: Q: Which of these countries is the leading country in clothing experience in 2019? | GT: China* | Pred:  Do not make up data or statistics. If the chart does not contain enough information to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "The chart shows the\n",
            "Sample 578: Q: What is the average value of share of clothing exports between India and Turkey? | GT: 3.35 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average value of share of clothing exports\n",
            "Sample 579: Q: What growth rate has the second highest bar? | GT: 10k-100k | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the growth rates of different companies over a period of time. The\n",
            "Sample 580: Q: What was the combined growth rate for 1m-10m and 10m+? | GT: 28.6 | Pred:  The chart has the following columns: Year, 1m-10m, 10m+, Total. The chart has the following rows: \n",
            "Sample 581: Q: What purpose was the third most popular? | GT: Business and professional | Pred:  Each row in the chart represents a different category. The first column is the category name. The rest of the columns are time periods. Values in the columns are\n",
            "Sample 582: Q: What was the combined percentage of the business and professional and not specified purposes? | GT: 17 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Do not say \"The answer is\" or a variation\n",
            "Sample 583: Q: What year did Roche spend the most in? | GT: 2020 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart\". Do not say \"The chart shows\n",
            "Sample 584: Q: What was the increase in spending from 2015 to 2020? | GT: 3428 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is a header row. The first column is a header column\n",
            "Sample 585: Q: What distribution channel has the 3rd biggest piece? | GT: Connected fitness | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The answer must be one\n",
            "Sample 586: Q: What percentage did both wholesale and direct to consumer distribution channels account for? | GT: 94 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 587: Q: What is the net sales of General Mills wordwide in 2018(in million U.S. dollars)? | GT: 15740 | Pred:  Do not make up numbers. Do not say \"The chart does not show\". The chart shows the net sales of General Mills worldwide in 2018\n",
            "Sample 588: Q: What is the sum of net sales of General Mills when it was highest and lowest? | GT: 33530 | Pred:  The chart has the following columns: Year, Net Sales (in millions), Net Income (in millions), Net Profit Margin. General Mills' net sales were highest\n",
            "Sample 589: Q: What is the percentage of people choose to celebrating Easter this year ? | GT: 79 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the percentage of people who celebrate Easter in various countries. The data\n",
            "Sample 590: Q: What is the percentage difference of people choosing yes and no? | GT: 58 | Pred:  The chart shows the number of people who chose \"yes\" and \"no\" in a survey. The total number of people surveyed is 100.\n",
            "Sample 591: Q: What is the percentage of billionaires globally in the 50-70 age group? | GT: 50.3 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "100% of\n",
            "Sample 592: Q: What is the difference between the percentage of billionaires in two age groups, one with the lowest and the other with the highest number of billionaires? | GT: 40.5 | Pred:  The chart shows the distribution of billionaires by age group. The age groups are: 30-39, 40-49, 5\n",
            "Sample 593: Q: 40% of which group answered YES? | GT: Baby Boomers (49-67) | Pred:  Table cells in the same row are separated by '|', and each row corresponds to a group. The first row in the table is the header.  Table:\n",
            "\n",
            "Sample 594: Q: What is the difference between the two groups who answered YES by highest and lowest percentage? | GT: 5 | Pred:  Do not make up data. Do not say \"Insufficient data\". \n",
            "\n",
            "Chart: \n",
            "| Question | Group A | Group B |\n",
            "| --- | --- |\n",
            "Sample 595: Q: What is the percentage revenue share of the LVMH Group worldwide in 2020 from the United States? | GT: 24 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Data not available in chart.\n",
            "Sample 596: Q: What is the total percentage revenue share of the LVMH Group worldwide in 2020 from Asia and Japan? | GT: 41 | Pred:  The chart shows the revenue share of the LVMH Group worldwide in 2020 by region. The revenue share of the LVMH Group worldwide\n",
            "Sample 597: Q: What is the sales share of Target for the Food & Beverages segment in 2020? | GT: 20 | Pred:  The chart shows the sales share of different companies in the Food & Beverages segment for the year 2020. The sales share of Target is \n",
            "Sample 598: Q: What is the sum of the sales share of Food & Beverages and Beauty & household essentials segment in 2020? | GT: 46 | Pred:  The chart shows the sales share of different product segments in 2020. The sales share of Food & Beverages is 30%, and the\n",
            "Sample 599: Q: Which year has the highest number of fatalities? | GT: 2006 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The year with the highest number of fatalities is...\". The\n",
            "Sample 600: Q: What is the average of all fatalities in all years? | GT: 14.07 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot tell\". Do not say \"Not enough information\". Do not\n",
            "Sample 601: Q: What is the unemployment rate for individuals aged 15 to 24 years in Singapore in the year 2016? | GT: 9.12 | Pred:  The chart shows the unemployment rate for individuals aged 15 to 24 years in Singapore from 2010 to 2016.\n",
            "Sample 602: Q: What is the increase in the unemployment rate for individuals aged 15 to 24 years in Singapore between the year 2014 and 2015? | GT: 0.6 | Pred:  The chart shows the unemployment rate for individuals aged 15 to 24 years in Singapore from 2014 to 2015.\n",
            "Sample 603: Q: How many Facebook fans (in millions) does Mango have? | GT: 11.68 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart content: None\n",
            "Final Answer: Data\n",
            "Sample 604: Q: What is the total number of Facebook fans (in millions) that BOSS and ROLEX have? | GT: 16.06 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I don't know\". Do not say \"Cannot determine\". Do not\n",
            "Sample 605: Q: What is the highest value of the monthly average earnings per hour of all employees in the US  between May 2020 and May 2021? | GT: 30.33 | Pred:  The chart shows the monthly average earnings per hour of all employees in the US between May 2020 and May 2021. The highest\n",
            "Sample 606: Q: What is the difference in the monthly average earnings per hour of all employees in the US  between May 2020 and May 2021 | GT: 0.59 | Pred:  The chart shows the monthly average earnings per hour of all employees in the US in May 2020 and May 2021. In May\n",
            "Sample 607: Q: Which film genre is most popular in the United Kingdom as of October 2013? | GT: Action/thriller | Pred:  Do not make up data. Do not say things like \"as of October 2013\" or \"according to the chart\". The chart shows the\n",
            "Sample 608: Q: What is the difference between the most popular and least popular film genres in the United Kingdom (UK) as of October 2013? | GT: 27 | Pred:  The chart shows the number of films released in the UK in 2013 by genre.\n",
            "Answer: The difference between the most popular and least popular film\n",
            "Sample 609: Q: What is the revenue of Brandstätter Group in 2009 (in million euros)? | GT: 474 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Sure. Please provide the chart or\n",
            "Sample 610: Q: What is the average revenue of Brandstätter Group from 2008 to 2009 (in million euros)? | GT: 463 | Pred:  The chart shows the revenue of Brandstätter Group from 2008 to 2009. In 2008, the\n",
            "Sample 611: Q: What is the value (in billion euros) of the Ingenico Group S.A - Worldline SA deal in Europe? | GT: 9.2 | Pred:  Do not make up data. If the data is not present in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart content: None\n",
            "Answer: Data not\n",
            "Sample 612: Q: What is the sum total of the value (in billion euros) of the top two deals in Europe in 2020 in terms of deal value? | GT: 48.3 | Pred:  Do not make up data. If information is not available in the chart, say so.\n",
            "\n",
            "Sum total of the value (in billion euros) of the top two\n",
            "Sample 613: Q: Which category of age does yellow indicate? | GT: 30-39 years | Pred:  Each row in the chart represents a different category of age. The chart has the following columns: Age Category, Lower Bound, Upper Bound.\n",
            "| Age Category |\n",
            "Sample 614: Q: What is the difference between the highest and lowest people infection? | GT: 34.5 | Pred:  Table cells in a row are seperated by tabs, and different rows are new lines. Assume the value is missing if the header doesn't exist in the row\n",
            "Sample 615: Q: What is the profit percentage  of Europe? | GT: 37 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 616: Q: What is the difference between maximum profit contribution and minimum profit contribution? | GT: 21 | Pred:  Do not make up data or statistics. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Chart: \n",
            "|  |\n",
            "Sample 617: Q: What is the number of fatalities in 2016? | GT: 563 | Pred:  The chart is: 2016 2017 2018 2019 2020 20\n",
            "Sample 618: Q: What is the average of 2017, 2018, 2019? | GT: 632.66 | Pred:  2017 2018 2019 2020 2021 2022 2\n",
            "Sample 619: Q: What is the percentage of nickel imports in Canada? | GT: 42 | Pred:  The chart has the following columns: Country, Nickel (in thousands of metric tons), Copper (in thousands of metric tons), Zinc (in thousands of metric tons\n",
            "Sample 620: Q: What is the total number of percentage in Canada and Russia? | GT: 50 | Pred:  The chart has the following columns: Country, % of population in urban areas, % of population in rural areas. Canada: 79%, 21\n",
            "Sample 621: Q: What's the highest Share of Puma's net sales worldwide in 2020, by segment? | GT: Footwear | Pred:  The chart shows the share of Puma's net sales worldwide in 2020, by segment. The segments are: Footwear, Apparel, Accessories\n",
            "Sample 622: Q: What's the total of apparel and footwear, Share of Puma's net sales worldwide in 2020, by segment | GT: 82.9 | Pred:  The chart shows the share of Puma's net sales worldwide in 2020, by segment. The segments are: Apparel, Footwear, and\n",
            "Sample 623: Q: What is distribution of potash reserves in Germany in 2019? | GT: 4.2 | Pred:  The chart shows the distribution of potash reserves in Germany in 2019.\n",
            "\n",
            "The distribution of potash reserves in Germany in 2019\n",
            "Sample 624: Q: What is the sum of China and Russia in the  potash reserves worldwide in 2019? | GT: 26.4 | Pred:  The chart is as follows: 2019 World Potash Reserves (Million Metric Tons)\n",
            "Country\tReserves (Million Metric T\n",
            "Sample 625: Q: In which year the line on the graph saw its peak point? | GT: 2000 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The peak point is in...\". Do not say \"The\n",
            "Sample 626: Q: What is the difference between the  employees between the years when the percentage of employees were maximum and minimum? | GT: 10.59 | Pred:  Do not make up data. Do not say \"Insufficient data\". The chart shows the number of employees in a company from 2010 to \n",
            "Sample 627: Q: What color does Green indicate? | GT: Perfumes | Pred:  Do not make up information. If the information is not in the chart, say \"Information not found\".\n",
            "\n",
            "Chart content: None\n",
            "Final answer: Information not found\n",
            "Sample 628: Q: WHat is the difference between hair care and makeup? | GT: 6.12 | Pred:   Chart:  | Question | Answer |\n",
            "| --- | --- |\n",
            "| What is the difference between hair care and makeup? | Hair care involves washing, conditioning\n",
            "Sample 629: Q: What is the number of passengers entry and exit in Victoria? | GT: 73.56 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 630: Q: What is the sum of highest value and lowest value of blue bar ?? | GT: 119.43 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 631: Q: What is the maximum percentage of frequency of instagram? | GT: 97 | Pred:  Chart: None\n",
            "\\question{What is the maximum percentage of frequency of instagram?} \n",
            "\\answer{}\n",
            "\\end{question} The chart provided does not\n",
            "Sample 632: Q: Daily, how many percentage of people use Instagram? | GT: 63 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Data not available\".\n",
            "\n",
            "Daily, 23% of people use Instagram\n",
            "Sample 633: Q: In which year the line graph saw its peak? | GT: 2019 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The peak occurs in...\". Do not say \"The peak\n",
            "Sample 634: Q: What is the difference between maximum and minimum average annual wage over the years? | GT: 6229 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. The chart shows the average annual wage in the United States\n",
            "Sample 635: Q: What is the maximum number of freelance workers? | GT: 59 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | Male | Female | Total |\n",
            "|\n",
            "Sample 636: Q: Which year has the least number of workers? | GT: 2014 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"From the chart...\". Do not say \"According to the\n",
            "Sample 637: Q: How many colors are there in the pie chart ? | GT: 4 | Pred:  Do not make up numbers. Do not say \"Based on the chart...\". Do not say \"The pie chart shows...\". Do not say \"I notice\n",
            "Sample 638: Q: What value we get if we add blue and red color? | GT: 42 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the information in the chart...\". Do not say things like\n",
            "Sample 639: Q: How many years has the metric tons surpassed 125,000? | GT: 6 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"From the\n",
            "Sample 640: Q: What is the difference between the first and last year's results? | GT: 2.95 | Pred:  The chart has the following columns: Year, Revenue, Expenses, Net Income. The chart has the following rows: 2018, 20\n",
            "Sample 641: Q: How many bars are shown in the charts ? | GT: 10 | Pred:  Each chart has a title, x-axis, y-axis, and data. The data is given as a list of (x, y) points. When a\n",
            "Sample 642: Q: What is the sum of Chief executives and senior officials  and Marketing and sales directors ? | GT: 2976.1 | Pred:  Each cell in the chart is a single number. The chart has the following rows and columns: \n",
            "Row labels: 1990, 19\n",
            "Sample 643: Q: What is the highest surgical cosmetic procedures worldwide in 2019? | GT: Breast augmentation | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart does not\n",
            "Sample 644: Q: What si the difference between the highest and lowest projected surgical cosmetic procedures? | GT: 1347066 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The difference is...\". Do not say \"According to the\n",
            "Sample 645: Q: Which year has the highest number of all-electric car registrations in Italy from 2015 to 2020? | GT: 2020 | Pred:  The chart shows the number of all-electric car registrations in Italy from 2015 to 2020.\n",
            "\n",
            "2015: \n",
            "Sample 646: Q: What is the average of 1st highest value and 2nd highest value in blue bar? | GT: 21557 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just give the answer. Do not say \"Based on the chart...\". Just\n",
            "Sample 647: Q: What is the value of grey sector? | GT: 22.8 | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Question: What is the value of grey sector? Answer\n",
            "Sample 648: Q: What is the sum of natural gas and oil? | GT: 54.4 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart does not exist.\n",
            "\n",
            "The sum of natural gas and oil is not a\n",
            "Sample 649: Q: Does the life expectancy increase or decrease over time? | GT: increasing | Pred:  Do not make up data or statistics. If the information is not available in the chart, say so.\n",
            "\n",
            "Answer: The chart does not provide information on life expectancy\n",
            "Sample 650: Q: What is the average life expectancy between 2008 and 2018? | GT: 58.56 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: What is the average life expectancy between 2\n",
            "Sample 651: Q: What is the value of highest blue bar? | GT: 30 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 652: Q: What is the sum all the blue bar? | GT: 38 | Pred:  Do not make up data. Do not say \"insufficient information\". The chart shows the number of blue bars in each row. Row 1 has 3\n",
            "Sample 653: Q: Which color segment is the third smallest? | GT: gray | Pred:  Assume all values in the chart are in millions. \n",
            "\n",
            "Chart: \n",
            "Color | Segment Size (millions)\n",
            "--- | ---\n",
            "Red | 10\n",
            "Blue\n",
            "Sample 654: Q: What is the maximum of the income range represented by the biggest segment? | GT: 149999 | Pred:  Assume all values are in thousands of dollars.\n",
            "\n",
            "Chart: \n",
            "| Income Range | Number of People |\n",
            "|--------------|------------------|\n",
            "| 0-10\n",
            "Sample 655: Q: What energy source has the largest share? | GT: Hard coal | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The chart is: \n",
            "\n",
            "Sample 656: Q: what's the combined share of top three energy sources? | GT: 81.2 | Pred:  The chart shows the share of different energy sources in total energy consumption. The top three energy sources are coal, oil, and natural gas. Their shares are \n",
            "Sample 657: Q: What is the value for Lago d'lseo? | GT: 251 | Pred:  Do not make up information. If the information is not in the chart, respond with \"Information not available in chart\".\n",
            "\n",
            "Lago d'lseo\n",
            "Lago\n",
            "Sample 658: Q: What is the sum of Lago di Bolsena and Lago di Bracciano ? | GT: 306 | Pred:  If information is not available in the chart, say \"Insufficient information\".\n",
            "\n",
            "Lago di Bolsena: 12 km²  \n",
            "Lago di Bracc\n",
            "Sample 659: Q: What is the percentage value for soybean ? | GT: 48.2 | Pred:  Do not make up data. Do not say \"insufficient information\". \n",
            "\n",
            "Chart: \n",
            "| Crop | 2010 | 2011\n",
            "Sample 660: Q: What is the sum , if we add  soybean and corn percentage ? | GT: 80.2 | Pred:  Do not make up data. Do not say \"insufficient information\". Do not say \"I cannot tell\". Do not say \"not enough information\". Do not\n",
            "Sample 661: Q: Which country has the maximum revenue share? | GT: North America | Pred:  The chart shows the revenue share of different countries in a global market.\n",
            "\n",
            "United States: 30%\n",
            "Germany: 15%\n",
            "China: 25\n",
            "Sample 662: Q: What is the sum of Latin America, EMEA and Asia-pacific? | GT: 31 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 663: Q: What is the third data value in the blue bar ? left to right | GT: 4.7 | Pred:  Do not use abbreviations. Do not say I cannot answer this question. Do not say the chart is missing. Do not say based on the information provided.\n",
            "Sample 664: Q: How many quarters the exchange rate is above 4.5 value? | GT: 5 | Pred:  Each row in the table represents a data point. The first column is the date, the second column is the exchange rate, and the number of quarters is the\n",
            "Sample 665: Q: In the pie chart, what blue color denotes ? | GT: Gucci | Pred:  Do not make up information. Do not say I cannot answer that question. Do not say based on the chart. Do not say from the chart. The answer\n",
            "Sample 666: Q: If we add Gucci and Saint Laurent percentage, write the result? | GT: 73 | Pred:  Do not make up data. If information is not available in the chart, say so.\n",
            "\n",
            "Chart content: None\n",
            "Final answer: Information not available in the chart\n",
            "Sample 667: Q: What color is the Reward-based slice? | GT: gray | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Question: What color is the Reward-based slice? Answer\n",
            "Sample 668: Q: What 2 slices make up over 75% of the crowdfunding total? | GT: [Equity-based crowdfunding, Real estate crowdfunding] | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "What 2 slices make up over 75%\n",
            "Sample 669: Q: What is the ratio of the navy blue bar over the gray bar? | GT: 2.6 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The ratio is\". Do not say \"Final Answer\". Do\n",
            "Sample 670: Q: What is the value of the Yes opinion adds to the difference between No answer and No? | GT: 80 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Question | Yes | No | Don't know\n",
            "Sample 671: Q: What does the light blue part represent? | GT: Fresh milk and cream | Pred:  Do not make up information. Do not say I cannot answer that question. Do not say the chart is missing. Do not say the chart is not available.\n",
            "Sample 672: Q: What's the difference between other dairy products and Fresh milk and cream? | GT: 36 | Pred:  Table cells in a row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Product | Fat Content | Protein Content | Calcium\n",
            "Sample 673: Q: What is the Net non-performing assets in 2018? | GT: 931.08 | Pred:  Do not make up data or inferences. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Net non-performing assets in\n",
            "Sample 674: Q: Which year has seen a increase in Net non -performing assets? | GT: 2018 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Net non-performing assets (NPA)\n",
            "Sample 675: Q: What is the percentage value of purchases by people from 16-24 years old? | GT: 17 | Pred:  Do not make up data. Do not say \"Insufficient data\". \n",
            "\n",
            "Chart: \n",
            "| Age Group | Purchases (%) |\n",
            "| --- | --- |\n",
            "|\n",
            "Sample 676: Q: What's the percentage value of purchases by people over 55 years old? | GT: 22 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"More information is needed\".\n",
            "Sample 677: Q: Which country has the highest consumption? | GT: Cyprus | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 678: Q: Which country has 0.3 difference when compared with Poland? | GT: Austria | Pred:  The chart has the following columns: Country, Difference. Poland, 0.3\n",
            "\n",
            "Based on the chart, the country with a difference of 0.\n",
            "Sample 679: Q: What is the percentage value for \"Never\" Category? | GT: 36 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 680: Q: What is the average of 'once a week' and ' once a month' ? | GT: 9 | Pred:  Do not make up data. Do not say things like 'Based on the chart...'. Just answer the question.\n",
            "\n",
            "Average of 'once a week' and '\n",
            "Sample 681: Q: Which year represents the highest expenditure? | GT: 2028 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart is: Year | Expenditure (in millions) 20\n",
            "Sample 682: Q: What is the median of 2014, 2015 and 2016? | GT: 1590.4 | Pred:  2014, 2015, 2016\n",
            "\n",
            "The median of 2014, 2015\n",
            "Sample 683: Q: Has any category reached 70% of all respondents? | GT: No | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "% of respondents by category\n",
            "Category: A\n",
            "Sample 684: Q: What percentage believe the government is slightly or not at all corrupt? | GT: 11 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. The chart shows the percentage of people who believe the government\n",
            "Sample 685: Q: What year has the lowest point on this graph? | GT: 2000 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The lowest point is in...\". Do not say \"The\n",
            "Sample 686: Q: What is the average for the last 5 years? | GT: 77.8 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available\".\n",
            "\n",
            "Year | 2018 | 2\n",
            "Sample 687: Q: How many people use youtube daily? | GT: 21 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 688: Q: What is the ratio of the people who use youtube monthly to less often? | GT: 1 | Pred:  The chart shows the number of people who use YouTube monthly and less often. Monthly users: 200, Less often: 100. \n",
            "\n",
            "\n",
            "Sample 689: Q: Which two market shares have been taken? | GT: [Investment funds, Discretionary mandate assets] | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The two market shares taken are...\". Do not say \"\n",
            "Sample 690: Q: Which is the highest among the two? | GT: Investment funds | Pred:  Do not make up data. Do not invent information. Do not hallucinate. Do not add extra text. Do not answer questions that are not answerable from\n",
            "Sample 691: Q: Which group has the majority exports? | GT: Manufactures | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: Which group has the majority exports?, Answer:\n",
            "Sample 692: Q: What does the sum of Agricultural and fuesl and mining products amount to? | GT: 24.6 | Pred:  Do not make up data. Table cells in a row are seperated by '|', and rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | Total |\n",
            "Sample 693: Q: Which date the line chart have vertical rise? | GT: Mar 31 '20 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The date is...\". Do not say \"The line chart\n",
            "Sample 694: Q: What is the ratio between the last two data? | GT: 0.099009901 | Pred:  Chart cells are separated by tabs, rows and columns are separated by newlines. \n",
            "Chart:\n",
            "Year\\tSales (in $ millions)\\tProfit (in $\n",
            "Sample 695: Q: Which colored segment makes a right angle? | GT: blue | Pred:  The chart has the following rows and columns: Row headers: A, B, C, D, E; Column headers: 1, 2, \n",
            "Sample 696: Q: Sum the three biggest opinions and then divide the result by the average opinion.? | GT: 3.8 | Pred:  The chart has the following data:\n",
            "| Opinion | Count |\n",
            "|--------|-------|\n",
            "| 1      | 3     |\n",
            "| 2      | \n",
            "Sample 697: Q: Which year has the least receipts? | GT: 11/12 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. \n",
            "\n",
            "Year | Receipts (in millions)\n",
            "--- |\n",
            "Sample 698: Q: What is the average of values above 70? (in million U.S. dollars)? | GT: 71.5 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. \n",
            "\n",
            "Chart:\n",
            "| Year | Value (in million U\n",
            "Sample 699: Q: Which region had maximum number of Gucci stores in 2016? | GT: Emerging countries | Pred:  The chart shows the number of Gucci stores in different regions in 2016.\n",
            "Answer: Asia-Pacific region had the maximum number of Gucci stores\n",
            "Sample 700: Q: What is the difference between maximum number of Gucci stores operated in Emerging Countries over the years and minimum number of stores operated in Western Europe over the years? | GT: 123 | Pred:  The chart shows the number of Gucci stores operated in different regions over the years. The regions are: Western Europe, Eastern Europe, North America, South America\n",
            "Sample 701: Q: In which year was the number of Starbucks stores the highest? | GT: 2019 | Pred:  The chart shows the number of Starbucks stores in the United States from 2010 to 2019.\n",
            "\n",
            "2010: 1\n",
            "Sample 702: Q: What is the highest difference between the number of Licensed stores and Number of Company-operated stores of Starbucks? | GT: 743 | Pred:  Do not make up data. Do not say anything like \"Based on the data in the chart...\" or \"According to the chart...\". Do not say anything\n",
            "Sample 703: Q: In Red line chart there is a same percentage value in two years, what is that percentage? | GT: 46 | Pred:  Red line chart: 2010: 30%, 2011: 30%, 2012: 3\n",
            "Sample 704: Q: In year 2021, what is the highest percentage value shown? | GT: 95 | Pred:  Chart cells are separated by new lines, with headers on the first line. Each cell in a row is separated by a tab from the next. Each row is\n",
            "Sample 705: Q: What player has the smallest light blue bar? | GT: Gareth Bale (Real Madrid) | Pred:  Each row in the chart represents a player, and each column represents a statistic. The columns are: Name, Points, Rebounds, Assists, Steals\n",
            "Sample 706: Q: What was the combined number for Manchester United players? | GT: 61 | Pred:  The chart shows the number of goals scored by Manchester United players in the 2022-2023 season.\n",
            "\n",
            "| Player | Goals |\n",
            "|\n",
            "Sample 707: Q: The rate of homicide in Canada and the United States are  available from which year ? | GT: 2000 | Pred:  The chart shows the rate of homicide in Canada and the United States from 1960 to 2010.\n",
            "\n",
            "1960: Canada\n",
            "Sample 708: Q: What is the difference in the highest value of homicide in United States to lowest value in Canada ? | GT: 4.33 | Pred:  The chart shows the number of homicides per 100,000 people in the United States and Canada for the years 2010-\n",
            "Sample 709: Q: What's the percentage value of Hispanic respondents who think movies are very important for avoiding racial stereotypes? | GT: 20 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "We are given a question about the percentage of\n",
            "Sample 710: Q: What's the total of all the bars of Hispanic respondents? | GT: 99 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 711: Q: What is the category which value is 73 and 27 percentage ? | GT: British Columbia | Pred:  Table cells in the chart are separated by tabs, and headers are separated by a new line. Each row in the chart is on a new line. The chart\n",
            "Sample 712: Q: What is the ratio between concerned and not concerned in Atlantic ? | GT: 3.16 | Pred:  Table cells in the chart are separated by '|', and rows in the chart are separated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "|  | Concerned | Not Concerned |\n",
            "Sample 713: Q: Find the missing category in the series,  Republicans, Independents, Total ? | GT: Democrats | Pred:   Answer: Democrats\n",
            "\n",
            "**Question:** Find the missing category in the series, Republicans, Independents, Total ?, You are a chart question-answering\n",
            "Sample 714: Q: In Total, Assume 39% equals to 1000 respondents, 57% equals to what?  round off to whole number | GT: 1462 | Pred:  39% = 1000\n",
            "\n",
            "57% = ?\n",
            "Answer: 1460\n",
            "\n",
            "**Final Answer: 146\n",
            "Sample 715: Q: How many years are represented in the data? | GT: 3 | Pred:  Chart cells are separated by tabs, and each row is a new line. The header row contains the column titles.\n",
            "\n",
            "Year\\tSales (in $ millions)\\t\n",
            "Sample 716: Q: What is the average monthly income for informal workers? | GT: 764.666666 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Date: 2023\n",
            "| Category | January | February | March | April\n",
            "Sample 717: Q: Which sector has the highest 'family administration'? | GT: Building | Pred:  Chart cells are separated by newlines, columns are separated by tabs. Chart:\n",
            "sector|2010|2011|2012\n",
            "Sample 718: Q: What is the average for industry? | GT: 60 | Pred:  Table cells in the chart are separated by tabs, and each row is on a new line. The header row contains the titles of each column. Table:\n",
            "|\n",
            "Sample 719: Q: What's the percentage value of White female presidents? | GT: 33 | Pred:  Chart cells are separated by tabs, rows and columns are separated by new lines.\n",
            "\"White female presidents\":\t0%\n",
            "Answer: 0%Human:\n",
            "Sample 720: Q: Is the average of Black and Hispanic female presidents 43? | GT: Yes | Pred:  If the information is not available in the chart, respond with \"Not available in chart\".\n",
            "\n",
            "Thought: The chart does not contain information about the average age of Black\n",
            "Sample 721: Q: Who is playing more mobile games in several times a day ? | GT: Female | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 722: Q: What is the ratio between several times a day vs several times a week in male category? | GT: 2.576923077 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 723: Q: Which colored bars trump other bars for all years | GT: navy blue | Pred:  Chart cells that are blank are empty.\n",
            "| Year | Red | Blue | Green | Yellow | Purple |\n",
            "| --- | --- | --- | --- | --- |\n",
            "Sample 724: Q: The maximum of 0-14 age group minus the mode of 65 years and older equals to what | GT: 40.92 | Pred:  The chart shows the distribution of age groups in a population. \n",
            "\n",
            "| Age Group | Population |\n",
            "|-----------|------------|\n",
            "| 0-14      |\n",
            "Sample 725: Q: Which has the least value? | GT: Perks such as elite status | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"Final Answer\". Do\n",
            "Sample 726: Q: Which option has an increasing order of Air to hotel to car? | GT: The lowest negotiable rate | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"Final Answer\". Do\n",
            "Sample 727: Q: The two data lines intersect after which year | GT: 2015 | Pred:  Do not make up data or facts. Do not say anything like \"Based on the chart...\" or \"From the chart we can see...\". Do not say\n",
            "Sample 728: Q: What is the peak robbery number minus the least theft number | GT: 11.01 | Pred:   Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | Robbery | Theft | Burg\n",
            "Sample 729: Q: What does the tallest bar represent | GT: No | Pred:  Do not make up data. Do not refer to attachments. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"\n",
            "Sample 730: Q: What is the maximum Yes opinion minus the mode of Don't know opinion | GT: 35 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Question | 18-24 |\n",
            "Sample 731: Q: Which gender spend more times playing games in the year 2014? | GT: Male | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Male\n",
            "Female\n",
            "Total\n",
            "2014\n",
            "\n",
            "Sample 732: Q: What is the sum value of Male and female in the year 2012? | GT: 11 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 733: Q: What is the total in 2016? | GT: 94.53 | Pred:  Do not make up data. Do not say \"insufficient information\". \n",
            "\n",
            "Chart: \n",
            "| Year | Total |\n",
            "|------|-------|\n",
            "| 20\n",
            "Sample 734: Q: What is the difference between male and female in 2008? | GT: 3.94 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 735: Q: What is the highest number of respondents in Hazardous waste? | GT: 29 | Pred:  Each cell in the chart is a single number. Rows are ordered from top to bottom. Columns are ordered from left to right. The first row is the header\n",
            "Sample 736: Q: What is the difference betweeen respondents of Non-hazardous waste between 2017 and 2008? | GT: 25 | Pred:  The chart shows the number of respondents for hazardous and non-hazardous waste from 2008 to 2017. In 20\n",
            "Sample 737: Q: What is the percentage of Processor market share in the year end March 2018? | GT: 40.6 | Pred:  Your answer must be a number between 0 and 100. If the information is not available in the chart, respond with \"Insufficient data\".\n",
            "\n",
            "\n",
            "Sample 738: Q: What is the sum total of all type in the year to end June 2018? | GT: 99.9 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year | Jan | Feb\n",
            "Sample 739: Q: What is the smallest value represented | GT: 9 | Pred:  Do not make up data. Do not refer to \"the chart\" or \"the table\". Do not use phrases like \"based on the information\" or \"\n",
            "Sample 740: Q: What is the difference between the average of Asian/Asian American and American | GT: 2.67 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: \n",
            "| \n",
            "Sample 741: Q: In which period the disapproval rate was maximum? | GT: February 26-27, 2015 | Pred:  Assume the chart is visible and all necessary data is available.\n",
            "\n",
            "1990s\n",
            "2000s\n",
            "2010s\n",
            "20\n",
            "Sample 742: Q: What is the difference between the highest disapproval and lowest approval? | GT: 21 | Pred:  The chart has the following columns: Year, Approval, Disapproval, and Other. The chart has the following rows: 2000, 2\n",
            "Sample 743: Q: which year was the highest revenue in pharmacy sector obtained | GT: 2017 | Pred:  2013 2014 2015 2016 2017 2018 2\n",
            "Sample 744: Q: what is the difference between the highest and smallest pharmacy service | GT: 10.1 | Pred:  Do not make up data. Do not say things like \"based on the chart\" or \"from the chart\". Do not say things like \"the highest is\n",
            "Sample 745: Q: In which year was the percentage of employment in  Industry the highest? | GT: 2013 | Pred:  The chart shows the percentage of employment in the primary, secondary, and tertiary sectors of the economy in a country from 1960 to 20\n",
            "Sample 746: Q: In which year was the employment between Agriculture and Industry the least? | GT: 2020 | Pred:  The chart shows the number of people employed in Agriculture and Industry in a country from 1980 to 1990.\n",
            "\n",
            "1980\n",
            "Sample 747: Q: what is the highest number of the high school female student that have been cyber bullied lifetime | GT: 38.7 | Pred:  Do not make up data. If information is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 748: Q: what is the sum of the high school  that have been bullied in lifetime Both male and female | GT: 72.8 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: None\n",
            "Answer\n",
            "Sample 749: Q: which age group has the highest number of people using Facebook messanger? | GT: 18-29 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the number of Facebook Messenger users by age group: 18\n",
            "Sample 750: Q: What is the total percentage of both people using Facebook and WhatsApp at 60+ | GT: 49 | Pred:  Do not make up data. Do not say \"Insufficient data\". \n",
            "\n",
            "Chart: \n",
            "| Age Group | Facebook | WhatsApp |\n",
            "| --- | --- | ---\n",
            "Sample 751: Q: What type of building has the highest  Construction costs of buildings in Ontario, Canada in 2020? | GT: Health care - ambulatory care | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"One possible answer is\n",
            "Sample 752: Q: What's the highest total Health care Construction costs of buildings in Ontario, Canada in 2020 | GT: 9550 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data\n",
            "Sample 753: Q: What's the highest Distribution of employment by economic sector in 2010 | GT: Services | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the distribution of employment by economic sector in 2010\n",
            "Sample 754: Q: What's the average of Distribution of employment by economic sector from 2010 | GT: 33.3 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 755: Q: which value has the highest GBP? | GT: Direct and indirect value | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The highest value is...\". Do not say \"GBP\".\n",
            "Sample 756: Q: What is the the differencebetween GBP in 2014? | GT: 20 | Pred:  Avoid making up information. If the question cannot be answered from the chart, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart content: None\n",
            "Answer: Cannot be determined\n",
            "Sample 757: Q: which year did the grey bar had the less sales? | GT: 2013 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the data...\". Do not say \"The chart\n",
            "Sample 758: Q: what is the addition of the blue bar in the year 2010 and 2012 | GT: 10 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 759: Q: which age group had the highest number of yes | GT: 18-34 years | Pred:  Do not make up data. Do not say things like \"based on the chart\" or \"as shown in the chart\". Do not say things like \"the\n",
            "Sample 760: Q: what is the number of yes subtracted from the first age group and the last age group? | GT: 6 | Pred:  The chart is as follows: \n",
            "Age Group | Number of Yes\n",
            "--- | ---\n",
            "18-24 | 10\n",
            "25-34\n",
            "Sample 761: Q: When did sales of beer lowest? | GT: 2010/11 | Pred:  Make sure to follow the format: Q: When did sales of beer lowest? A: [answer]\n",
            "\n",
            "Q: When did sales of beer lowest? A:\n",
            "Sample 762: Q: what is the difference in sales of beer in the year 2013 and 2011 | GT: 0.5 | Pred:  The chart shows the sales of beer in the years 2011 and 2013. In 2011, the sales of\n",
            "Sample 763: Q: which year  has the highest single | GT: 2018 | Pred:  Do not make up data or invent information. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year |\n",
            "Sample 764: Q: what is the sum of the highest and smallest number of the single  in all the year | GT: 77.8 | Pred:  Do not make up data. Do not say things like \"based on the chart\" or \"from the chart\". Do not say things like \"I don't\n",
            "Sample 765: Q: Which year has the maximum percentage of people with age group 0-14 ? | GT: 2010 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The year with the maximum percentage...\". Do not say \"\n",
            "Sample 766: Q: What is the difference between maximum percentage of people of age group 15-64 and minimum percentage of people of age group 0-14 over the years? | GT: 52.13 | Pred:  The chart has the following columns: Year, Age group 0-14, Age group 15-64, Age group 65 and\n",
            "Sample 767: Q: How much percentage of males in chins smoked in the year 2014? | GT: 49.2 | Pred:  The chart shows the percentage of males and females who smoked in various years.\n",
            "\n",
            "In 2014, the percentage of males who smoked was 20\n",
            "Sample 768: Q: In which year the difference between the male and female who smokes in China is minimum? | GT: 2016 | Pred:  The chart shows the number of males and females who smoke in China from 1990 to 2010.\n",
            "\n",
            "1990: M\n",
            "Sample 769: Q: How much percentage of Apple Pay payments are already accepted as of December 2018? | GT: 50 | Pred:  The chart shows the percentage of Apple Pay payments accepted in various countries as of December 2018.\n",
            "\n",
            "Country | Percentage of Apple Pay payments accepted\n",
            "---\n",
            "Sample 770: Q: What is the difference between the minimum already accepted payment method and maximum accept within 2 years method? | GT: 19 | Pred:  The chart has the following columns: Year, Minimum already accepted payment method, Maximum accept within 2 years method.\n",
            "\n",
            "Year | Minimum already accepted payment method | Maximum\n",
            "Sample 771: Q: What is the percentage of avid male sports fans? | GT: 39 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Age Group | Female | Male | Total |\n",
            "\n",
            "Sample 772: Q: What is the difference between minimum percentage of male and maximum percentage of female sports fans? | GT: 32 | Pred:  The chart has the following columns: Country, Male Fans (%), Female Fans (%), Total Fans (%). \n",
            "\n",
            "Country | Male Fans (%) | Female Fans (%) |\n",
            "Sample 773: Q: What is the largest growth segment for Revenue share between 2009 and 2020? | GT: Outdoor/Fitness | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "The largest growth segment for Revenue share between 20\n",
            "Sample 774: Q: What is the average growth in Aviation between 2012 and 2013? | GT: 12 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 775: Q: Which is the most famous cross platform mobile framework used by developers? | GT: React Native | Pred:  Each row in the chart represents a different option. The first column is the option name. The remaining columns are platforms. True means the framework supports the platform,\n",
            "Sample 776: Q: What is the percentage  difference between the highest Flutter users and the minimum Dojo users over the years? | GT: 38 | Pred:  Assume all values in the chart are in millions. \n",
            "\n",
            "Chart: \n",
            "Year | Flutter Users (millions) | Dojo Users (millions)\n",
            "--- |\n",
            "Sample 777: Q: Whats the percentage of in sexy attire for those 13-20 year old in movies? | GT: 37.3 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: None\n",
            "Answer\n",
            "Sample 778: Q: What's the total percentage of sexy attire for those 13-20 year old in movies? | GT: 37.3 | Pred:  Do not make up data. If information is not available in the chart, say so.\n",
            "\n",
            "Chart content: None\n",
            "Answer: Information not available in the chart.\n",
            "Sample 779: Q: Which age group is \"very likely\" to subscribe to Disney's new online video streaming service? | GT: 30-44 | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Do not make up information. Do not say \"Based\n",
            "Sample 780: Q: Which age group has the minimum difference between \"Not likely at all\" and \"Very likely\" to subscribe to Disney's new online video streaming service? | GT: 65+ | Pred:  The chart has the following columns: Age Group, % Not likely at all, % Likely, % Very likely. \n",
            "\n",
            "| Age Group | % Not likely at\n",
            "Sample 781: Q: What is the median weekly earnings of a full time wage and salary worker in 2020 in the US who has a Bachelors's Degree and is male? | GT: 990 | Pred:  Do not make up data or statistics. If the data is not available in the chart, you must say so. The chart is: 2020\n",
            "Sample 782: Q: For which of the degrees is there the biggest gap between the median weekly earnings of full-time wage and salary workers in 2020 in the US? | GT: Some college or associate's degree | Pred:  The chart shows the median weekly earnings of full-time wage and salary workers in 2020 in the US by degree. The degrees are: no degree\n",
            "Sample 783: Q: What percentage of people were employed in agriculture in 2015? | GT: 18.01 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Thought: The chart does not contain\n",
            "Sample 784: Q: How many more people were employed in services than in agriculture in 2020? | GT: 48.62 | Pred:  Assume all values in the chart are in thousands. \n",
            "\n",
            "Chart: \n",
            "Year | Agriculture | Services | Manufacturing\n",
            "--- | --- | --- | ---\n",
            "201\n",
            "Sample 785: Q: What was the total population of women in 2018? | GT: 99.64 | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "| Year | Men (in thousands) | Women (in thousands) |\n",
            "|------|--------------------|----------------------|\n",
            "|\n",
            "Sample 786: Q: How many more men were there than women in 2018? | GT: 2.6 | Pred:   Chart cells are separated by tabs, rows and columns are terminated by newlines.\n",
            "1990\t1995\t2000\t\n",
            "Sample 787: Q: What was the 3rd most popular item in 2013? | GT: Shoes | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". The\n",
            "Sample 788: Q: What was the difference in the popularity of Clothes from 2013 to 2014? | GT: 0 | Pred:  The chart shows the popularity of different types of clothes in 2013 and 2014. In 2013, the popularity\n",
            "Sample 789: Q: What year was the price of germanium metal the highest? | GT: 2014 | Pred:  Each row in the chart represents a year, and each column represents a price in US dollars per kilogram. The chart shows the price of germanium metal over\n",
            "Sample 790: Q: What was the difference in price for germanium metal and germanium dioxide in 2020? | GT: 280 | Pred:  The chart has the following columns: Year, Germanium Metal (USD/lb), Germanium Dioxide (USD/lb). 2020,\n",
            "Sample 791: Q: What is the percentage of households with Stand-alone air conditioning in Canada in 2015? | GT: 18 | Pred:  The chart shows the percentage of households with different types of air conditioning in Canada in 2015.\n",
            "Answer: 33% of households in Canada\n",
            "Sample 792: Q: Which year has the minimum difference between the percentage of households with central air conditioning and Stand-alone air conditioning? | GT: 2013 | Pred:  The chart shows the percentage of households with central air conditioning and stand-alone air conditioning in the United States from 1970 to 2010\n",
            "Sample 793: Q: Which tour operators in Europe had highest revenue in 2014? | GT: TUI | Pred:  Do not make up data. If a chart is not provided, say \"Chart not provided.\"\n",
            "\n",
            "Chart not provided.Human: Which tour operators in Europe had\n",
            "Sample 794: Q: What is the difference between highest revenue of Thomas cook and lowest revenue of Kuoni  over the years ? | GT: 6.6 | Pred:  The chart shows the annual revenue of Thomas Cook and Kuoni from 2010 to 2018. The highest revenue of Thomas Cook is\n",
            "Sample 795: Q: What is the percentage share of children participating in gym, gymnastics, trampolining or climbing frame in the last 4 weeks in England in the year 2016 among 11-15 year olds? | GT: 30.4 | Pred:  The chart shows the percentage share of children participating in gym, gymnastics, trampolining or climbing frame in the last 4 weeks in England in the\n",
            "Sample 796: Q: What is the difference in the percentage between the share share of children participating in gym, gymnastics, trampolining or climbing frame in the last 4 weeks in England among 5-10 year olds between the years 2012 and 2013? | GT: 2 | Pred:  The chart shows the share of children participating in gym, gymnastics, trampolining or climbing frame in the last 4 weeks in England among 5\n",
            "Sample 797: Q: What is the average of all the light blue bars? | GT: 6.83 | Pred:  Chart cells are separated by tabs, rows are separated by new lines.\n",
            "Bar 1\tBar 2\tBar 3\tBar 4\tBar \n",
            "Sample 798: Q: Which year(s) had the greatest difference between the soft drink price and hot dog price? | GT: [2010/11, 2011/12, 2012/13] | Pred:  The chart shows the price of a soft drink and a hot dog at various years.\n",
            "\n",
            "Year | Soft Drink Price | Hot Dog Price\n",
            "--- | --- | ---\n",
            "\n",
            "Sample 799: Q: Are all the grey bars below 30%? | GT: No | Pred:  Question: Are all the grey bars below 30%? Chart: 30% 40% 50% 60% \n",
            "Sample 800: Q: What is the percent average of the respondents not being a fan at all across all age groups? | GT: 28 | Pred:  The chart has the following columns: Age Group, 18-24, 25-34, 35-44, \n",
            "Sample 801: Q: What age group was most in favor if repealing the 8th amendment? | GT: 25-34 | Pred:  The chart has the following columns: Age Group, Percentage in Favor of Repealing the 8th Amendment, Percentage in Favor of Keeping the 8th\n",
            "Sample 802: Q: How many more people in the 50-64 group refused to vote than the 35-49 group? | GT: 3 | Pred:  The chart shows the number of people who refused to vote in each age group. The age groups are: 18-24, 25-\n",
            "Sample 803: Q: What is the percentage of art buyers who bought art online in 2020? | GT: 67 | Pred:  The chart shows the percentage of art buyers who bought art online in 2020. The chart has the following data: 20% of art\n",
            "Sample 804: Q: What is the average percentage of art buyers who bought art online from 2018 to 2019? | GT: 43.5 | Pred:  The chart shows the percentage of art buyers who bought art online in 2018 and 2019. In 2018,\n",
            "Sample 805: Q: what is the highest value in blue bar ? | GT: 47 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 806: Q: What is the sum of highest value and lowest value of blue bar ? | GT: 59 | Pred:  Chart: 10000000000000000000000000000\n",
            "Sample 807: Q: What is the Agriculture percentage in 2015 | GT: 7.94 | Pred:  Chart cells are separated by tabs, rows and columns are separated by new lines.\n",
            "1990\t1995\t2000\t2\n",
            "Sample 808: Q: What is the difference between Agriculture and industry in 2020 | GT: 17.21 | Pred:  Do not make up data. Do not say things like \"based on the chart\" or \"as shown in the chart\". Do not say things like \"the\n",
            "Sample 809: Q: The shortest light blue bar minus the tallest grey bar yields what value?? | GT: 545 | Pred:  Assume all values are in inches.\n",
            "\n",
            "Chart:\n",
            "|  | A | B | C | D | E |\n",
            "| --- | --- | --- | --- | ---\n",
            "Sample 810: Q: Is the sum of all the  WarnerMedia's global revenue for advertising from 2018 to 2019? | GT: 6896 | Pred:  The chart is: 2018 2019 2020 2021 2022 20\n",
            "Sample 811: Q: Which gender distribution of passengers is highest in Luton? | GT: Male | Pred:  The chart shows the gender distribution of passengers in Luton.\n",
            "\n",
            "Answer: The gender distribution of passengers in Luton is not provided in the chart. Answer\n",
            "Sample 812: Q: What is the average of males in Gatwick and Stansted? | GT: 52 | Pred:  The chart shows the number of males and females in different airports. Gatwick has 100 males and 150 females. Stansted has \n",
            "Sample 813: Q: In which year the sales of dietary supplements was  minimum? | GT: 2014 | Pred:  The chart shows the sales of dietary supplements in different years. The sales are given in millions of dollars. \n",
            "\n",
            "Year | Sales (in millions)\n",
            "--- | ---\n",
            "\n",
            "Sample 814: Q: What is the difference between minimum dietary supplements sold over the years and maximum tonics sold over the years? | GT: 37.6 | Pred:  The chart has the following columns: Year, Minimum Dietary Supplements (in millions), Maximum Tonics (in millions). \n",
            "\n",
            "Year | Minimum Dietary Supplements (in millions\n",
            "Sample 815: Q: Which has the least wholesale unit sales in the U.S overall? | GT: Smart home controllers | Pred:  Do not make up data. Do not say \"The chart shows\". Do not say \"Based on the chart\". Do not say \"According to the chart\".\n",
            "Sample 816: Q: What is the average wholesale unit devices of Smart home devices? | GT: 27.85 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 817: Q: Which color does men indicate in the graph? | GT: light blue | Pred:  The chart shows the distribution of men and women in different age groups. The age groups are 20-29, 30-39,\n",
            "Sample 818: Q: What is the difference between the lowest in men and women? | GT: 7.5 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\".\n",
            "\n",
            "The difference between the lowest\n",
            "Sample 819: Q: Which gender has the highest life expectancy? | GT: female | Pred:  Chart: \n",
            "| Gender | Life Expectancy (years) |\n",
            "|--------|-------------------------|\n",
            "| Male   | 76                      |\n",
            "| Female | \n",
            "Sample 820: Q: What is the average life expectancy of female from 2015 to 2018? | GT: 67.83 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average life expectancy of female from \n",
            "Sample 821: Q: What is the value of the highest bar in the chart ? | GT: 5.9 | Pred:  Do not make up data. Do not say \"insufficient information\". The chart shows the number of students in each grade level at Lincoln High School. \n",
            "\n",
            "Grade\n",
            "Sample 822: Q: What is the total value of 13-17 years old who using Facebook ? | GT: 1.6 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 823: Q: How much did Peter Dinklage earn both by net worth and earnings per episode? | GT: 16.05 | Pred:  The chart is as follows: | Name | Net Worth (USD) | Earnings per Episode (USD) |\n",
            "| --- | --- | --- |\n",
            "| Peter\n",
            "Sample 824: Q: What is the average of net worth of the first three actors in the graph? | GT: 15 | Pred:  The chart is as follows:  | Name | Net worth (in millions) |  |  |  |  |  |  |  | \n",
            "Sample 825: Q: What does the light blue color indicate? | GT: Beer* | Pred:  Do not make up information. Do not say anything like \"Based on the chart...\" or \"According to the chart...\". The chart is: 1.\n",
            "Sample 826: Q: What is the average of Hot dog? | GT: 4.625 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Item | Price |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 827: Q: How many new cancer cases are there in male ? | GT: 970250 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 828: Q: What is the difference between the genders in the all category? | GT: 1289590 | Pred:  Do not make up data. Table cells in the same row are seperated by '|', and each row corresponds to a category. The first row in the table\n",
            "Sample 829: Q: How many payment methods are considered in the graph? | GT: 5 | Pred:  The chart shows the number of transactions for different payment methods in a month.\n",
            "\n",
            "| Payment Method | Number of Transactions |\n",
            "|----------------|------------------------|\n",
            "| Credit Card\n",
            "Sample 830: Q: What is the average of cash payments? | GT: 38.5 | Pred:  Table cells in the chart are separated by tabs, and each row is on a new line. The first row contains the table header. Each data point is unique\n",
            "Sample 831: Q: In which year the white members were maximum? | GT: 1995 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "Year | White Members | Black\n",
            "Sample 832: Q: In which year the difference between white and black members is maximum? | GT: 2010 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the number of white and black members in a club from 1\n",
            "Sample 833: Q: The shortest light blue bar minus the tallest dark blue bar yields what value? | GT: 17 | Pred:  Do not make up data. Do not say \"based on the chart\". The chart has the following data: \n",
            "|   | A | B | C |\n",
            "Sample 834: Q: What is the difference between the highest and the lowest respondents who were satisfied with their sex life in the  United Kingdom (UK) in 2017 for male? | GT: 17 | Pred:  The chart shows the percentage of respondents who were satisfied with their sex life in the United Kingdom (UK) in 2017 for males and females.\n",
            "Sample 835: Q: What's the Economic growth forecast after the COVID-19 outbreak in Denmark in 2020? | GT: 1.5 | Pred:  The chart shows the GDP growth rate of Denmark from 2010 to 2020. The GDP growth rate in 2020\n",
            "Sample 836: Q: What's the total Economic growth forecast after the COVID-19 outbreak in Denmark in 2020 | GT: 2.5 | Pred:  Do not make up data.\n",
            "\n",
            "The total Economic growth forecast after the COVID-19 outbreak in Denmark in 2020 was -3.1%.\n",
            "\n",
            "\n",
            "Sample 837: Q: What is the highest share in 2013? | GT: 75.9 | Pred:  Chart: 2013 2014 2015 2016 2017 2018\n",
            "Sample 838: Q: What is the difference of shares of Private motor insurers? | GT: 4 | Pred:  Table cells in the chart are separated by tabs, and each row in the table contains one item of data. Table:\n",
            "|  | 2018\n",
            "Sample 839: Q: What is the second lowest bar value in the blue bar? | GT: 59 | Pred:  Do not make up data. Do not say \"Insufficient data\". The following chart is provided: 2020-2021: \n",
            "Sample 840: Q: Find  the sum of the value between 50 to 60 in the chart. | GT: 112 | Pred:  Chart: 50 51 52 53 54 55 56 57 58 59\n",
            "Sample 841: Q: What is the lowest value in dark blue bar? | GT: 21 | Pred:  Do not make up information. Do not say I cannot answer this question. The chart shows the number of students in each grade level at Lincoln High School. \n",
            "\n",
            "\n",
            "Sample 842: Q: What is the total of japan bar? | GT: 29 | Pred:  Do not make up data. Do not say \"insufficient information\". Do not say \"I cannot tell\". Do not say \"not enough information\". Do not\n",
            "Sample 843: Q: How many Non blacks have no opinion? | GT: 18 | Pred:  The chart has the following columns: Race, Opinion, Number of people. \n",
            "Race: Black, Opinion: Yes, Number of people: 100\n",
            "Sample 844: Q: Which race has the highest value? | GT: Blacks | Pred:  Each row in the chart represents a different race. The chart has the following columns: Race, Number of people, Percentage of total.\n",
            "Answer: The race with\n",
            "Sample 845: Q: Which year have blue bar with value 71.7? | GT: 2015 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Blue bar with value 71.7 is in\n",
            "Sample 846: Q: What is the sum of the 2012 two bars? | GT: 66.4 | Pred:  Assume all values in the chart are in whole numbers.\n",
            "\n",
            "Chart:\n",
            "| Bar | Length (cm) | Width (cm) | Height (cm) |\n",
            "|\n",
            "Sample 847: Q: Which year the blue bar is above 5? | GT: 2020 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart\". Do not say \"Looking at the\n",
            "Sample 848: Q: What is the sum of all blue bars? | GT: 18.93 | Pred:  Do not make up data. Do not say \"insufficient information\". Do not say \"I cannot tell\". Do not say \"not enough information\". Do not\n",
            "Sample 849: Q: Which category have the highest value of blue bar? | GT: Pollution of drinking water | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The category with the highest value of blue bar is...\".\n",
            "Sample 850: Q: what is sum of the value in extinction of plants and animal species? | GT: 79 | Pred:  Each row in the chart represents a single data point. The first column is the category, the second column is the value. \n",
            "\n",
            "Category\tValue\n",
            "Extinction of\n",
            "Sample 851: Q: What is the highest percentage in the blue line? | GT: 58 | Pred:  Chart cells are separated by tabs, rows are separated by new lines.\n",
            "Line 1: 2010\t2011\t201\n",
            "Sample 852: Q: What is the difference between first and last data in black line (somewhat concerned)? | GT: 13 | Pred:  Table cells in a row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Date | Open | High | Low | Close\n",
            "Sample 853: Q: What is the blue bar value in 2020? | GT: 716.55 | Pred:  The chart has the following columns: Year, Blue Bar Value, Red Bar Value, Green Bar Value.\n",
            "Year: 2015, 20\n",
            "Sample 854: Q: What is the average of 2019 and 2020 blue bar? | GT: 711.92 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Average of 2019 and \n",
            "Sample 855: Q: What is the highest value in dark blue bar? | GT: 240 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 856: Q: What is the sum of first data and last data in the chart? | GT: 247 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot tell\". Do not say \"Not enough information\". Do not\n",
            "Sample 857: Q: What is the sum of the two smallest bars? | GT: 30 | Pred:  The chart has the following data: \n",
            "Bar 1: 30\n",
            "Bar 2: 40\n",
            "Bar 3: 50\n",
            "\n",
            "Sample 858: Q: What is the difference between the largest and the smallest navy blue bar? | GT: 49 | Pred:  The chart has the following columns: Color, Length (inches), Width (inches), Height (inches). The chart has the following rows: Navy\n",
            "Sample 859: Q: What percentage is shown by navy blue bar? | GT: 50 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The percentage is\". Do not say \"According to the chart\n",
            "Sample 860: Q: What is the average value of male and female reason? | GT: 46 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Reason | Male\n",
            "Sample 861: Q: Which device has the least traffic? | GT: Tablet | Pred:  Table cells in a row are seperated by tabs, and different rows are new lines. Assume the value is missing if the header doesn't exist.\n",
            "\n",
            "header:\n",
            "Sample 862: Q: Which year has the maximum traffic of smartphones? | GT: 2017 | Pred:  The chart shows the number of smartphones sold in different years.\n",
            "\n",
            "Year | Number of Smartphones Sold (in millions)\n",
            "--- | ---\n",
            "2015 | \n",
            "Sample 863: Q: How many millennial are Aware(net)? | GT: 91 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 864: Q: What is the sum of the people of Boomers and Generation X who have used this service? | GT: 22 | Pred:  The chart shows the number of people in each generation who have used a certain service. \n",
            "\n",
            "| Generation | Number of people |\n",
            "|-----------|------------------|\n",
            "|\n",
            "Sample 865: Q: What is the highest value of the light blue bar? | GT: 4.2 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 866: Q: What is the value of shortest light blue bar? | GT: 2.5 | Pred:  Table cells in the chart are separated by tabs, and each row is on a new line. Table:\n",
            "|  | A | B | C | D |\n",
            "Sample 867: Q: In 18-29 age group, what is the percentage value of very interested respondents? | GT: 13 | Pred:  Your answer must be a number between 0 and 100.\n",
            "\n",
            "100\n",
            "\n",
            "In 18-29 age group, the percentage of\n",
            "Sample 868: Q: What is the difference between highest and lowest value of red bar? | GT: 15 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: What is the difference between highest and lowest value\n",
            "Sample 869: Q: How man years does the graph represent? | GT: 11 | Pred:  Do not make up information. Do not say I cannot answer this question. Do not say the chart is missing. Do not say the chart is not provided.\n",
            "Sample 870: Q: What is the average from 2010 to 2015 in import value? | GT: 361048.33 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that question\". Do not say \"The chart does not\n",
            "Sample 871: Q: Which color represents the navy blue line? | GT: Male | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The navy blue line is represented by...\". Do not say\n",
            "Sample 872: Q: What is the sum of total in year, 2017 and 2018? | GT: 21.14 | Pred:  Do not make up data. Do not say \"insufficient information\". Do not say \"I cannot tell\". Do not say \"not enough information\". Do not\n",
            "Sample 873: Q: Find out which category shows 1.8, 2 ,2.3 in the chart 2017,2018,2019 respectively? | GT: Heart | Pred:  Chart: 2017 2018 2019 2020 2021 2022\n",
            "Sample 874: Q: Find the average of all the bars in Kidney category? | GT: 9.2 | Pred:  The chart has the following columns: Category, Bar 1, Bar 2, Bar 3, Bar 4, Bar 5, Bar 6\n",
            "Sample 875: Q: How many respondents are not sure? | GT: 29 | Pred:  Each row in the chart represents a different category. Each column represents a different response option. The first column contains the category names. The first row contains the response\n",
            "Sample 876: Q: What is the value of the highest bar? | GT: 42 | Pred:  Do not make up data. Do not say \"Insufficient data\". \n",
            "\n",
            "Bar chart: \n",
            "- X-axis: Days of the week (Monday, Tuesday,\n",
            "Sample 877: Q: Which color does light blue indicate? | GT: Male | Pred:  Do not make up information. Do not say things like \"Based on the chart...\" or \"According to the chart...\". The chart is: \n",
            "| Color\n",
            "Sample 878: Q: For which social network, the percentage is minimum between male and female? | GT: Twitter | Pred:  Assume all values in the chart are in percentage. \n",
            "\n",
            "Chart: \n",
            "| Social Network | Male (%) | Female (%) |\n",
            "|---------------|----------|------------|\n",
            "|\n",
            "Sample 879: Q: Which skin  has a least difference between male and female? | GT: Other nonepithelial skin | Pred:  Do not make up information. Do not say \"Based on the chart...\". \n",
            "\n",
            "Chart:\n",
            "| Skin Type | Male | Female |\n",
            "| --- | --- |\n",
            "Sample 880: Q: What is the average number of skin cancers in male? | GT: 34060 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. If the data is not available in the chart, say\n",
            "Sample 881: Q: which justice has highest very favorable percentage? | GT: Ruth Bader Ginsburg | Pred:  The chart has the following columns: Justice, Very Favorable, Favorable, Slightly Favorable, Unfavorable, Very Unfavorable. \n",
            "\n",
            "Justice\n",
            "Sample 882: Q: What's the percentage of people that are at least somewhat favorable toward Brett Kavanaugh? | GT: 32 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot determine from the chart\". \n",
            "\n",
            "Chart:\n",
            "Sample 883: Q: Which year has a value of above 20000? | GT: 2028 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 884: Q: What is the total spending in Medicaid? | GT: 28728 | Pred:  The chart has the following columns: Year, Total Spending (in billions), Total Spending (in billions), Total Spending (in billions), Total Spending (in billions\n",
            "Sample 885: Q: What is the value of dark blue bar in 2015? | GT: 10832 | Pred:  The chart has the following columns: Year, Red, Orange, Yellow, Green, Blue, Purple, Dark Blue. The chart has the following rows: \n",
            "Sample 886: Q: What is the sum of blue bar of 2008 and 2015? | GT: 157073 | Pred:  Do not make up data. Do not say \"insufficient information\". The chart shows the number of blue bars in different years. In 2008\n",
            "Sample 887: Q: How many color bars shown in the chart? | GT: 5 | Pred:  Each cell in the chart contains a number. The numbers represent the number of items of a certain color. The colors are: red, green, blue, yellow\n",
            "Sample 888: Q: Subtract the value of green bar from red bar in the judges and politicians category and sum the result? | GT: 26 | Pred:  The chart has the following columns: category, subcategory, red bar, green bar. Here is the chart:\n",
            "category: judges and politicians, subcategory:\n",
            "Sample 889: Q: Which is highest percentage value in green bar? | GT: 33 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 890: Q: What is the difference between highest blue bar and highest green bar? | GT: 28 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". The chart\n",
            "Sample 891: Q: How many dark blue bar crossed 50 mark? | GT: 2 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Question: How many dark blue bar crossed \n",
            "Sample 892: Q: What is the difference between two bars in For clarity category? | GT: 39 | Pred:  Avoid making things up. If information is not available in the chart, say so.\n",
            "\n",
            "The chart does not contain information about the \"For clarity category\" or any\n",
            "Sample 893: Q: Which category has value of 30% in 2017/18? | GT: 11-15 years | Pred:  Chart cells that are blank are empty.\n",
            "| Category | 2015/16 | 2016/17 | 20\n",
            "Sample 894: Q: What is the difference between the ages in 2014/15? | GT: 21.2 | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "2014/15 | 2015/16 | 2016/1\n",
            "Sample 895: Q: What is the value of frozen fruits? | GT: 24 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Item | Price |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 896: Q: What is the total value of fresh and shelf-stable vegetables? | GT: 42 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 897: Q: Which region the females value shows 10.4 and males value as 3.8? | GT: London | Pred:  The chart has the following columns: Region, Female Value, Male Value.\n",
            "Answer: The region where females value is 10.4 and males value is\n",
            "Sample 898: Q: What is the average  of females value in the first five region,  from Yorkshire and the humber to south west? | GT: 9.8 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". The chart is: Region\n",
            "Sample 899: Q: Find the lowest value in the dark blue bar? | GT: 130 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 900: Q: What is the average of last 3 year in Danish citizenship? | GT: 1972 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Average of last 3 year in Danish citizenship\n",
            "Sample 901: Q: How much is the e commerce sales for companies under 50 employees in 2019? | GT: 35.6 | Pred:  The chart shows the e commerce sales for companies under 50 employees in 2019. The e commerce sales for companies under 50 employees\n",
            "Sample 902: Q: How much is the e commerce sales for companies under 250 employees in 2019? | GT: 83.4 | Pred:  The chart shows the e commerce sales for companies under 250 employees in 2019. The e commerce sales for companies under 25\n",
            "Sample 903: Q: What is the percentage share of Industry in GDP in 2015? | GT: 13.65 | Pred:  The chart has the following columns: Year, Agriculture, Industry, Services. The chart has the following rows: 2015, 201\n",
            "Sample 904: Q: What is the difference between highest and lowest agriculture share? | GT: 12.3 | Pred:  The chart has the following columns: Country, Agriculture share (%), Industry share (%), Services share (%). \n",
            "\n",
            "Country\tAgriculture share (%)\tIndustry share (%)\n",
            "Sample 905: Q: What is the prevelance of dietary supplements in men of age group 31-50 between 2003 and 2006 in the US? | GT: 44 | Pred:  The chart shows the prevalence of dietary supplements in men aged 31-50 in the US between 2003 and 2006\n",
            "Sample 906: Q: What is the average prevelance of dietary supplements in people of age group 19-30 between 2003 and 2006 in the US? | GT: 39.5 | Pred:  The chart shows the average prevalence of dietary supplements in people of age group 19-30 between 2003 and 2006\n",
            "Sample 907: Q: What is the biggest value among all the bars? | GT: 37 | Pred:  Do not make up data. Do not say things like \"The biggest value is...\" or \"The answer is\". Just give the value.\n",
            "\n",
            "100\n",
            "\n",
            "Sample 908: Q: What is the difference between the modes of Somewhat interested and that of Don't know? | GT: 27 | Pred:  If the question cannot be answered from the chart, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: \n",
            "| Mode | Description |\n",
            "|------|-------------|\n",
            "| Som\n",
            "Sample 909: Q: What is the number of viewers in 2005? | GT: 8.1 | Pred:  The chart has the following columns: Year, Viewers (in millions), Revenue (in millions). The chart has the following rows: 2000\n",
            "Sample 910: Q: What is the difference between the rating and viewers in 2013? | GT: 3.4 | Pred:  The chart has the following columns: Year, Rating, Viewers (in millions).\n",
            "Answer: The difference between the rating and viewers in 2013\n",
            "Sample 911: Q: Which sector is largest in 2021? | GT: TLC network systems | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the distribution of the economy by sector in 2021\n",
            "Sample 912: Q: What is the market size of top 3 sectors in 2021? | GT: 51.2 | Pred:  The chart shows the market size of the top 3 sectors in 2021.\n",
            "Answer: The market size of the top 3 sectors in \n",
            "Sample 913: Q: Which generation enjoy social media the least? | GT: Boomers | Pred:  Do not make up data. If the chart does not contain enough information to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: \n",
            "| Generation |\n",
            "Sample 914: Q: What's the percentage of boomers who never use social media? | GT: 48 | Pred:  Do not make up data. If the chart does not contain the information, say so.\n",
            "\n",
            "The chart does not contain the information. Final answer: Cannot determine.\n",
            "Sample 915: Q: Identify what is referred  61% and 55%? | GT: Hardware | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"Final Answer\". Do\n",
            "Sample 916: Q: How much percentage points increased in services from 2014 to 2020? | GT: 3.4 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 917: Q: Identify the category in y-axis, where the bar value is 8,5,12,20 %? | GT: Chinese language TV | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The category is...\". Do not say \"The y-axis\n",
            "Sample 918: Q: What is the average all grey bar (2 to 5 hours data)? | GT: 12.4 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Average all grey bar (2 to 5 hours data\n",
            "Sample 919: Q: What is the highest value of Moscow? | GT: Moscow | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Question | Answer |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 920: Q: What is the ratio between sales and average bill in 'Across Russia'? | GT: 0.4333 | Pred:  The chart has the following data: \n",
            "| Region | Sales | Average Bill |\n",
            "|--------|-------|--------------|\n",
            "| Across Russia | 1000\n",
            "Sample 921: Q: In which year there was more usage of internet everyday among individual? | GT: 2019 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the number of internet users per day in millions for various years.\n",
            "Sample 922: Q: what is the sum total of usage of internet every day and  often/sometime among individual in the year 2013 ? | GT: 73 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 923: Q: Which opinion has the least difference between 2011 and 2012? | GT: Important | Pred:  Chart: 2011 2012 2013 2014 2015 2016\n",
            "Sample 924: Q: How many opinions have a percentage of equal or above 20%? | GT: 3 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"From the chart...\". Do not say \"I cannot tell\". \n",
            "\n",
            "Chart\n",
            "Sample 925: Q: Which color shows the highest value? | GT: yellow | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 926: Q: What is the difference between the red and green color? | GT: 4 | Pred:  Do not make up information. If the information is not in the chart, respond with \"Information not available in the chart\". \n",
            "\n",
            "Chart: \n",
            "| Color |\n",
            "Sample 927: Q: In the chart, Lesbian women data shows 28 and gay men data shows 9, find that category? | GT: Dating | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". The\n",
            "Sample 928: Q: Use Gay men data from Dating, Hook up and Entertainment and Find the average of this data ? | GT: 34.66 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with 'Data not available'.\n",
            "\n",
            "Average of Gay men data from Dating\n",
            "Sample 929: Q: Which is the lowest unpaid internships by sector in US? | GT: Government | Pred:  Each row in the chart represents a sector, and each column represents a type of unpaid internship. The values in the cells represent the number of unpaid internships in\n",
            "Sample 930: Q: What is the average unpaid internships ? | GT: 34 | Pred:  Do not make up data or statistics. If the information is not available in the chart, respond with \"Insufficient data in chart to answer the question.\"\n",
            "\n",
            "[\n",
            "Sample 931: Q: What is the highest percentage recorded in Happy with current Hours? | GT: 69 | Pred:  Table cells in the chart are separated by '|', and each row in the chart represents a record. Table header row is labeled with header names.\n",
            "\n",
            "Table:\n",
            "|\n",
            "Sample 932: Q: What is the average of all the blue bar data? | GT: 54.44 | Pred:  Chart cells are separated by tab and new rows by a line break. Each cell contains either a number or a text value. The first row contains the header names\n",
            "Sample 933: Q: Which political party dominated in all the segment ? | GT: Democratic | Pred:  Do not make up data. If the chart does not contain enough information to answer the question, respond with \"Insufficient information\".\n",
            "\n",
            "![](https://i.imgur\n",
            "Sample 934: Q: What is the average percentage of Republican ? | GT: 41.75 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The average is...\". Do not say \"According to the\n",
            "Sample 935: Q: How many bars ( combined) in the chart ? | GT: 12 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"From the chart\n",
            "Sample 936: Q: Find the average of this three factor in Positive data, Medical care, Rights of women and Protection against the Taliban? | GT: 51 | Pred:  If the information is not available in the chart, say so.\n",
            "\n",
            "The chart is not provided.\n",
            "Answer: The information is not available in the chart.Human\n",
            "Sample 937: Q: Which age range has more population than others? | GT: 25-59 years | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 938: Q: In which age range is the gender gap the largest? | GT: 25-59 years | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Age range: 18-\n",
            "Sample 939: Q: Which year does the purple color indicate? | GT: 2019 | Pred:  Make sure to follow the formatting instructions: Question: [question] Answer: [answer] Question: Which year does the purple color indicate? Answer: 2\n",
            "Sample 940: Q: What is the ratio of fixed broadband in the years 2018 and 2019? | GT: 1 | Pred:  Chart: 2018 2019 2020 2021 2022 2023\n",
            "Sample 941: Q: What is the number of Macy's stores  worldwide in the year 2018? | GT: 649 | Pred:  Each cell in the chart is either blank or contains a positive integer. A blank cell means \"missing information\". The chart has the following rows and columns: Row\n",
            "Sample 942: Q: What is the total of Macy's, Bloomingdale's and Bluemercury brand stores worldwide in the 2019? | GT: 839 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Date: 2019\n",
            "| Store Type | North America | Europe | Asia\n",
            "Sample 943: Q: WHich period has the least e-reader owners? | GT: November 2010 | Pred:  Do not make up data. Do not say things like \"Based on the chart...\" or \"From the chart we can see...\". Do not say things like\n",
            "Sample 944: Q: WHat is the total value of 30-49 age group? | GT: 41 | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"The total value is...\n",
            "Sample 945: Q: In which period, there should be a referendum is high ? | GT: Jul 25-26 | Pred:  Do not make up data or statistics. If the information is not in the chart, you should say \"Information not available in the chart\".\n",
            "\n",
            "Question: In which\n",
            "Sample 946: Q: How many periods represent least difference between should and should not? | GT: 3 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Period | Should | Should not | Difference |\n",
            "\n",
            "Sample 947: Q: Which segments has the higher average, general merchandisers or grocers? | GT: General Merchandisers | Pred:  Each row in the chart represents a segment. Each column in the chart represents a metric. The first column is the segment name. The first row is the metric\n",
            "Sample 948: Q: What is the average for general merchandisers? | GT: 46.75 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The average is...\". Do not say \"According to the\n",
            "Sample 949: Q: How many genders have been considered? | GT: 2 | Pred:  Each row in the chart represents a different gender. The chart includes the following columns: Gender, Number of people, Percentage of people, and Notes. \n",
            "Chart\n",
            "Sample 950: Q: What is the average of highest values of male and female? | GT: 70.445 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 951: Q: Which data line experienced the biggest changes across all years? | GT: Europe, Middle East and Africa | Pred:  Data: 2010 2011 2012 2013 2014 2015\n",
            "Sample 952: Q: For North America and Asia Pacific regions, which revenue average across all years is bigger? | GT: North America | Pred:   Chart: \n",
            "Year | North America | Asia Pacific\n",
            "--- | --- | ---\n",
            "2015 | 100 | 120\n",
            "\n",
            "Sample 953: Q: Are the bars sorted in increasingly or decreasingly from left to right? | GT: decreasing | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Question: Are the bars sorted in increasingly or decreasingly\n",
            "Sample 954: Q: Which two firms have above 90 billion U.S. dollars total revenue? | GT: [Deloitte, PwC] | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"From the\n",
            "Sample 955: Q: Which sector has the tallest bars in all years? | GT: Services | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The sector with the tallest bars in all years is...\".\n",
            "Sample 956: Q: In which year the GDP of the services sector was maximum and the GDP of the Industry was minimum? | GT: 2019 | Pred:  Do not make up data. Do not say things like 'Based on the chart...'. Just give the year.\n",
            "\n",
            "1991 1992\n",
            "Sample 957: Q: Which viewer type does of the upper bar in the stacked bars represent? | GT: Occasional viewers | Pred:  Do not use abbreviations. Do not say I cannot answer this question. Do not say based on the chart. Do not say in the chart. Do not\n",
            "Sample 958: Q: In how many years the number of eSports enthusiasts is above 200 in this graph? | GT: 3 | Pred:  The chart shows the number of eSports enthusiasts (in millions) from 2010 to 2019.\n",
            "Answer: 10 years.\n",
            "Sample 959: Q: What's the color of the tallest bar in this graph? | GT: Red | Pred:  Do not make up data. Do not say I cannot answer that question. Do not say based on the chart. Do not say from the chart. Do not\n",
            "Sample 960: Q: On average, which candidate had the lowest share of votes among all the military personnel in this graph? | GT: Hillary Clinton | Pred:  The chart shows the number of votes each candidate received from military personnel in a recent election.\n",
            "\n",
            "Answer: To determine which candidate had the lowest share of votes among all\n",
            "Sample 961: Q: Who portrayed Jon Snow? | GT: Kit Harington | Pred:  Each row in the chart represents a different person. The first column is the name of the person, the second column is their profession, and the third column is\n",
            "Sample 962: Q: Who played Mother of Dragons Daenerys Targaryen? | GT: Emilia Clarke | Pred:  Each row in the chart represents a different person. The first column is the name of the person, the second column is their profession, and the third column is\n",
            "Sample 963: Q: What was the estimated net worth of Peter Dinklage and Nikolaj Coster-Waldau? | GT: 16 | Pred:  The chart is as follows: | Name | Net Worth (USD) |\n",
            "| --- | --- |\n",
            "| Peter Dinklage | 10 million |\n",
            "|\n",
            "Sample 964: Q: What is the most popular cross-platform mobile framwork used by global developers? | GT: React Native | Pred:  Each row in the chart represents a different option. The first column is the option name. The remaining columns are the number of developers using that option, with each\n",
            "Sample 965: Q: When did the population of the Dominican Republic begin to increase? | GT: 2008 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart\n",
            "Sample 966: Q: What was the population of the Dominican Republic in 2018? | GT: 10.63 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Population of the Dominican Republic by year\n",
            "Sample 967: Q: Which Supreme Court justice did 32 percent of respondents not know if they had a favorable or unfavorable opinion of? | GT: Brett Kavanaugh | Pred:  Do not make up information. Do not say I cannot answer the question or I don't have information. If the chart does not contain the necessary information, respond\n",
            "Sample 968: Q: When did the population of Antigua & Barbuda begin to increase? | GT: 2008 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Antigua & Barbuda\n",
            "Sample 969: Q: How many Macy's branded stores did Macy's operate in 2020? | GT: 572 | Pred:  Each row in the chart represents a year. The first column is the year, the second column is the number of Macy's branded stores, and the third column\n",
            "Sample 970: Q: How many Bluemercury stores did Macy's operate in 2020? | GT: 162 | Pred:  Each row in the chart represents a different store. The first column is the store name, the second column is the city, the third column is the state,\n",
            "Sample 971: Q: What was the average ticket in general merchandisers and grocers during the week of February 25 to March 2, 2020? | GT: 53 | Pred:  The chart shows the average ticket in general merchandisers and grocers during the week of February 25 to March 2, 2020\n",
            "Sample 972: Q: What was the average transaction value in grocers in prior weeks? | GT: 49 | Pred:  The chart shows the following data: Week 1: Grocers - $120, Week 2: Grocers - $130, Week\n",
            "Sample 973: Q: What was the average transaction value in general merchandisers and grocers in prior weeks? | GT: 46 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|} \\hline \\textbf{\n",
            "Sample 974: Q: How much did a 24 ounce beer cost in the 2012-13 season? | GT: 6.25 | Pred:  The chart shows the price of a 24-ounce beer in the 2012-13 season. The price is $3.0\n",
            "Sample 975: Q: What did the majority of people who immigrated to Greenland in 2020 have? | GT: Danish citizenship | Pred:  Each row in the chart represents a group of people. The first column is the group name. The second column is the number of people in the group. The\n",
            "Sample 976: Q: What does the vast majority of the population of Greenland have? | GT: Danish citizenship | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "The vast majority of the population of Greenland has Inuit\n",
            "Sample 977: Q: What is included in the statistics for people originating from Greenland moving back home to Greenland as well as Danish people born in Denmark moving to | GT: Danish citizenship | Pred:  Do not make up data or statistics. If the chart does not contain the information, respond with \"Information not available in the chart.\"\n",
            "\n",
            "The chart shows the number\n",
            "Sample 978: Q: What is the forecast for the ICT sector in Italy in 2020? | GT: 2022 | Pred:  The chart shows the forecast for the ICT sector in Italy in 2020.\n",
            "Answer: The forecast for the ICT sector in Italy in 20\n",
            "Sample 979: Q: What was the revenue of the software and ICT solutions sector in 2019? | GT: 12.3 | Pred:  The chart shows the revenue of the software and ICT solutions sector in 2019. The revenue of the software and ICT solutions sector in 20\n",
            "Sample 980: Q: What generation was most satisfied with their sex life? | GT: Millennials | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: \n",
            "| Generation\n",
            "Sample 981: Q: What generation was least satisfied with their sex life? | GT: Boomers | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. \n",
            "\n",
            "Chart: \n",
            "| Generation | Satisfaction with Sex Life\n",
            "Sample 982: Q: What percentage of females were satisfied with their sex life in 2017? | GT: 37 | Pred:  Do not make up data. Do not say \"The chart does not show\". Do not say \"I don't know\". Do not say \"Insufficient data\n",
            "Sample 983: Q: What percentage of voters with less than high school education voted for the democratic candidate? | GT: 72 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. The answer must be a number between 0 and \n",
            "Sample 984: Q: How many drug recall enforcement reports did the FDA issue for over-the-counter drugs in 2015? | GT: 39 | Pred:  The chart has the following columns: Year, Over-the-Counter Drug Recall Enforcement Reports, Prescription Drug Recall Enforcement Reports, Total Drug Recall Enforcement Reports. The chart\n",
            "Sample 985: Q: How many drug recall enforcement reports were issued for prescription drugs in 2015? | GT: 195 | Pred:  The chart has the following columns: Year, Type of Drug, Number of Reports, and Type of Enforcement. The chart has the following rows: 20\n",
            "Sample 986: Q: What was the highest rate of thyroid cancer among men in the North East in 2018? | GT: 5.5 | Pred:  Chart cells that are blank are empty. All values are in cases per 100,000 people.\n",
            "\n",
            "North East\n",
            "2018\n",
            "\n",
            "Sample 987: Q: What was the only airport with a noticeable difference in the gender of its passengers? | GT: Heathrow | Pred:  Table cells in the chart are separated by tabs, and each row is a new line.\n",
            "\n",
            "Airport|Male|Female|Total\n",
            "---|---|---|\n",
            "Sample 988: Q: In what year did the popularity of internet connection technologies increase in Great Britain? | GT: 2013 | Pred:  Do not make up information. The chart shows the popularity of internet connection technologies in Great Britain from 1995 to 2005. The\n",
            "Sample 989: Q: Which motorcycle brand offered the greatest profit returns according to dealers? | GT: Harley Davidson | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Chart title: Motorcycle Profit Returns by Brand:\n",
            "| Brand | 2015 |\n",
            "Sample 990: Q: Which tour operator topped the list of Europe's leading tour operators in 2014? | GT: Thomas Cook | Pred:  Do not make up information. If the information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Chart: \n",
            "| Rank | Tour Operator |\n",
            "Sample 991: Q: How much revenue did TUI have in 2012 and 2014? | GT: 18.7 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: \n",
            "201\n",
            "Sample 992: Q: How many smart home devices were sold to dealers in the United States in 2014? | GT: 20.7 | Pred:  The chart has the following columns: Year, Devices Sold to Dealers (in millions), Devices Sold to Consumers (in millions), Devices Sold to Both (in millions\n",
            "Sample 993: Q: Which candidate did 34 percent of military voters vote for? | GT: Hillary Clinton | Pred:  Chart cells that are blank are empty. Table cells in the chart are separated by '|', and rows in the chart are separated by '\n",
            "'.\n",
            "\n",
            "Chart content:\n",
            "|\n",
            "Sample 994: Q: What rating does the 2013 All-Star game have? | GT: 4.6 | Pred:  Chart cells that are blank are empty cells. The chart is as follows: | Year | Rating | | --- | --- | | 2012 |\n",
            "Sample 995: Q: How many homicides occurred in Canada per 100,000 residents in 2019? | GT: 1.8 | Pred:  The chart shows the number of homicides per 100,000 residents in various countries in 2019.\n",
            "Answer: 1.\n",
            "Sample 996: Q: What was the second-most-shared news page on Facebook in January 2017? | GT: CNN | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"According to the data...\". Do not say \"The information\n",
            "Sample 997: Q: How many times was The Daily Mail's video shared on Facebook in January 2017? | GT: 11.13 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "The Daily Mail's video was shared 1\n",
            "Sample 998: Q: How did Belize score in estimated earned income? | GT: 0.56 | Pred:  The chart has the following columns: Country, Estimated Earned Income, Estimated Unearned Income, Estimated Total Income. Belize has Estimated Earned Income of 1\n",
            "Sample 999: Q: What was the average retail price of snowboard boots in specialty shops in the United States in 2015/16? | GT: 179.62 | Pred:  The chart shows the average retail price of snowboard boots in specialty shops in the United States in 2015/16. The average retail price\n",
            "Sample 1000: Q: What online review site did 59 percent of respondents say they had visited to conduct research on a local business? | GT: Yelp | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"One possible answer is\n",
            "Sample 1001: Q: How many seats did Pakatan Harapan win? | GT: 113 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Question: How many seats did Pak\n",
            "Sample 1002: Q: How many road fatalities were there in Portugal in 2007? | GT: 974 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". \n",
            "\n",
            "Data not available in chart.\n",
            "Sample 1003: Q: How many road fatalities were there in Portugal in 2019? | GT: 621 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". \n",
            "\n",
            "Data not available in chart\n",
            "Sample 1004: Q: Where did 42 percent of nickel imports into the U.S. come from between 2016 and 2019? | GT: Canada | Pred:  The chart shows the percentage of nickel imports into the U.S. from different countries between 2016 and 2019.\n",
            "Answer: \n",
            "Sample 1005: Q: What country had the world's largest potash reserves in 2019? | GT: Canada | Pred:  Each row in the chart represents a country and its potash reserves. The column \"Reserves (million metric tons)\" shows the amount of potash reserves in\n",
            "Sample 1006: Q: What percentage of potash reserves did Canada have in 2019? | GT: 27.8 | Pred:  The chart has the following columns: Country, Potash Reserves (%), Potash Production (%), and Potash Exports (%). Canada has a Potash\n",
            "Sample 1007: Q: Who is the most successful actress in the history of the Academy Awards? | GT: Katharine Hepburn | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart content: The chart\n",
            "Sample 1008: Q: What is the deepest lake in Italy? | GT: Lago Maggiore | Pred:  Do not make up information. If the chart does not contain the information, respond with \"Information not available in the chart\".\n",
            "\n",
            "Lake Como\n",
            "Lake Garda\n",
            "\n",
            "Sample 1009: Q: What is the average EUR/PLN exchange rate at the end of 2020? | GT: 4.25 | Pred:  Do not make up data.\n",
            "\n",
            "The average EUR/PLN exchange rate at the end of 2020 was 4.38. 4\n",
            "Sample 1010: Q: What brand generated 59 percent of Kering Group's global revenue in 2020? | GT: Gucci | Pred:  The chart shows the revenue contribution of different brands under the Kering Group in 2020. The chart lists the following brands and their revenue percentages:\n",
            "Sample 1011: Q: What percentage of Kering Group's global revenue did Gucci generate in 2020? | GT: 59 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100% of Kering\n",
            "Sample 1012: Q: When was Kuwait's domestic travel and tourism expenditure first measured? | GT: 2012 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "QUESTION: When was Kuwait\n",
            "Sample 1013: Q: How many Kuwaiti dinars will domestic travel expenditure in Kuwait be by 2028? | GT: 3237.9 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "QUESTION: How many Kuwaiti din\n",
            "Sample 1014: Q: What was the most popular fashion brand on Facebook as of January 2021? | GT: Louis Vuitton | Pred:  Do not make up information. If the information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Information not available in chart\n",
            "Sample 1015: Q: What was the second most popular fashion brand on Facebook in 2021? | GT: Dior | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "The chart does not contain information about the most\n",
            "Sample 1016: Q: How many fans did Louis Vuitton have on Facebook as of January 2021? | GT: 24.07 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Number of fans on Facebook as of January \n",
            "Sample 1017: Q: How many fans did Dior have on Facebook as of January 2021? | GT: 17.64 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Number of fans on Facebook as of January \n",
            "Sample 1018: Q: What was the average hourly earnings for all employees on private nonfarm payrolls in the United States in May 2021? | GT: 30.33 | Pred:  The chart shows the average hourly earnings for all employees on private nonfarm payrolls in the United States in May 2021. The average hourly earnings\n",
            "Sample 1019: Q: Which station was the busiest in the financial year of 2019/20? | GT: Waterloo | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "The busiest station in the financial year of 20\n",
            "Sample 1020: Q: How many Taco Bell stores did Yum! Brands have in Spain at the end of the third quarter of 2020? | GT: 69 | Pred:  Each cell in the table is separated by a tab. Table cells in a row are separated by tabs, and each row is on a new line. Table:\n",
            "\n",
            "Sample 1021: Q: Which accounting firm was the biggest of the Big Four accounting firms in 2020? | GT: Deloitte | Pred:  Each row in the chart represents a different company. Each column in the chart represents a different attribute of the company. The columns are: Company, Revenue (in\n",
            "Sample 1022: Q: What was Deloitte's total revenue in dollars in 2020? | GT: 47.6 | Pred:  Do not make up numbers. Do not say \"Insufficient data\". \n",
            "\n",
            "Chart: \n",
            "| Year | Revenue (in millions) |\n",
            "|------|------------------------\n",
            "Sample 1023: Q: Since what year has the number of freelancers in the U.S. been increasing? | GT: 2014 | Pred:  The chart shows the number of freelancers in the U.S. from 2010 to 2020.\n",
            "Answer: 201\n",
            "Sample 1024: Q: Which liquid soap brand has managed to maintain positive sales growth over the specified time period? | GT: Carex | Pred:  The chart shows the sales growth of various liquid soap brands from 2010 to 2015.\n",
            "\n",
            "- Brand A: 201\n",
            "Sample 1025: Q: What is the projected amount of flash memory capital expenditures in the United States in 2018? | GT: 31.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "The chart shows the projected amount of\n",
            "Sample 1026: Q: What was the market share of cotton socks in Italy in 2016? | GT: 19 | Pred:  The chart shows the market share of different types of socks in Italy in 2016. The chart includes the following data: cotton socks - 3\n",
            "Sample 1027: Q: How much was the internal travel and tourism consumption in the U.S. Virgin Islands in 2013? | GT: 3.24 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Query: How much was the internal\n",
            "Sample 1028: Q: What is the 2019 revenue of the U.S. Virgin Islands tourism industry? | GT: 2.59 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "2019 Revenue (in\n",
            "Sample 1029: Q: What was the net sales share of Capri Holdings' footwear segment in fiscal year 2020? | GT: 19.8 | Pred:  The chart shows the net sales share of each segment of Capri Holdings in fiscal year 2020.\n",
            "\n",
            "The net sales share of Capri Holdings'\n",
            "Sample 1030: Q: As of the third quarter of 2014, Twitter timelines had generated more than how many views? | GT: 180.64 | Pred:  The chart shows the number of views generated by Twitter timelines as of the third quarter of 2014. The chart indicates that Twitter timelines had generated more\n",
            "Sample 1031: Q: What percentage of people infected with the coronavirus were female? | GT: 51.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\". Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1032: Q: What percentage of pet store revenue did shoppers between 45 and 64 account for in 2021? | GT: 45.2 | Pred:  The chart shows the distribution of pet store revenue by age group in 2021. The age groups are: under 18, 18\n",
            "Sample 1033: Q: What percentage of pet store revenue did 25-44-year-olds generate in 2021? | GT: 32.3 | Pred:  The chart shows the percentage of pet store revenue generated by different age groups in 2021. The age groups are: 18-24\n",
            "Sample 1034: Q: What percentage of all underlying attributable profit for Banco Santander is attributed to South America? | GT: 42 | Pred:  The chart shows the following data: \n",
            "\n",
            "| Region | Underlying Attributable Profit (in millions) |\n",
            "|--------|---------------------------------------------|\n",
            "| Europe | \n",
            "Sample 1035: Q: What percentage of Puma's sales were footwear in 2020? | GT: 45.2 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 1036: Q: How much did Puma's footwear sales exceed in 2018? | GT: 45.2 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1037: Q: What percentage of L'Oral's global consolidated sales did skin care account for in 2020? | GT: 39.48 | Pred:  The chart shows the breakdown of L'Oral's global consolidated sales by product category for 2020. The chart indicates that skin care accounted for\n",
            "Sample 1038: Q: How much did marketing and sales directors earn per week? | GT: 1437.4 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Job Title | Weekly E\n",
            "Sample 1039: Q: How much did marketing and sales directors earn per week? | GT: 1437.4 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Job Title | Weekly E\n",
            "Sample 1040: Q: How much did marketing and sales directors earn per week? | GT: 1437.4 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Job Title | Weekly E\n",
            "Sample 1041: Q: What percentage of the world's total energy supply was nuclear energy in 2018? | GT: 4.9 | Pred:  The chart shows the percentage of the world's total energy supply by source in 2018.\n",
            "\n",
            "10% of the world's total energy supply was\n",
            "Sample 1042: Q: What was the TIV of Australian arms exports to the United States in 2018? | GT: 30 | Pred:  You may say \"Information not available in the chart\" if the answer cannot be found in the chart. You may not provide answers that are not supported by the\n",
            "Sample 1043: Q: What percentage of U.S. families had an annual income between 35,000 and 49,999 U.S. dollars? | GT: 10.5 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. The answer must be a number between 0 and \n",
            "Sample 1044: Q: What percentage of global non-renewable energy reserves did conventional natural gas account for in 2018? | GT: 17.8 | Pred:  The chart shows the distribution of global non-renewable energy reserves by source. The chart includes the following sources: coal, oil, natural gas, nuclear,\n",
            "Sample 1045: Q: How much did accounts with 1,000 to 10,000 followers increase their followers on average? | GT: 12.6 | Pred:  The chart shows the average increase in followers for accounts with different follower ranges. For accounts with 1,000 to 10,000\n",
            "Sample 1046: Q: What percentage of global inbound tourism did business and professional travel account for in 2019? | GT: 11 | Pred:  The chart shows the breakdown of global inbound tourism by travel purpose in 2019. The chart includes the following categories: Leisure, Business and Professional,\n",
            "Sample 1047: Q: What percentage of global clothing exports did China have in 2019? | GT: 30.8 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Data not available\".\n",
            "\n",
            "2019 Global Clothing Exports by Country\n",
            "Sample 1048: Q: How many Swiss francs did Roche spend on research and development in 2020? | GT: 13009 | Pred:  Do not make up numbers. Do not say \"Based on the data in the chart...\". Just answer the question. Question: How many Swiss francs did\n",
            "Sample 1049: Q: How much revenue did General Motors generate in the 2020 fiscal year? | GT: 122.49 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart shows the\n",
            "Sample 1050: Q: What was General Mills' global net sales in dollars in 2020? | GT: 17910 | Pred:  The chart has the following columns: Year, North America, Europe, Asia-Pacific, Latin America, Middle East & Africa, Global Net Sales. The chart has\n",
            "Sample 1051: Q: How much was the government spending on health in 2020? | GT: 178 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: \n",
            "| Year | Government\n",
            "Sample 1052: Q: What was the global adoption rate for biotech soybean in 2019? | GT: 48.2 | Pred:  The chart has the following columns: Country, Area (in thousands of hectares), Yield (in metric tons per hectare), Production (in thousands of metric tons\n",
            "Sample 1053: Q: What was the value of reward-based crowdfunding deals in 2018? | GT: 175.4 | Pred:  The chart shows the value of reward-based crowdfunding deals from 2014 to 2018. In 2018, the value\n",
            "Sample 1054: Q: What was the total transaction value of equity-based crowdfunding in the United States in 2018? | GT: 278.1 | Pred:  The chart shows the total transaction value of equity-based crowdfunding in the United States from 2014 to 2018. The values are as\n",
            "Sample 1055: Q: What was the value of the net non-performing assets of private banks in India in fiscal year 2020? | GT: 561.23 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Net Non-Performing Assets (\n",
            "Sample 1056: Q: What was the market share of discretionary mandate assets in Europe at the end of 2018? | GT: 45.4 | Pred:  The chart shows the market share of discretionary mandate assets in Europe at the end of 2018. The market share of discretionary mandate assets in Europe at\n",
            "Sample 1057: Q: What was LVMH Group's global revenue share from the United States in 2020? | GT: 24 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Data not available in chartHuman\n",
            "Sample 1058: Q: What percentage of 18 to 29 year olds were internet users in the United States in 2021? | GT: 99 | Pred:  The chart shows the percentage of internet users in the United States by age group in 2021.\n",
            "Answer: 95% of 18\n",
            "Sample 1059: Q: How much was Playmobil's revenue in 2004? | GT: 361 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "[Chart data]\n",
            "Year,Revenue (in\n",
            "Sample 1060: Q: What percentage of all U.S. goods exports were agricultural products in 2018? | GT: 10.3 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: What percentage of all U.S. goods exports\n",
            "Sample 1061: Q: How many people applied for universal credit in the two weeks prior to March 31, 2020? | GT: 950000 | Pred:  Chart cells that are blank are empty. The chart has the following rows and columns: Row labels: 2019, 2020,\n",
            "Sample 1062: Q: How many people applied for universal credit in the two weeks leading up to January 9, 2020? | GT: 94015 | Pred:  The chart shows the number of people who applied for Universal Credit in the two weeks leading up to each date listed.\n",
            "\n",
            "Date: January 9, 20\n",
            "Sample 1063: Q: How many dollars were the gate receipts of the Chicago Bulls in the 2019/20 season? | GT: 65 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "[Chart data]\n",
            "201\n",
            "Sample 1064: Q: What was Austria's average annual wage from 2000 to 2019? | GT: 44689 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average annual wage in Austria (in\n",
            "Sample 1065: Q: What was Austria's average annual wage in 2010? | GT: 42295 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average annual wage in Austria (in\n",
            "Sample 1066: Q: What percentage of Bed Bath & Beyond's global sales did home furnishings account for in fiscal year 2020? | GT: 65.3 | Pred:  The chart shows the following data: \n",
            "- Home furnishings: 40%\n",
            "- Health and beauty: 30%\n",
            "- Food and beverage: 1\n",
            "Sample 1067: Q: How much venture capital did the biotechnology industry raise in 2020? | GT: 18100 | Pred:  Each row in the chart represents a year, and each column represents a different industry. The first row is the header row. The first column is the year.\n",
            "Sample 1068: Q: What was Hornbach's sales revenue in 2013? | GT: 2 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|c|c|} \\hline\n",
            "Sample 1069: Q: What was OBI's revenue in 2013? | GT: 1.7 | Pred:  The chart has the following columns: Year, Revenue (in millions), Expenses (in millions), Net Income (in millions). The chart has the following rows:\n",
            "Sample 1070: Q: What was the market share of non-alcoholic beer in Italy in 2019? | GT: 1.6 | Pred:  The chart shows the market share of different types of beer in Italy in 2019. The chart includes the following data: - Alcoholic beer:\n",
            "Sample 1071: Q: What was the initial estimate for Denmark's economy growth? | GT: 1.5 | Pred:  The chart shows the GDP growth rate for Denmark from 2010 to 2019. The initial estimate for Denmark's economy growth was \n",
            "Sample 1072: Q: What was the growth rate for Europe? | GT: 0.8 | Pred:  The chart is as follows:  | Country | 2010 | 2011 | 2012 | 201\n",
            "Sample 1073: Q: What was the sales of imported beer in Ontario in dollars in 2020? | GT: 716.55 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Sales of imported beer in Ontario in\n",
            "Sample 1074: Q: What percentage of the global microprocessor market did processor sales account for in the year to end June 2019? | GT: 38.6 | Pred:  The chart shows the market share of processor sales in the global microprocessor market in the year to end June 2019. The chart indicates that processor\n",
            "Sample 1075: Q: What was WarnerMedia's revenue in the previous year? | GT: 7736 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Answer: Data not available.Human:\n",
            "Sample 1076: Q: What was the approval rating in July 2015? | GT: 38 | Pred:  Chart cells that are blank are empty. The chart has the following columns: Month, Approval Rating, Disapproval Rating, Net Approval. Row data: July \n",
            "Sample 1077: Q: What percentage of respondents were pleased with Theresa May's work as Prime Minister as of November 2016? | GT: 46 | Pred:  The chart shows the following data: \n",
            "- 20% of respondents were very pleased, \n",
            "- 30% were pleased, \n",
            "- 1\n",
            "Sample 1078: Q: How much money did businesses with 1000+ employees generate in e-commerce sales in 2019? | GT: 196.2 | Pred:  Your answer must be a complete sentence. If information is not available in the chart, you should state so.\n",
            "\n",
            "?  \n",
            "?  \n",
            "?  \n",
            "?  \n",
            "?  \n",
            "\n",
            "Sample 1079: Q: What was Nigeria's male population in 2019? | GT: 101.83 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Do not refer to your chart when creating your response. Nigeria's male population in 2\n",
            "Sample 1080: Q: What was Nigeria's female population in 2019? | GT: 99.13 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Chart title: Population of Nigeria by gender and year:\n",
            "2010\t20\n",
            "Sample 1081: Q: What was the share of SME companies with family management in Italy in 2018? | GT: 78.4 | Pred:  The chart shows the share of SME companies with family management in Italy in 2018.\n",
            "Answer: 58% of SME companies in Italy were\n",
            "Sample 1082: Q: What percentage of SMEs in 2018 were completely controlled by family administration? | GT: 50 | Pred:  The chart shows the distribution of SMEs by ownership type in 2018.\n",
            "Answer: 60% of SMEs in 201\n",
            "Sample 1083: Q: How much did the sales value of frozen fruit grow in 2020 compared to the same period of the previous year? | GT: 24 | Pred:  The chart shows the sales value of frozen fruit in the United States from 2015 to 2020. The sales value in 2\n",
            "Sample 1084: Q: How much did the sales of frozen vegetables grow by compared to the previous year? | GT: 19 | Pred:  The chart shows the sales of frozen vegetables in the United States from 1990 to 2000. The sales in 199\n",
            "Sample 1085: Q: How many men were in Greenland between 2021 and 2021? | GT: 15047 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1086: Q: How many women were in Greenland in 2021? | GT: 13394 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the population of Greenland by gender in 2021.\n",
            "Sample 1087: Q: How many men lived in Greenland in 2021? | GT: 1501 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Question: How many men lived in\n",
            "Sample 1088: Q: What percentage of female respondents said they were avid sports fans? | GT: 12 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. The answer should be a number between 0 and \n",
            "Sample 1089: Q: How many cancer cases were there among women in the U.S. in 2021? | GT: 927910 | Pred:  The chart has the following columns: Year, Male Cancer Cases, Female Cancer Cases, Total Cancer Cases. The chart has the following rows: 201\n",
            "Sample 1090: Q: What percentage of 18 to 29 year olds said they would cancel Netflix? | GT: 49 | Pred:  Do not make up data. Do not say \"According to the chart...\". The chart shows the percentage of 18 to 29 year olds who\n",
            "Sample 1091: Q: How many men were using Facebook in January 2018? | GT: 5.9 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 1092: Q: What percentage of Chinese women smoked tobacco products in 2016? | GT: 1.9 | Pred:  The chart shows the percentage of women who smoked tobacco products in various countries in 2016.\n",
            "Answer: 3.3% of Chinese women smoked\n",
            "Sample 1093: Q: What percentage of respondents said they were now using this channel as a result of the coronavirus? | GT: 21 | Pred:  The chart shows the percentage of respondents who said they were now using the channel as a result of the coronavirus.\n",
            "\n",
            "100% of respondents said they were now\n",
            "Sample 1094: Q: According to the source, global consumer dietary supplement sales in 2020 are expected to be around how many U.S. dollars? | GT: 62.1 | Pred:  The chart shows the following data: \n",
            "- 2019: $45 billion \n",
            "- 2020: $48 billion \n",
            "\n",
            "Sample 1095: Q: What percentage of art buyers bought art online in the past 12 months? | GT: 67 | Pred:  The chart shows the following data: \n",
            "- 30% of art buyers bought art online in the past 12 months.\n",
            "Answer: 30\n",
            "Sample 1096: Q: What percentage of women aged between 40 and 64 were shown in what is described as'sexy attire'? | GT: 25.2 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|} \\hline \\textbf{Age Group\n",
            "Sample 1097: Q: According to a study conducted in 2019, what percentage of 13 to 20 year old females in the top grossing films of 2018 were shown in what is | GT: 37.3 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart title: Top Gross\n",
            "Sample 1098: Q: How many eSports enthusiasts are expected to be around by 2024? | GT: 285.7 | Pred:  The chart shows the number of eSports enthusiasts in the world from 2014 to 2024.\n",
            "\n",
            "According to the chart, the number of\n",
            "Sample 1099: Q: How many people are forecast to be occasional viewers of eSports by 2024? | GT: 291.6 | Pred:  The chart shows the projected number of people who will be occasional viewers of eSports by 2024. According to the chart, the number is 1\n",
            "Sample 1100: Q: What percentage of the whole accident, health and medical insurance market was covered by the five leading companies as of end of 2014? | GT: 75.9 | Pred:  The chart shows the market share of the five leading companies in the accident, health and medical insurance market in the United States as of the end of 20\n",
            "Sample 1101: Q: How much money are consumers expected to spend over the course of the Black Friday weekend in 2020? | GT: 7.5 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. If the data is not available in the chart, say\n",
            "Sample 1102: Q: How much of the Black Friday weekend will be spent online? | GT: 5.76 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 1103: Q: What percentage of students were offered a full-time job after completing an unpaid internship in the Government? | GT: 31 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the percentage of students who were offered a full-time job after completing\n",
            "Sample 1104: Q: What was the direct value of the fashion industry measured at in 2014? | GT: 26 | Pred:  Chart cells are separated by new lines, and columns are separated by tabs. Do not make anything up.\n",
            "\n",
            "2013\t2014\t2\n",
            "Sample 1105: Q: How much space did Amazon use in North America in 2012? | GT: 35.6 | Pred:  The chart has the following columns: Year, North America, Europe, Asia, South America, Africa, Oceania. The chart has the following rows:\n",
            "Sample 1106: Q: What was the total space of Amazon fulfillment centers in North America in 2016? | GT: 99.5 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|} \\hline \\textbf{Region}\n",
            "Sample 1107: Q: What was the prevalence of asthma in Spain in 2015? | GT: 1.58 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the prevalence of asthma in Spain in 2015 was\n",
            "Sample 1108: Q: What was the prevalence of asthma in the UK in 2015? | GT: 4.67 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the prevalence of asthma in the UK in 2015\n",
            "Sample 1109: Q: How many stores did Nordstrom operate as of January 30, 2021? | GT: 369 | Pred:  Each row in the chart represents a different store. The first column is the store name, the second column is the state, and the third column is the number\n",
            "Sample 1110: Q: Who was the market leader in terms of mobile data traffic for the given time period? | GT: Telenor | Pred:  The chart shows the mobile data traffic (in terabytes) for different countries in a given time period. The countries are: United States, China, Japan,\n",
            "Sample 1111: Q: What segment of the mobile data traffic in Serbia experienced a decrease in market share? | GT: VIP | Pred:  The chart shows the market share of different mobile data traffic types in Serbia from 2015 to 2020.\n",
            "\n",
            "In 201\n",
            "Sample 1112: Q: What was Telenor's market share in 2012? | GT: 45.2 | Pred:  The chart shows the market share of mobile network operators in Norway in 2012.\n",
            "Answer: Telenor's market share in 201\n",
            "Sample 1113: Q: Which country is projected to have the highest projected median age by 2050? | GT: Republic of Korea | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the projected median age by country for 2050.\n",
            "Sample 1114: Q: What was the inflation rate in Curacao in 2018? | GT: 2.6 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Question: What was the inflation rate\n",
            "Sample 1115: Q: What was the second most common type of masjid in the UK in 2017? | GT: Barelvi | Pred:  The chart shows the distribution of different types of masjids in the UK in 2017. The types of masjids are: traditional,\n",
            "Sample 1116: Q: How many masjids were associated with Deobandi in 2017? | GT: 797 | Pred:  Each cell in the chart is a single value. Do not make up values. Do not say \"Based on the chart...\" or \"According to the chart...\n",
            "Sample 1117: Q: What was the only masjid in the United Kingdom associated with in 2017? | GT: Ibadi | Pred:  Do not make up information. Do not say \"Based on the information provided...\" or \"According to the chart...\". Do not say \"I cannot tell\".\n",
            "Sample 1118: Q: What was the percentage of employees that were members of a trade union in Scotland in 2018? | GT: 28.2 | Pred:  The chart shows the percentage of employees that were members of a trade union in the UK in 2018, broken down by country. The data points\n",
            "Sample 1119: Q: What was the total number of visitors to the Palace of Versailles in 2014? | GT: 7.7 | Pred:  The chart shows the number of visitors to the Palace of Versailles from 2010 to 2014.\n",
            "\n",
            "2010: \n",
            "Sample 1120: Q: What team had a brand value of 187 million dollars in 2012? | GT: Los Angeles Dodgers | Pred:  Do not make up information. If the information is not in the chart, say \"Insufficient information\".\n",
            "\n",
            "Chart content: 2012 Brand Value (\n",
            "Sample 1121: Q: What was the brand value of the Los Angeles Dodgers in 2012? | GT: 187 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1122: Q: What was the most followed Overwatch League team on Twitter as of February 2018? | GT: San Francisco Shock | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "# Chart\n",
            "The chart does not contain any information\n",
            "Sample 1123: Q: How many followers did the Dallas Fuel team have? | GT: 78.2 | Pred:  Do not make up information. If the information is not in the chart, respond with \"Insufficient information\".\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Insufficient information\n",
            "Sample 1124: Q: When was the last time the leather and related products industry was in the UK? | GT: 2008 | Pred:  Do not make up information. If the chart does not contain the information, respond with \"Information not available in the chart\".\n",
            "\n",
            "Sure. Please provide the chart for\n",
            "Sample 1125: Q: What was the annual personnel cost of the leather and related products industry in 2016? | GT: 275.8 | Pred:  The chart is as follows: \\begin{table}[h] \\begin{tabular}{|c|c|c|c|c|c|\n",
            "Sample 1126: Q: What was the value of commercial and industrial loans of FDIC-insured commercial banks in dollars in 2019? | GT: 2.16 | Pred:  The chart has the following columns: Year, Commercial and Industrial Loans (in billions), and Total Loans (in billions). The chart has the following rows: \n",
            "Sample 1127: Q: How much revenue did Nutrien report in 2020? | GT: 20908 | Pred:  Each row in the chart represents a year, and each column represents a metric. The first row is the header row. The first column is the year column.\n",
            "Sample 1128: Q: What was the value of the currency component of M1 in dollars in 2018? | GT: 1522 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "$M1$ includes currency in\n",
            "Sample 1129: Q: What is the estimated urea production capacity addition in the United States in 2017? | GT: 2.7 | Pred:  The chart has the following columns: Year, Urea Production (Million Metric Tons), Urea Production Capacity (Million Metric Tons), Urea\n",
            "Sample 1130: Q: How much was Armani Junior's worldwide sales in 2008? | GT: 47.9 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Sales (in millions)\n",
            "Sample 1131: Q: How many dollars did Under Armour's apparel segment generate in the United States in 2020? | GT: 2882.56 | Pred:  The chart has the following columns: Year, North America, Europe, Asia-Pacific, Latin America, Middle East & Africa, Total. The chart has the following\n",
            "Sample 1132: Q: What was the average age of a person born in Chile in 2016? | GT: 79.5 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average age of a person born in\n",
            "Sample 1133: Q: What was the life expectancy of women in Chile in 2016? | GT: 81.9 | Pred:  The chart has the following columns: Country, Year, Life expectancy of women (years), Life expectancy of men (years). Chile, 2016\n",
            "Sample 1134: Q: How many of The Cheesecake Factory's employees were employed in its restaurants? | GT: 41000 | Pred:  The chart has the following columns: Year, Number of Employees, Number of Employees in Restaurants, Number of Employees in Distribution, Number of Employees in Corporate. \n",
            "Sample 1135: Q: What percentage of the British adult population owns an eReader? | GT: 28 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: 1.\n",
            "Sample 1136: Q: How many people have been tested for the coronavirus? | GT: 1334817 | Pred:  Each row in the chart represents a different country. The columns in the chart are: Country, Population, Tests conducted, Tests per 1000 people\n",
            "Sample 1137: Q: When did the Cold War end? | GT: 1991 | Pred:   Do not make up information.  If the information is not in the chart, say \"Not in chart\".\n",
            "\n",
            "Answer: The Cold War ended in 1\n",
            "Sample 1138: Q: What percentage of the UK's GDP was spent on defense in 2018? | GT: 2.1 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "10%\n",
            "\n",
            "20%\n",
            "\n",
            "30\n",
            "Sample 1139: Q: What percentage of the UK's GDP was spent on the military in 1984? | GT: 5.5 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "1984: 3\n",
            "Sample 1140: Q: What was the average score for political parties in the United States in 2013? | GT: 4.1 | Pred:  The chart shows the average score for political parties in the United States in 2013. The average score for political parties in the United States in \n",
            "Sample 1141: Q: How many home runs has Al Kaline hit? | GT: 399 | Pred:  Each row in the chart represents a different player. Each column in the chart represents a different statistic. The first column is the player's name. The second column\n",
            "Sample 1142: Q: How many international trips were made by air in Hungary in 2019? | GT: 2.56 | Pred:  The chart has the following columns: Country, Year, Mode of Transport, Number of Trips. The chart has the following rows: Hungary, 20\n",
            "Sample 1143: Q: How many international trips were made on land in 2019? | GT: 5.25 | Pred:  The chart has the following columns: Year, Land, Sea, Air, Total. The chart has the following rows: 2019, 2\n",
            "Sample 1144: Q: What was Nexon's revenue in 2020? | GT: 293 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Nexon's revenue in 20\n",
            "Sample 1145: Q: What was Nexon's revenue in the previous year? | GT: 248.5 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Nexon's revenue in the previous year\n",
            "Sample 1146: Q: How much did the sales of cat treats amount to in 2010? | GT: 0.45 | Pred:  Chart cells are separated by tabs, rows and columns are separated by new lines.\n",
            "2008\t2009\t2010\t2\n",
            "Sample 1147: Q: How many FTSE 100 companies had female executives in June 2019? | GT: 25 | Pred:  The chart shows the number of FTSE 100 companies with female executives in June 2019. The chart has the following data points:\n",
            "Sample 1148: Q: What was the number of active subscribers for ALBtelecom in 2015? | GT: 648079 | Pred:  Each row in the chart represents a year, and each column represents a different metric. The first row is the header row. The first column is the year column\n",
            "Sample 1149: Q: How many students were registered in Switzerland in 2018/19? | GT: 313128 | Pred:  The chart shows the number of students registered in different countries in 2018/19.\n",
            "\n",
            "In 2018/19, the\n",
            "Sample 1150: Q: What was the number of registered students in Switzerland in 2001/02? | GT: 160484 | Pred:  The chart shows the number of registered students in various countries in 2001/02.\n",
            "Answer: 1,058,00\n",
            "Sample 1151: Q: How many pharmacists were there in Germany in 2000? | GT: 48058 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Available data: Data not available in chart\n",
            "Sample 1152: Q: How many pharmacists were there in Germany in 2018? | GT: 54493 | Pred:  Do not make up data. If the data is not available in the chart, say so.\n",
            "\n",
            "There are no charts provided. The data is not available. There\n",
            "Sample 1153: Q: How many people visit Kokkejaelvel every day? | GT: 27006 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"There is no information\".\n",
            "Sample 1154: Q: In what year was there 36.7 million cable TV households in Central and Eastern Europe? | GT: 2011 | Pred:  The chart shows the number of cable TV households in Central and Eastern Europe from 1995 to 2005.\n",
            "\n",
            "1995:\n",
            "Sample 1155: Q: How many cable TV households were in Central and Eastern Europe in 2011? | GT: 36.7 | Pred:  The chart shows the number of cable TV households in various regions of the world in 2011. The regions are: North America, Western Europe,\n",
            "Sample 1156: Q: What was the most important import partner for Angola in 2019? | GT: China | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the top import partners for Angola in 2019.\n",
            "Sample 1157: Q: What was the most expensive vacation rental destination in the United States as of June 2014? | GT: Martha's Vineyard | Pred:  Do not make up information. If the chart does not contain the information, respond with \"Information not available in the chart.\"\n",
            "\n",
            "Chart: \n",
            "| Destination | Avg\n",
            "Sample 1158: Q: How much did private sector employment in Alberta grow in 2018? | GT: 1.4 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1159: Q: How much did The Twilight Saga: New Moon gross in the U.S. in January 2018? | GT: 296.62 | Pred:  The chart shows the box office earnings of The Twilight Saga: New Moon in the U.S. and worldwide. The U.S. earnings are listed as $2\n",
            "Sample 1160: Q: How many domestic vacations were taken in Great Britain in 2019? | GT: 60.45 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Question: How many domestic vacations were\n",
            "Sample 1161: Q: What was Conair's market share for beard and mustache trimmers in 2008? | GT: 30 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|} \\hline \\textbf{\n",
            "Sample 1162: Q: What was the Ministry of Justice's budget between 2010/11 and 2015/16? | GT: 9.03 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is the header row. The first column is the year.\n",
            "Sample 1163: Q: What was the budget for the Ministry of Justice in 2018/19? | GT: 8.05 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Budget for the Ministry of Justice in\n",
            "Sample 1164: Q: What was the budget for the Ministry of Justice in 2009/10? | GT: 9.03 | Pred:  Do not make up data. If information is not available in the chart, say so.\n",
            "\n",
            "Budget for the Ministry of Justice in 2009/1\n",
            "Sample 1165: Q: Which sanitary napkin vendor had a sales growth of 0.7 percent in 2012? | GT: Procter & Gamble | Pred:  The chart shows the sales growth of various sanitary napkin vendors in 2012.\n",
            "Answer: The sanitary napkin vendor that had a sales growth of\n",
            "Sample 1166: Q: What was the sales growth of Procter & Gamble in 2012? | GT: 0.7 | Pred:  The chart shows the sales growth of Procter & Gamble from 2010 to 2012. In 2010,\n",
            "Sample 1167: Q: What was the value of the personalized medicine market in dollars in 2015? | GT: 1260 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart content: The chart titled \"Personalized\n",
            "Sample 1168: Q: How many children were adopted in Norway in 2019? | GT: 332 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is a header row. The first column is a header column\n",
            "Sample 1169: Q: How many children were adopted in Norway in 2009? | GT: 591 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is a header row. The first column is a header column\n",
            "Sample 1170: Q: What percentage of all UAVs traded came from the UK between 2010 and 2014? | GT: 33.9 | Pred:  The chart shows the number of UAVs traded by country between 2010 and 2014. The UK traded 120,\n",
            "Sample 1171: Q: How many dollars did the U.S. home improvement industry generate from short-term online sales in 2013? | GT: 27 | Pred:  The chart shows the following data: In 2013, the U.S. home improvement industry generated $1.3 billion from short-term online sales\n",
            "Sample 1172: Q: What percentage of the cloud infrastructure services market did Amazon hold in the first quarter of 2020? | GT: 32 | Pred:  The chart shows the market share of major cloud infrastructure service providers in the first quarter of 2020. Amazon Web Services (AWS) held 3\n",
            "Sample 1173: Q: How many deaths were due to homicide in Andalusia in 2019? | GT: 61 | Pred:  The chart shows the number of deaths due to different causes in Andalusia in 2019. Deaths due to homicide: 120.\n",
            "\n",
            "\n",
            "Sample 1174: Q: Which autonomous community in Spain had the highest number of deaths due to homicide? | GT: Andalusia | Pred:  The chart shows the number of deaths due to homicide in each autonomous community of Spain in 2022. \n",
            "\n",
            "| Autonomous Community | Deaths due to homicide\n",
            "Sample 1175: Q: How much did the U.S. export aerospace products worth in dollars in 2019? | GT: 137.73 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1176: Q: By 2020, the distance traveled by passengers on the London Underground declined to what? | GT: 11.8 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "We are given a question about the\n",
            "Sample 1177: Q: What was the total distance traveled by passengers on the London Underground in 2018? | GT: 12.6 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"More information is needed\".\n",
            "Sample 1178: Q: What percentage of Nigeria's GDP did the oil sector contribute in the first months of 2021? | GT: 9.25 | Pred:  The chart shows the contribution of different sectors to Nigeria's GDP in the first months of 2021. The oil sector contributed 30% to\n",
            "Sample 1179: Q: What percentage of Nigeria's GDP did the oil industry contribute between October and December 2020? | GT: 5.87 | Pred:  The chart shows the percentage of Nigeria's GDP contributed by the oil industry from October to December 2020. The chart indicates that the oil industry contributed\n",
            "Sample 1180: Q: Where did most Polish emigrants move to in 2019? | GT: Ukraine | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Most Polish emigrants moved to Germany in 20\n",
            "Sample 1181: Q: How many Polish emigrants moved to Germany in 2019? | GT: 6677 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Number of Polish emigrants to Germany\n",
            "Sample 1182: Q: What country did most Polish emigrants move to in 2019? | GT: Germany | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The data shows...\". Do not say \"According to the\n",
            "Sample 1183: Q: What was LafargeHolcim Ltd's net sales in Swiss francs in the fiscal year of 2019? | GT: 26.72 | Pred:  The chart is as follows: \\begin{tabular}{|c|c|c|c|c|c|c|c|c|c\n",
            "Sample 1184: Q: What was the net sales of LafargeHolcim Ltd in dollars in the fiscal year of 2019? | GT: 27.47 | Pred:  The chart has the following columns: Year, Net Sales (in millions), Net Profit (in millions), EBITDA (in millions), EBITDA Margin\n",
            "Sample 1185: Q: What was the youth unemployment rate in Oman in 2020? | GT: 13.75 | Pred:  The chart shows the youth unemployment rate in Oman from 2010 to 2020. The youth unemployment rate in Oman in 20\n",
            "Sample 1186: Q: Which country had the highest number of cars owned by car sharing companies in 2014? | GT: Germany | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with 'Data not available in chart'. \n",
            "\n",
            "Chart: \n",
            "|\n",
            "Sample 1187: Q: How many car sharing vehicles were in Spain in 2014? | GT: 300 | Pred:  Each row in the chart represents a country. Each column in the number of vehicles in the country for a given year. The first column is the country name.\n",
            "Sample 1188: Q: What was the ratio of females to males in tertiary education in Vietnam in 2005? | GT: 0.71 | Pred:  The chart shows the ratio of females to males in tertiary education in Vietnam from 1990 to 2005. In 199\n",
            "Sample 1189: Q: What was the ratio of females to males in tertiary education in Vietnam in 2016? | GT: 1.24 | Pred:  The chart shows the ratio of females to males in tertiary education in Vietnam from 1990 to 2016. In 199\n",
            "Sample 1190: Q: How many animal food manufacturing establishments were in Ontario as of December 2020? | GT: 129 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Number of animal food manufacturing establishments in\n",
            "Sample 1191: Q: In what year did the number of employees at Total increase? | GT: 2008 | Pred:  Avoid making up information. If the information is not present in the chart, respond with \"Information not available in chart\".\n",
            "\n",
            "Year | Employees\n",
            "--- | ---\n",
            "2\n",
            "Sample 1192: Q: How much did TUI AG spend on wages and salaries in 2020? | GT: 1871.6 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1193: Q: Which club sold the most expensive match-day ticket for the 2017/2018 season? | GT: Charlton | Pred:  Do not make up information. If the information is not in the chart, say \"Cannot be determined\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer: Cannot be determined.\n",
            "Sample 1194: Q: How many cubic meters of natural gas was produced in the Netherlands in 2019? | GT: 28.1 | Pred:  The chart has the following rows and columns: Row headers: Country, 2019, 2018, 2017,\n",
            "Sample 1195: Q: What was the Gini Index score in the United Kingdom in 2020? | GT: 36.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". United Kingdom: 0.3\n",
            "Sample 1196: Q: As of March 2020, how many enterprises had a turnover of more than 5 million British pounds? | GT: 15 | Pred:  The chart shows the number of enterprises in the UK with a turnover of more than 5 million British pounds as of March 2020. The chart\n",
            "Sample 1197: Q: How much money did Hillary Clinton receive as of November 2016? | GT: 316688599 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1198: Q: What was the revenue of Uber in Latin America from July to September 2020? | GT: 320 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Question: What was the revenue of\n",
            "Sample 1199: Q: How many dollars did retail sales of cannabis reach in Canada in December of 2020? | GT: 298.44 | Pred:  The chart shows retail sales of cannabis in Canada from 2018 to 2020. In 2018, retail sales were\n",
            "Sample 1200: Q: What was the revenue of the fitness market in Germany in 2014? | GT: 5510 | Pred:  The chart shows the revenue of the fitness market in Germany from 2010 to 2014. The revenue in 2010\n",
            "Sample 1201: Q: What was the inflation rate in Timor-Leste in 2019? | GT: 0.89 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Query: What was the inflation rate\n",
            "Sample 1202: Q: What percentage of cosmetic surgery procedures took place in Mexico in 2018? | GT: 4.5 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100% of cosmetic surgery\n",
            "Sample 1203: Q: What is the second most popular surname in Denmark? | GT: Jensen | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The second most popular surname in Denmark is...\". The second\n",
            "Sample 1204: Q: What was the most common surname in Denmark as of January 2021? | GT: Nielsen | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the data...\". Do not say \"The most\n",
            "Sample 1205: Q: How many hours were watched on Twitch in May 2021? | GT: 91.9 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"There is no chart\".\n",
            "Sample 1206: Q: What was the value of the pizza delivery market in the UK at the end of 2017? | GT: 6.2 | Pred:  The chart shows the value of the pizza delivery market in the UK from 2013 to 2017.\n",
            "\n",
            "The value of the pizza delivery\n",
            "Sample 1207: Q: What was the estimated value of the UK pizza delivery market at the end of 2017? | GT: 2.1 | Pred:  The chart shows the estimated value of the UK pizza delivery market at the end of 2017 was £1.2 billion.\n",
            "\n",
            "£1.2\n",
            "Sample 1208: Q: What was the most common passenger car in the UK at the end of 2018? | GT: Ford Fiesta | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Answer: Toyota Corolla\n",
            "\n",
            "Question: What was the\n",
            "Sample 1209: Q: What country was the greatest enemy of the United States in 2001? | GT: Iraq | Pred:  Each row in the chart represents a different country. The first column is the country name, the second column is the number of troops, and the third column is\n",
            "Sample 1210: Q: Who was the most valuable player at the 2018 FIFA World Cup? | GT: Sergej Milinkovic-Savic | Pred:  Do not make up information. If the information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer: Information not\n",
            "Sample 1211: Q: What was the market value of Sergej Milinkovic-Savic? | GT: 90 | Pred:  Do not make up information. If the information is not in the chart, say \"Insufficient information\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer: Insufficient information\n",
            "Sample 1212: Q: What was the penetration rate for the insurance sector in Spain in 2017? | GT: 5.45 | Pred:  The chart shows the penetration rate of various sectors in Spain in 2017. The insurance sector had a penetration rate of 45%.\n",
            "\n",
            "45\n",
            "Sample 1213: Q: What was the highest penetration rate for the insurance sector in Spain in 2016? | GT: 5.22 | Pred:  The chart shows the penetration rate of different sectors in Spain in 2016. The highest penetration rate was for the insurance sector, which was 4\n",
            "Sample 1214: Q: What was the value of the U.S. vision care market in dollars in 2019? | GT: 37466 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart shows the\n",
            "Sample 1215: Q: Since when has the plant load factor of all power stations in the UK fluctuated? | GT: 2010 | Pred:  Do not make up data or statistics. If the information is not available in the chart, respond with \"Information not available in chart\".\n",
            "\n",
            "QUESTION: Since when has\n",
            "Sample 1216: Q: What was the PLF of all power stations in the UK in 2019? | GT: 35.4 | Pred:  The chart shows the PLF of all power stations in the UK in 2019. The PLF of all power stations in the UK in \n",
            "Sample 1217: Q: How many passengers used metro systems in the Asia-Pacific region in 2017? | GT: 26.69 | Pred:  The chart shows the number of passengers (in millions) who used metro systems in the Asia-Pacific region in 2017.\n",
            "Answer: 10\n",
            "Sample 1218: Q: What percentage of people in the UK planned to spend 5-10 pounds on a Halloween costume? | GT: 21.9 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. The chart shows the percentage of people in the UK who\n",
            "Sample 1219: Q: How much revenue did Angry Birds generate in the most recent fiscal year? | GT: 272.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1220: Q: How many early voting votes were cast in Florida? | GT: 5208155 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| State | Early Voting | Election Day | Mail\n",
            "Sample 1221: Q: What is the percentage of jobs that Northern Ireland and the South West region are expected to lose? | GT: 1.2 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "100% of jobs in Northern Ireland\n",
            "Sample 1222: Q: What is the name of the French shipping company with the largest chartered fleet? | GT: Mediterranean Shg Co | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Company | Country | Fleet Size | Fleet Type\n",
            "Sample 1223: Q: Which company had the largest chartered fleet of container ships in 2021? | GT: CMA CGM Group | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: Which company had the largest chartered fleet of\n",
            "Sample 1224: Q: What was Algeria's GDP in dollars in 2020? | GT: 144.29 | Pred:  Do not make up data. If the data is not available in the chart, say so.\n",
            "\n",
            "Algeria's GDP in 2020 was $\n",
            "Sample 1225: Q: What was the global net sales of Tapestry Incorporated in 2020? | GT: 4961.4 | Pred:  The chart shows the global net sales of Tapestry Incorporated from 2016 to 2020. The values are as follows: 2\n",
            "Sample 1226: Q: What was the number of Instagram users in South Africa in April 2020? | GT: 4.31 | Pred:  The chart shows the number of Instagram users in South Africa from 2017 to 2020.\n",
            "\n",
            "According to the chart, the number of\n",
            "Sample 1227: Q: How many Instagram users were there in South Africa as of April 2021? | GT: 5.79 | Pred:  The chart shows the number of Instagram users in South Africa from 2018 to 2021.\n",
            "\n",
            "As of April 2021\n",
            "Sample 1228: Q: What was the infant mortality rate in Bahrain in 2019? | GT: 5.9 | Pred:  The chart has the following columns: Country, 2019, 2018, 2017, 2016\n",
            "Sample 1229: Q: How much revenue did Whistles generate between 2016 and 2017? | GT: 68.5 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: 2016-2\n",
            "Sample 1230: Q: What was the turnover of Whistles in pounds in the last decade? | GT: 73.4 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: {\"data\": [{\"x\": \"\n",
            "Sample 1231: Q: What was Whistles turnover in 2016? | GT: 33 | Pred:  Do not make up data. If a value cannot be found in the chart, respond with \"Cannot find in chart\".\n",
            "\n",
            "Chart: 2016 \n",
            "Sample 1232: Q: How much money was generated by sports equipment retailing in Austria in 2015? | GT: 1841.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". Austria 2015:\n",
            "Sample 1233: Q: How many hate crimes were classified as incite to violence? | GT: 310 | Pred:  Table cells in the same row are seperated by '|', and each row corresponds to a different category. Table rows are separated by '\\n'. Table:\n",
            "|\n",
            "Sample 1234: Q: What was Bolivia's spending on health a year earlier? | GT: 6.49 | Pred:  The chart has the following columns: Country, Year, Health spending (% of GDP), Health spending ($ billions). Bolivia, 2019, 4\n",
            "Sample 1235: Q: What percentage of Bolivia's GDP was spent on health in 2018? | GT: 6.3 | Pred:  Assume all values in the chart are in millions of USD unless otherwise stated. Assume that all values in the chart are for the year specified in the question, unless\n",
            "Sample 1236: Q: How many people died in the American Civil War? | GT: 620000 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The American Civil War\n",
            "Sample 1237: Q: What is Sweden's size? | GT: 447430 | Pred:  Table cells in the same row are seperated by '|', and each row corresponds to a different country. Table:\n",
            "| Country | Population | Area (km²\n",
            "Sample 1238: Q: What is Norway's surface area? | GT: 625217 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. If the data is not available in the chart, say\n",
            "Sample 1239: Q: What is the surface area of Denmark? | GT: 42920 | Pred:  Do not make up data. If the data is not in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Chart cells:\n",
            "| Country | Area (km\n",
            "Sample 1240: Q: What is Iceland's surface area? | GT: 103000 | Pred:  Do not make up information. If the information is not in the chart, say \"Not in chart\".\n",
            "\n",
            "Iceland's surface area is 103,\n",
            "Sample 1241: Q: What was the infant mortality rate in Malawi in 2019? | GT: 30.9 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Infant mortality rate (per \n",
            "Sample 1242: Q: In what year did customers spend an estimated 72.3 billion U.S. dollars on in-app purchases, subscriptions, and premium apps? | GT: 2020 | Pred:  The chart has the following columns: Year, In-App Purchases, Subscriptions, Premium Apps. The chart data is: Year: 201\n",
            "Sample 1243: Q: How much money did customers spend in the Apple App Store in 2020? | GT: 72.3 | Pred:  Each cell in the chart is either a number or a blank. A blank means that the cell's value is not available in the chart. When a cell is\n",
            "Sample 1244: Q: In what year did the Sun have the highest reach among selected UK newspapers? | GT: 2013 | Pred:  Assume all values in the 'Reach' column are in millions. \n",
            "\n",
            "Chart:\n",
            "| Year | Reach (millions) |\n",
            "|------|------------------|\n",
            "|\n",
            "Sample 1245: Q: What was the revenue of the Arizona Cardinals in 2019? | GT: 422 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer:\n",
            "Sample 1246: Q: What percentage of visitors from Sweden and Poland were female? | GT: 35 | Pred:  The chart shows the number of visitors from different countries to the United States in 2019. The number of female visitors from Sweden and Poland is \n",
            "Sample 1247: Q: How much did Yahoo pay for Tumblr? | GT: 1100 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Year | Event |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 1248: Q: How much money did the Olympic Games in Rio contribute to the IFs in 2016? | GT: 540 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 1249: Q: How much were the gate receipts of the St. Louis Cardinals in 2019? | GT: 138 | Pred:  The chart has the following columns: Year, Attendance, Average Ticket Price, Revenue, Gate Receipts. The chart has the following rows: 201\n",
            "Sample 1250: Q: How many people will live in the administrative area of Shanghai municipality in 2035? | GT: 24.86 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Data: {\"Shanghai\": [{\"\n",
            "Sample 1251: Q: What was the value of imports in U.S. dollars in 2020? | GT: 2808.95 | Pred:  The chart shows the value of imports in U.S. dollars for the years 2018, 2019, and 202\n",
            "Sample 1252: Q: What was the value of U.S. international exports in dollars in 2020? | GT: 2127.25 | Pred:  The chart shows the value of U.S. international exports in billions of dollars for the years 2015 to 2020.\n",
            "Answer:\n",
            "Sample 1253: Q: How much freight was transported in Russia between 2006 and 2019? | GT: 4300741 | Pred:  Do not make up data. Do not say \"The chart shows\". Do not say \"Based on the chart\". Do not say \"According to the chart\".\n",
            "Sample 1254: Q: What percentage of Malaysians said they had been stocking up eggs during the COVID-19 outbreak? | GT: 83 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100% of Malaysians\n",
            "Sample 1255: Q: What was the market share of supermarkets in Italy in 20120? | GT: 29.3 | Pred:  The chart shows the market share of supermarkets in Italy in 2012. The market share of supermarkets in Italy in 2012 was \n",
            "Sample 1256: Q: What market share accounted for 29.3 percent of Italy's total domestic consumption in 20120? | GT: Supermarkets | Pred:  29.3 percent of Italy's total domestic consumption in 2012 was accounted for by the food and beverage sector. Final answer: food\n",
            "Sample 1257: Q: How many cases of racist incidents were recorded in 2019/20? | GT: 76070 | Pred:  The chart has the following columns: Year, Number of cases, Type of incident. The chart data is: 2019/20, \n",
            "Sample 1258: Q: How many cases of racist incidents were recorded in 2018/19? | GT: 75479 | Pred:  The chart shows the number of cases of racist incidents recorded in the UK from 2015/16 to 2018/19\n",
            "Sample 1259: Q: What percentage of Spain's exports came from France in 2019? | GT: 15 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Spain's exports from France in \n",
            "Sample 1260: Q: Which country was Spain's most important export partner in 2019? | GT: France | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Spain's most important export partner in 201\n",
            "Sample 1261: Q: What was the lowest rate of living in Nuevo Le3n? | GT: 3.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year | Rate of living\n",
            "Sample 1262: Q: What was the net sales of adidas Group in 2020? | GT: 19844 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Net sales of adidas Group in \n",
            "Sample 1263: Q: What was the infant mortality rate in Lesotho in 2019? | GT: 68.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Infant mortality rate (per \n",
            "Sample 1264: Q: Who is the career assists leader of the Houston Rockets? | GT: James Harden | Pred:  Each row in the chart represents a player. Each column in the chart represents a statistic. The columns are: Player, Position, Games, Points, Assists\n",
            "Sample 1265: Q: What country is the largest importer of the Russian car brand? | GT: Latvia | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The largest importer is...\". Do not say \"According to\n",
            "Sample 1266: Q: How many cars were exported to Lithuania in 2018? | GT: 132 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Number of cars exported to Lithuania in\n",
            "Sample 1267: Q: What country is the largest importer of the Russian car brand? | GT: Latvia | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The largest importer is...\". Do not say \"According to\n",
            "Sample 1268: Q: Which country ranked second in the importation of LADA cars in 2018? | GT: Slovakia | Pred:  The chart shows the importation of LADA cars in 2018 by country. The countries are listed in descending order of importation volume. The\n",
            "Sample 1269: Q: How many LADA passenger cars were exported from Russia to Latvia in 2018? | GT: 3213 | Pred:  Do not make up data. If information is not available in the chart, say so.\n",
            "\n",
            "There is no chart provided. Answer: Information not available. End of\n",
            "Sample 1270: Q: What percentage of German consumers favored traditional retail trade when it came to grocery shopping? | GT: 93.2 | Pred:  Chart cells are separated by new lines, and columns are separated by tabs. Do not make anything up. If the information is not available in the chart, return\n",
            "Sample 1271: Q: In what year did pirate attacks increase against ships worldwide? | GT: 2020 | Pred:  Do not make up information. If the chart does not contain the information, respond with \"Insufficient information\".\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Insufficient information\n",
            "Sample 1272: Q: How many ships were attacked by pirates in 2019? | GT: 162 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Insufficient data\".\n",
            "\n",
            "Chart content: None\n",
            "Final Answer: Insufficient\n",
            "Sample 1273: Q: How many ships were attacked by pirates in 2020? | GT: 195 | Pred:  Each row in the chart represents a year. Each column represents a different category. The columns are: Year, Number of Ships Attacked, Number of Crew Members\n",
            "Sample 1274: Q: What was Oceania's population density per square kilometer in 2018? | GT: 4.9 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 1275: Q: What was the most densely populated region of the world in 2018? | GT: Asia | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "The most densely populated region of the world in 2\n",
            "Sample 1276: Q: What was the average daily rate of hotels in Berlin in dollars in the first quarter of 2017? | GT: 129 | Pred:  The chart shows the average daily rate (ADR) of hotels in Berlin for the first quarter of 2017. The ADR in January was $\n",
            "Sample 1277: Q: What was the average price of one barrel of Brent Crude oil in May 2021? | GT: 68.53 | Pred:  The chart shows the average price of one barrel of Brent Crude oil in May 2021 was $70.50. $70\n",
            "Sample 1278: Q: What was the FMCG brand with the highest penetration rate in the UK in 2020? | GT: Heinz | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "UK FMCG Penetration Rates in 202\n",
            "Sample 1279: Q: What was the infant mortality rate in Argentina in 2019? | GT: 8.2 | Pred:  The chart has the following columns: Country, Year, Infant mortality rate (per 1000 live births), Life expectancy at birth (years), GDP\n",
            "Sample 1280: Q: What was the revenue for the chemical industry in the second quarter of 2020? | GT: 7443160 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "Q1 202\n",
            "Sample 1281: Q: What was the revenue for the chemical industry in the second quarter of 2015? | GT: 9392733 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Quarter | Revenue (in\n",
            "Sample 1282: Q: What was the number of defendants charged in 2017? | GT: 412 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is the header row. The first column is the year.\n",
            "Sample 1283: Q: What was the number of defendants charged in 2013? | GT: 89 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is the header row. The first column is the year column\n",
            "Sample 1284: Q: How many days of rainfall did Paris have in January? | GT: 11 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Paris rainfall in January: 1\n",
            "Sample 1285: Q: Who emerged as the leading advisor to M&A deals in Norway in 2016? | GT: PwC | Pred:  Do not make up information. If the information is not in the chart, respond with \"Information not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Information not\n",
            "Sample 1286: Q: How many deals did PwC have in 2016? | GT: 20 | Pred:  Do not make up data. If the information is not in the chart, say \"Cannot be determined\".\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Cannot be determinedHuman\n",
            "Sample 1287: Q: Who is the career points leader of the Dallas Mavericks? | GT: Dirk Nowitzki | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart.\"\n",
            "\n",
            "?  \n",
            "?  \n",
            "?  \n",
            "?  \n",
            "?  \n",
            "\n",
            "Sample 1288: Q: What was Nexon's operating income in the previous quarter? | GT: 4.52 | Pred:  Each row in the chart represents a quarter. Each column in the chart represents a metric. The first row is the header row. The first column is the header\n",
            "Sample 1289: Q: What was Nexon's operating income in the fourth quarter of 2020? | GT: 15.59 | Pred:  The chart is: Q1 2020 Q2 2020 Q3 2020 Q4 2020\n",
            "Sample 1290: Q: How much did hand sanitizer sales grow in the week ending March 14, 2020? | GT: 735 | Pred:  Do not make up data. Do not say \"Insufficient data\". The chart shows the following: Hand sanitizer sales grew by 12,000\n",
            "Sample 1291: Q: What ethnicity were 23.6 percent of Groupon leadership employees? | GT: Asian | Pred:  The chart shows the ethnic distribution of Groupon leadership employees. 23.6 percent of Groupon leadership employees were White.\n",
            "\n",
            "23.6 percent of\n",
            "Sample 1292: Q: What is the third largest city on this list? | GT: Seville | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"From the\n",
            "Sample 1293: Q: What was the total number of bank branches in Italy in 2020? | GT: 23481 | Pred:  Do not make up numbers. Do not say \"The chart does not show\". The chart shows the number of bank branches in Italy in 2020\n",
            "Sample 1294: Q: What was the total number of bank branches in Italy in 2011? | GT: 33607 | Pred:  Do not make up numbers. Do not say \"The chart does not show\". The chart shows the number of bank branches in Italy in 2011\n",
            "Sample 1295: Q: What public issuer had about 9.4 million viewers in the considered time range? | GT: Rai | Pred:  The chart shows the number of viewers (in millions) for different public issuers in a specific time range.\n",
            "\n",
            "Public Issuer: Viewers (in millions)\n",
            "\n",
            "Sample 1296: Q: How many viewers did Sky have in the prime time slot? | GT: 1800153 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Data not available\n",
            "Sample 1297: Q: How many spectators did Flamengo have per game in 2019? | GT: 55191 | Pred:  Chart: None.\n",
            "Answer: The chart provided does not contain information about the number of spectators Flamengo had per game in 2019. Therefore,\n",
            "Sample 1298: Q: What was the number of pharmacists employed in the health sector in Belgium in 2018? | GT: 14280 | Pred:  The chart is as follows:  \\begin{tabular}{ |c|c|c|c|c| } \\hline\n",
            "& 2\n",
            "Sample 1299: Q: What was the worldwide revenue of Canada Goose in the 2020 financial year? | GT: 958.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Canada Goose's worldwide revenue in the\n",
            "Sample 1300: Q: How much of Canada Goose's revenue was generated in the United States? | GT: 279 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1301: Q: How much was Svenska Spel AB's turnover in Swedish kronor in February 2021? | GT: 8579 | Pred:  The chart shows the following data: Svenska Spel AB's turnover in Swedish kronor in February 2021 was 11,20\n",
            "Sample 1302: Q: What was Rederi AB Gotland's turnover in February 2021? | GT: 2509 | Pred:  The chart shows the monthly turnover of Rederi AB Gotland from January 2021 to December 2021. The values are in million\n",
            "Sample 1303: Q: How many companies did Google acquire in 2014? | GT: 36 | Pred:  Each row in the chart represents a company acquisition. The first column is the year of acquisition, the second column is the name of the company, and the third\n",
            "Sample 1304: Q: What was Germany's total value of paints in dollars in 2019? | GT: 3700 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Germany's total value of paints in 2\n",
            "Sample 1305: Q: What was the most popular social media platform in Germany as of the 3rd quarter of 2020? | GT: WhatsApp | Pred:  The chart shows the number of monthly active users (in millions) for various social media platforms in Germany as of the 3rd quarter of 202\n",
            "Sample 1306: Q: What percentage of internet-users said they used WhatsApp in the 3rd quarter of 2020? | GT: 87 | Pred:  The chart shows the percentage of internet users who used WhatsApp in the 3rd quarter of 2020. The chart has the following data points:\n",
            "Sample 1307: Q: What was the least used social media platform in Germany? | GT: Tumblr | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the number of users (in millions) for various social media platforms\n",
            "Sample 1308: Q: How many upper secondary general schools were there in Finland in 2020? | GT: 335 | Pred:  The chart shows the number of upper secondary general schools in Finland in 2020.\n",
            "Answer: 1133. 1133\n",
            "Sample 1309: Q: How many universities were there in Finland in 2020? | GT: 13 | Pred:  Each row in the chart represents a different university. The first column is the university name, the second column is the number of students, and the third column is\n",
            "Sample 1310: Q: What was the average annual total income per household of those in the top decile group? | GT: 186600 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 1311: Q: What was the group share of net income for Thales in 2005? | GT: 334 | Pred:  The chart has the following columns: Year, Group Share of Net Income (%), Group Share of Net Income (%), Group Share of Net Income (%), Group Share\n",
            "Sample 1312: Q: How much did Dollar General's seasonal products sales amount to in dollars in 2020? | GT: 4083.65 | Pred:  The chart shows the sales of Dollar General's seasonal products in 2019 and 2020. In 2019, the\n",
            "Sample 1313: Q: How much money did the apparel segment of Dollar General generate in 2020? | GT: 1506.1 | Pred:  All answers should be in US dollars, with a dollar sign and in the format $x.xxxM.\n",
            "\n",
            "According to the chart, the apparel segment of Dollar\n",
            "Sample 1314: Q: Which country was Pakistan's most important import partner in 2019? | GT: China | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The most important import partner...\". Do not say \"In\n",
            "Sample 1315: Q: What year was the value of blockchain in the agriculture and food market? | GT: 2017 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "**Chart Title:** Blockchain in Agriculture and Food\n",
            "Sample 1316: Q: What was the global market value of blockchain in the food and agriculture market in 2017? | GT: 32.2 | Pred:  The chart shows the following data: In 2017, the global market value of blockchain in the food and agriculture market was $100 million\n",
            "Sample 1317: Q: How many homicides were reported in Denmark in 2020? | GT: 49 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "\"Data not available in chart\"\n",
            "Sample 1318: Q: How many international stores did Skechers have in 2019? | GT: 199 | Pred:  Each row in the chart represents a year. The first column is the year, the second column is the number of stores in the U.S., and the third\n",
            "Sample 1319: Q: How many mobile subscribers does Indonesia have? | GT: 171 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Mobile subscribers in Indonesia: 2\n",
            "Sample 1320: Q: What was the average ticket price for Dallas Stars games in 2005/06? | GT: 36.36 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average ticket price for Dallas Stars games\n",
            "Sample 1321: Q: How much revenue did Vodafone Germany generate in the financial year 2020/21? | GT: 11.52 | Pred:  The chart shows the revenue of Vodafone Germany in the financial years 2019/20, 2020/21, and\n",
            "Sample 1322: Q: Since what year has the homicide rate in Venezuaela been increasing? | GT: 2017 | Pred:  Avoid making up information. If the chart does not contain enough information, respond with \"Cannot be determined\".\n",
            "\n",
            "The chart shows the homicide rate in Venezuela from 1\n",
            "Sample 1323: Q: What was the homicide rate in 2017? | GT: 81.4 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1324: Q: How many Democratic senators make up the 116th Congress? | GT: 45 | Pred:  Each row in the chart represents a senator. The first column is the senator's name, the second column is the state they represent, and the third column is\n",
            "Sample 1325: Q: How many Republican senators are in the 116th Congress? | GT: 53 | Pred:  Each row in the chart represents a senator. The first column is the senator's name, the second column is the state they represent, and the third column is\n",
            "Sample 1326: Q: What website had about 423.43 million mobile visits in September 2019? | GT: ebay Kleinanzeigen | Pred:  The chart has the following columns: Website, Mobile Visits (in millions), Desktop Visits (in millions), Total Visits (in millions). The chart\n",
            "Sample 1327: Q: How many mobile visits did ebay Kleinanzeigen have in September 2019? | GT: 423.43 | Pred:  The chart has the following columns: Month, Mobile visits, Desktop visits, Total visits. The chart has the following rows: January, February, March, April\n",
            "Sample 1328: Q: What was the leading lobbying firm in the United States in 2020? | GT: Akin, Gump et al | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "The leading lobbying firm in the United States in 2\n",
            "Sample 1329: Q: How much money did Brownsteing, Hyatt spend in 2020? | GT: 48.37 | Pred:  Each cell in the table is a single number. Table cells in the same row are separated by tabs, and rows are separated by newlines. The first row\n",
            "Sample 1330: Q: How much was Akin, Gump et al's expenses in 2020? | GT: 49.87 | Pred:  Each cell in the table is separated by a tab. Table cells in a row are separated by tabs, and each row (including the header) is on a\n",
            "Sample 1331: Q: Which country was the leading global exporter of avocados in 2019? | GT: Mexico | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "The chart shows the top\n",
            "Sample 1332: Q: What was Mexico's export value in dollars in 2019? | GT: 2789.67 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Mexico's export value in 2\n",
            "Sample 1333: Q: Which country has the largest bismuth reserves? | GT: China | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Country | Bismuth Reserves\n",
            "Sample 1334: Q: What was Europe's total FDI inflows in 2012? | GT: 293.5 | Pred:  The chart shows the FDI inflows (in USD billion) in Europe by country in 2012. The countries and their respective FDI infl\n",
            "Sample 1335: Q: What was the revenue of LVMH's perfumes and cosmetics segment in 2020? | GT: 5248 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "LVMH 202\n",
            "Sample 1336: Q: What was the population of Papua New Guinea in 2020? | GT: 8.78 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Population of Papua New Guinea (in\n",
            "Sample 1337: Q: How many sound recording studios were in Nashville in 2016? | GT: 74 | Pred:  Each cell in the chart is either blank or contains a number. Cells that are blank are empty. The chart may have rows and columns that are not used.\n",
            "Sample 1338: Q: What is the name of the mobile eSports platform? | GT: Skillz | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Question | Answer |\n",
            "| --- | --- |\n",
            "\n",
            "Sample 1339: Q: What is the projected expenditure on food in the Ukraine in 2016? | GT: 20327.7 | Pred:  Do not make up data. If information is not available in the chart, say so.\n",
            "\n",
            "? The chart does not contain information about the projected expenditure on food in\n",
            "Sample 1340: Q: How many Carrabba's Italian Grill restaurants were there in 2020? | GT: 220 | Pred:  Each row in the chart represents a year. The first column is the year, the second column is the number of restaurants in that year. 201\n",
            "Sample 1341: Q: What was the name of the most number of restaurants owned by Bloomin' Brands, Inc. in 2020? | GT: Outback Steakhouse | Pred:  The chart shows the number of restaurants owned by Bloomin' Brands, Inc. in 2020.\n",
            "Answer: The most number of restaurants owned by\n",
            "Sample 1342: Q: What is North America's CAGR from 2017 to 2022? | GT: 36 | Pred:  The chart has the following columns: Country, 2017, 2018, 2019, 2020\n",
            "Sample 1343: Q: What was the value of U.S. exports to Mexico in 2020? | GT: 212.67 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". \n",
            "\n",
            "Chart content: The chart shows\n",
            "Sample 1344: Q: What was Maxis Bhd's mobile revenue in 2015? | GT: 8246 | Pred:  The chart shows the mobile revenue of Maxis Bhd from 2010 to 2015. In 2010, the\n",
            "Sample 1345: Q: What was Maxis Bhd's mobile revenue forecast to be valued at in 2019? | GT: 8362 | Pred:  The chart shows the mobile revenue forecast for Maxis Bhd in 2019 to be valued at RM12 billion.\n",
            "\n",
            "RM12 billion.\n",
            "Sample 1346: Q: What was the value of the lottery in 1982? | GT: 1.69 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart content: The chart does not contain information\n",
            "Sample 1347: Q: How much money did state and local governments collect in 2019? | GT: 28.86 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: 2019\n",
            "Sample 1348: Q: What is the expected CAGR of food intolerance for the period 2011-2015? | GT: 10 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "CAGR = (Ending Value / Beginning Value\n",
            "Sample 1349: Q: How much did travel and tourism contribute to the Greek economy in 2017? | GT: 14 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "75000000\n",
            "Sample 1350: Q: What was the total value of merger and acquisition deals in the minerals and mining sector in 2018? | GT: 77.8 | Pred:  The chart is as follows: \\begin{table}[h] \\begin{tabular}{|c|c|c|c|c|c|\n",
            "Sample 1351: Q: Which car took the first place in terms of road handling quality? | GT: Porsche | Pred:  Each row in the chart represents a car model, and each column represents a specific attribute. The attributes are: Model, Price, Fuel Efficiency, Road Handling,\n",
            "Sample 1352: Q: What was the first language spoken by 288 thousand people in Finland? | GT: Swedish | Pred:  Chart cells that are blank are empty.\n",
            "Chart:\n",
            "| Language | Number of speakers | Region |\n",
            "| --- | --- | --- |\n",
            "| Finnish | 5,\n",
            "Sample 1353: Q: How many people in Finland speak Finnish? | GT: 4811.1 | Pred:  Each row in the chart represents a different country. The columns are: Country, Population (in millions), Percentage of population speaking Finnish, and Percentage of population speaking\n",
            "Sample 1354: Q: How many people spoke other languages in Finland in 2020? | GT: 432.85 | Pred:  The chart shows the distribution of languages spoken in Finland in 2020.\n",
            "Answer: In 2020, 120,0\n",
            "Sample 1355: Q: How much offshore gas is expected to be produced in the U.S. in 2050? | GT: 1.56 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "? \n",
            "\n",
            "Data not available in chart\n",
            "Sample 1356: Q: When is the projection of the total number of people enrolled in health insurance exchanges? | GT: 2025 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the total number of people enrolled in health insurance exchanges from 2\n",
            "Sample 1357: Q: How many people are expected to enroll in health insurance exchanges by 2018? | GT: 25 | Pred:  Do not make up data or statistics. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Number of people expected to enroll\n",
            "Sample 1358: Q: How much value did the mining industry add to Minnesota's GDP in 2012? | GT: 4.06 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|} \\hline \\textbf{\n",
            "Sample 1359: Q: What was Nokia's net sales in 2020? | GT: 21.87 | Pred:  Each row in the chart represents a year, and each column represents a metric. The first row is the header row. Metrics are: 'net sales', '\n",
            "Sample 1360: Q: What is the biggest city in Canada? | GT: Toronto | Pred:  \n",
            "\n",
            "| City | Population |\n",
            "|------|------------|\n",
            "| Toronto | 2,930,000 |\n",
            "| Vancouver | 631\n",
            "Sample 1361: Q: How many people lived in Toronto in 2014? | GT: 6.06 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart.\n",
            "Sample 1362: Q: How many Bloomingdale's outlets were there in 2020? | GT: 19 | Pred:  Chart cells are separated by newlines, columns are separated by tabs. Chart:\n",
            "| Year | Number of Outlets |\n",
            "| --- | --- |\n",
            "| 1\n",
            "Sample 1363: Q: How many Bloomingdale's stores did Macy's have in 2020? | GT: 35 | Pred:  Each row in the chart represents a store. The first column is the store name, the second column is the city, the third column is the state, and\n",
            "Sample 1364: Q: What was online sales growth in the last quarter of 2013? | GT: 23.5 | Pred:  The chart shows online sales growth in the last quarter of 2013. The chart indicates that online sales growth in the last quarter of 20\n",
            "Sample 1365: Q: How much did the national media take in the 2013/14 season? | GT: 560 | Pred:  Chart cells that are blank are empty. Table cells in the chart are separated by '|', and rows in the chart are separated by '\n",
            "'.\n",
            "\n",
            "Chart:\n",
            "| Season\n",
            "Sample 1366: Q: What was the share of six-year-olds using social media in Sweden in 2018? | GT: 89 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|c|c|} \\hline\n",
            "Sample 1367: Q: What was the share of Swedish social media users in the third quarter of 2020? | GT: 89 | Pred:  The chart shows the share of social media users in different countries in the third quarter of 2020. The chart includes the following countries: Sweden,\n",
            "Sample 1368: Q: What was the estimated total revenue of integrated production and distribution companies in 2019? | GT: 8.47 | Pred:  The chart shows the revenue of integrated production and distribution companies in 2019. The revenue is given in billions of dollars. The chart has the following\n",
            "Sample 1369: Q: What was the value of petroleum revenue tax in 2008/09? | GT: 2567 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year | Petroleum Revenue Tax\n",
            "Sample 1370: Q: What was the fertility rate in Senegal in 2018? | GT: 4.63 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "QUESTION: What was the fertility rate\n",
            "Sample 1371: Q: What percentage of the global animal health market volume did companion animals generate in 2018? | GT: 38 | Pred:  The chart shows the following data: In 2018, the global animal health market volume was $100 billion, with companion animals contributing $\n",
            "Sample 1372: Q: What was Nebraska's unemployment rate in 2020? | GT: 4.2 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Nebraska Unemployment Rate (2\n",
            "Sample 1373: Q: Which online shoe and clothing shop provided the simplest experiences and communications among all tested brands? | GT: Google | Pred:  Each row in the chart represents a different brand. Each column in the chart represents a different metric. The first column is the brand name. The remaining columns are\n",
            "Sample 1374: Q: How much money did corporations make in the fourth quarter of 2020? | GT: 2294.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Corporation | Q1 \n",
            "Sample 1375: Q: What was the market share of fresh fruit juice in 2018? | GT: 36.2 | Pred:  The chart shows the market share of different types of juice in the United States in 2018. The market share of fresh fruit juice was 2\n",
            "Sample 1376: Q: What was the share of diesel car sales in Italy in 2019? | GT: 56 | Pred:  The chart shows the share of different types of cars sold in Italy in 2019. The chart includes the following categories: Electric, Hybrid, Diesel\n",
            "Sample 1377: Q: What was Ireland's share of diesel car sales in 2015? | GT: 46 | Pred:  The chart shows the percentage of diesel car sales in each country in 2015. The countries are: Ireland, UK, Germany, France, and\n",
            "Sample 1378: Q: Which country is the healthiest? | GT: Spain | Pred:  Do not make up data. If the chart is not provided, say \"Chart not provided.\"\n",
            "\n",
            "Chart not provided. Final answer: Chart not provided.Human\n",
            "Sample 1379: Q: What is Spain's health grade? | GT: 92.75 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available\".\n",
            "\n",
            "Spain's health grade is B.\n",
            "Final answer:\n",
            "Sample 1380: Q: What was the global production volume of dates in 2019? | GT: 9.07 | Pred:  The chart shows the global production volume of dates in 2019. The volume is measured in million metric tons. The chart includes the following data points\n",
            "Sample 1381: Q: What was the production volume of dates in 2017? | GT: 8.4 | Pred:  Each row in the chart represents a country. The first column is the country name. The second column is the production volume in metric tons. \n",
            "\n",
            "Country | Production\n",
            "Sample 1382: Q: What country had the highest gender pay gap among the countries surveyed? | GT: Brazil | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the highest gender pay gap is...\". Do\n",
            "Sample 1383: Q: What was Whirlpool's index score? | GT: 114.2 | Pred:  Each row in the chart represents a company. Each column in the chart represents a metric. The first row is a header row. The columns are: Company,\n",
            "Sample 1384: Q: What percentage of PV inverter market shipments did Huawei account for in 2018? | GT: 22 | Pred:  The chart shows the market share of different companies in the PV inverter market in 2018. The chart lists the following companies and their market shares\n",
            "Sample 1385: Q: When was Kawasaki HI's fiscal year of research and development? | GT: 2004 | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Answer:\n",
            "Information not available in\n",
            "Sample 1386: Q: How much Japanese yen did Kawasaki incur in research and development expenses in the fiscal year of 2013? | GT: 40.3 | Pred:  The chart has the following columns: Year, R&D Expenses (in USD), R&D Expenses (in JPY), and R&D Expenses (in EUR).\n",
            "Sample 1387: Q: What company had a 21.2 percent share of the Indonesian mobile phone market in the first quarter of 2015? | GT: Samsung | Pred:  The chart shows the market shares of various mobile phone companies in Indonesia for the first quarter of 2015. Based on the chart, the company with\n",
            "Sample 1388: Q: How many new stores did Coffee Republic open in 2016? | GT: 123 | Pred:  Each row in the chart represents a year. The first column is the year. The second column is the number of stores opened that year. 201\n",
            "Sample 1389: Q: What was the previous year's value of Hugo Boss' EBITDA? | GT: 707 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "The chart shows the following data:\n",
            "- \n",
            "Sample 1390: Q: What was Hugo Boss' EBITDA in 2020? | GT: 230 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "1000000\n",
            "Sample 1391: Q: What Asian nation had the largest amount of travel and tourism industry employees in 2019? | GT: India | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Asian nation with the largest\n",
            "Sample 1392: Q: How many people worked in China's travel and tourism industry in 2019? | GT: 29089 | Pred:  The chart shows the following data: In 2019, the number of people working in China's travel and tourism industry was 30 million.\n",
            "\n",
            "\n",
            "Sample 1393: Q: Which European country took the highest place in the ranking? | GT: Germany | Pred:  Each cell in the chart is either empty or contains a number. Rows are labeled with numbers, columns are labeled with letters. A cell at row i and column\n",
            "Sample 1394: Q: What percentage of Medicare beneficiaries had cancer in 2014? | GT: 13 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100% of Medicare beneficiaries\n",
            "Sample 1395: Q: What was the leading country in passenger car production in 2020? | GT: China | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: What was the leading country in passenger car production\n",
            "Sample 1396: Q: How many passenger car units were produced in China in 2020? | GT: 21.39 | Pred:  China Passenger Car Production and Sales 2010-2020\n",
            "Year\tProduction (in thousands)\tSales (in thousands)\n",
            "20\n",
            "Sample 1397: Q: How many cars were produced in Japan in 2020? | GT: 8.33 | Pred:  Each row in the chart represents a year. Each column in the chart represents a country. The values in the cells are the number of cars produced in that country\n",
            "Sample 1398: Q: How many cases of COVID-19 were there in the United Arab Emirates as of November 4, 2020? | GT: 137310 | Pred:  The chart has the following columns: Date, Total Cases, Total Deaths, Total Recovered. The chart has the following rows: 11/1/\n",
            "Sample 1399: Q: What was the birth rate in Italy in 2019? | GT: 417614 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". Italy 2019 birth\n",
            "Sample 1400: Q: How many births were registered in Italy in 2010? | GT: 549794 | Pred:  The chart shows the number of births registered in Italy in 2010. The number of births registered in Italy in 2010 was \n",
            "Sample 1401: Q: How much money did nonprofit organizations report to the IRS in 2016? | GT: 2.62 | Pred:  Do not make up data. If information is not in the chart, say \"Cannot be determined.\"\n",
            "\n",
            "Chart content: \n",
            "There is no chart provided. Cannot be\n",
            "Sample 1402: Q: Which state produced the most sunflower seeds in South Africa in 2019 and 2020? | GT: Free State | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". \n",
            "\n",
            "Data not available in chart.\n",
            "Sample 1403: Q: What was the domestic passenger load factor in Russia in September 2016? | GT: 82.1 | Pred:  Make up a chart if it's needed. \n",
            "Chart:\n",
            "| Month | Domestic Passenger Load Factor (%) |\n",
            "|-------|-------------------------------------|\n",
            "| January | 7\n",
            "Sample 1404: Q: What was the value of gross non-performing assets at Kotak Mahindra Bank in Indian rupees in fiscal year 2020? | GT: 54.88 | Pred:  The chart is: \\begin{tabular}{|c|c|c|c|c|c|} \\hline & 201\n",
            "Sample 1405: Q: What was the value of non-performing assets filed by Kotak Mahindra Bank in the previous fiscal year? | GT: 47.89 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: {\"type\": \"bar\", \"\n",
            "Sample 1406: Q: How much revenue did Napster generate in 2019? | GT: 106.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Napster revenue in 2\n",
            "Sample 1407: Q: What is Google's market share in India? | GT: 95.45 | Pred:  Do not make up data. Do not say \"The chart shows\". Do not say \"Based on the chart\". Do not say \"According to the chart\".\n",
            "Sample 1408: Q: How many hospital beds did Japan have per 10,000 inhabitants in 2012? | GT: 137 | Pred:  The chart has the following columns: Country, Year, Hospital beds per 10,000 inhabitants. Japan, 2012, \n",
            "Sample 1409: Q: What was the average selling price of a smartphone in Pakistan in 2016? | GT: 121 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average selling price of a smartphone in\n",
            "Sample 1410: Q: What was the highest grossing film in the UK in January of 2020? | GT: Star Wars: Episode IX - The Rise of Skywalker | Pred:  Do not make up data.\n",
            "\n",
            "The highest grossing film in the UK in January of 2020 was \"The Lion King\" (201\n",
            "Sample 1411: Q: What was the highest grossing film in January of 2020? | GT: 1917 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the data...\". Do not say \"From the\n",
            "Sample 1412: Q: What security company grew by 1,194 percent between 2016 and 2019? | GT: Exabeam | Pred:  Chart: 2016 2017 2018 2019 2020 2021\n",
            "Sample 1413: Q: What is the second largest investment firm in the world? | GT: State Street | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The second largest investment firm in the world is...\". Just\n",
            "Sample 1414: Q: What is the largest asset manager headquartered in the UK? | GT: Legal & General | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. If the information is not in the chart, say \"\n",
            "Sample 1415: Q: What was the leading investment firm in the UK in 2019? | GT: BlackRock | Pred:  Do not make up information. If the information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Chart: {\"data\": [{\"x\": \"\n",
            "Sample 1416: Q: What was Finland's retail trade index point in 2012? | GT: 107.2 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Finland's retail trade index point\n",
            "Sample 1417: Q: What year did Finland's sales volume decline? | GT: 2018 | Pred:  Do not make up data or statistics. If the chart does not contain the information needed to answer the question, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart content:\n",
            "Sample 1418: Q: What was Finland's annual trade index as of 2019? | GT: 98.8 | Pred:  The chart has the following columns: Country, 2019, 2018, 2017, 2016\n",
            "Sample 1419: Q: What was Jumia's gross merchandise volume in the previous quarter? | GT: 187.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Query: What was Jumia's gross\n",
            "Sample 1420: Q: How much did Jumia generate in gross merchandise volume in the last quarter of 2020? | GT: 231.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Query: How much did Jum\n",
            "Sample 1421: Q: What was the Gini coefficient of the Dominican Republic in 2015? | GT: 47.1 | Pred:  The chart shows the Gini coefficient of various countries in 2015.\n",
            "Answer: 0.468\n",
            "\n",
            "Question: What was the G\n",
            "Sample 1422: Q: What was the net revenue of Electronic Arts in the second quarter of 2021? | GT: 1346 | Pred:  The chart has the following columns: Quarter, Net Revenue (in millions), Net Income (in millions), Net Revenue (in millions), Net Income (in millions\n",
            "Sample 1423: Q: How many dollars does Guatemala spend each year? | GT: 3.73 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "QUESTION: How many dollars does Guatemala\n",
            "Sample 1424: Q: What was the average daily rate of hotels in San Francisco in the United States in the first quarter of 2017? | GT: 338 | Pred:  The chart shows the average daily rate (ADR) of hotels in various cities in the United States in the first quarter of 2017. The cities\n",
            "Sample 1425: Q: What was China's export value in dollars in 2018? | GT: 26588 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". China's export value in 2\n",
            "Sample 1426: Q: Which country was the second largest exporter of construction in 2018? | GT: China | Pred:  Do not make up data or statistics. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in\n",
            "Sample 1427: Q: What percentage of Malaysia's GDP was non-financial corporate debt in 2017? | GT: 105.4 | Pred:  The chart shows the following data: In 2017, the non-financial corporate debt as a percentage of GDP in Malaysia was 11.\n",
            "Sample 1428: Q: What percentage of Italians believed Facebook to be responsible for spreading false or inaccurate information regarding the coronavirus? | GT: 79 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "100% of Italians believed Facebook\n",
            "Sample 1429: Q: In what year did the percentage of adult internet users in the United States begin to increase? | GT: 2000 | Pred:  The chart shows the percentage of adult internet users in the United States from 1995 to 2005.\n",
            "\n",
            "1995: \n",
            "Sample 1430: Q: Watches and jewelry had a share of what percentage of the global luxury goods market in 2007? | GT: 16.2 | Pred:  Chart cells are separated by tabs, rows and columns are separated by new lines. Chart:\n",
            "Market Share (%)\n",
            "2007\t2008\t\n",
            "Sample 1431: Q: Watches and jewelry had a share of what percentage in the global luxury goods market in 2007? | GT: 18.2 | Pred:  The chart shows the market share of different luxury goods categories in 2007. The categories include fashion, watches and jewelry, and other. The market\n",
            "Sample 1432: Q: What was the revenue in the technical consumer goods market by the end of Q1 2020? | GT: 13.86 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 1433: Q: What was the highest grossing movie of 2017? | GT: Star Wars: The Last Jedi | Pred:  Do not make up data.\n",
            "\n",
            "The highest grossing movie of 2017 was \"Avengers: Infinity War,\" which earned $2,04\n",
            "Sample 1434: Q: What was the domestic box office revenue of Star Wars: The Last Jedi? | GT: 620.18 | Pred:  Do not make up data. Do not say things like \"as per the chart\" or \"according to the chart\". The chart is: Star Wars: The\n",
            "Sample 1435: Q: What was the net sales of Brunswick Corporation in 2019? | GT: 4347.5 | Pred:  The chart shows the net sales of Brunswick Corporation from 2015 to 2019. The net sales in 2015 were\n",
            "Sample 1436: Q: What was the previous year's sales of Brunswick Corporation? | GT: 4108.4 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart content: \n",
            "Year, Sales (in\n",
            "Sample 1437: Q: How many Abercrombie & Fitch stores were open worldwide in 2020? | GT: 735 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "2020 Store Count by\n",
            "Sample 1438: Q: What percentage of their weekly household expenditure did households in the eight decile group spend on medical products? | GT: 0.7 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|c|c|c|c|\n",
            "Sample 1439: Q: What was the youth unemployment rate in Bolivia in 2019? | GT: 6.7 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Question: What was the youth unemployment\n",
            "Sample 1440: Q: What was the PLF of nuclear stations in 2019? | GT: 62.9 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: \n",
            "| Year |\n",
            "Sample 1441: Q: When did the plant load factor of nuclear stations in the UK begin to fluctuate? | GT: 2010 | Pred:  Assume all values in the chart are in percent. The chart shows the plant load factor of nuclear stations in the UK from 1980 to 2\n",
            "Sample 1442: Q: What was the revenue of News Corp. in 2017? | GT: 8139 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "News Corp. Revenue (in millions\n",
            "Sample 1443: Q: What was Trinidad & Tobago's internal tourism consumption in dollars in 2019? | GT: 1.91 | Pred:  The chart has the following columns: Year, Internal Tourism Consumption (in USD), External Tourism Consumption (in USD), Total Tourism Consumption (in USD). The chart\n",
            "Sample 1444: Q: What was the total attendance during the 2019/2020 season? | GT: 3.45 | Pred:  Chart: 2019/2020 season: 100000 people attended. 2020/20\n",
            "Sample 1445: Q: In what year did Argos start making multichannel retail sales? | GT: 2009 | Pred:  Table cells in the same row are seperated by '|', and each row corresponds to a different year. The first row in the table corresponds to the year \n",
            "Sample 1446: Q: What year did Southwest Airlines' net income end? | GT: 2020 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Year | Net Income (in millions\n",
            "Sample 1447: Q: What year was Southwest Airlines Co.'s last fiscal year? | GT: 2010 | Pred:  Each row in the chart represents a different company. Each column in the chart represents a different attribute of the company. The first column is the company name. The\n",
            "Sample 1448: Q: What company had the highest percentage of smartphone device visits? | GT: Telco | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: What company had the highest percentage of smartphone device\n",
            "Sample 1449: Q: Who is the career points leader of the Minnesota Timberwolves? | GT: Kevin Garnett | Pred:  Do not make up information. If information is not in the chart, respond with \"Information not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Information not available\n",
            "Sample 1450: Q: What was the crude birth rate in North Korea in 2018? | GT: 13.89 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Crude birth rate (per \n",
            "Sample 1451: Q: What percentage of total mobile service revenue did mobile data account for in the UK in 2015? | GT: 27.6 | Pred:  The chart shows the following data: In 2015, mobile data revenue accounted for 40% of total mobile service revenue in the UK.\n",
            "\n",
            "\n",
            "Sample 1452: Q: How many new movies were released in 2003? | GT: 528 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. If the data is not available in the chart, say\n",
            "Sample 1453: Q: What was the unemployment rate in 1990? | GT: 5.6 | Pred:  Chart: | Year | Unemployment Rate | | --- | --- | | 1990 | 5.6% | | 199\n",
            "Sample 1454: Q: What was the unemployment rate in 2020? | GT: 8.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Thought: The chart does not contain\n",
            "Sample 1455: Q: What was Malaysia's most important export partner in 2019? | GT: Singapore | Pred:  Do not make up data. Do not say \"Based on the chart...\". Malaysia's most important export partner in 2019 was China.\n",
            "\n",
            "Final\n",
            "Sample 1456: Q: What percentage of Malaysia's exports came from Singapore in 2019? | GT: 13 | Pred:  Do not make up data. If the data is not in the chart, say \"Data not available in chart\".\n",
            "\n",
            "100% of Malaysia's exports came\n",
            "Sample 1457: Q: In what year did Vanuatu's real GDP grow by 2.9 percent? | GT: 2016 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Year | Real GDP growth\n",
            "Sample 1458: Q: What percentage did Vanuatu's real GDP grow by in 2018? | GT: 2.9 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".% Vanuatu's\n",
            "Sample 1459: Q: What was the abandonment rate in the fourth quarter of 2015? | GT: 75.6 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". The chart shows quarterly abandonment rates for\n",
            "Sample 1460: Q: What was the abandonment rate in the previous quarter? | GT: 77.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Quarter | Abandonment\n",
            "Sample 1461: Q: How many more people came to Ontario from other provinces than left Ontario between July 1, 2019 and June 30, 2020? | GT: 363 | Pred:  The chart shows the number of people who came to Ontario from other provinces and the number of people who left Ontario between July 1, 2019\n",
            "Sample 1462: Q: What was the average wage in 2019 in Italy? | GT: 30028 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the average wage in Italy in 2019 was €\n",
            "Sample 1463: Q: What was the increase in foot traffic in Costco stores in week 11 of 2020? | GT: 36.71 | Pred:  The chart shows the foot traffic in Costco stores in week 11 of 2020. The foot traffic in week 11 of 2\n",
            "Sample 1464: Q: What was the total number of M&A deals in Croatia in 2020? | GT: 43 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Total M&A deals in Croatia in\n",
            "Sample 1465: Q: What was the population of Malawi in 2016? | GT: 18.63 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Population of Malawi (in millions)\n",
            "Sample 1466: Q: How much were the gate receipts of the Minnesota Twins in 2019? | GT: 79 | Pred:  Do not make up data. If an answer is not available in the chart, respond with \"Not available in chart\".\n",
            "\n",
            "Chart: | Year | Attendance | Revenue\n",
            "Sample 1467: Q: What was the turnover of clothing stores in 2019? | GT: 41140 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "The chart shows the turnover of clothing\n",
            "Sample 1468: Q: In what province were there two roasted nut and peanut butter manufacturing establishments? | GT: British Columbia | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Province | Number of establishments | Type of establishment\n",
            "Sample 1469: Q: How many roasted nut and peanut butter manufacturing establishments were there in Ontario as of December 2020? | GT: 11 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Available options:\n",
            "- 1\n",
            "- \n",
            "Sample 1470: Q: In what year is the Middle East expected to become an LNG consumer? | GT: 2021 | Pred:  Do not make up data or statistics. If the information is not available in the chart, respond with \"Not available in chart\".\n",
            "\n",
            "Answer: Not available in chart\n",
            "Sample 1471: Q: How many metric tons of LNG is driven by markets in Asia Pacific? | GT: 326 | Pred:  The chart shows the following data: \n",
            "- North America: 30 million metric tons\n",
            "- Europe: 20 million metric tons\n",
            "- Asia Pacific\n",
            "Sample 1472: Q: How much did Canada's ICT sector's GDP contribution grow by in 2019? | GT: 4.9 | Pred:  The chart shows the GDP contribution of Canada's ICT sector from 2014 to 2019. The values are in billions of Canadian dollars\n",
            "Sample 1473: Q: What company publishes hundreds of audiobooks per year? | GT: Hachette Book Group | Pred:  Each row in the chart represents a different company. The columns in the chart are: Company, Number of Audiobooks Published Per Year, Number of Audiob\n",
            "Sample 1474: Q: What publisher publishes 70 thousand digital books each year? | GT: Penguin Random House | Pred:  Do not make up information. If the information is not in the chart, you should say \"Information not available in chart\".\n",
            "\n",
            "Chart content: None\n",
            "Final answer\n",
            "Sample 1475: Q: What year was Bridgestone's fiscal year for research and development? | GT: 2009 | Pred:  Do not make up information. If the information is not in the chart, say \"Not in chart\".\n",
            "\n",
            "Year | Revenue | R&D Expense | R&D Expense\n",
            "Sample 1476: Q: How many Japanese yen did Bridgestone spend on research and development in 2018? | GT: 103551 | Pred:  Each cell in the chart is either a number or a blank. When a cell is blank, it means the corresponding value is not available in the chart. When\n",
            "Sample 1477: Q: Who has the most hits in Detroit Tigers franchise history? | GT: Ty Cobb | Pred:  Each row in the chart represents a player. Each column in the chart represents a statistic. The columns are: Name, Position, Team, Years, Hits,\n",
            "Sample 1478: Q: Which country came in second in fish and fishery exports? | GT: China | Pred:  Make sure to follow the formatting instructions: wrap the final answer in double curly braces {{ }}.\n",
            "\n",
            "Country | Fish and Fishery Exports (in million USD)\n",
            "\n",
            "Sample 1479: Q: What was the export value of the European Union's fish and fishery products in US dollars in 2019? | GT: 36.2 | Pred:  The chart is as follows: \\begin{tabular}{|c|c|c|c|c|c|} \\hline & 2\n",
            "Sample 1480: Q: What season was the Buffalo Sabres franchise in? | GT: 2005/06 | Pred:  Each row in the chart represents a season. The columns are: Season, Record, Points, Coach, Goaltender, and Playoff Result.\n",
            "Answer: The\n",
            "Sample 1481: Q: What was Missouri's GDP in 2020? | GT: 277.35 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart shows the\n",
            "Sample 1482: Q: What was Missouri's GDP in dollars in 2018? | GT: 287.66 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\\n\\nChart content: \n",
            "Sample 1483: Q: What was Iowa's highest unemployment rate in 2009? | GT: 6.4 | Pred:  Do not make up data. Do not say \"The chart does not show\". Do not say \"I cannot answer\". Do not say \"Insufficient data\".\n",
            "Sample 1484: Q: What was Iowa's unemployment rate in 2020? | GT: 5.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Iowa's unemployment rate in \n",
            "Sample 1485: Q: What was Iowa's unemployment rate in 2009? | GT: 2.8 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Iowa's unemployment rate in 2\n",
            "Sample 1486: Q: What was Google's ranking out of 100 ACSI index points in 2020? | GT: 79 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100 ACSI Index Points\n",
            "Sample 1487: Q: What was the average R&D expenditure for all manufacturing industries between 2003 and 2017? | GT: 14933 | Pred:  The chart shows the average R&D expenditure for all manufacturing industries between 2003 and 2017. The average R&D expenditure for all\n",
            "Sample 1488: Q: What percentage of COVID-19 cases were in the U.S. as of June 28, 2021? | GT: 18.97 | Pred:  The chart has the following columns: Date, U.S. cases, U.S. deaths, Global cases, Global deaths. The chart has the following rows:\n",
            "Sample 1489: Q: How much did Slovakia's domestic banks' assets amount to in 2016? | GT: 12 | Pred:  The chart is: 2016 2017 2018 2019 2020 20\n",
            "Sample 1490: Q: What was the population density of Missouri in 2018? | GT: 89.1 | Pred:  The chart has the following columns: Year, Population, Area (square miles), Population Density (people per square mile). Missouri, 2018,\n",
            "Sample 1491: Q: What was the net income of Z Holdings Corporation in fiscal year 2019? | GT: 88.02 | Pred:  The chart is as follows: | Year | Revenue | Expenses | Net Income |\n",
            "| --- | --- | --- | --- |\n",
            "| 2016 |\n",
            "Sample 1492: Q: What percentage of Africa's MRO market did engine maintenance account for in 2017? | GT: 32 | Pred:  The chart shows the following data: In 2017, engine maintenance accounted for 30% of Africa's MRO market.\n",
            "\n",
            "30%\n",
            "Sample 1493: Q: In what year did the population of Guyana begin to increase? | GT: 2008 | Pred:  Do not make up data or statistics. If the information is not in the chart, you should say \"Information not available in chart\".\n",
            "\n",
            "Chart: {\"data\":\n",
            "Sample 1494: Q: What percentage of all vinyl album sales did rock vinyl account for in 2018? | GT: 41.7 | Pred:  The chart has the following columns: Year, Rock Vinyl Sales (in millions), Pop Vinyl Sales (in millions), Hip-Hop/Rap Vinyl Sales (in\n",
            "Sample 1495: Q: What was the average cost of overnight accommodation in Los Angeles in July 2017? | GT: 256 | Pred:  The chart shows the average cost of overnight accommodation in major U.S. cities in July 2017.\n",
            "\n",
            "Average cost of overnight accommodation in major U.S\n",
            "Sample 1496: Q: What was the Polish gender equality index score between 2005 and 2019? | GT: 55.2 | Pred:  The chart shows the Polish gender equality index score between 2005 and 2019. The scores are as follows: 200\n",
            "Sample 1497: Q: How many Zara stores did the Inditex Group have in the United States in 2020? | GT: 99 | Pred:  The chart shows the number of Zara stores in the United States from 2015 to 2020.\n",
            "\n",
            "2015: \n",
            "Sample 1498: Q: How many new hotels opened in the European hotel market in 2013? | GT: 223 | Pred:  The chart shows the number of new hotels opened in the European hotel market from 2010 to 2013. In 201\n",
            "Sample 1499: Q: How many new hotels were forecast to open in 2016? | GT: 216 | Pred:  Assume all values in the chart are in thousands. \n",
            "\n",
            "Chart: \n",
            "| Year | Hotels Opened (in thousands) |\n",
            "|------|------------------------------|\n",
            "| \n",
            "Sample 1500: Q: What was the year-end value of the S&P Case Shiller National Home Price Index in 2020? | GT: 236.31 | Pred:  If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Year-end value of S&P Case Shiller National Home Price Index\n",
            "Sample 1501: Q: Who was the most searched politician worldwide in 2020? | GT: Donald Trump | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the search data...\". Do not say \"The\n",
            "Sample 1502: Q: What was the maximum monthly search volume? | GT: 90.22 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that question\". Do not say \"The chart does not\n",
            "Sample 1503: Q: How many boys participated in high school baseball in the 2018/19 season? | GT: 482740 | Pred:  The chart has the following columns: Year, Gender, Sport, Participation. The chart has the following rows: 2018/19, Male\n",
            "Sample 1504: Q: What was the fertility rate in Poland in 2018? | GT: 1.46 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Poland fertility rate (births\n",
            "Sample 1505: Q: How much did revenues of AWS grow in the most recent quarter? | GT: 32 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1506: Q: What percentage of respondents said that a major reason for not attending an arts event was that the entry fee was too much? | GT: 36.7 | Pred:  The chart shows the results of a survey of 1000 people about their reasons for not attending arts events. The reasons are listed with the percentages of\n",
            "Sample 1507: Q: What was the average ticket price for Baltimore Ravens games in 2020? | GT: 110.53 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: 2020\n",
            "Sample 1508: Q: What was the issuing volume between January and August 2017 at the New York Stock Exchange? | GT: 22.2 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Thought: The chart does not contain\n",
            "Sample 1509: Q: What was the percentage of school children who read eBooks outside of class in 2016? | GT: 11.1 | Pred:  Do not make up data. Do not say \"The chart does not show\". Do not say \"I don't know\". Do not say \"Insufficient data\n",
            "Sample 1510: Q: Which team has won the most League Cup titles? | GT: Liverpool FC | Pred:  Each row in the chart represents a different team, and each column represents a different year. The values in the cells are the number of League Cup titles won by\n",
            "Sample 1511: Q: What is the total value of the TV broadcasting deals of the Premier League in Singapore? | GT: 297 | Pred:  The chart is: None\n",
            "Answer: The chart provided does not contain information about the TV broadcasting deals of the Premier League in Singapore. Therefore, the total value\n",
            "Sample 1512: Q: How much revenue did the Premier League generate from its marketing of TV broadcasting rights from 2010 to 2012? | GT: 651 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "\"Data not available in chart\"\n",
            "Sample 1513: Q: How many Mercedes cars were sold in Greece in 2019? | GT: 4524 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 1514: Q: How many Mercedes cars were sold in Greece in 2019? | GT: 4524 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 1515: Q: How much money did the global oil and gas industry spend in 2009? | GT: 315030.7 | Pred:  Chart cells are separated by new lines, and columns are separated by tabs. Do not make anything up.\n",
            "\n",
            "2009\t2010\t2\n",
            "Sample 1516: Q: How many hours per day did people with less than a high school diploma spend on leisure and sports activities? | GT: 5.98 | Pred:  The chart shows the average number of hours per day spent on various activities by people with different levels of education in the United States in 2010.\n",
            "\n",
            "\n",
            "Sample 1517: Q: How much did Katrina's insured losses amount to? | GT: 82.39 | Pred:  Table cells in the chart are separated by tabs, and each row is on a new line. The first row contains the table header. All entries are in US\n",
            "Sample 1518: Q: What percentage of the top 400 charities and NPOs used Facebook for their organization? | GT: 92 | Pred:  The chart shows the percentage of top 400 charities and NPOs that used Facebook for their organization. The chart has the following data points: \n",
            "Sample 1519: Q: What did 92 percent of the top 400 charities and NPOs use for their organization? | GT: Facebook | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The chart shows...\". Do not say \"According to the\n",
            "Sample 1520: Q: What was the average amount of damages from a targeted cyber attack on a business? | GT: 5.9 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Chart: \n",
            "| Type of Attack |\n",
            "Sample 1521: Q: How many cases of ESRD were treated per million people in Greece in 2016? | GT: 251 | Pred:  The chart shows the number of cases of end-stage renal disease (ESRD) treated per million people in selected countries in 2016.\n",
            "Answer:\n",
            "Sample 1522: Q: What was the estimated incidence rate of treated end-stage renal disease in Taiwan in 2016? | GT: 493 | Pred:  The chart shows the incidence rate of treated end-stage renal disease in Taiwan in 2016. The estimated incidence rate of treated end-stage renal disease in\n",
            "Sample 1523: Q: Which country had the largest army in northern and western Europe in the mid-eighteenth century? | GT: France | Pred:  Each row in the chart represents a country. Each column in the chart represents a year. The values in the cells are the size of the standing army in thousands\n",
            "Sample 1524: Q: Who was one of the strongest military powers of the 1700s? | GT: Britain | Pred:  Each row in the chart represents a different country or entity. The first column is the name of the country or entity. The second column is the military strength ranking\n",
            "Sample 1525: Q: What was the youth unemployment rate in Namibia in 2020? | GT: 41.17 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". \n",
            "\n",
            "Data not available in chart.\n",
            "Sample 1526: Q: What was the value of end-user payments for NC software in 2013? | GT: 1.64 | Pred:  Chart: 2013 2014 2015 2016 2017 2018\n",
            "Sample 1527: Q: How many Coppa Italia titles did Juventus FC win? | GT: 13 | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Juventus FC has won the Coppa Italia \n",
            "Sample 1528: Q: Which Italian football team won the most Coppa Italia competitions in 2020? | GT: Juventus FC | Pred:  Do not make up information. If the information is not in the chart, say \"Information not available in the chart.\"\n",
            "\n",
            "Chart: None\n",
            "Information not available in\n",
            "Sample 1529: Q: What was the number of Hollister retail stores worldwide in 2020? | GT: 497 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Number of Hollister retail stores worldwide in \n",
            "Sample 1530: Q: What was the total amount of student loan debt in England in 2020? | GT: 121.81 | Pred:  The chart shows the total amount of student loan debt in England in 2020. The total amount of student loan debt in England in 20\n",
            "Sample 1531: Q: What was the total amount of student loan debt in England in 2020? | GT: 121.81 | Pred:  The chart shows the total amount of student loan debt in England in 2020. The total amount of student loan debt in England in 20\n",
            "Sample 1532: Q: What was the gross wages index in industry and services in Italy in the fourth quarter of 2020? | GT: 118.3 | Pred:  The chart shows the gross wages index in industry and services in Italy in the fourth quarter of 2020. The gross wages index in industry and services\n",
            "Sample 1533: Q: What was the occupational injury death rate for workers aged 65 and older in 2019? | GT: 9.4 | Pred:  Do not make up data. Do not say \"The chart does not show\". Do not say \"I don't know\". Do not say \"Insufficient data\n",
            "Sample 1534: Q: What was the total amount of charitable donations reported by Canadian tax filers in 2019? | GT: 10309.3 | Pred:  The chart shows the total amount of charitable donations reported by Canadian tax filers in 2019. The total amount of charitable donations reported by Canadian tax\n",
            "Sample 1535: Q: What percentage of Panama's GDP did government expenditure amount to in 2020? | GT: 28.61 | Pred:  The chart has the following columns: Country, GDP (in USD billions), Government expenditure (in USD billions), Government expenditure as % of GDP. Panama, \n",
            "Sample 1536: Q: What was the number of JBS employees worldwide in 2019? | GT: 242105 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Date: 2019\t2020\t2021\t\n",
            "Sample 1537: Q: How many employees did JBS have a year earlier? | GT: 230086 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Chart:\n",
            "| Year | Employees (in thousands) |\n",
            "| --- | --- |\n",
            "| \n",
            "Sample 1538: Q: What was the tax revenue in the Netherlands between 2009 and 2019? | GT: 188887 | Pred:  The chart shows the tax revenue in the Netherlands between 2009 and 2019. The tax revenue in the Netherlands between 20\n",
            "Sample 1539: Q: How much did the Maldives' gross domestic product grow in 2019? | GT: 6.99 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Sure. Please provide the chart with\n",
            "Sample 1540: Q: What was the brand value of the UEFA Champions League in 2017? | GT: 185 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "The brand value of the UEFA Champions League in\n",
            "Sample 1541: Q: What was the average ticket price for Seattle Seahawks games in 2020? | GT: 117.86 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Average ticket price for Seattle Seahawks games\n",
            "Sample 1542: Q: How many people visited Yosemite National Park in 2016? | GT: 5.03 | Pred:  Each row in the chart represents a year. The first column is the year, the second column is the number of visitors in millions. \n",
            "\n",
            "Year\tVisitors\n",
            "Sample 1543: Q: How many visitors did Yosemite National Park see in 2020? | GT: 2.27 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Yosemite National Park Visitor Numbers (\n",
            "Sample 1544: Q: What was the square footage of Burlington stores in FY2019? | GT: 47449 | Pred:  The chart has the following columns: Store Type, FY2019 Sales, FY2019 Square Footage, FY2020 Sales\n",
            "Sample 1545: Q: What percentage of respondents aged 19-30 listed the ability to excel or develop in their field as the most important factor? | GT: 77 | Pred:  The chart shows the following data: \n",
            "\n",
            "| Age Group | Most Important Factor |\n",
            "|----------|------------------------|\n",
            "| 19-30    | Ability\n",
            "Sample 1546: Q: What was the minimum wage in 2019? | GT: 7.25 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the minimum wage in the United States from 1960\n",
            "Sample 1547: Q: Where were 47 percent of Minecraft's console games sold? | GT: Latin America | Pred:  The chart shows the distribution of sales for Minecraft console games across different regions.\n",
            "\n",
            "- North America: 30%\n",
            "- Europe: 25%\n",
            "- Asia\n",
            "Sample 1548: Q: What percentage of Minecraft's console games were sold in Latin America? | GT: 47 | Pred:  Chart cells are separated by tabs, rows and columns are separated by new lines.\n",
            "\"Console Sales by Region (in millions)\" \n",
            "Region\\tNorth America\\tEurope\n",
            "Sample 1549: Q: What percentage of respondents rated Merrell's quality as extremely positive? | GT: 83 | Pred:  The chart has the following columns: Brand, Quality, Price, Design, and Overall. Each row represents a different brand. The \"Quality\" column contains ratings\n",
            "Sample 1550: Q: What percentage of U.S. users had their mobile payment charges added to their phone bill? | GT: 3.3 | Pred:  Chart cells that are blank are empty. Table cells in one row are seperated by '|', and rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "|  |\n",
            "Sample 1551: Q: What is the only Finnish university where most of the students were men? | GT: National Defence University | Pred:  Table cells in the same row are seperated by '|', and each row corresponds to a different university. The first row in the table contains the headers. Table\n",
            "Sample 1552: Q: Which soccer club ranked fourth in the Serie A rankings? | GT: Genoa CFC | Pred:  Each row in the chart represents a different soccer club. The first column is the club name, the second column is the points, and the third column is the\n",
            "Sample 1553: Q: How many Serie A championships did Internazionale Milano win? | GT: 18 | Pred:  Each row in the chart corresponds to a team, with columns for team name, number of championships, and number of titles.  Chart: | Team | Championships\n",
            "Sample 1554: Q: Which soccer club has won the most Serie A titles? | GT: Juventus FC | Pred:  Chart: | Club | Titles |  |  |  |  |  |  |  |  |  |  |  |  | \n",
            "Sample 1555: Q: How many metric tons of emissions did Dow Chemical avoid in 2005? | GT: 224 | Pred:  The chart has the following columns: Year, Company, Emissions (metric tons), and Reduction (metric tons). The chart has the following rows: 2\n",
            "Sample 1556: Q: How many metric tons of greenhouse gases did Dow Chemical emit in 2005? | GT: 47 | Pred:  The chart has the following columns: Year, Company, Metric Tons of Greenhouse Gases, and Metric Tons of Greenhouse Gases (CO2\n",
            "Sample 1557: Q: How much CO2 did agriculture emit in Finland in 2018? | GT: 6.6 | Pred:  Assume values in the chart are in millions of tonnes.\n",
            "\n",
            "In 2018, agriculture in Finland emitted 13.3 million tonnes of CO2\n",
            "Sample 1558: Q: How many times has Iker Casillas appeared in the Champions League? | GT: 181 | Pred:  Each cell in the chart below contains a number. The first row contains the names of the players, and the first column contains the names of the competitions. The\n",
            "Sample 1559: Q: Who follows Iker Casillas in appearances in the Champions League? | GT: Cristiano Ronaldo | Pred:  The chart shows the number of appearances in the UEFA Champions League for each player.\n",
            "\n",
            "| Player | Appearances |\n",
            "|--------|-------------|\n",
            "| Iker Cas\n",
            "Sample 1560: Q: What was the average ticket price for Minnesota Vikings games in 2020? | GT: 108.79 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: 2020\n",
            "Sample 1561: Q: What was the most popular social media for Dutch Millennials in 2020? | GT: Instagram | Pred:  Do not make up data. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"The most popular social media\n",
            "Sample 1562: Q: How many marriages took place in Luxembourg in 2019? | GT: 2019 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "10000000\n",
            "Sample 1563: Q: What was the average annual wine consumption per resident in the United States in 2018? | GT: 2.95 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1564: Q: What is the expected number of inbound visitors in the Netherlands in 2020? | GT: 20.1 | Pred:  The chart shows the number of inbound visitors in the Netherlands in 2019 and 2020. In 2019, there\n",
            "Sample 1565: Q: How many international travelers did the Netherlands welcome in 2019? | GT: 20.1 | Pred:  Each row in the chart represents a different country. The first column is the country name. The second column is the number of international travelers (in millions). \n",
            "\n",
            "\n",
            "Sample 1566: Q: In what year did Walmart have a stable gross profit margin? | GT: 2006 | Pred:  The chart shows the gross profit margin for Walmart from 1990 to 2000.\n",
            "\n",
            "1990: 18.3\n",
            "Sample 1567: Q: What was Walmart's global profit margin in fiscal year 2021? | GT: 24.3 | Pred:  The chart shows the following data: \n",
            "- Walmart's global profit margin in fiscal year 2021 was 2.3%.\n",
            "\n",
            "2.3%\n",
            "Sample 1568: Q: What was China's share in global gross domestic product in 2020? | GT: 18.34 | Pred:  China's share in global gross domestic product in 2020 was 17%. 17% China's share in global gross domestic product in\n",
            "Sample 1569: Q: What was the estimated international sales of Debenhams? | GT: 442.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year | Sales (in\n",
            "Sample 1570: Q: What was Debenhams revenue in the UK in the year ending September 1st 2018? | GT: 1832.7 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Question: What was Debenhams\n",
            "Sample 1571: Q: What percentage of Spotify's revenues went towards royalty payments in 2020? | GT: 74.44 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100% of Spotify's\n",
            "Sample 1572: Q: How many people had access to the internet by the end of 2020? | GT: 988.99 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: \n",
            "| Year | Internet\n",
            "Sample 1573: Q: What was the average amount people gave in the month prior to being asked to donate to charity in England in 2019/20? | GT: 24 | Pred:  The chart shows the average amount people gave in the month prior to being asked to donate to charity in England in 2019/20 was £\n",
            "Sample 1574: Q: What was the price index of machinery and equipment in Canada in 2016? | GT: 128.4 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Price Index of Machinery and Equipment in\n",
            "Sample 1575: Q: How many Easter bunnies were produced in Germany in 2019? | GT: 220 | Pred:  Do not make up data. If the data is not in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Number of Easter bunnies produced in Germany\n",
            "Sample 1576: Q: How many people worked in the food and drink retailing sector in the first quarter of 2017? | GT: 1.12 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|} \\hline \\textbf{\n",
            "Sample 1577: Q: How many players did Juventus FC have as of October 2020? | GT: 23 | Pred:  Each row in the chart represents a player, with columns for name, position, age, and nationality. The chart ends with a row that says \"Total:\n",
            "Sample 1578: Q: What is the Serie A soccer club with the highest number of players? | GT: Genoa CFC | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Cannot determine from the chart\".\n",
            "\n",
            "Serie A\n",
            "Sample 1579: Q: Which football club had the lowest number of footballers as of October 2020? | GT: Juventus FC | Pred:  Do not make up information. If the chart does not contain the information needed to answer the question, respond with \"Insufficient data\".\n",
            "\n",
            "Chart: None\n",
            "Answer\n",
            "Sample 1580: Q: What is the projected number of World of Warcraft subscribers in 2023? | GT: 4.46 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "1000000\n",
            "Sample 1581: Q: How many global subscribers did World of Warcraft have in 2015? | GT: 5.5 | Pred:  Each cell in the chart is a single number. The chart has the following columns: Year, Subscribers (in millions), Revenue (in millions). The chart\n",
            "Sample 1582: Q: What was the average face amount of individual life insurance policies purchased in the United States in 2018? | GT: 168 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that question\". Do not say \"The chart does not\n",
            "Sample 1583: Q: What was the average face amount of individual life insurance policies purchased in the United States in 2018? | GT: 168 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that question\". Do not say \"The chart does not\n",
            "Sample 1584: Q: What percentage of all households in New Orleans, Louisiana were one-person households in 2019? | GT: 46.81 | Pred:  The chart shows the distribution of household types in New Orleans, Louisiana in 2019. \n",
            "\n",
            "| Household Type | Percentage |\n",
            "|----------------|------------|\n",
            "\n",
            "Sample 1585: Q: How many smartphone users are expected to be in Germany by 2024? | GT: 75.6 | Pred:  The chart shows the number of smartphone users in Germany from 2018 to 2024. The values are: 2018\n",
            "Sample 1586: Q: What was the total value of the global data visualization market in 2017? | GT: 4.51 | Pred:  The chart shows the following data: In 2017, the global data visualization market was valued at $1.8 billion. Answer: $1\n",
            "Sample 1587: Q: What is the market expected to grow to by 2023? | GT: 7.76 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "The market is expected to grow to\n",
            "Sample 1588: Q: Who has the most RBI in Pittsburgh Pirates franchise history? | GT: Willie Stargell | Pred:  Each row in the chart represents a player. Each column in the chart represents a statistic. The columns are: Name, Position, Team, Year, Games,\n",
            "Sample 1589: Q: What was Malaysia's share in the global gross domestic product adjusted for Purchasing Power Parity in 2019? | GT: 0.7 | Pred:  The chart has the following columns: Country, GDP (in USD), GDP (PPP) (in USD), GDP (PPP) per capita (in USD).\n",
            "Sample 1590: Q: How many immigrants lived in Mongolia in 2010? | GT: 16 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". \n",
            "\n",
            "Data: Data not available in\n",
            "Sample 1591: Q: How many people died as a result of intentional homicide in Haiti in 2018? | GT: 743 | Pred:  Each row in the chart represents a different country. Each column in the chart represents a different year. The values in the cells are the number of deaths due to\n",
            "Sample 1592: Q: In what year was the app sensor market forecast to be worth 5.6 billion U.S. dollars? | GT: 2017 | Pred:  The chart shows the forecasted value of the app sensor market in billions of U.S. dollars from 2015 to 2020.\n",
            "\n",
            "\n",
            "Sample 1593: Q: How much is the app sensor market expected to be worth by 2017? | GT: 5600 | Pred:  The chart shows the following data: 2014: $1.2 billion, 2015: $1.5 billion, \n",
            "Sample 1594: Q: What was the U.S. notebook market penetration in 2010? | GT: 63 | Pred:  The chart shows the U.S. notebook market penetration in 2010, which was 48%. Final answer: 48%.Human\n",
            "Sample 1595: Q: How many infant deaths were there in Canada in 2019? | GT: 345 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the number of infant deaths in Canada in 2019\n",
            "Sample 1596: Q: What was the global number of Inditex employees in 2020? | GT: 144116 | Pred:  The chart shows the following data: Zara (Inditex) had 100,000 employees in 2020.\n",
            "\n",
            "1\n",
            "Sample 1597: Q: How much revenue did Digital Bros generate in fiscal 2020? | GT: 133.22 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "? \n",
            "? \n",
            "? \n",
            "?\n",
            "Sample 1598: Q: What year was Audi's last fiscal year? | GT: 2002 | Pred:  Each row in the chart represents a fiscal year. The first column is the fiscal year. The second column is the revenue. The third column is the profit.\n",
            "Sample 1599: Q: When did Audi's total assets end? | GT: 2020 | Pred:  Do not make up data or statistics. If the information is not available in the chart, respond with \"Information not available in chart\".\n",
            "\n",
            "Audi's total assets\n",
            "Sample 1600: Q: What was Audi's total assets in the fiscal year of 2020? | GT: 67229 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Audi's total assets in the\n",
            "Sample 1601: Q: How many direct operated stores did Tod's Group control in 2019? | GT: 137 | Pred:  The chart shows the number of direct operated stores for Tod's Group in 2019. The chart indicates that Tod's Group controlled 120\n",
            "Sample 1602: Q: What was Pakistan's gross domestic product in dollars in 2020? | GT: 262.8 | Pred:  The chart has the following columns: Country, GDP (in USD), GDP per capita (in USD), Population (in millions). The chart has the following rows\n",
            "Sample 1603: Q: What was Nicaragua's unemployment rate in 2020? | GT: 7.36 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". Nicaragua's unemployment rate in 2\n",
            "Sample 1604: Q: What was Kentucky's GDP in 2020? | GT: 183.8 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Sure. Please provide the chart with\n",
            "Sample 1605: Q: What was Kentucky's GDP in dollars in 2018? | GT: 190.81 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart shows the\n",
            "Sample 1606: Q: How many men were admitted to hospital as a result of a road traffic accident in Scotland in 2019/20? | GT: 613 | Pred:  The chart shows the number of people admitted to hospital as a result of a road traffic accident in Scotland in 2019/20, broken down\n",
            "Sample 1607: Q: What was the GVA of the financial and insurance services sector in 2019? | GT: 125910 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the GVA of the financial and insurance services sector in 2\n",
            "Sample 1608: Q: What was the GVA of the financial and insurance services sector in 2019? | GT: 125910 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the GVA of the financial and insurance services sector in 2\n",
            "Sample 1609: Q: Where was the 2014 FIFA World Cup held? | GT: Brazil | Pred:  Do not make up information. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"Final answer\". Do\n",
            "Sample 1610: Q: What is the combined market/transfer value of the Spanish squad? | GT: 622 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1611: Q: What was the net banking income of European banks in 2013? | GT: 700 | Pred:  The chart shows the net banking income of European banks in 2013. The net banking income of European banks in 2013 was $\n",
            "Sample 1612: Q: When was Faurecia's global OEM automotive parts sales first reported? | GT: 2001 | Pred:  Chart cells are separated by tabs, rows and columns are indexed starting from 0. Make sure your answer is precise and matches the chart data.\n",
            "\n",
            "Row 0\n",
            "Sample 1613: Q: What was Faurecia's global sales in dollars in 2019? | GT: 19900 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: {\"data\": [{\"x\": \"\n",
            "Sample 1614: Q: How much of the EU budget came from VAT resources in 2013? | GT: 9.4 | Pred:  The chart shows the share of EU budget resources by source in 2013. The chart has the following data points: \n",
            "- Own resources: \n",
            "Sample 1615: Q: What was the average price per 1,000 cubic feet of natural gas in 2020? | GT: 10.84 | Pred:  The chart shows the average price per 1,000 cubic feet of natural gas in the United States from 2010 to 20\n",
            "Sample 1616: Q: What was the population of Dallas-Fort Worth-Arlington in the previous year? | GT: 7573990 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Question: What was the population of\n",
            "Sample 1617: Q: What was the population of Dallas-Fort Worth-Arlington in 2020? | GT: 7694138 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Population of Dallas-Fort\n",
            "Sample 1618: Q: In what year did the child mortality rate drop to its lowest ever? | GT: 2020 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: In what year did the child mortality rate drop\n",
            "Sample 1619: Q: What was Nigeria's most popular social media in the third quarter of 2020? | GT: WhatsApp | Pred:  The chart shows the following data: Nigeria's most popular social media in the third quarter of 2020 was TikTok.\n",
            "\n",
            "TikTok.\n",
            "Sample 1620: Q: What percentage of Nigerians use Facebook and Youtube? | GT: 81.6 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Data not available\".\n",
            "\n",
            "100% of Nigerians use Facebook and\n",
            "Sample 1621: Q: What percentage of Nigerians use Facebook and Youtube? | GT: 86.2 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Data not available\".\n",
            "\n",
            "100% of Nigerians use Facebook and\n",
            "Sample 1622: Q: How much revenue did Zynga generate in the first quarter of 2021? | GT: 680.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Zynga Revenue (in millions\n",
            "Sample 1623: Q: How much revenue did Zynga generate in the first quarter of 2021? | GT: 616 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Zynga Revenue (in millions\n",
            "Sample 1624: Q: How many femicide victims were registered in Veracruz? | GT: 84 | Pred:  Table cells in the same row are seperated by '|', and each row corresponds to a state. The table has the following columns: state, femicide victims\n",
            "Sample 1625: Q: How many widowed people were there in Canada in 2020? | GT: 1.95 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "1000000\n",
            "Sample 1626: Q: How many widowed people lived in Canada in 2000? | GT: 1.55 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Number of widowed people in Canada\n",
            "Sample 1627: Q: What was the total number of participants in lacrosse in 2018? | GT: 2.1 | Pred:  The chart has the following columns: Year, Men's Lacrosse, Women's Lacrosse, Total. The chart has the following rows: 201\n",
            "Sample 1628: Q: What country has the largest population in Africa? | GT: Nigeria | Pred:  Do not make up data. Do not say things like 'based on the chart' or 'as shown in the chart'. Do not say things like 'the\n",
            "Sample 1629: Q: What was the infant mortality rate in the Kyrgyz Republic in 2019? | GT: 16.4 | Pred:  The chart has the following columns: Country, Year, Infant mortality rate (per 1000 live births), Life expectancy at birth (years), GDP\n",
            "Sample 1630: Q: Which country was the most popular long-haul summer holiday destination in 2015? | GT: Spain | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". The\n",
            "Sample 1631: Q: What neighbor country received roughly four percent of the long-haul Dutch tourists in 2015? | GT: Belgium | Pred:  The chart shows the distribution of long-haul Dutch tourists in 2015 by destination country.\n",
            "\n",
            "The chart indicates that the neighbor country receiving roughly four percent\n",
            "Sample 1632: Q: Which country was the most popular destination to spend a long-haul summer holiday in 2015? | GT: France | Pred:  The chart shows the number of long-haul summer holidays taken to various countries in 2015.\n",
            "\n",
            "The most popular destination to spend a long-haul\n",
            "Sample 1633: Q: What is the only intercontinental country in the top 10 long haul summer destinations? | GT: Great Britain | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". \n",
            "\n",
            "\n",
            "Sample 1634: Q: What percentage of Dutch long-haul summer holiday tourists come from the United States? | GT: 2.5 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the distribution of Dutch long-haul summer holiday tourists by country of\n",
            "Sample 1635: Q: What was Turkey's poverty headcount ratio in 2018? | GT: 14.4 | Pred:  The chart shows the poverty headcount ratio in Turkey from 1990 to 2018. The poverty headcount ratio in Turkey in \n",
            "Sample 1636: Q: What was the lowest value of French imports from Russia in 2016? | GT: 6119 | Pred:  The chart shows the value of French imports from Russia in millions of euros from 2013 to 2017. The values are: \n",
            "Sample 1637: Q: What was the highest value of French imports from Russia in 2011? | GT: 19346 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the value of French imports from Russia in millions of euros from \n",
            "Sample 1638: Q: What was the annual value of French imports from Russia in 2019? | GT: 9158 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Annual value of French imports from Russia\n",
            "Sample 1639: Q: What percentage of Beiersdorf employees were employed in Europe by the end of the 2020 fiscal year? | GT: 56.8 | Pred:  The chart shows the number of employees in different regions of Beiersdorf by the end of the 2020 fiscal year. The regions are: Europe\n",
            "Sample 1640: Q: What was the percentage of foreign nationals in Luxembourg in 2019? | GT: 47.42 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the percentage of foreign nationals in Luxembourg in 2019\n",
            "Sample 1641: Q: What was the highest rating for En Punto con Denise Maerker? | GT: 11.8 | Pred:  Each row in the chart represents a different show. The first column is the show name, the second column is the rating, and the third column is the date\n",
            "Sample 1642: Q: How many criminal offences were solved in the same year? | GT: 313438 | Pred:  The chart has the following columns: Year, Number of Criminal Offences, Number of Criminal Offences Solved, and Number of Criminal Offences Unsolved.\n",
            "\n",
            "\n",
            "Sample 1643: Q: How many criminal offences were reported to the authorities in 2020? | GT: 543429 | Pred:  The chart shows the number of criminal offences reported to the authorities in the UK from 2010 to 2020. In 20\n",
            "Sample 1644: Q: What was the value of U.S. textile and apparel exports to Germany in dollars in 2020? | GT: 314.75 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "We are unable to access or interpret\n",
            "Sample 1645: Q: What was the estimated market value of edible insects in 2018? | GT: 406.32 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1646: Q: What was the average electricity supply price in Brazil in June 2019? | GT: 497.65 | Pred:  The chart shows the average electricity supply price in Brazil from January 2019 to December 2019. The prices are given in reais\n",
            "Sample 1647: Q: How much did the population of Latin America & Caribbean grow in 2019? | GT: 0.93 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the population of Latin America & Caribbean in 2019\n",
            "Sample 1648: Q: How many passenger cars were sold in Pakistan between July 2018 and June 2019? | GT: 207630 | Pred:  The chart shows the number of passenger cars sold in Pakistan from July 2018 to June 2019. The total number of passenger cars\n",
            "Sample 1649: Q: How much money did Universal spend on '1917'? | GT: 10.41 | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart\". \n",
            "\n",
            "Chart: None\n",
            "Information not available in chart\n",
            "Sample 1650: Q: How much money did Universal spend on 'Dolittle'? | GT: 5.77 | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart\". \n",
            "\n",
            "Chart: None\n",
            "Information not available in chart\n",
            "Sample 1651: Q: What is the name of the tax deferred pension plan available to self-employed individuals or unincorporated businesses for retirement purposes? | GT: KEOGH | Pred:  Each row in the chart represents a different option. Columns in the chart represent different attributes of the options. Use the attributes in the chart to determine the correct answer\n",
            "Sample 1652: Q: What was eBay's net revenue in the prior year? | GT: 8636 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1653: Q: How much was eBay's net revenue in the most recent fiscal year? | GT: 9927 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "eBay Inc. Financial Data (in millions\n",
            "Sample 1654: Q: What was the brand value of Chelsea FC in dollars in 2019? | GT: 1085 | Pred:  The chart shows the brand value of several football clubs in 2019. The brand value of Chelsea FC in 2019 was $1\n",
            "Sample 1655: Q: What was the value of the Minnesota Vikings in 2020? | GT: 2950 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer: Data not\n",
            "Sample 1656: Q: How much did Zygmunt Wilf pay for the Minnesota Vikings in 2005? | GT: 604 | Pred:  Do not make up information. If information is not in the chart, say \"Not in chart\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer: Not in chartHuman\n",
            "Sample 1657: Q: What country had the second largest share of the global blood plasma market? | GT: China | Pred:  Do not make up data or statistics. If the information is not in the chart, you cannot answer the question.\n",
            "\n",
            "Available choices:\n",
            "(A). United States\n",
            "(B\n",
            "Sample 1658: Q: Which country was responsible for five percent of the global blood plasma market? | GT: Germany | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Data not available in chart\n",
            "Sample 1659: Q: When did the number of ATM-related physical attacks increase? | GT: 2014 | Pred:  The chart has the following columns: Year, Number of ATM-related physical attacks, Number of ATM-related cyber attacks, Number of ATM-related fraud cases. The chart\n",
            "Sample 1660: Q: In what year did the number of hospitals in Hungary begin to stabilize? | GT: 2000 | Pred:  Assume missing values are not present. The chart shows the number of hospitals in Hungary from 1990 to 2010.\n",
            "\n",
            "199\n",
            "Sample 1661: Q: What was the peak number of hospitals between 2004 and 2005? | GT: 182 | Pred:  Chart: 2004 2005 2006 2007 2008 2009\n",
            "Sample 1662: Q: How many hospitals were there in Hungary in 2018? | GT: 165 | Pred:  Each row in the chart represents a country. Each column in the chart represents a different year. The values in the cells are the number of hospitals in that country\n",
            "Sample 1663: Q: What is OPEC's average share of global natural gas reserves? | GT: 35.5 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "**Chart Title:** OPEC's\n",
            "Sample 1664: Q: What percentage of respondents purchased Kent brand cigarettes in the last three to twelve months of 2013? | GT: 9 | Pred:  The chart shows the percentage of respondents who purchased Kent brand cigarettes in the last three to twelve months of 2013. The chart has the following data\n",
            "Sample 1665: Q: What is the estimated global demand for ethylene by 2022? | GT: 185 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". \n",
            "\n",
            "Chart content: None\n",
            "Final\n",
            "Sample 1666: Q: What was the global demand for ethylene in 2017? | GT: 152 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the global demand for ethylene in 2017 was\n",
            "Sample 1667: Q: What was the government spending in France in 2019? | GT: 1349.03 | Pred:  The chart shows the government spending in France in 2019.\n",
            "Answer: The government spending in France in 2019 was 37\n",
            "Sample 1668: Q: What was the government revenue in France in 2019? | GT: 1275.06 | Pred:  The chart shows the government revenue in France in 2019.\n",
            "Answer: The government revenue in France in 2019 was 3,\n",
            "Sample 1669: Q: What was the unemployment rate in Sierra Leone in 2020? | GT: 4.44 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Sierra Leone Unemployment Rate (\n",
            "Sample 1670: Q: What percentage of votes did Alberto Fernandez get? | GT: 48.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Candidate | Votes | %\n",
            "Sample 1671: Q: What was Austrian sales of Ford cars in 2017? | GT: 20748 | Pred:  The chart has the following columns: Country, Year, Sales (in thousands). The chart has the following rows: Austria, 2017, \n",
            "Sample 1672: Q: How many Ford cars were sold in Austria in 2011? | GT: 23678 | Pred:  Each row in the chart represents a year. Each column in the chart represents a country. The values in the cells are the number of cars sold in that country\n",
            "Sample 1673: Q: What was the price of one thousand board feet of Western hemlock in 2015? | GT: 69.04 | Pred:  Each row in the chart represents a different year. The columns represent different types of wood. The values in the cells are the prices in dollars per thousand board feet\n",
            "Sample 1674: Q: What was the total sales of sanitary napkins/tampons in the United States in 2018? | GT: 2.8 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1675: Q: What was the dollar sales of sanitary napkins and liners in the United States in 2018? | GT: 1.76 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: \n",
            "| Year | San\n",
            "Sample 1676: Q: What percentage of Antigua and Barbuda's total employment did tourism contribute to in 2019? | GT: 90.7 | Pred:  The chart shows the percentage of total employment in Antigua and Barbuda by sector in 2019. The chart includes the following sectors: Agriculture,\n",
            "Sample 1677: Q: What was the total contribution of travel and tourism to employment in the whole Caribbean region in 2019? | GT: 15.2 | Pred:  The chart shows the total contribution of travel and tourism to employment in the whole Caribbean region in 2019. The total contribution of travel and tourism to\n",
            "Sample 1678: Q: What was Aruba's contribution share in 2019? | GT: 84.3 | Pred:  Each cell in the table is separated by a tab. Table cells in a row are separated by tabs, and each row (including the header) is on a\n",
            "Sample 1679: Q: What was the total sales of office supplies, stationery, and gift stores in the United States a year earlier? | GT: 30.32 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|} \\hline \\textbf{\n",
            "Sample 1680: Q: How much did office supplies, stationery, and gift store sales in the U.S. in 2019? | GT: 28.92 | Pred:  The chart has the following columns: Year, Office Supplies, Stationery, Gift Store. The chart has the following rows: 2019, \n",
            "Sample 1681: Q: How many carvedilol prescriptions were there in 2018? | GT: 22.78 | Pred:  Each row in the chart represents a year, and each column represents a drug. The first column is the year, and the following columns are drug names. The\n",
            "Sample 1682: Q: What was the national debt of the United States of America in dollars in September of 2020? | GT: 26945.39 | Pred:  Do not make up numbers. Do not say \"The chart does not show\". The chart shows the national debt of the United States of America in dollars from \n",
            "Sample 1683: Q: How many people in Indonesia had access to the internet in 2019? | GT: 184.94 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "2019: 1\n",
            "Sample 1684: Q: By 2025, how many people are expected to access the internet in Indonesia? | GT: 256.37 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100 million\n",
            "\n",
            "15\n",
            "Sample 1685: Q: How many Brazilian reals were estimated to be needed for the Carnival in Rio de Janeiro in 2020? | GT: 70 | Pred:  Chart: None\n",
            "Answer: The chart provided does not contain information about the estimated number of Brazilian reals needed for the Carnival in Rio de Janeiro in 2\n",
            "Sample 1686: Q: How many reals would come from the city government's budget? | GT: 42 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Category | 2018 | \n",
            "Sample 1687: Q: What was the GDP of Germany in 2018? | GT: 3386000 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "GDP of Germany in 20\n",
            "Sample 1688: Q: What country had the highest GDP in 2018? | GT: Germany | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the highest GDP in 2018\n",
            "Sample 1689: Q: Which country came in second among the countries shown in this graph? | GT: Mexico | Pred:  Do not make up information. Do not say I cannot answer this question. The chart is not provided.\n",
            "\n",
            "Answer: I cannot answer this question.Human:\n",
            "Sample 1690: Q: What was the estimated value of the Cincinnati Reds in 2021? | GT: 1085 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1691: Q: What percentage of respondents identified the problems with integrating systems and operations as the main obstacle on the way to smooth integration? | GT: 29 | Pred:  Chart cells are separated by new lines. % of respondents who identified the problems with integrating systems and operations as the main obstacle on the way to smooth integration: \n",
            "Sample 1692: Q: What percentage of Venezuela's GDP did Venezuela's military budget account for in 2017? | GT: 2.2 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Data not available\".\n",
            "\n",
            "Chart: {\"type\": \"table\", \"title\n",
            "Sample 1693: Q: How many Swiss Francs did Rolex sell in 2013? | GT: 4300 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Rolex Sales (in millions)\n",
            "Sample 1694: Q: What was the leading Swiss watch brand in 2013? | GT: Rolex | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "Patek Philippe\n",
            "Omega\n",
            "Rolex\n",
            "Sw\n",
            "Sample 1695: Q: Who has the most hits in Pittsburgh Pirates franchise history? | GT: Roberto Clemente | Pred:  Each row in the chart represents a player. Each column in the chart represents a statistic. The columns are: Player, Team, Position, Years, Hits,\n",
            "Sample 1696: Q: How much money did Madison Square Garden Company generate in annual revenue in 2020? | GT: 603.32 | Pred:  The chart shows the annual revenue of Madison Square Garden Company from 2015 to 2020.\n",
            "\n",
            "2015: $1.\n",
            "Sample 1697: Q: By what year did Brunei expect to have a population over 65? | GT: 2040 | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just answer the question. Question: By what year did Brunei expect to have\n",
            "Sample 1698: Q: What was the percentage of Brunei's population older than 65 in 2020? | GT: 5.6 | Pred:  Chart: 2020 Population by Age Group in Brunei (in thousands) Age Group | Population (in thousands) 0-14 |\n",
            "Sample 1699: Q: What was the average retail price for 2.5 kilograms of flour in Canada in February 2021? | GT: 4.42 | Pred:  The chart shows the average retail price for 2.5 kilograms of flour in Canada from January 2020 to February 2021.\n",
            "\n",
            "\n",
            "Sample 1700: Q: What was the crude birth rate in the Congo in 2019? | GT: 40.64 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Crude birth rate (per \n",
            "Sample 1701: Q: In the previous reporting year, how many fire-related deaths were there in Great Britain? | GT: 317 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "1000s of fire-related deaths\n",
            "Sample 1702: Q: How many fire-related deaths occurred in Great Britain in 2019/20? | GT: 286 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "2019/20\n",
            "Sample 1703: Q: What was the initial forecast for smartphone shipments in 2020? | GT: 6.4 | Pred:  The chart shows the forecasted smartphone shipments (in millions) for 2019 and 2020. In 2019,\n",
            "Sample 1704: Q: What is the predicted decrease in smartphone shipment value in 2020? | GT: 6.4 | Pred:  The chart shows the smartphone shipment value in 2018, 2019, and 2020. In 201\n",
            "Sample 1705: Q: How many job openings were there in April of 2021? | GT: 8.29 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Number of Job Openings (in thousands)\n",
            "Sample 1706: Q: How many job openings were there by the last business day of April 2021? | GT: 9.29 | Pred:  Do not make up data. Do not say \"Insufficient data\". The chart shows the number of job openings in the United States by month from January 2\n",
            "Sample 1707: Q: What was the operating income of the Brooklyn Nets in the 2019/20 season? | GT: 44 | Pred:  The chart shows financial data for the Brooklyn Nets from 2015 to 2020, including revenue, net income, and operating income.\n",
            "Sample 1708: Q: What was the most-followed brand on Facebook in Hong Kong as of March 2021? | GT: Blackview | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "The most-followed brand on Facebook\n",
            "Sample 1709: Q: How many fans did Blackview have in Hong Kong as of March 2021? | GT: 1714353 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Number of fans in Hong Kong as\n",
            "Sample 1710: Q: In what year did online sales make up 0.4 percent of food and grocery retail sales? | GT: 2013 | Pred:  The chart shows the following data: Year, Online Sales as % of Food and Grocery Retail Sales, 2000, 0.1, \n",
            "Sample 1711: Q: What percentage of food and grocery retail sales did online sales make up in 2013? | GT: 0.4 | Pred:  The chart shows the following data: In 2013, online food and grocery retail sales accounted for 1.3% of total food and grocery\n",
            "Sample 1712: Q: What percentage of online sales is expected to increase to by 2018? | GT: 0.7 | Pred:  The chart shows the following data: \n",
            "Year | Online Sales (% of total sales)\n",
            "2014 | 12%\n",
            "2015 | \n",
            "Sample 1713: Q: What was the population of the Minneapolis-St. Paul-Bloomington metropolitan area in 2020? | GT: 3639892 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Population of the Minneapolis-St\n",
            "Sample 1714: Q: What was the population of the Minneapolis-St. Paul-Bloomington metropolitan area in the previous year? | GT: 3611648 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the population of the Minneapolis-St. Paul-Bloomington metropolitan area\n",
            "Sample 1715: Q: What was the Barclays Premier League's brand value in 2012? | GT: 4170 | Pred:  The chart shows the brand value of the Barclays Premier League in 2012 as £1.4 billion. Final answer: £1.4 billion\n",
            "Sample 1716: Q: What country had 41,320 cubic meters of renewable water resources per capita in 2017? | GT: Brazil | Pred:  The chart has the following columns: Country, Renewable Water Resources (cubic meters per capita), and Year.\n",
            "Answer: The provided information does not include a chart\n",
            "Sample 1717: Q: How many mobile subscriptions were registered for every 100 people in South Africa between 2000 and 2019? | GT: 165.6 | Pred:  The chart shows the number of mobile subscriptions per 100 people in South Africa from 2000 to 2019. The values\n",
            "Sample 1718: Q: What was the number of domestic tourist arrivals in Belgium in 2020? | GT: 4632153 | Pred:  The chart shows the number of domestic tourist arrivals in Belgium in 2019 and 2020.\n",
            "\n",
            "In 2019, the\n",
            "Sample 1719: Q: How many Dutch tourists arrived in Belgium in 2020? | GT: 736926 | Pred:  The chart shows the number of tourists arriving in Belgium from various countries in 2020.\n",
            "Answer: The chart does not provide specific data on the number\n",
            "Sample 1720: Q: What religion made up 93 percent of the population in the Middle East and North Africa in 2010? | GT: Muslims | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "93 percent of the\n",
            "Sample 1721: Q: When was the last fiscal year of ServiceMaster Global Holdings? | GT: 2014 | Pred:  Do not make up information. If the information is not available in the chart, respond with \"N/A\".\n",
            "\n",
            "Answer: N/A\n",
            "\n",
            "Reason: The chart does\n",
            "Sample 1722: Q: How many Swedish kronor were intended expenses for Christmas in 2018? | GT: 5860 | Pred:  Chart cells are separated by newlines, rows are separated by newlines, and the first row contains the headers. Each cell is separated by a tab. The\n",
            "Sample 1723: Q: Who is the career rushing leader of the Kansas City Chiefs? | GT: Jamaal Charles | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart.\"\n",
            "\n",
            "Chart: None\n",
            "Answer: Information not available in\n",
            "Sample 1724: Q: How much did the sales of gardening equipment grow in the first six months of 2015? | GT: 5.3 | Pred:  The chart shows the sales of gardening equipment in the first six months of 2014 and 2015. In the first six months of\n",
            "Sample 1725: Q: What year was the highest number of gang-related homicides in the US? | GT: 2007 | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the number of gang-related homicides in the US from 19\n",
            "Sample 1726: Q: Who is the career rushing leader of the New England Patriots? | GT: Sam Cunningham | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Final Answer: Information not available\n",
            "Sample 1727: Q: What was the percentage of baptized children in Norrbotten county in 2020? | GT: 41.5 | Pred:  The chart shows the number of baptized children in Norrbotten county in 2020. The number of baptized children in Norrbotten county in \n",
            "Sample 1728: Q: What percentage of children were baptized in Stockholm in 2020? | GT: 30.7 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100% of children were\n",
            "Sample 1729: Q: How many people used a foodbank in 2008/09? | GT: 25899 | Pred:  Do not make up data. If the data is not in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Number of people using foodbanks in the UK\n",
            "Sample 1730: Q: How many dollars did PR agencies generate with media relations services in 2019? | GT: 764 | Pred:  The chart shows the following data: In 2019, PR agencies generated $1.2 billion in revenue from media relations services.\n",
            "\n",
            "1.2\n",
            "Sample 1731: Q: How much money did full public relations services bring in in 2019? | GT: 764 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is the header row. The first column is the year column\n",
            "Sample 1732: Q: What was the percentage of support for the SDP in May 2019? | GT: 17.7 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "The chart shows the percentage of support\n",
            "Sample 1733: Q: How many followers did Charli D'Amelio have on the TikTok app? | GT: 72.5 | Pred:  Chart: 1. Charli D'Amelio has 100 million followers on TikTok. 2. The number of followers on Tik\n",
            "Sample 1734: Q: What percentage of hedge fund investments did fund of hedge funds managers account for in August 2018? | GT: 43 | Pred:  The chart shows the percentage of hedge fund investments accounted for by fund of hedge funds managers in August 2018. The chart indicates that fund of hedge\n",
            "Sample 1735: Q: When did the combined operating revenue of U.S. airlines begin to increase? | GT: 2015 | Pred:  Do not make up data or statistics. If the information is not available in the chart, say so.\n",
            "\n",
            "The chart shows the combined operating revenue of U.S.\n",
            "Sample 1736: Q: How much operating revenue did U.S. airlines generate in 2020 due to the coronavirus pandemic? | GT: 130.69 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1737: Q: What was the combined operating revenue of U.S. airlines in 2019? | GT: 248 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1738: Q: What was the sales of Outback Steakhouse in the United States in 2014? | GT: 2.48 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Sales of Outback Steakhouse in the United\n",
            "Sample 1739: Q: What full service chain's U.S. sales reached approximately 2.48 billion U.S. dollars in 2014? | GT: Outback Steakhouse | Pred:  Do not make up data or statistics. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "2.48 billion U\n",
            "Sample 1740: Q: What was the average passenger revenue per passenger-mile in 2018? | GT: 40.7 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1741: Q: What was the value of passenger revenue per passenger-mile in the year after 2018? | GT: 41.7 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1742: Q: Which soap bar brand managed to maintain a positive sales growth over the time period? | GT: Dove | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: Which soap bar brand managed to maintain a positive\n",
            "Sample 1743: Q: What was the youth unemployment rate in the United States in 2020? | GT: 8.94 | Pred:  The chart shows the youth unemployment rate in the United States from 2010 to 2020. The youth unemployment rate in the United States\n",
            "Sample 1744: Q: How many movie theaters visited Russia in the week ending June 16, 2021? | GT: 2.6 | Pred:  The chart shows the number of movie theaters visited by Russia in the week ending June 16, 2021. The chart has the following data\n",
            "Sample 1745: Q: What was the weekly attendance of Russian cinemas during the New Year's holidays? | GT: 7.4 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Weekly attendance of Russian cinemas during the\n",
            "Sample 1746: Q: Which country had the highest pedestrian death rate out of all the countries of the UK? | GT: Romania | Pred:  Do not make up data or statistics. If the chart does not contain the information needed to answer the question, respond with \"Insufficient data\".\n",
            "\n",
            "Insufficient data\n",
            "Sample 1747: Q: How many Formula One races has Red Bull Racing won? | GT: 64 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The chart\n",
            "Sample 1748: Q: Who is the career assists leader of the Golden State Warriors? | GT: Guy Rodgers | Pred:  Each row in the chart represents a player. Each column in the chart represents a statistic. The columns are: Player, Position, Games, Points, Assists\n",
            "Sample 1749: Q: What was the year with the highest number of arrests for public drunkenness? | GT: 2007 | Pred:  The chart has the following columns: Year, Number of Arrests for Public Drunkenness, Number of Arrests for Public Intoxication, Number of Arrest\n",
            "Sample 1750: Q: Which state had the highest number of turkeys raised in 2018? | GT: Minnesota | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The answer is\". Do not say \"One possible answer is\n",
            "Sample 1751: Q: Which state was the leading producer of turmeric in India in 2018? | GT: Telangana | Pred:  Do not make up information. If the chart does not contain the information, respond with \"Information not available in the chart\".\n",
            "\n",
            "Thought: The chart does not contain\n",
            "Sample 1752: Q: How many games have Clemens and Young won? | GT: 192 | Pred:  The chart has the following columns: Year, Clemens, Young. Each row represents a year, and the values in the columns represent the number of games won\n",
            "Sample 1753: Q: What was India's revenue from international tourism in 2019? | GT: 30.06 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 1754: Q: What was India's revenue from international tourism in 2010? | GT: 14.49 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 1755: Q: How much was merchandise imported to the United States from China in 2019? | GT: 17.18 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "1000000\n",
            "Sample 1756: Q: In March 2018, what was the average waiting time for treatment in the UK? | GT: 64 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available\n",
            "Sample 1757: Q: As of March 2020, how many enterprises had between 50 and 99 employees? | GT: 10 | Pred:  The chart is as follows:  \\begin{tabular}{|c|c|c|c|c|c|c|c|c|\n",
            "Sample 1758: Q: In what year did 328 subsea wells come onstream or start achieving first production? | GT: 2014 | Pred:  Each row in the chart represents a year. The first column is the year. The second column is the number of subsea wells that came onstream or started\n",
            "Sample 1759: Q: What was Rothschild's M&A deal count in 2016? | GT: 101 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Question: What was Rothschild's M&A\n",
            "Sample 1760: Q: Which company was ranked as the leading financial advisor with an M&A deal count amounting to 101 in 2016? | GT: Rothschild | Pred:  Do not make up information. If the information is not in the chart, you should say \"Information not available in chart\".\n",
            "\n",
            "Answer: Information not available in chart\n",
            "Sample 1761: Q: What was the net revenue of Goldman Sachs in dollars in 2020? | GT: 44.56 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Net revenue of Goldman Sachs in \n",
            "Sample 1762: Q: Which state had the lowest income distribution inequality? | GT: Tlaxcala | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The state with the lowest income distribution inequality is...\". Do\n",
            "Sample 1763: Q: What was the Gini coefficient of Mexico City above the national average? | GT: 0.47 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Gini coefficient of Mexico\n",
            "Sample 1764: Q: What was the value of the harvested area of rice crops in Thailand in 2020? | GT: 56.83 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\\n\\nChart content: Thailand\n",
            "Sample 1765: Q: What was the size of the harvested area of rice crops in Thailand in 2019? | GT: 54.11 | Pred:  The chart is as follows: \\begin{tabular}{|c|c|c|c|c|} \\hline \\textbf{Year\n",
            "Sample 1766: Q: What percentage of industrial NC software seats did Dassault Syst mes provide in 2013? | GT: 5.6 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "100% of industrial NC\n",
            "Sample 1767: Q: What was the population density per square kilometer in the United States in 2018? | GT: 35.71 | Pred:  The chart has the following columns: Country, Population (in millions), Area (in square kilometers), Population density (in people per square kilometer). The chart\n",
            "Sample 1768: Q: How many retail stores did Herm s operate in 2020? | GT: 306 | Pred:  Each cell in the chart is either a number or a blank. When a cell is blank, it means the corresponding value is not available in the chart. When\n",
            "Sample 1769: Q: How many cases of COVID-19 were confirmed in Denmark as of March 23, 2020? | GT: 564 | Pred:  Chart cells are separated by new lines, and columns are separated by tabs. Use \"Insufficient data\" if the answer cannot be found in the chart.\n",
            "\n",
            "Date\n",
            "Sample 1770: Q: Where did 298 of Denmark's confirmed cases originate from? | GT: Austria | Pred:  The chart has the following columns: Date, Total Confirmed Cases, New Confirmed Cases, Total Recovered, New Recovered, Total Deaths, New Deaths\n",
            "Sample 1771: Q: How much ad-supported revenue did Spotify generate in the most recent fiscal year? | GT: 745 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Data: {\"2018\n",
            "Sample 1772: Q: How much has premium revenue grown by since 2017? | GT: 7135 | Pred:  Do not make up data. If the chart does not contain the information needed to answer the question, respond with \"Insufficient data\".\n",
            "\n",
            "2017:\n",
            "Sample 1773: Q: How much premium revenue did Spotify generate in the most recent fiscal year? | GT: 7135 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Data: {\"fiscal_year\":\n",
            "Sample 1774: Q: What was Russia's fertility rate in 2020? | GT: 1.74 | Pred:  Do not make up data points or extrapolate. Russia's fertility rate in 2020 was 1.58 children per woman.\n",
            "\n",
            "Answer:\n",
            "Sample 1775: Q: What was the average number of children born per one woman in the urban area? | GT: 1.43 | Pred:  The chart shows the average number of children born per one woman in different regions of the world.\n",
            "\n",
            "| Region | Average number of children born per one woman |\n",
            "|\n",
            "Sample 1776: Q: In what year was a national average of existing office space available in the Netherlands? | GT: 2015 | Pred:  Do not make up information. If the information is not in the chart, say \"Not in chart\".\n",
            "\n",
            "Year: 1990, 19\n",
            "Sample 1777: Q: What was the value of money market funds as of December 2020? | GT: 49.26 | Pred:  The chart shows the value of money market funds as of December 2020.\n",
            "Answer: $1.4 trillion.Human: What was the\n",
            "Sample 1778: Q: How much money did the US Chamber of Commerce spend in the 2016 election cycle? | GT: 20355534 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: 2016 Election Cycle\n",
            "Sample 1779: Q: By what year is it expected that consumer sales of cannabidiol will reach around 1.8 billion U.S. dollars? | GT: 2022 | Pred:  Do not make up information. If the information is not in the chart, say \"Information not available in chart\".\n",
            "\n",
            "Year | Sales (in billions USD)\n",
            "---\n",
            "Sample 1780: Q: How many people in Catalonia were vaccinated against influenza in 2017-2018? | GT: 725635 | Pred:  The chart shows the number of people vaccinated against influenza in Catalonia in 2017-2018. The chart has the following data: \n",
            "Sample 1781: Q: How many daily active users did Douyin have in comparison to the period prior to the epidemic? | GT: 81.92 | Pred:  The chart shows the daily active users (in millions) of Douyin from January 2020 to December 2021. The data\n",
            "Sample 1782: Q: How many people were killed in motor vehicle accidents in Luxembourg in 2010? | GT: 32 | Pred:  The chart shows the number of deaths in motor vehicle accidents in Luxembourg from 2000 to 2010.\n",
            "\n",
            "In 2010\n",
            "Sample 1783: Q: How many road fatalities occurred in Luxembourg in 2009? | GT: 48 | Pred:  Do not make up data. If information is not in the chart, say \"Data not available in the chart.\"\n",
            "\n",
            "100000000\n",
            "Sample 1784: Q: How many wins have the New England Patriots had during the postseason? | GT: 37 | Pred:  Each row in the chart represents a team, and each column represents a statistic. The columns are: Team, Postseason Wins, Regular Season Wins, Postseason\n",
            "Sample 1785: Q: What was the value of UK exports to the EU in 2019? | GT: 294.3 | Pred:  The chart shows the value of UK exports to the EU in 2019. The value of UK exports to the EU in 2019\n",
            "Sample 1786: Q: How much British pounds worth of goods and services did the UK export to the EU in 2015? | GT: 225.5 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Cannot be determined\".\n",
            "\n",
            "Chart: {\"data\": [{\"x\": \"2\n",
            "Sample 1787: Q: Which region had the highest number of cases of coronavirus? | GT: Lombardy | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: Which region had the highest number of cases of\n",
            "Sample 1788: Q: How much did adjusted U.S. retail e-commerce sales amount to in the first quarter of 2021? | GT: 215035 | Pred:  The chart is: 2021 Q1 U.S. Retail E-Commerce Sales (in billions of dollars) 2021 Q1\n",
            "Sample 1789: Q: How many TV households were in the Middle East and Africa in 2012? | GT: 65 | Pred:  The chart shows the number of TV households in various regions of the world in 2012. The regions are: North America, South America, Europe\n",
            "Sample 1790: Q: How many metric tons of fresh vegetables did India produce in 2019? | GT: 132.03 | Pred:  Do not make up data. If the data is not available in the chart, say so.\n",
            "\n",
            "There is no chart provided. The data on India's fresh vegetable\n",
            "Sample 1791: Q: What was the benchmark index of commercial rents during the 1st quarter of 2020? | GT: 116.23 | Pred:  The chart has the following columns: Quarter, Benchmark Index, Year-on-Year Change, Month-on-Month Change. The chart has the following rows: Q1\n",
            "Sample 1792: Q: What was the value of imports of synthetic resins and rubbers in Canada in 2019? | GT: 8624 | Pred:  The chart shows the value of imports of synthetic resins and rubbers in Canada from 1990 to 2019.\n",
            "\n",
            "In 2\n",
            "Sample 1793: Q: How much did the real hourly earnings of all employees in the United States decrease in May 2021? | GT: 0.2 | Pred:  The chart shows the real hourly earnings of all employees in the United States from January 2020 to May 2021.\n",
            "\n",
            "According to the\n",
            "Sample 1794: Q: What was the payroll of the Red Sox in 2020? | GT: 95 | Pred:  The chart has the following columns: Team, 2018 Payroll, 2019 Payroll, 2020 Payroll\n",
            "Sample 1795: Q: What was the second most popular newspaper in the UK? | GT: The Times | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". \n",
            "\n",
            "\n",
            "Sample 1796: Q: What was the most popular newspaper in the UK in the fourth quarter of 2020? | GT: Metro | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "The most popular newspaper in the UK in the fourth quarter\n",
            "Sample 1797: Q: What was the second most popular newspaper in the UK? | GT: The Guardian | Pred:  Do not make up information. Do not say \"Based on the chart...\" or \"According to the chart...\". Do not say \"I cannot tell\". \n",
            "\n",
            "\n",
            "Sample 1798: Q: Which country had the largest loss of sales due to counterfeit sporting goods? | GT: France | Pred:  Each row in the chart represents a country and each column represents a different year. The first column is 'Country', and the first row is 'Year'. The\n",
            "Sample 1799: Q: How much did the French sporting goods sector lose in 2015? | GT: 82 | Pred:  The chart is as follows: 2014 2015 2016 2017 2018 \n",
            "Sample 1800: Q: What was the value of private equity investments as of 2016? | GT: 87.23 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "We are not given a chart.\n",
            "Sample 1801: Q: What was the total value of private equity investments in 2007? | GT: 443.81 | Pred:  Do not make up data. Do not say \"Insufficient data\". The chart shows the total value of private equity investments in 2007 was $\n",
            "Sample 1802: Q: What was Brazil's national gross income per person in the previous year? | GT: 9130 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart shows the\n",
            "Sample 1803: Q: What was Brazil's gross income per capita in 2019? | GT: 9130 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\". Brazil's gross income per capita in\n",
            "Sample 1804: Q: How much money did travel and tourism directly contribute to the North East Asian economy in 2017? | GT: 573.7 | Pred:  The chart shows the direct contribution of travel and tourism to the economy of North East Asia in 2017. The values are in billions of USD.\n",
            "Sample 1805: Q: How much money did Snap spend on sales and marketing in 2015? | GT: 555.47 | Pred:  Each row in the chart represents a year, and each column represents a category. The first row is the header row. The first column is the year column.\n",
            "Sample 1806: Q: How many international tourists and non-resident Indians arrived in India in 2019? | GT: 17.91 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "We are not provided with any chart\n",
            "Sample 1807: Q: What percentage of GDP did the national debt of the Philippines amount to in 2020? | GT: 47.07 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "% of GDP\n",
            "Answer: Data\n",
            "Sample 1808: Q: Who is the career passing leader of the Philadelphia Eagles? | GT: Donovan McNabb | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'. Table:\n",
            "| Player | Position | Years | Career Passing Y\n",
            "Sample 1809: Q: How many enterprises made games and toys in the Netherlands in 2017? | GT: 432 | Pred:  The chart shows the number of enterprises in the Netherlands that made games and toys in 2017. The chart has the following data points: 1\n",
            "Sample 1810: Q: How many points does Ronan O'Gara have for the Irish national rugby team? | GT: 93 | Pred:  Each row in the chart represents a player, with columns for name, position, and points. \n",
            "\n",
            "Name: Ronan O'Gara, Position: Fly\n",
            "Sample 1811: Q: Who holds the record for most points scored at the Rugby World Cup? | GT: Ronan O'Gara | Pred:  Chart cells that are blank are empty.\n",
            "\n",
            "Chart:\n",
            "| Player | Country | Points | Games | Tries | Conversions | Penalties | Drop Goals |\n",
            "|\n",
            "Sample 1812: Q: What percentage of the Aosta Valley population had risky alcohol consumption? | GT: 23 | Pred:  The chart shows the percentage of the population with risky alcohol consumption in different regions of Italy. The Aosta Valley is one of the regions listed. The chart indicates\n",
            "Sample 1813: Q: What was the total revenue of Bartlett Tree Experts in 2020? | GT: 352 | Pred:  Do not make up numbers. If a chart is not provided, say \"Chart not provided.\n",
            "\n",
            "Chart not provided.Human: Chart not provided.Human\n",
            "Sample 1814: Q: What was the inflation rate in the Central African Republic in 2020? | GT: 2.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data\n",
            "Sample 1815: Q: What was Deutsche Telekom's revenue in Germany in 2020? | GT: 24.63 | Pred:  The chart shows the revenue of Deutsche Telekom in Germany from 2015 to 2020.\n",
            "\n",
            "According to the chart, Deutsche Telekom\n",
            "Sample 1816: Q: What was the percentage of female managing directors working at Barclays in 2017? | GT: 14 | Pred:  The chart shows the number of female managing directors at Barclays from 2010 to 2017. In 2017, there\n",
            "Sample 1817: Q: What was the production value of the Romanian textile manufacturing sector in 2015? | GT: 1286.2 | Pred:  The chart shows the production value of the Romanian textile manufacturing sector from 2010 to 2015. In 2010,\n",
            "Sample 1818: Q: What was the value of the Nashville Predators in dollars in 2020? | GT: 435 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1819: Q: What percentage of COVID-19 patients died after contracting the virus? | GT: 65.7 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"The chart does not show\". Do not say \"I cannot answer\".\n",
            "Sample 1820: Q: What was the brand value of HSBC in 2015? | GT: 27.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Sure. Please provide the chart or\n",
            "Sample 1821: Q: How many dollars did Callaway Golf spend on research and development in 2020? | GT: 46.3 | Pred:  The chart has the following columns: Year, Revenue, R&D Expenses, Gross Profit, Net Profit. The chart has the following rows: 201\n",
            "Sample 1822: Q: How much was proposed for military crisis management in 2021? | GT: 59 | Pred:  Each row in the chart represents a year, and each column represents a different category. The first row is the header row. The first column is the year column\n",
            "Sample 1823: Q: How much did the Defense Forces pay in 2021? | GT: 815 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"More information is needed\n",
            "Sample 1824: Q: What accounts for the largest part of the 2021 budget? | GT: HX Fighter Program | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The largest part of the 2021 budget is\n",
            "Sample 1825: Q: What was the GDP of Massachusetts in dollars in the previous year? | GT: 519.96 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: {\"data\": [{\"x\": \"\n",
            "Sample 1826: Q: What was the GDP of Massachusetts in 2020? | GT: 500.24 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Chart content: The chart shows the GDP\n",
            "Sample 1827: Q: What was Egypt's birth rate per one thousand inhabitants in 2013? | GT: 28.52 | Pred:  The chart has the following columns: Country, 2013 Birth Rate, 2013 Death Rate, 2013 Natural Increase\n",
            "Sample 1828: Q: What was the crude birth rate in Egypt in 2019? | GT: 25.71 | Pred:  The chart has the following columns: Country, Year, Crude Birth Rate, Crude Death Rate, Natural Increase Rate. The chart has the following rows:\n",
            "Sample 1829: Q: What was Egypt's birth rate per one thousand inhabitants in 2013? | GT: 28.52 | Pred:  The chart has the following columns: Country, 2013 Birth Rate, 2013 Death Rate, 2013 Natural Increase\n",
            "Sample 1830: Q: What was Coca Cola's market share in Egypt in 2010? | GT: 32 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\\n\\nChart content: Coca\n",
            "Sample 1831: Q: How many home runs has Frank Thomas hit? | GT: 448 | Pred:  Each row in the chart represents a different player. Each column in the chart represents a different statistic. The first column is the player's name. The second column\n",
            "Sample 1832: Q: Who has hit the most home runs in Chicago White Sox franchise history? | GT: Frank Thomas | Pred:  Do not make up information. If information is not in the chart, say \"Information not available in chart.\"\n",
            "\n",
            "Chicago White Sox franchise history home run leaders:\n",
            "-\n",
            "Sample 1833: Q: What is the name of the Haitian youtube news channel? | GT: Tele Image Valerio Saint-Louis | Pred:  Do not make up information. If the information is not in the chart, say \"Not in chart\".\n",
            "\n",
            "Answer: Not in chart.Human: What is\n",
            "Sample 1834: Q: What is the name of the comedy channel in Haiti? | GT: Komedyen Lakay Official | Pred:  Do not make up information.\n",
            "\n",
            "Answer: There is no known comedy channel specifically named in the provided chart. Final answer: There is no known comedy channel in Haiti\n",
            "Sample 1835: Q: How many views did Tele Image Valerio Saint-Louis have in Haiti as of March 2021? | GT: 83.02 | Pred:  Chart cells that are blank are empty. All values are in millions.\n",
            "```\n",
            "+----------------+----------------+----------------+----------------+----------------+----------------+----------------+----------------\n",
            "Sample 1836: Q: How many fans did the USA Today profile have on Facebook? | GT: 4824550 | Pred:  Chart cells that are blank are empty. Table cells in one row are seperated by '|', and each row is in one line. Table:\n",
            "|  |\n",
            "Sample 1837: Q: How many dollars did Callaway Golf report in golf club sales in 2020? | GT: 787.1 | Pred:  The chart is as follows: 2019 2020 2021 2022 2023 Golf\n",
            "Sample 1838: Q: What is the estimated amount of eSports sponsorship and advertising spending in the United States in 2023? | GT: 634.03 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Answer: Data not available in chart\n",
            "Sample 1839: Q: What was the estimated amount of sponsorship and advertising spending on the eSports market in 2017? | GT: 124.41 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "2017 Sponsorship and\n",
            "Sample 1840: Q: What was the percentage of energy from renewable sources in Poland from 2006 to 2015? | GT: 6.9 | Pred:  The chart shows the percentage of energy from renewable sources in Poland from 2006 to 2015.\n",
            "\n",
            "2006: 1\n",
            "Sample 1841: Q: What was the market share of Zurich Insurance Group in 2019? | GT: 3.7 | Pred:  The chart shows the market share of the top 10 insurance companies in the world in 2019.\n",
            "\n",
            "According to the chart, the market share\n",
            "Sample 1842: Q: For every male participant, how many females were in the labor force in Bangladesh in 2016? | GT: 0.53 | Pred:  The chart has the following columns: Country, Year, Male, Female. The chart has the following rows: Bangladesh, 2016, 1\n",
            "Sample 1843: Q: What was Zimbabwe's youth unemployment rate in 2020? | GT: 8.07 | Pred:  The chart shows the youth unemployment rate in Zimbabwe from 2015 to 2020. The youth unemployment rate in Zimbabwe in 20\n",
            "Sample 1844: Q: What was Lloyds Banking Group's cost to income ratio in 2019? | GT: 48.5 | Pred:  The chart shows the cost to income ratio for Lloyds Banking Group from 2015 to 2019. The cost to income ratio\n",
            "Sample 1845: Q: How many people lived in Region Nordjylland in 2021? | GT: 589936 | Pred:  The chart shows the population of different regions in Denmark in 2021.\n",
            "Answer: 378,000 people lived in Region Nord\n",
            "Sample 1846: Q: How many people lived in Hovedstaden in the first quarter of 2021? | GT: 1846023 | Pred:  The chart shows the population of Hovedstaden in the first quarter of 2021.\n",
            "\n",
            "The population of Hovedstaden in the first quarter\n",
            "Sample 1847: Q: What was the franchise value of the Denver Broncos in 2020? | GT: 3200 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data\n",
            "Sample 1848: Q: What was the monthly CPI for lamb and goat meat in Italy at the beginning of the year 2015? | GT: 101.7 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Monthly CPI for lamb and goat meat\n",
            "Sample 1849: Q: What was the monthly CPI for lamb and goat meat in November 2020? | GT: 104.5 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Monthly CPI for Lamb and Goat Meat\n",
            "Sample 1850: Q: How much money did the convenience store industry generate from fuel sales in 2011? | GT: 486.9 | Pred:  Chart cells are separated by new lines, columns are separated by tabs. Chart title: Fuel Sales in the Convenience Store Industry in 2011:\n",
            "|\n",
            "Sample 1851: Q: How much did the 2016 Olympic Summer Games licensing revenue amount to? | GT: 31 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1852: Q: What percentage of vote shares did the Conservative Party gain? | GT: 5.5 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "100% of the vote\n",
            "Sample 1853: Q: What percentage of e-commerce visits via tablet devices were converted into purchases in the second quarter of 2020? | GT: 3.32 | Pred:  Chart: Q2 2020 E-commerce Conversion Rates by Device\n",
            "| Device | Conversion Rate |\n",
            "|--------|-----------------|\n",
            "| Desktop | \n",
            "Sample 1854: Q: How many stores did Dillard's operate in 2020? | GT: 282 | Pred:  Each row in the chart represents a year. The first column is the year. The second column is the number of stores. 2010: \n",
            "Sample 1855: Q: What was Five Below's net sales per store a year earlier? | GT: 2.2 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"Not enough information\". Do\n",
            "Sample 1856: Q: What country had the largest Snapchat user base in the world? | GT: India | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the largest Snapchat user base is...\". Do\n",
            "Sample 1857: Q: How many users did Snapchat have in the United States as of April 2021? | GT: 108.65 | Pred:  Do not make up data. If the data is not in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Number of Snapchat Users in the United States (\n",
            "Sample 1858: Q: What percentage of white respondents said they see the Confederate flag as a symbol of racism? | GT: 25 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. The chart shows the percentage of white respondents who said they\n",
            "Sample 1859: Q: What was Kuwait's infant mortality rate per 1,000 live births in 2019? | GT: 6.8 | Pred:  The chart has the following columns: Country, Year, Infant Mortality Rate (per 1,000 live births), Life Expectancy at Birth (\n",
            "Sample 1860: Q: How many people committed suicide by throwing themselves in front of a train in 2006? | GT: 24 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Thought: The question is\n",
            "Sample 1861: Q: How many dollars did Foot Locker generate in the United States in 2020? | GT: 5581 | Pred:  Each row in the chart represents a year. Each column in the chart represents a country. The values in the cells are the revenue in millions of dollars. The\n",
            "Sample 1862: Q: What percentage of the gross domestic product did Mexico spend in 2020? | GT: 29.12 | Pred:  Do not make up data. Do not say \"The chart does not show\". Do not say \"I don't know\". Do not say \"Insufficient data\n",
            "Sample 1863: Q: What was the lowest production of duck foie gras in 2017? | GT: 11519 | Pred:  Avoid making up data or inferences. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year | Duck\n",
            "Sample 1864: Q: How many ducks were euthanized due to the H5N8 virus? | GT: 11519 | Pred:  Each row in the chart represents a different country. The columns are: Country, Number of birds affected, Number of birds died, Number of birds euthanized\n",
            "Sample 1865: Q: What was the average amount of duck foie gras produced in France between 2007 and 2015? | GT: 18602 | Pred:  The chart shows the average amount of duck foie gras produced in France between 2007 and 2015. The average amount of duck\n",
            "Sample 1866: Q: How much money did Etsy invest in its advertising in 2016? | GT: 442.2 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1867: Q: What was the most frequently used social network in Canada? | GT: Instagram | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The most frequently used social network in Canada is...\". The\n",
            "Sample 1868: Q: What was the most frequently used social network in Canada? | GT: Facebook | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The most frequently used social network in Canada is...\". The\n",
            "Sample 1869: Q: How much did Alphabet spend on lobbying in 2020? | GT: 8.85 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "We are given a question about Alphabet's lobbying\n",
            "Sample 1870: Q: How much did J.K. Rowling earn from June 2018 to June 2019? | GT: 92 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Name | 20\n",
            "Sample 1871: Q: What was Vodafone Germany's EBITDA in 2020/21? | GT: 5.63 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Vodafone Germany's EBITDA\n",
            "Sample 1872: Q: What was the previous year's EBITDA? | GT: 5.08 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: \n",
            "| Year | Revenue | E\n",
            "Sample 1873: Q: What percentage of Google's revenue was generated in the UK in 2015? | GT: 10 | Pred:  Do not make up data. Do not say \"The chart does not show\". The chart shows the revenue distribution of Google across different countries in 201\n",
            "Sample 1874: Q: Which country has the most markets? | GT: France | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"The country with the most markets is...\". The country with\n",
            "Sample 1875: Q: What was the highest salary in the cruise industry in 2019? | GT: 9.93 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Thought: The chart does not contain\n",
            "Sample 1876: Q: How much did the cruise industry pay in employee wages in 2009? | GT: 5.48 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "Available data: 2009\n",
            "Sample 1877: Q: How much was the expenses of the Green Bay Packers in 2017? | GT: 376.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available\".\n",
            "\n",
            "Chart: None\n",
            "Answer: Data not available\n",
            "Sample 1878: Q: What percentage of all legal abortions in Alabama were performed on Hispanic women in 2018? | GT: 5.1 | Pred:  Avoid making up data or inferences. If the data is not available in the chart, respond with 'Data not available in chart'.\n",
            "\n",
            "% of all legal abortions\n",
            "Sample 1879: Q: What was the import trade value of bamboo and rattan furniture in the United States in 2015? | GT: 21.07 | Pred:  The chart is as follows: \\begin{table}[h] \\begin{tabular}{|c|c|c|c|c|c|\n",
            "Sample 1880: Q: What was the import trade value of bamboo and rattan furniture between 2015 and 2016? | GT: 18.7 | Pred:  The chart shows the import trade value of bamboo and rattan furniture between 2015 and 2016. In 2015\n",
            "Sample 1881: Q: How much did the import trade value of bamboo and rattan furniture increase between 2011 and 2016? | GT: 21.07 | Pred:  The chart shows the import trade value of bamboo and rattan furniture in China from 2011 to 2016. The values are in\n",
            "Sample 1882: Q: What was the revenue from video analytics in 2015? | GT: 858 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I can't answer that\". Do not say \"Not enough information\".\n",
            "Sample 1883: Q: What religion were about 116,000 Canadian citizens, permanent and non-permanent residents of Prince Edward Island identified as in 2011? | GT: Christian | Pred:  Do not make up data. Do not say \"Based on the chart...\". Do not say \"According to the chart...\". Do not say \"The data\n",
            "Sample 1884: Q: When did the value of gross written premiums by life insurance companies on the domestic market in Malta increase? | GT: 2012 | Pred:  Do not make up data or statistics. If the information is not available in the chart, respond with \"Insufficient data in chart to answer the question.\"\n",
            "\n",
            "?\n",
            "Sample 1885: Q: What was the peak value of gross written premiums in Malta in 2018? | GT: 415 | Pred:  The chart shows the following data: In 2018, the peak value of gross written premiums in Malta was 100 million euros.\n",
            "\n",
            "1\n",
            "Sample 1886: Q: What was the value of life insurance premiums in 2019? | GT: 378 | Pred:  Do not make up data. If the data is not available in the chart, say \"Data not available in chart\".\n",
            "\n",
            "?  \n",
            "?  \n",
            "?  \n",
            "?  \n",
            "\n",
            "Sample 1887: Q: How many UCI beds were there in Mexico City in April of 2020? | GT: 453 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Number of UCI beds in Mexico\n",
            "Sample 1888: Q: How many adult intensive care units were in Mexico City in April 2020? | GT: 891 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Number of adult intensive care units in\n",
            "Sample 1889: Q: Which social media site accounted for 57.52 percent of all social media site visits in Canada in May 2021? | GT: Facebook | Pred:  The chart shows the percentage of social media site visits in Canada in May 2021. Facebook accounted for 57.52 percent of all\n",
            "Sample 1890: Q: Who is the career touchdown leader of the Atlanta Falcons? | GT: Roddy White | Pred:  Each row in the chart represents a player. The columns are: Name, Position, Games, Touchdowns, Receptions, Yards, and Yards\n",
            "Sample 1891: Q: How many career touchdowns has Roddy White scored? | GT: 63 | Pred:  Each row in the chart represents a different player. The first column is the player's name. The second column is the player's position. The third column is\n",
            "Sample 1892: Q: What percentage of Rio 2016 viewers were women? | GT: 22 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "% of Rio 201\n",
            "Sample 1893: Q: What percentage of India's GDP did military expenditure amount to in 2019? | GT: 2.4 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1894: Q: What was Ethiopia's share in the global gross domestic product adjusted for Purchasing Power Parity in 2020? | GT: 0.22 | Pred:  The chart shows the following data: Ethiopia's share in the global gross domestic product adjusted for Purchasing Power Parity in 2020 was 0\n",
            "Sample 1895: Q: How much revenue did A.P. M ller - Maersk A/S generate from its ocean segment in 2020? | GT: 29.18 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "We are not given a chart.\n",
            "Sample 1896: Q: How much money did pirates receive in ransom for the release of the oil tanker Savina Caylyn? | GT: 11.5 | Pred:  Table cells in one row are seperated by '|', and different rows are seperated by '\n",
            "'.\n",
            "\n",
            "Table:\n",
            "| Date | Location | Event | Amount |\n",
            "|\n",
            "Sample 1897: Q: Which beer brand topped the beer production volume in Germany in 2016? | GT: Krombacher | Pred:  Each chart has a title, x-axis, y-axis, and data. The data is given as a list of lists, where each inner list represents a row\n",
            "Sample 1898: Q: How much did Manchester United's operating expenses in 2020 amount to? | GT: 645.88 | Pred:  Do not make up data or statistics. If the data is not available in the chart, respond with 'Data not available'.\n",
            "\n",
            "Thought: The chart does not contain\n",
            "Sample 1899: Q: What percentage of the Dominican Republic's GDP would be lost as a result of the COVID-19 pandemic? | GT: 0.8 | Pred:  The chart shows the following data: \n",
            "\n",
            "| Country | GDP Loss (%) |\n",
            "|---------|--------------|\n",
            "| Argentina | 12.5 |\n",
            "| Brazil |\n",
            "Sample 1900: Q: What percentage of the Dominican Republic's GDP would be affected by the COVID-19 pandemic? | GT: 6.1 | Pred:  Do not make up data. Do not say things like 'Based on the chart' or 'As shown in the chart'. Do not say things like 'The\n",
            "Sample 1901: Q: What percentage of Netflix subscribers said they would keep the service if the monthly price increased by five dollars per month? | GT: 53 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"I don't know\".\n",
            "Sample 1902: Q: Which candidate received the most donations from the oil and gas industry? | GT: Hillary Clinton | Pred:  Each row in the chart represents a candidate. Each column represents a different industry. The values in the cells represent the amount of money (in thousands of dollars)\n",
            "Sample 1903: Q: When is the forecasted year with the highest consumption volume? | GT: 2020 | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question. Question: When is the forecasted year with the highest\n",
            "Sample 1904: Q: What is the average annual consumption of biodiesel in OECD countries? | GT: 21759.24 | Pred:  The chart shows the average annual consumption of biodiesel in OECD countries in million tonnes. The values are: France: 1.2, Germany: 1\n",
            "Sample 1905: Q: In what year did the turnover of the retail sale of leisure products increase to 6.7 billion British pounds? | GT: 2017 | Pred:  The chart shows the turnover of the retail sale of leisure products in the UK from 1990 to 2000.\n",
            "\n",
            "1990\n",
            "Sample 1906: Q: What percentage of 17 year olds attended school? | GT: 93.3 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "17 year olds: 9\n",
            "Sample 1907: Q: What percentage of 14 year olds were schooled in 2017-2018? | GT: 98.8 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "We are given a question about the\n",
            "Sample 1908: Q: What was Sweden's per capita gross domestic product in kronor in 2019? | GT: 488 | Pred:  The chart has the following columns: Country, Year, GDP (in USD), GDP per capita (in USD), GDP (in EUR), GDP per capita (\n",
            "Sample 1909: Q: What was the value of the gross domestic product in Sweden in kronor in 2019? | GT: 488 | Pred:  Do not make up data. If the chart does not contain the information, respond with \"Data not available\".\\n\\nChart content: None\n",
            "\\n\\n\n",
            "Sample 1910: Q: In what year did the per capita gross domestic product reach its highest value? | GT: 2019 | Pred:  Do not make up data or statistics. If the chart does not contain the necessary information, respond with \"Cannot be determined\". The chart shows the per capita gross\n",
            "Sample 1911: Q: What was the population of Eswatini in 2017? | GT: 1.1 | Pred:  Do not make up data. If the data is not available in the chart, respond with \"Data not available in chart\".\n",
            "\n",
            "Population of Eswatini (\n",
            "Sample 1912: Q: What was the inflation rate in Suriname in 2019? | GT: 4.39 | Pred:  The chart shows the inflation rate in Suriname from 2015 to 2020.\n",
            "\n",
            "In 2019, the inflation rate\n",
            "Sample 1913: Q: What was the share of consumers who wrote checks in 2018? | GT: 31 | Pred:  Do not make up data. Do not say \"Insufficient data\". Do not say \"I cannot answer that\". Do not say \"The chart does not show\n",
            "Sample 1914: Q: How many specialised stores were there in the UK in March of 2020? | GT: 15 | Pred:  The chart shows the number of specialised stores in the UK from 2010 to 2020.\n",
            "\n",
            "In March 2020,\n",
            "Sample 1915: Q: Which country is the most active in CAR cell therapy trials? | GT: China | Pred:  Each row in the chart represents a country, and each column represents a type of therapy. The columns are: CAR T-cell therapy, CAR NK-cell therapy,\n",
            "Sample 1916: Q: What was the most valuable British-Dutch oil and gas company in 2021? | GT: Shell | Pred:  Do not make up data. Do not say \"Based on the chart...\". Just answer the question.\n",
            "\n",
            "The most valuable British-Dutch oil and gas company in\n",
            "Sample 1917: Q: What was the only brand in the top ten with headquarters outside of the UK? | GT: Shell | Pred:  The chart shows the top 10 brands by market capitalization in the UK as of 2023. The brands and their headquarters are: \n",
            "Sample 1918: Q: What was the second most valuable oil and gas company in the UK in 2021? | GT: BP | Pred:  Do not make up data. Do not say \"Based on the chart...\". The chart shows the market capitalization of the top 5 oil and gas companies\n",
            "Sample 1919: Q: Where did migrants arrive from January to December 2018? | GT: Pozzallo | Pred:  Do not make up data. Do not say \"The chart shows\". Do not say \"Based on the chart\". Do not say \"According to the chart\".\n",
            "Sample 1920: Q: Which country ranked second in the Italian migration chart? | GT: Lampedusa | Pred:  Do not make up information. Do not say \"Based on the chart...\". Just give the final answer.\n",
            "\n",
            "France\n",
            "Germany\n",
            "United Kingdom\n",
            "Spain\n",
            "Italy\n",
            "\n",
            "==============================\n",
            "CLIP → Qwen PROJECTION RESULTS\n",
            "==============================\n",
            "Total samples: 1920\n",
            "Exact Accuracy: 0.0000\n",
            "Relaxed Accuracy: 0.0354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5KDa_v5OYgcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TwCcO55sYgVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, CLIPProcessor, CLIPModel\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# CLIP model\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "c0d73325ab804e14bcbf3127a522f9bb",
            "0eb0886e04564b68a534d951100663f6",
            "ed93d9a6ace845c6bb8f5ca420777d38",
            "f799693a715e461a8c6f7054eaeb3490",
            "be46c2cbebe84a8f86f0c1a639483bf4",
            "912bf3de54f8402a95c7c808deadec74",
            "04fe89967a614e10a6e87404a4b76aab",
            "e22ec2e3b3084d40b74f22a71a4a7d71",
            "6d68d224b2b343faae1667a392c62fbf",
            "2e7fed93a15240c390679a5f3de3ee62",
            "edee28f67a8442cabcb75be4091b21b2"
          ]
        },
        "id": "pzc6Ez-AO8cm",
        "outputId": "213b1982-d4f3-463d-cbc4-0b78395b2896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0d73325ab804e14bcbf3127a522f9bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CLIPModel LOAD REPORT from: openai/clip-vit-base-patch32\n",
            "Key                                  | Status     |  | \n",
            "-------------------------------------+------------+--+-\n",
            "vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
            "text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Qwen model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B-Instruct-2507\")\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-4B-Instruct-2507\").to(device)\n",
        "\n",
        "# Qwen\n",
        "qwen_model.eval().to(device)\n",
        "for p in qwen_model.parameters():\n",
        "    p.requires_grad = False  # freeze Qwen\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7cb919c00caa470a8b1038a5128eba4f",
            "82193e8d7fa141558b5476d74ebc4445",
            "280e230519cd4604be0ea4c37d703c7e",
            "646bf18c09e94602a1ba5f978b31002e",
            "80b005b21d864324ad3cc4a17b8ec4a2",
            "ec0a42d4cbf14bb5a348120ee33a1a09",
            "fa8a5f8d70ff4482a0a0c2b53c8f84d0",
            "33f9a713a4f64f28ac88bc0f0b963f65",
            "f7c4bfe279a54302abfad72e8bb6884b",
            "8e8effdcf4234fafb95e2f073cc497d3",
            "c914f625900f4ab0b8a98de537cdedda"
          ]
        },
        "id": "PRi_MOE1O8aS",
        "outputId": "453ab62c-8f2e-4ef7-e49b-598f6db398d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cb919c00caa470a8b1038a5128eba4f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "clip_dim = 768      # CLIP-ViT-B/32 image embedding size\n",
        "qwen_dim = 2560     # Qwen3B/4B input embedding size\n",
        "projection = nn.Linear(clip_dim, qwen_dim).to(device)"
      ],
      "metadata": {
        "id": "h3tr4H4gdijM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "optimizer = optim.Adam(projection.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n"
      ],
      "metadata": {
        "id": "I3oE0m5CefW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_clip_embedding(img):\n",
        "    \"\"\"Get CLIP embedding for a single PIL image\"\"\"\n",
        "    inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        # This returns a BaseModelOutputWithPooling sometimes\n",
        "        output = clip_model.get_image_features(**inputs)\n",
        "\n",
        "        # Convert to a tensor if it's not already\n",
        "        if hasattr(output, \"last_hidden_state\"):  # old CLIP versions\n",
        "            img_emb = output.last_hidden_state[:, 0, :]\n",
        "        elif isinstance(output, (tuple, list)):\n",
        "            img_emb = output[0]\n",
        "        else:\n",
        "            img_emb = output  # should already be a tensor\n",
        "\n",
        "        # Make sure it's float32 on the right device\n",
        "        img_emb = img_emb.float().to(device)\n",
        "\n",
        "    return img_emb  # [1, clip_dim]\n",
        "\n",
        "\n",
        "\n",
        "def generate_answer_from_clip(img_emb, question):\n",
        "    \"\"\"Project image embedding, prepend to question, and generate answer\"\"\"\n",
        "    # Project image embedding\n",
        "    projected_emb = projection(img_emb)  # [1, qwen_hidden_dim]\n",
        "\n",
        "    # Build prompt with question\n",
        "    prompt = f\"Question: {question}\\nAnswer:\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Tokenize prompt\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        padding=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Prepend projected image embedding to input embeddings\n",
        "    qwen_inputs = qwen_model.get_input_embeddings()(inputs[\"input_ids\"])\n",
        "    projected_emb = projected_emb.to(qwen_inputs.dtype)\n",
        "    combined_emb = torch.cat([projected_emb.unsqueeze(1), qwen_inputs], dim=1)\n",
        "\n",
        "    # Generate\n",
        "    with torch.no_grad():\n",
        "        outputs = qwen_model.generate(\n",
        "            inputs_embeds=combined_emb,\n",
        "            max_new_tokens=60,\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0][combined_emb.shape[1]:], skip_special_tokens=True)\n",
        "    return answer.strip()\n",
        "\n",
        "def normalize_text(text):\n",
        "    return text.lower().strip()\n",
        "\n",
        "def relaxed_numeric_match(pred, gt):\n",
        "    try:\n",
        "        pred_val = float(pred)\n",
        "        gt_val = float(gt)\n",
        "        return abs(pred_val - gt_val) / max(1.0, abs(gt_val)) <= 0.05\n",
        "    except:\n",
        "        return False"
      ],
      "metadata": {
        "id": "HxOT5k3bZeEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_list = [dict(ex) for ex in ds[\"val\"].select(range(50))]\n",
        "results = []\n",
        "exact_correct = 0\n",
        "relaxed_correct = 0\n",
        "total = 0\n",
        "\n",
        "for ex in tqdm(split_list):\n",
        "    img = ex[\"image\"]\n",
        "    question = ex[\"query\"]\n",
        "    gt_list = ex[\"label\"]\n",
        "\n",
        "    pred = generate_answer_from_clip(extract_clip_embedding(img), question)\n",
        "    pred_norm = normalize_text(pred)\n",
        "\n",
        "    exact = False\n",
        "    relaxed = False\n",
        "    for gt in gt_list:\n",
        "        gt_norm = normalize_text(str(gt))\n",
        "        if pred_norm == gt_norm:\n",
        "            exact = True\n",
        "            relaxed = True\n",
        "            break\n",
        "        if relaxed_numeric_match(pred_norm, gt_norm):\n",
        "            relaxed = True\n",
        "\n",
        "    if exact:\n",
        "        exact_correct += 1\n",
        "    if relaxed:\n",
        "        relaxed_correct += 1\n",
        "    total += 1\n",
        "\n",
        "    results.append({\n",
        "        \"question\": question,\n",
        "        \"ground_truth\": gt_list,\n",
        "        \"prediction\": pred,\n",
        "        \"exact_match\": exact,\n",
        "        \"relaxed_match\": relaxed\n",
        "    })\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Metrics\n",
        "# ------------------------------\n",
        "exact_acc = exact_correct / total\n",
        "relaxed_acc = relaxed_correct / total\n",
        "print(\"\\n==============================\")\n",
        "print(\"SIMPLE CLIP-TO-QWEN BASELINE RESULTS\")\n",
        "print(\"==============================\")\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact Accuracy: {exact_acc:.4f}\")\n",
        "print(f\"Relaxed Accuracy (±5%): {relaxed_acc:.4f}\")\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"chartqa_clip_qwen_results_50.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "-N6414g-Zlqa",
        "outputId": "60066d1c-0722-4a91-ec61-f80f57ae5b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 6/50 [00:05<00:39,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3744837376.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgt_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_answer_from_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_clip_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpred_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2773402715.py\u001b[0m in \u001b[0;36mgenerate_answer_from_clip\u001b[0;34m(img_emb, question)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         outputs = qwen_model.generate(\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_emb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2669\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2670\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2872\u001b[0m                 \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2873\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_model_for_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2874\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2875\u001b[0m             \u001b[0mprefill_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2876\u001b[0m             model_kwargs = self._update_model_kwargs_for_generation(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 505\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    506\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "clip_dim = 512      # CLIP-ViT-B/32 image embedding size\n",
        "qwen_dim = 2560     # Qwen3B/4B input embedding size\n",
        "proj_tokens = 4  # number of \"virtual tokens\" projected from CLIP\n",
        "projection = nn.Sequential(\n",
        "    nn.Linear(clip_dim, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, qwen_dim)\n",
        ").to(device)\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "optimizer = optim.Adam(projection.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "def extract_clip_embedding(img):\n",
        "    \"\"\"Get CLIP embedding for a single PIL image\"\"\"\n",
        "    inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        output = clip_model.get_image_features(**inputs)\n",
        "        # Handle BaseModelOutputWithPooling\n",
        "        if hasattr(output, \"pooler_output\"):\n",
        "            img_emb = output.pooler_output\n",
        "        elif hasattr(output, \"last_hidden_state\"):\n",
        "            img_emb = output.last_hidden_state[:, 0, :]\n",
        "        elif isinstance(output, (tuple, list)):\n",
        "            img_emb = output[0]\n",
        "        else:\n",
        "            img_emb = output  # already tensor\n",
        "\n",
        "        img_emb = img_emb.float().to(device)\n",
        "\n",
        "    return img_emb  # [1, clip_dim]\n",
        "\n",
        "\n",
        "\n",
        "def prepare_inputs_for_training(img_emb, question):\n",
        "    projected_emb = projection(img_emb)  # [1, qwen_dim]\n",
        "\n",
        "    prompt = f\"Question: {question}\\nAnswer:\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        padding=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    qwen_inputs = qwen_model.get_input_embeddings()(inputs[\"input_ids\"])\n",
        "    projected_emb = projected_emb.to(qwen_inputs.dtype)\n",
        "    combined_emb = torch.cat([projected_emb.unsqueeze(1), qwen_inputs], dim=1)\n",
        "\n",
        "    # Prepend padding token for labels to match new seq_len\n",
        "    pad_label = torch.full((inputs[\"input_ids\"].shape[0], 1),\n",
        "                           -100,\n",
        "                           #tokenizer.pad_token_id,\n",
        "                           device=inputs[\"input_ids\"].device,\n",
        "                           dtype=inputs[\"input_ids\"].dtype)\n",
        "    labels = torch.cat([pad_label, inputs[\"input_ids\"]], dim=1)\n",
        "\n",
        "    return combined_emb, labels\n",
        "\n",
        "\n",
        "\n",
        "def generate_answer_from_clip(img_emb, question, max_new_tokens=60):\n",
        "    \"\"\"Inference: generate answer from image + question\"\"\"\n",
        "    projected_emb = projection(img_emb)\n",
        "    prompt = f\"Question: {question}\\nAnswer:\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=True,\n",
        "        padding=True,\n",
        "        return_dict=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    qwen_inputs = qwen_model.get_input_embeddings()(inputs[\"input_ids\"])\n",
        "    projected_emb = projected_emb.to(qwen_inputs.dtype)\n",
        "    combined_emb = torch.cat([projected_emb.unsqueeze(1), qwen_inputs], dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = qwen_model.generate(\n",
        "            inputs_embeds=combined_emb,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            num_beams=3,      # beam search\n",
        "            do_sample=True,\n",
        "        )\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0][combined_emb.shape[1]:], skip_special_tokens=True)\n",
        "    return answer.strip()\n",
        "\n",
        "\n",
        "\n",
        "def relaxed_numeric_match(pred, gt):\n",
        "    try:\n",
        "        pred_val = float(pred)\n",
        "        gt_val = float(gt)\n",
        "        return abs(pred_val - gt_val) / max(1.0, abs(gt_val)) <= 0.05\n",
        "    except:\n",
        "        return False"
      ],
      "metadata": {
        "id": "lxe0UNS8oW0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_list = [dict(ex) for ex in ds[\"val\"].select(range(50))]\n",
        "epochs = 5\n",
        "batch_size = 4\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    for i in tqdm(range(0, len(split_list), batch_size)):\n",
        "        batch = split_list[i:i+batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss = 0.0\n",
        "\n",
        "        for ex in batch:\n",
        "            img = ex[\"image\"]\n",
        "            question = ex[\"query\"]\n",
        "            combined_emb, input_ids = prepare_inputs_for_training(extract_clip_embedding(img), question)\n",
        "\n",
        "            outputs = qwen_model(inputs_embeds=combined_emb, labels=input_ids)\n",
        "            loss = outputs.loss\n",
        "            batch_loss += loss\n",
        "\n",
        "        batch_loss = batch_loss / len(batch)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += batch_loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(split_list):.4f}\")\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# 4️⃣ Evaluation\n",
        "# ------------------------------\n",
        "results = []\n",
        "exact_correct = 0\n",
        "relaxed_correct = 0\n",
        "total = 0\n",
        "\n",
        "for ex in tqdm(split_list):\n",
        "    img = ex[\"image\"]\n",
        "    question = ex[\"query\"]\n",
        "    gt_list = ex[\"label\"]\n",
        "\n",
        "    pred = generate_answer_from_clip(extract_clip_embedding(img), question)\n",
        "    pred_norm = pred.lower().strip()\n",
        "\n",
        "    exact = False\n",
        "    relaxed = False\n",
        "    for gt in gt_list:\n",
        "        gt_norm = str(gt).lower().strip()\n",
        "        if pred_norm == gt_norm:\n",
        "            exact = True\n",
        "            relaxed = True\n",
        "            break\n",
        "        if relaxed_numeric_match(pred_norm, gt_norm):\n",
        "            relaxed = True\n",
        "\n",
        "    if exact: exact_correct += 1\n",
        "    if relaxed: relaxed_correct += 1\n",
        "    total += 1\n",
        "\n",
        "    results.append({\n",
        "        \"question\": question,\n",
        "        \"ground_truth\": gt_list,\n",
        "        \"prediction\": pred,\n",
        "        \"exact_match\": exact,\n",
        "        \"relaxed_match\": relaxed\n",
        "    })\n",
        "\n",
        "exact_acc = exact_correct / total\n",
        "relaxed_acc = relaxed_correct / total\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"TRAINED CLIP-TO-QWEN RESULTS\")\n",
        "print(\"==============================\")\n",
        "print(f\"Total samples: {total}\")\n",
        "print(f\"Exact Accuracy: {exact_acc:.4f}\")\n",
        "print(f\"Relaxed Accuracy (±5%): {relaxed_acc:.4f}\")\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"chartqa_clip_qwen_trained_results_50.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDuL3BOnZovi",
        "outputId": "6d1517d6-6932-4f15-94e0-76874738fb7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:02<00:00,  5.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 1.2546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:02<00:00,  5.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5, Loss: 1.1980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:02<00:00,  5.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5, Loss: 1.1238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:02<00:00,  5.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5, Loss: 1.0532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:02<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5, Loss: 0.9752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:45<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "TRAINED CLIP-TO-QWEN RESULTS\n",
            "==============================\n",
            "Total samples: 50\n",
            "Exact Accuracy: 0.0000\n",
            "Relaxed Accuracy (±5%): 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymLuAKOLeno8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}